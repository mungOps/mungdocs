[{"id":0,"href":"/cloud/docs/AWS/AWSSAA/SAA-1/","title":"1장 AWS의 핵심 서비스","section":"AWS SAA 시험정리","content":"\rSAA 요약정리\r#\r정리를 들어가기 전 핵심요소\r#\r자격 시험의 합격과 실패는 현장에서의 실무 경험과 실습 중심의 학습, 시험에 필요한 세부적인 정보와 숫자를 얼마나 잘 기억하는지에 달려 있다. AWS SAA는 핵심 AWS 서비스 구성 요소와 운영은 물론 서비스 간의 상호작용 방식도 이해가 필요 기본적인 공부는 Amazon의 공식문서 및 여러 실습 경험을 필요로 한다. #\rAWS SAA 참고자료 #\r시험영역 출제 비율 1. 복원력을 갖춘 아키텍처 설계 34% 1-1. 안정적이고, 복원력을 갖춘 스토리지를 선택한다. 1-2. 어떻게 AWS 서비스를 사용해 결합 해제 매커니즘을 설계할지 결정한다. 1-3. 어떻게 멀티 티어 아키텍처 솔루션을 설계할지 결정한다. 1-4. 어떻게 고가용성 및/ 또는 내결함성을 갖춘 아키텍처를 설계할지를 결정한다. 2. 성능이 뛰어난 아키텍처 정의 24% 2-1. 성능이 뛰어난 스토리지 및 데이터베이스르 선택한다. 2-2. 캐싱을 적용해 성능을 개선한다. 2-3. 탄력성과 확장성을 갖춘 솔루션을 설계한다. 3. 안전한 애플리케이션 및 아키텍처 설명 26% 3-1. 어떻게 애플리케이션 티어를 보호할지 결장한다. 3-2. 어떻게 데이터를 보호할지 결정한다. 3-3. 단일 VPC 애플리케이션을 위한 네트워킹 인프라를 정의한다. 4. 비용에 최적화된 아키텍처 설계 10% 4-1. 어떻게 비용에 최적화된 스토리지를 설계할지 결정한다. 4-2. 어떻게 비용에 최적화된 컴퓨팅을 설계할지 결정한다. 5. 운영 면에서 탁월한 아키텍처 정의 6% 5.1 솔루션에서 운영 우수성을 지원할 수 있는 기능을 선택한다. #\r#\r1장 AWS의 핵심 서비스\r#\r#\r1장의 핵심내용 AWS 플랫폼 아키텍처와 그 기반 기술을 이해한다. AWS 관리 도구의 종류화 사용법을 이해한다. 지원 플랜의 종류와, 선택하는 방법을 이해한다. #\r#\r클라우드 컴퓨팅과 가상화\r#\r#\r모든 클라우드 운영 기술의 토대는 가상화라고 할 수 있다. 가상화란 단일 물리 서버를 하드웨어 리소스를 더 작은 단위로 나눌 수 있고, 물리 서버는 가상 머신 여러 개를 호스트할 수 있개 해주는 기술이다. 이러한 가상화의 장점은 가상 서버를 짧은 시간만에 프로비저닝해서 프로젝트에 필요한 시간만 정확하게 실행하고, 언제든지 종료해서 사용하던 리소스를 다른 워크로드에 즉시 활용할 수 있다. 클라우드 환경의 키워드는 확장성과 탄력성 #\r#\r확장성과 탄력성\r#\r#\r키워드 설명 확장성 예기치 않은 수요가 발생하더라도 자동적으로 리소스츨 추가해서 효과적으로 대응할 수 있음 AWS 에서는 수요에 능동적으로 대처할 수 있게 설게 된 Auto Scaling 서비스를 사용해서 머신 이미지를 신속히 복제 및사용 탄력성 수요를 관리한다는 목적에서는 학장성과 동일한 못적을 자기고 있지만, 탄력성은 수요가 떨어질 때 용량을 자동으로 줄이는 개념 #\r#\rAWS 서비스의 범주\r#\r#\rAWS 서비스의 서비스는 매우 다향하며, 현재도 그 범위가 확장되어가고 있다. #\r#\r범주 기능 컴퓨팅 데이터 센터에서 물리 서버가 하는 역할을 복제한 클라우드 서비스 Auto Scaling, 로드 밸런싱, 서버리스 아키텍처에 이르는 고급 기능을 제공 네트워크 애플케이션 연결, 엑세스 제어, 향상된 원격 연결 스토리지 빠른 액세스와 장기적인 백업 요구에 모두 적합하게 설계된 여러 종류의 스토리지 플랫폼 데이터 베이스 관계형, NoSQL, 캐싱 등 데이터 형식이 필요한 사용 사레에 사용할 수 있는 관리형 데이터 솔루션 애플리케이션관 관리 AWS 계정 서비스와 운영 리소스 모니터링, 감사, 구성 보안과 자격 증명 인증 및 권한 부여, 데이터 및 연결 암호화, 타사 인증 관리 시스템과 통합 등을 관리하는 서비스 애플리케이션 통합 결합 해제, API를 사용한 애플리케이션 개발 프로세스를 설계하기 위한 도구 #\r#\rAWS 핵심 서비스 #\r범주 서비스 기능 Computing EC2 AWS 상의 가상화된 인스턴스 Lambda 서버리스 애플리케이션 Auto Scaling 자동으로 인스턴스를 확장, 축소시키는 서비스 Elastic Load Balancing 네트워크의 트래픽을 분산시켜주는 라우팅 서비스 Elastic Beanstalk 컴퓨팅과 네트워킹 인프라를 프로비저닝하는 작업을 추상화한 관리형 서비스 Networking VPC 사용자 개인의 프라이빗 네트워크를 생성하는 서비스 Direct Connect AWS 서비스의 전용선을 통해 직접 연결하는 서비스 Router 53 AWS의 DNS서비스로 도메인 등록, 레코드 관리, 라우팅 프로토콜, 상태검사 등의 서비스를 제공 CloudFront AWS에서 제공하는 분산 글로벌 콘텐츠 전송 네트워크 ( CDN ) Storage S3 저렴하고 안정적인 다목적 객체 스토리지 서비스 Glacier 저렴하고 장기 저장할 수 있는 대형 데이터 아카이브를 제공하는 서비스 EBS EC2와 OS의 작업 데이터를 호스팅하는 가상의 데이터 드라이브 서비스 Storage Gateway AWS 클라우드 스토리지를 로컬 온프레미스 어플라이언스처럼 사용하는 하이브리드 스토리지 시스템 Database RDS 관리형 데이터베이스 인스턴스로 Mysql, Oracle, Aurora 등의 다양한 엔진을 제공 DynamoDB 빠르고 유연하며, 확장성이 뛰어난 관리현 서비스로 비관계형 (NoSQL) 데이터 베이스 워크로드에 적합 Application management CloudWatch 이벤트를 통해 프로세스 성능 및 활용률을 모니터링 하는 서비스 CloudFormation 탬플릿을 사용하여 AWS 리소스에 대한 사용을 스크립트화 시켜 사용하는 서비스 CloudTrail 계정내 모든 API 이벤트 기록을 수집하는 서비스 Config AWS 계정에서 변경 관리와 규정 준수를 지원하도록 설계된 서비스 Security, identification IAM AWS 계정의 사용자를 역할을 통해 관리하는 서비스 KMS AWS 리소스의 데이터를 보호하는 암호화 키를 생성하고 키사용을 관리하는 관리형 서비스 Directory Service AWS에서 자격 증면이나 관계를 정리할 때, Cognito, Microsoft AD도메인과 같은 자격 증명 공급자와 통합시키는 역할을 수행 Application Intergrated SNS 자동으로 주제에 관한 알림을 다른 서비스로 보내는 알림 서비스 SWF 수행해야하는 일련의작업을 조정하는 서비스로, 윤활유나 접착제의 역할을 수행 SQS 분산 시스템 내에서 이벤트 중심 메시징으로 결합을 해제해서 대형 프로세스의 개별 단계를 조정하는 서비스 APT Gateway Application 구현에 필요한 API를 생성 및 관리하는 서비스 #\r#\rAWS 플랫폼 아키텍처\r#\r#\rAWS는 짧은 지연 시간 엑세스를 보장하는 것이 매우 중요하기 때문에, 이와 관련해서 CloudFront, Route53, Firewall Manager 등의 여러 서비스가 사용된다. AWS 계정 내의물리적 AWS 데이터 센터는 AZ ( Available Zone ), 가용영역이라 하며 아래와 같이 Region code로 표시된다. 같은 Region 내의 가용 영역은 6개까지가능하며, 리전 내에는 일종의 네트워크 주소 공간인 VPC가 있는 데, 리소스는 이 VPC에 배포된다. VPC 내에 서브넷을 만들 어 특정 가용 영역과 연결시켜, 리소스를 효과적으로 격리하고 내구성을 높이기 위한 복제를 수행할 수 있다. AWS 리전의 종류 #\rRegion name Region code Endpoint 미국 동부(오하이오) us-east-2 us-east-2.amazonaws.com 미국 동부(버지니아 북부) us-east-1 us-east-1.amazonaws.com 미국 서부(캘리포니아 북부) us-west-1 us-west-1.amazonaws.com 미국 서부(오레곤) us-west-2 us-west-2.amazonaws.com 아프리카(케이프타운) af-south-1 af-south-1.amazonaws.com 아시아 태평양(홍콩) ap-east-1 ap-east-1.amazonaws.com 아시아 태평양(뭄바이) ap-south-1 ap-south-1.amazonaws.com 아시아 태평양(오사카-로컬) ap-northeast-3 ap-northeast-3.amazonaws.com 아시아 태평양(서울) ap-northeast-2 ap-northeast-2.amazonaws.com 아시아 태평양(싱가포르) ap-southeast-1 ap-southeast-1.amazonaws.com 아시아 태평양(시드니) ap-southeast-2 ap-southeast-2.amazonaws.com 아시아 태평양(도쿄) ap-northeast-1 ap-northeast-1.amazonaws.com 캐나다(중부) ca-central-1 ca-central-1 .amazonaws.com 중국(베이징) cn-north-1 cn-north-1.amazonaws.com 중국(닝샤) cn-northwest-1 cn-northwest-1.amazonaws.com 유럽(프랑크푸르트) eu-central-1 eu-central-1.amazonaws.com 유럽(아일랜드) eu-west-1 eu-west-1.amazonaws.com 유럽(런던) eu-west-2 eu-west-2.amazonaws.com 유럽(밀라노) eu-south-1 eu-south-1.amazonaws.com 유럽(파리) eu-west-3 eu-west-3.amazonaws.com 유럽(스톡홀름) eu-north-1 eu-north-1.amazonaws.com 중동(바레인) me-south-1 me-south-1.amazonaws.com 남아메리카(상파울루) sa-east-1 sa-east-1.amazonaws.com #\r#\rAWS 안정성과 규정\r#\r#\rAWS의 대부분의 서비스는 기본 규정, 법률, 보안의 대한 기초 사항이 존재한다. AWS 보안과 안정성을 위해 수 많은 노력과 시도들을 해왔으며, 이에 관련된 내용은 AWS 규정를 참조하길바란다. #\r#\rAWS의 공동 책임 모델\r#\r#\rAWS의 서비스는 기본적으로 보안에 대학 책임은 AWS와 사용자가 책임을 분담하는 구조를 이루고 있다. 클라우드 상의 인프라를 안정적으로 관리하는 일은 AWS의 책임이지만, AWS의 리소스를 사용하는 것은 사용자의 일이며, 그에 따른 책임도 사용자에게 있다. #\r#\rAWS 책임의 따른 분류\r#\r#\r사용자의 책임\r#\r클라우드 내부 사용자의 데이터 사용자 애플리케이션, 엑세스 관리 운영 체제, 네트워크, 엑세스 구성 데이터 암호화 AWS의 책임\r#\r클라우드 자체 하드웨어와 네트워크 유지보수 AWS 글로벌 인프라 관리형 서비스 #\r#\rAWS 작업\r#\r#\rAWS 서비스를 실행하려면 해당 서비스를 관리할 도구가 있어야 한다. AWS 서비스는 기본적으로 GUI 환경을 제공하지만, 보다 복잡한 환경을 구현할 경우에는 전문적인 관리 도구를 사용해야 할 수도 있다. #\rAWS CLI AWS CLI를 사용하면 컴퓨터 명령줄에서 복잡한 AWS 작업을 실행할 수 있다. 작동방식에 익숙해지면 GUI에 비해 간단하고 효율적인 작업이 가능해진다. #\rAWS SDK AWS 리소스에 엑세스하는 작업을 애플리케이션 코드에 통합하려면 쓰고 있는 언어에 맞는 SDk를 사용해야 한다. #\r기술지원 및 온라인 리소스 AWS에는 다양한 유형의 지원이 있으며, 지원마다 어떤 내용이 있는 지 이해할 필요가 있다. #\r지원플랜\n기본 플랜은 모든 계정에 무료로 제공되며, 문서, 백서, 지원 포럼 등의 고객 서비스에 요구할 수 있고, 청구 및 계정 지원 문제가 포함된다.\n개발자 플랜은 $29부터 시작하며, 계정 소유자 한 명만 일반적 지침과, 시스템 손상에 관해 문의할 수 있으며, 클라우드 지원 담당자가 응답한다.\n비즈니스 플랜은 $100 이상이며 문의할 수 있는 사용자 수에 제한이 없고, 신속한 응답을 보장한다. 시스템 손상, 개별적 지침, 문제 해결, 지원 API 등의 서비스를 제공한다.\n엔터프라이즈 지원 플랜은 다른 지원 모든 지원 플랜을 포함하며, 운영과 설계 검토를 위한 AWS 솔루션스 아키텍트 지원, 전담 기술 지원, 관리자 지원, 컨시어지 지원이 추가된다.\n엔터프라이즈 지원은 복잡한 미션 크리티컬 배포에 큰 도움이 될 수 있지만, 매월 최소 $15.000을 지급해야 한다.\n지원플랜 참고 사이트\n#\r기타 지원 리소스 AWS 커뮤니티 포럼 AWS 설명서 AWS Well-Architected #\r#\r1장 요약\r#\r#\r클라우드 컴퓨팅은 물리적 리소스를 작고 유연한 가상 단위로 나누는 기술에 기반을 둔다.\nAWS는 거대한 물리적 리소스를 가상 단위로 나누어, 가장의 리소스를 종량제로 임대하여 저렴하게 제공해주는 서비스이다.\nAWS 장점은 탄력성과 확장성으로, 이는 자원의 소모를 자동적으로 유동적으로 비용을 최소화시킬 수 있다.\n많은 AWS의 서비스들이 있으며, 이를 통해 거의 모든 디지털 요구사항을 처리할 수 있다. 또한 이러한 서비스들은 지금도 확장되어가고 있다.\nAWS 리소스는 Management Console과 AWS CLI로 관리할 수 있으며, AWS SDK로 생성한 코드로도 관리할 수 있다.\n기술 및 계정 지원에는 지원 플랜, 설명서, 포럼, 백서 등이 있다.\n#\r"},{"id":1,"href":"/cloud/docs/AWS/AmazonWebService/","title":"AWS docs","section":"Amazon Web Services","content":"\rAmazon Web Service\r#\rAws와 CloudComputing\r#\rAmazon Web Services ( AWS ) AWS Cloud Computing 와 aws Cloud Computing의 종류 IaaS PaaS SaaS On Premise 서버와 Cloud 서버의 차이 소유자 ( Owner ) 용량 ( Capacity ) 렌탈 서버 ( 공유 서버 )와 Public의 차이 렌탈 서버 전용 서버와 가상 전용 서버 렌탈 서버와 AWS ( Public )의 차이 Private Cloud와 Public Cloud AWS에서의 Private Cloud의 정의 AWS 서비스의 구성 AWS Computing\r#\rEC2 EC2 상태의 종류 EC2 구매옵션 Lightsail Lightsail의 유료 Plan Lightsail\u0026amp; EC2 ECS Linux Container Kernel Docker Lambda Lambda EC2 vs Lambda Batch amazonwebservice Batch의 구성요소 Batch Group Elastic Beanstalk Elastic Beanstalk의 장점 #\rAWS Database\r#\rAmazon RDS ( Relational Database Service ) DB Instance DB Instance Storage Multi-AZ Read Replica Automated Backup Enhanced Monitoring RDS vs DB in EC2 Amazon DynamoDB DynamoDB의 특징 Amazon ElastiCache Cache In Memory Cache ( In Memory DataBase ) Memcache ElastiCache Amazon Redshift Redshift Redshift의 구성 Data Warehouse(DW) ETL(Extract, Tranform, Load) BI(Business Intelligence) Redshift vs RDS Amazon Aurora #\rAWS Storage\r#\rAWS Network\r#\rAWS Migrate\r#\rAWS Developer\r#\rAWS Management\r#\rAWS Security\r#\rAWS Analysis\r#\r"},{"id":2,"href":"/cloud/docs/AWS/AWSTraining/Start/","title":"AWS 시작하기","section":"AWS Training","content":"\rAWS 시작히기\r#\r#\rAWS 계정 생성\r#\r#\rAWS 서비스를 이용하기 위한 계정을 생성하고, MFA를 사용하여 보안을 강화하는 방법에 대해 알아보도록 하겠습니다. #\r#\r-먼저 AWS을 통해 AWS에 접속합니다.\n#\r#\rAWS 계정 새로 만들기를 선택합니다. #\r#\r다음 항목들을 기입 후, 계정 만들기를 선택합니다. #\r#\r프로페셔널과 개인 중 맞는 항목을 선택 후, 아래 항목들을 기입합니다. 영어 주소를 모를시 Link를 참조하세요. 프로페셔널 : 조직, 기업의 사용\n개인 : 개인적으로 사용\n#\r#\r사용가능한 카드에 대한 정보를 입력합니다. 여기서 amazon에서 $1를 뺏어감니다\u0026hellip;. 후 실습예제 중에서는, 최대한 프리 티어를 기준으로 사용하지만, 특정 서비스 사용시 과금이 발생할 수 있습니다. #\r#\r각 항목에 알맞은 정보를 기입 후, 인증을 진행합니다. #\r#\r인증 진행 후, 기본 플랜을 선택합니다. #\r#\r가입이 완료되면 다시 초기화면으로 돌아와 이메일 주소와 암호를 입력 후 진행합니다. #\r#\r다음으로는 서비스를 다루기 앞서, 보안을 위해 MFA를 등록하겠습니다. 메인 창에서 IAM을 입력 후, IAM에 진입합니다. #\r#\rIAM 진입이 완료되면, 중앙에 메인페이지에 보이는 루트 계정에서 MFA 활성화를 선택 후, MFA 관리를 클릭합니다. #\r#\r멀티 팩터 인증 ( MFA )를 클릭 후, MFA 활성화를 클릭합니다. 혹시 다른 인증방법이 궁금하신 분들은 Link를 참조하세요. #\r#\r가상 MFA 디바이스를 클릭 후, Authenticator를 구글 스토어 혹은 앱 스토어에서 다운로드 받습니다. #\r#\r앱을 실행 시킨 후, QR 코드를 입력 후, MFA 코드를 2차례 입력합니다. #\r#\r등록이 완료되면 다음과 같이 일련번호를 확인 할 수 있습니다. #\r#\r계정을 로그아웃 후, 다시 로그인하면 다음과 같이 MFA코드를 입력창이 나옵니다. 설치한 Authenticator을 실행 후, MFA 값을 입력하면 성공적으로 로그인이 가능합니다. #\r다음으로는 IAM을 통한 사용자 계정생성에 대해 알아보도록 하겠습니다. "},{"id":3,"href":"/cloud/docs/Azure/AzureTraining/Base/","title":"Azure ","section":"Azure Training","content":"\r****\r#\r#\r****\r#\r#\r#\r****\r#\r#\r#\r"},{"id":4,"href":"/cloud/docs/Azure/MicrosoftAzure/","title":"Azure docs","section":"Microsoft Azure","content":"\r#\r#\rAzure\r#\r#\rAzure Docs\nAzure Computing\nAzure Networking\nAzure Mobile\nAzure DataBase\nAzure Storage\nAzure Web\nAzure IOT\nAzure BigData\nAzure AI\nAzure DevOps\nAzure HybridCloud\n#\rAzure Training\nAz-900 : CloudComputing\nAz-900 : Region\nAzure\n#\r"},{"id":5,"href":"/cloud/docs/AWS/AmazonWebService/AWS%EB%9E%80/","title":"CloudComputing과 AWS","section":"AWS docs","content":"\rAWS 란?\r#\r#\rAmazon Web Services ( AWS )\r#\r#\rAWS\r#\rAWS는 Amazon에서 제공하는 클라우드 서비스로, 네트워크를 기반으로 가상 컴퓨터와 스토리지를 비롯한 다양한 서비스를 제공 합니다. #\rCloud Computing 와 AWS\r#\r#\rAWS에 대해 공부하기 앞서, 우리는 Cloud Computing이 무엇이고, 어떠한 개념에 대해 알고 있어야 합니다. 그 이유는 AWS가 클라우드 컴퓨티 그 자체이기 때문이죠.\n클라우드 컴퓨팅 ( Cloud Computing : 이하 클라우드 )은 컴퓨터 리소스의 이용 형태로, 클라우드는 컴퓨터의 계산 리소스, 스토리지, 애플리케이션 처리를 네트워크 기반 서비스로 제공하는 것을 뜻 합니다.\n클라우드 컴퓨팅의 클라우드는 \u0026ldquo;구름 ( Cloud )\u0026ldquo;를 의미하는 것으로, Cloud는 Google의 최고 경영 책임자인 에릭 슈미트가 2006년 8월 \u0026ldquo;인터넷에 접속해서 다양한 리소스를 사용할 수 있게 하는 구조\u0026quot;를 구름으로 예를 들면서 널리 사용되게 되었으며, 현재는 대표적으로 Google의 GCP ( Google Cloud Platform ), Microsoft의 Azure, Amazon의 AWS가 널리 사용되어지고 있습니다.\n예전부터 네트워크를 이용한 컴퓨터 리소스를 공유하는 개념은 존재해왔지만, 클라우드란 용어가 정착하게 된 결정적인 이유는, 브로드 밴드 네트워크의 일반화, 하드웨어 및 소프트웨어의 진화와 구글과 같은 플랫폼을 제공하는 기업 등의 여러 상호작용의 결과라고 할 수 있습니다.\n#\r#\rCloud Computing의 종류\r#\r클라우드 컴퓨팅에도 여러 서비스의 종류가 있고, 이들 중 위의 그림에 나타난 클라우드 컴퓨팅을 대표하는 서비스에 대해 알아보도록 하겠습니다. #\r#\rInfratructure as a Service : IaaS\r#\r#\rIaaS는 가상 서버 또는 스토리지 등의 리소스를 인터넷을 기반으로 제공하는 서비스를 의미하며, 추가적으로 네트워크 서비스 자체를 포함하기도 합니다.\nIaaS의 가장 큰 장점은 물리적인 하드웨어를 관리할 필요가 없음에도, 직접적으로 컴퓨터 리소르를 사용할 수 있다는 점입니다.\nIaaS는 위의 그림에서처럼 가장 하단에 위치하며 클라우드 레이어로는 갖아 아래의 기초적인 부분을 담당합니다. 즉, IaaS는 물리 장치에 가장 가까운 서비스라 할 수 있습니다.\n#\rPlatform as a Service : PaaS\r#\rPaaS는 데이터베이스 또는 애플리케이션 서버 등의 미들웨어를 제공하는 서비스입니다.\nOS와 미들웨어의 관리는 서비스 제공자가 하며, 사용자는 미들웨어만을 직접 사용할 수 있습니다.\n#\rSoftware as as Service : SaaS\r#\rSaaS는 소프트웨어 또는 애플리케이션의 기능을 인터넷을 통해 제공합니다.\nSaaS는 내부적으로 메일 서비스, 큐 서비스, 업무 관리 시스템 등으로 다양하게 분류되어 있습니다.\nSaaS를 제공하는 것을 SaaS제공자 ( Provider )라고 부릅니다. 이는 ASP ( Application Service Provider )와 동일한 것으로, 다만 SaaS의 제공자는 클라우드라는 것에 조금 더 비중을 두어 말하는 것이 차이점이라 할 수 있습니다.\n#\r#\rOn Premise 서버와 Cloud 서버의 차이\r#\r#\rOn Premise ( 물리 서버 )라고하면 일반적으로 물리 머신을 한정해서 말하는 것이므로, 네트워크 장치 또는 전력 설비 등을 포함하는 의미로 On Premise라는 용어가 되었습니다.\nOn Premise는 조직 내부에서 사용할 목적으로 준비한 설비를 나타내며, 기업 내부에서 일반적으로 사용하는 형태라서 이전에는따로 명칭이 없었지만, 클라우드가 등장하면서 기존에 사용하던 형태를 나타내는 용어로 사용도기 시작했습니다.\n그러면, On premise와 Cloud의 가장 큰 차이는 무엇일까요?, 그것은 크게 2가지로 소유자 ( Owner )와 용량 ( Capacity ) 입니다.\n#\r#\r소유자 ( Owner )\r#\r#\r**On Premise와 Public의 첫 번째 차이는 소유자로, On Premise의 경우 리소스 등의 예외가 있을 수는 있지만, 일반적으로 설비를 준비한 기업이 소유하고 있습니다. 반면, Public은 해당 깅버이 모든 리소스를 소유하고, 해당 리소스를 서비스로 만든 것을 사용하는 형태로, **소유자와 사용자가 다르다고 할 수 있습니다.****\n소유자와 사용자가 다르다는 차이점은 다방면에서 영향을 끼칠 수 있습니다.\n먼저 초기 비용의 차이입니다. On Premise는 서버 등을 이용할 때, 초기에 물리 장치를 구매해서 도입해야 하며, 여러 비용이 발생할 수 있습니다. 반면, AWS는 사용자가 물리 잧이를 구매할 필요가 없어 초기 비용이 거의 들지 않습니다. 이는 Public 차원에서 미리 물리 장치에 투자한 자산을 서비스 제공이라는 형태로 분산해서 회수하는 형태이기 때문입니다. #\r이어서 서버 등의 조달 기간입니다. On Premise의 경우는 견적을 받고 발주 및 배송에 몇 주에서 몇 달의 시간이 걸리는 것이 일반적이지만, 반면 Public 환경에서는 웹 브라우저, 콘솔, 프로그램에서 호출하면 몇 분 내로 조달이 완료됩니다. #\r이와 마찬가지로 사용하고 있는 서버를 추가하거나, 크기를 변경할 때도 동일합니다. On Premise의 경우는 시간과 비용이 들어가지만, 서버의 성능을 Scale Up하거나 이와 반대되는 경우, 혹은 서버자체를 새로 구매해야할 때, Public 상에서는 버튼 하나로 변경 및 추가 구매가 가능합니다. Option On Premises Public 비용 초기에 모두 필요함 초기 비용은 따로 필요 없으며, 종량제 과금에 따라 비용이 분산되어 발생 서버 조달 기간 몇 주- 몇달 몇 분 서버 추가/ 변경 시간과 비용이 들어감 추가/ 변경과 관련된 비용이 필요하지 않음 #\r#\r용량 ( Capacity )\r#\r#\rOn Premise와 AWS에서는 소유와 사용에 따라 비용이 발생하는 방식이 다릅니다. 추가로 서버 조달 기간 또는 조달 비용도 다릅니다. 따라서 용량 ( Capacity ) 설계도 전혀 다르게 해야합니다.\nOn Premise는 서버 조달, 추가/변경으로 인한 기간이 길고, 비용이 크기 때문에 자원을 많이 사용할 때의 필요 자원에 맞춰서 모든 것을 준비해야 합니다. 반면 Public은 자원의 추가/ 변경이 쉬우며, 따라서 실제 수요에 맞춰 자원을 크게 만들 수도 있고, 작게 만들 수도 있습니다. 또한 대부분의 Public 플랫폼은 종량제 비용이므로 작게 만들면 비용을 줄일 수 있습니다.\n즉, Public 인프라를 효율적으로 활용하려면, On Premise에서와 다르게 해야한다는 점 을 확실하게 이해해야 합니다.\n#\r#\r렌탈 서버 ( 공유 서버 )와 Public의 차이\r#\r#\r렌탈 서버\r#\r#\r위에서 Public 인프라가 다른 소유자의 자원을 사용한다는 점을 말씀드렸습니다. 그렇다면 우리가 흔히 알고 있는 호스팅 서버 혹은 공용 서버라 불리는 렌탈서버와 다른 점을 무엇일까요?.\n먼저 렌탈서버란 1대의 서버를 여러 사용자가 공용으로 사용 하는 형태로, 주로 웹 서버나 메일 서버를 사용하는 것이 일반적이었습니다.\n즉, 1대의 물리서버를 모두 점유하는 전용 서버의 위에 가상 서버를 여러 개를 만들어, 해당 가상 서버를 점유하는 가상 전용 서버( VPS )라는 형태를 취하는 것이 렌탈 서버입니다.\n그렇다면, 이러한 렌탈 서버에 문제점은 무엇일까요? 그것은 크게 3가지로 말씀드릴수 있는데, 낮은 자유도, 보안문제, 다른 사용자로 부터의 영향으로 정리할 수 있습니다.\n먼저, 낮은 자유도라는 것은 공용 서버를 이용할 때에는 root 계정이 아닌, 사용자 권한의 계정만 부여되므로, 이는 애플리케이션이나 미들웨어를 자신이 원할 때 변경 등이 불가능하며, 자신이 원하는 대로 환경을 바꿀 수 없습니다.\n이어 보안 문제또한 위에 이어지는 문제로, 기본적으로 자신이 원하는 환경을 구축할 수 없으므로, 보안 대책도 업자에게 맡기게됩니다. 이에 따라 취약성이 있는 미들웨어를 사용하고 있다는 것을 파악하여도, 사용자는 이를 해결하기 어려우며, 또한 만약 다른 사람이 만든 애플리케이션에 취약점이 발견되면, 그 취약점에 영향을 받을 수도 있습니다.\n마지막으로는 다른 사용자로부터의 영향입니다. 만약 Apache를 사용하는 웹 서버를 이용할 때 공용 서버를 사용하면 유저마다 프로세스를 사용하는 것이 아닌, 모두 동일한 프로세스를 분할해서 사용하게 되는 데, 만약 1명의 사용자가 부하처리, CGI 등을 사용한 프로그램 처리가 폭주하면 모든 사용자는 영향을 받게 되어, 서비스가 중단될 수 있어, 공용 서버는 다른 사용자에게 영향을 받기 쉬운 형태라 할 수 있습니다.\n#\r#\r전용 서버와 가상 전용 서버\r#\r#\r위와 같은 렌탈 서버의 문제를 해결하기위해 전용서버와 가상 전용 서버라는 형태가 등장하게 되었습니다.\n전용 서버와 가상 전용 서버는 관리자의 권한이 부여되어 있는 사용자 계정이 생성이 가능하여, 자유도가 높으며 스스로 관리가 가능합니다.\n한편 전용서버는 1대의 물리 서버를 1명의 사용자에게 주어야 하기에, 비용적으로 부담이 크며, 이 때문에 가상화 기술을 사용해 1대의 물리 서버를 여러 대의 가상 서버로 분할해 비용을 줄인 것을 가상 전용 서버입니다.\n또한 전용서버는 한 대의 물리서버이므로 다른 사용자의 영향을 전혀 받지 않으며, 반면 가상 전용 서버는 어느 정도의 영향을 받을 수 있지만, 렌탈 서버, 즉 공용 서버에 비해서는 거의 영향을 받지 않는 다고 할 수 있습니다.\n옵션 공용 서버 전용 서버 가상 전용 서버 사용 형태 1대의 물리 서버를 분할해서 사용 1대의 물리 서버 점유 1대의 물리 서버 위에 있는 가상 서버를 점유 비용 적음 높음 중간 자유도 거의 없음 높음 높음 보안 관리 불가능 관리 가능 관리 가능 다른 사용자의 영향 높음 없음 거의 없음 #\r렌탈 서버와 AWS ( Public )의 차이\r#\r#\rEC2라는 AWS의 가상 컴퓨트 서비스는 가상화 기술을 사용해 1대의 물리 컴퓨터 위에 여러 개의 가상 컴퓨터를 만들어서 사용합니다.\n**여기에서 사용자는 관리자 권한을 가진 계정을 사용할 수 있으며, 해당 가상 컴퓨터 내부의 모든 것을 관리할 수 있습니다. 따라서 이러하 면에서 **EC2는 가상 전용 서버와 비슷하다 할 수 있습니다.**\n그러나 EC2는 디스크를 동적으로 추가하거나, CPU와 메모리를 다른 인스턴스 유형으로 쉽게 변경하는 등의 기존의 렌탈 서버에 없는 기능이 많습니다. 또한, 가상 머신 이미지를 생성해서 백업하고, 백업한 이미지를 사용하여 여러 서버로 복제하는 등의 서비스도 이용이 가능합니다. 이와 같이 AWS와 같은 대부분의 클라우드 컴퓨팅을 서비스를 하는 기업의 대부분은 위에 렌탈 서버가 제공하는 서비스 뿐만아닌 추가적인 서비스를 더 제공하는 형태라고 할 수 있습니다.\n#\r#\rPrivate Cloud와 Public Cloud\r#\r#\r크게 클라우드의 형태는 Private Cloud와 Public Cloud가 있습니다. 이는 말을 정의하는 사람에 따라 의미가 조금씩 다를 수 있으며, 일반적인 의미에서는 누구에게 서비스를 제공하는 가에 따라 정의됩니다.\n크게 Public Cloud는 GCP, Azure, AWS와 같이 누구에게나 서비스를 제공하는 형태의 서비스를 의미하고 Priavte Cloud는 기업 사내망, 즉 기업 전용서버로 해석되기도 하며, Public과는 반대로 특정 기업/ 조직 전용으로 제공되는 서비스를 의미합니다.\n이 뿐만 아니라 현재는 이 둘을 혼용으로 사용하는 Hybrid Cloud와 특정 업종의 기업들이 함께 운영해나가는 Community Cloud라는 용어가 있습니다.\n#\r#\rAWS에서의 Private Cloud의 정의\r#\r#\rAWS를 제공하는 Amazon은 Public과 Private라는 용어를 따로 사용하고 있지 않습니다. 이는 클라우드라는 용어가 없었던 때부터 서비스를 시작한 Amazon의 자부심이라 할 수 있겠으며, 일반적으로 AWS를 대표적인 Public Cloud Service로 분류합니다.\nAWS 내에는 Virtual Private Cloud ( VPC )라는 서비스가 있는 데, 이는 가상 네트워크를 생성하여 IP 주소 범위, 라우트 테이블, 네트워크 게이트웨이 등을 자유롭게 설정할 수 있게 해주는 서비스로, VPC를 사용하면 기존 데이터 센터와 회사 내부에 만들던 것과 같은 방식으로 네트워크를 만들 수 있습니다. 경우에 따라서는 이를 Private 클라우드라 표현하기도 합니다.\n#\r#\rAWS 서비스의 구성\r#\r#\rAWS는 이미 30개가 넘는 서비스가 있으며, 해마다 새로운 서비스와 기능이 추가되므로 서비스의 전체적인 구성을 파악하는 것은 굉장히 힘듭니다.\n하지만 AWS를 사용할 때에 대한 기본적인 개념, 사고방식 등은 베이스로 학습한 후에 진행하는 것이 보다 빠른 이해를 도울 것입니다.\n#\r"},{"id":6,"href":"/cloud/docs/OpenStack/OpenStack/openstack/","title":"OpenStack 개요","section":"OpenStack docs","content":"\r인프라 환경 변화의 시작, 클라우드\r#\r클라우드 컴퓨팅의 정의와 종류\r#\r#\r클라우드 컴퓨팅(Cloud Computing)\r#\r인터넷이 가능한 디바이스(스마트폰, 스마트패드, 스마트TV 등)로 클라우드에서 데이터를 처리하며, 저장 및 관리하는 컴퓨팅 시스템\n클라우드 서비스의 종류\nIaaS(Infrastrcture as a Service): 서버, 스토리지, 네트워크를 가상화 환경으로 만 들어 필요에 따라 인프라 자원을 제공하는 서비스\nPaaS(Platform as a Service): 웹에서 개발 플랫폼을 제공하는 서비스\nSaaS(Software as a Service): 온디맨드 소프트웨어(On-demand Software)라고도 하며, 중앙에서 호스팅 되는 소프트웨어를 웹 브라우저 등 클라우이언트로 이용하는 서비스\nDaas(Desktop as a Service): 클라우드 인프라를 이용해 os가 설치된 인스턴스를 제공하는 서비스\nBaaS(Backend as a Service): 모바일 환경에 맞춰 구현하기 힘든 백엔드 부분을 제공하는 서비스\nPublic Cloud: 언제든지 접근이 가능한 클라우드 서비스\nPrivate Cloud: 외부에서는 접근이 불가능한 사내 클라우드 서비스\nHybrid Cloud Management System: 퍼블릭 클라우드와, 프라이빗 클라우드를 혼용하는 클라우드 서비스\n#\r클라우드 핵심 서비스 컴퓨트와 스토리지\r#\r컴퓨트 서비스(Compute Service)\n사용자가 원하는 운영체제가 탑재된 컴퓨터나 서버를 인터넷에서 사용할 수 있게 제공하는 서비스 스토리지 서비스(Storage Service)\n사용자가 소유한 데이터나 음악, 동영상, 문서 파일을 인터넷에 있는 스토리지에 저장, 삭제 공유할 수 있는 서비스 #\r하이퍼바이저의 정의와 종류\r#\r#\r하이퍼바이저의 정의\r#\r#\r하이퍼바이저(Hypervisor)\n가상 머신 모니터라고도 하며, 호스트 컴퓨터 한 대에서 운영체제 다수를 동시에 실행하는 논리적 플랫폼을 의미 하이퍼바이저의 분류\nNative, 베어메탈 방식: 하드웨어에 직접 설치해서 실행되는 방식 Hosted 방식: 애플리케이션처럼 프로그램으로 설치되는 방식 가상화 방식에 따른 하이퍼바이저의 분류\n전가상화 방식(Full Virtualization): 하드웨어를 모두 가상화하는 방식으로, 게스트 운영체제를 변경하지 않고, 다양한 운영체제로 이용할 수 있음. Native 방식이 이에 해당\n반가상화 방식(Para Virtualization): 하이퍼바이저로만 제어가 가능한 방식으로, 높은 성능의 유지가 가능하지만, 오픈 소스가 아니면 운영이 불가능\n#\r하이퍼바이저의 종류\r#\rKVM(for Kerne-based VirtualMachine):\n오픈스택의 거본 하이퍼바이저로 전가상화 방식을 지원 반드시 Inter VT나 AMD-V가 있어야만 사용이 가능 리눅스, 윈도 이미지를 수정하지 않고 여러 가상 머신으로 실행이 가능 Xen과 Xen Server:\nCenter를 이용한 관리 기능, 스토리지 지원과 실시간 마이그레이션, 고가용성 기능처럼 데이터센터에서 요구하는 확장 기능을 제공 Hyper-V:\n디바이스 드라이버가 부모 파티션 위에서 동작하며, 콘솔 OS의 역할을 부모 파티션이 수행 다른 하이퍼바이저의 비해 크기가 작아 오류 코드가 포함될 확류이 낮음 Inter VT, AMD-V x64를 지원하는 하드웨어가 있어야 가상화가 가능 VMware vSphere ESX:\n적은 하드웨어서도 애플리케이션을 통합할 수 있도록 서버를 가상화해주는 무료 베어메탈 하이퍼바이저 ESX는 가상 머신의 업무를 지원하는 역할을 수행, 가상 머신이 발생시킨 명령어를 하이퍼바이저가 받아 재작업 후, 가상 환경에서 잘 구동하도록 바이너리 변환 방식을 사용 Inter, VT, AMD-V 같은 가상화를 지원하는 디바이스가 없어도 가상화를 구현할 수 있음 Docker:\n리눅스 기반의 컨테이너 런타임 오픈 소스로, 가상 머신과 기능이 유사하며, 가상 머신보다 훨씬 가벼운 형태로 배포가 가능 컨테이너의 개념으로 가상 머신처럼 Docker Engine을 호스트 웨어서 수행하며, 리눅스 기반의 운영체제만 수행이 가능 가상 머신처럼 하드웨어를 가상화하는 것이 아니라, 게스트 OS를 분리시켜 제공 호스트 운영체제의 프로세스 공간을 공유한다고 할 수 있음 VirtualBox:\n리눅스, OS X, 솔라리스, 윈도를 게스트 운영체제로 가상화하는 x86 가상화 소프트웨어 다른 하이퍼바이저와 비교했을 때는 기능이 부족 원격 데스크톱 프로토콜(RDP), iSCSI 지원, RDP를 거치는 원격 디바이스의 USB 지원처럼 원격 가상 컴퓨터를 제어할 수 있는 기능이 있음 Inter VT와 AMD-V를 지원 VMware Workstation:\n게스트 운영체제에 설치할 수 있는 다리이버 및 기타 소프트웨어의 묶음 게스트 머신이 고해상도 화면에 접근할 수 있게 하는 VESA호한 그래픽, 네트워크 인터페이스 카드용 네트워크 드라이버, 호스트와 게스트 간 클립보드 공유, 시간 동기화 기능 등을 제공 Parallels Desktop:\n맥용 인텔 프로세서가 있는 매킨토시 컴퓨터에 하드웨어 가상화를 제공하려고 만든 소프트웨어 MS-DOS, 윈도, 맥, 리눅스, 솔라시스 등 다양한 운영체제를 가상화 할 수 있음 #\r하이퍼바이저별 이미지 포맷\r#\rKVM: img, qcow2, vmdk VMWARE: vmdk 오라클 VirtualBOx: vdi, vmdk, qcow2, vhd 마이크로소프트 Hyper-V: vhd, vmdk, vdi Xen, Xen Server: qcow2, vhd #\r이미지포맷 설명\r#\rqcow2: QEMU Copy On Write 2 vdi: Virtual Disk Image vmdk: VMware Virtual Disk DevelopmentKit vhd: Virtual Hard Disk #\r클라우드에서 알아야 할 네트워크 상식\r#\r#\r고정 IP, 유동 IP\n고정IP (Fixed IP): 인터넷 공유기를 연결해 고정으로 할당받는 IP 유동IP (Floating IP): 가상 인스턴스가 외부에서 접근할 수 있도록 할당하는 인터넷이 가능한 IP 클래스의 범위\nA 클래스: 1 ~ 126 B 클래스: 128 ~ 191 C 클래스: 192 ~ 223 D 클래스: 224 ~ 239 E 클래스: 240 ~ 254 멀티캐스트는 D 클래스, E 연구 개발 목적으로 예약된 클래스 #\rCIDR(Classless Inter-Domain Routing)\r#\r클래스가 없는 도메인간 라우팅 기법으로 기존 IP할당 방식인 네트워크 클래스를 대체 급격히 부족해지는 IPv4 주소를 좀 더 효율적으로 사용 접두어를 이용한 주소 지정 방식의 계층적 구조를 사용해 인터넷 라우팅의 부담을 덜어 줌 #\rSDN(Software Defined Networking)\r#\r네트워크 제어 기능이 물리적 네트워크와 분리되도록 프로그래밍한 네트워크 구조를 뜻함 네트워크 제어 기능을 데이터 전달 기능과 분리해서 구현해야 한다. 네트워크 제어 기능이 개발되고 실행될 수 있는 환경을 분리해 낮은 성능의CPU가 있는 하드위어 위에 스위치에 더 이상 위치시키지 않는다. #\r오픈플로(OpenFlow)\r#\rSDN의 근간이 되는 기술로 SDN 아키텍처의 컨트롤 레이어와 인프라스트럭처 레이어 사이에 정의된 최초의 표준 통신 인터페이스 흐름정보로 패킷의 전달 경로와 방식을 제어 오픈플로는 오픈플로 컨트롤러와 오픈플로로 지원 네트워크 장비(라우터, 스위치) 사이에서 커뮤니케이션 역할을 담당 일반적인 네트워크 장비(라우터, 스위치)는 플로 테이블을 이용해서 네트워크 트래픽을 처리하는 반면, 오픈플로는 소프트웨어 컨트롤러로 플로테이블을 조작하고 데이터 경로를 설정 #\r네트워크 장비\r#\r#\r라우터(Router):\n인터넷 등 서로 다른 네트워크를 연결할 때 사용하는 장비 데이터 패킷이 목적지까지 갈 수 있는 경로를 검사하여 최적의 경로를 탐색하는 것을 라우팅이라 함 경로가 결정되면 결정된 길로 데이터 패킷하는 것을 스위칭이라고 함 허브(Hub):\n인터넷이 등장하기 이전, 컴퓨터와 컴퓨터를 연결해 네트워크를 구성하는 장비 멀티포트(Multiport) 또는 리피터(Repeater)라고도 할 수 있습니다. CSMA/CD(Carrier Sense Multiple Access/Collision Detect):\n이더넷 전송 프로토콜로 IEEE 802.3 표준에 규격화되어 있습니다. 브리지(Bridge):\n콜리전(충돌) 도메인을 나누어 서로 통신이 가능하도록 다리처럼 연결해 주는 네트워크 장비 분리된 콜리전 도메인을 세그먼트라고 한다. 스위치(Switch)\n브리지와 역할이 동일하지만, 소프트웨어적으로 처리하는 스위치가 소프트웨어적으로 처리하는 브리지보다 속도가 더 빠르다. 스위치가 브리지 보다 많은 포트 개수를 제공(20~ 100) 브리지는 Store-and-forward라는 프레임 처리 방식만 지원하지만, 스위치는 Cut-through, Store-and-forward라는 프레임 처리 방식을 지원 스위치 관련 용어\n프레임: 데이터를 주고받을 때 데이터를 적절한 크기로 묶어 놓은 것 프레임 처리 방식: 입력되는 프레임을 스위칭하는 방식입니다. Store-and-forward: 들어오는 프레임 전부를 일단 버퍼에 담아 두고, CRC 등 오류 검출을 완전히 처리한 후 전달(포워딩)하는 스위칭 기법 Cut-through: 스위칭 시스템에서 수신된 패킷 부분만 검사해 이를 곧바로 스위칭하는 방식 #\r블록 스토리지와 오브젝트 스토리지\r#\r#\r블록 스토리지(Block Storage)와 오브젝트 스토리지(Object Storage) 블록 스토리지: 컴퓨터의 용량을 추가하는 것처럼 클라우드 상의 하드 디스크를 블록 스토리지라고 함 오브젝트 스토리지: 사용자 계정별로 저장 공간을 할당할 수 있는 스토리지 시스템으로 블록 스토리지와는 다르게 단독으로 구성이 가능하며, 계정의 컨테이너 파일이나 데이터를 저장할 수 있는 저장 공간 #\r대표적인 스토리지 서비스\r#\r#\r아마존의 EBS와 S3:\nEBS(Elastic Block Store)는 블록 스토리지에 해당하는 서비스 EC2(Elastic Compute Cloud)은 생성한 인스턴스에 확장해서 사용할 수 있는 스토리지 서비스 S3는 오브젝트 스토리지에 해당하는 서비스로 사용자 계정에 해당하는 Owner, 컨테이너에 해당하는 Bucket, 파일이나 해당데이터에 해당하는 오브젝트로 구성되어있다. 오픈스택의 Cinder와 Swift\nCinder는 오픈스택의 기본 서비스 중 하나로 블록 스토리지 서비스를 제공한다. Cinder는 cinder-volume, cinder-backup, cinder-scheduler, Volume Provider, cinder-api로 구성 Nova에서 제공하는 인스턴스의 확장 스토리지로 사용할 수 있다. Swift는 오픈스택의 기본 서비스 중 하나로 오브젝트 스토리지 서비스를 제공한다. Swift는 proxy-server, account-server, container-server, object-server, swift-api로 구성된다. proxy-server는 여러 대의 스토리지 노드로 구성된 account-server, container-server, object-server을 관리한다. Ceph의 RBD와 RADOS\nCeph는 모든 종류의 스토리지 서비스를 모아 놓은 오픈 소스 서비스라고 할 수 있다. RADOS라는 스토리지 노드 위에 LIBRADOS라는 RADOS 라이브러리가 있다. 아마존의 S3, 오픈스택의 Swift와 연동하는 RADOSGW(게이트웨이)가 있다 QEMU나 KVM에서 생성한 인스턴스를 블록 스토리지로 사용하는 RBD(Rados Block Device), 사용자의 편의성을 제공하려고 POSIX(표준 운영체제 인터페이스)를 제공하는 Ceph FS로 구성되어 있다. #\r#\rOpenStack\r#\r#\r오픈스택과 아키텍처\r#\r#\r오픈스택\r#\r오픈스택은 컴퓨트, 오브젝트 스토리지, 이미지, 인증 서비스 등이 유기적으로 연결되어 하나의 커다한 클라우드 컴퓨팅 시스템을 구축하는 것.\n개념 아키텍처로 살펴보는 오픈스택의 변화\n오픈스택의 변화\r...\r백사버전부터는 컴퓨트 서비스에는 Nova 추가 스토리지 서비스에는 Swift 추가 이미지 관리 서비스에는 Glance 추가 Nova, Swift, Glance의 인증을 담당하는 Keystone 추가 서비스를 보다 쉽게 이용하려고 사용자에게 대시보드를 제공하는 Horizon 추가 폴섬 버전부터는 네트워크 서비스와 블록 스로리지 서비스를 Quantum와 Cinder 로 분류함 Quantum은 기존 nova-network와 다르게 OpenFlow를 사용해서 여러 네트워크 컨트롤러의 지원이 가능 하바나버전부터는 오케스트레이션 서비스인 Heat와 텔레미터 서비스인 Ceilometer가 있습니다. 킬로 이후 버전부터는 빅데이터 프로세싱 프레임워크인 Sahara 추가 데이터베이스 서비스인 Trove 추가 PXE나 IPMI를 사용해 베어메탈을 프로비저닝하는 Ironic 추가 코어 서비스 6개와 이를 지원하는 많은 서비스를 표현한 빅텐트(Big-tent)라는 개념 추가 #\r클라우드 서비스(오픈스택을 기준으로)\r#\r#\r시스템 관련 클라우드 서비스\nNova 스토리지 관련 클라우드 서비스\nSwift : 객체 스토리지 Cinder : 블록 스토리지 네트워크 관련 클라우드 서비스\nNeutron 데이터 관련 클라우드 서비스\nGlance Trove 기타 클라우드 서비스\nHorizon Keystone #\r논리 아키텍처로 살펴보는 오픈스택의 변화 오픈스택의 변화\r...\r상황별 오픈스택 구성 요소\n사내 클라우드 컴퓨팅 환경을 구축할 때나 퍼블릭 클라우드 서비스를 구성할 때 오픈스택을 주로 채택 회사의 클라우드 환경을 어떤 목적으로 사용하느냐에 따라 선택해야할 서비스가 달라질 수 있음 #\rHTC(High Throughput Computing): HTC 사용자는 종종 Nova 컴퓨트로 전환해 Horizon 대시보드로 단일 API 엔드포인트를 사용자에게 제공함. Keystone은 일반적으로 사용자 계정이 저장되는 LDAP 백엔드를 연결하는 데 사용 이런 종류의 프로젝트를 구성하려면 다음이 서비스가 필요함 대시보드 서비스 Horizon 텔레미터 서비스 Ceilometer 블록 스토리지 서비스 Cinder 오케스트레이션 서비스 Heat 이미지 서비스 Glance 인증 서비스 keystone 컴퓨트 서비스 Nova #\r웹 호스팅: 웹 호스팅 회사 중 하나로 수백만 개의 호스팅 사용하는 데 오픈스택을 활용 Nova, Neutron, Keystone, Glance, Horizon 같은 일반적인 코어 서비스를 이용 사용자 계정 데이터를 수집하고 요금을 청구할 때 일부 기술로 Ceilometer를 활용 네트워크 서비스 Neutron 대시보드 서비스 Horizon 텔레미터 서비스 Ceilometer 이미지 서비스 Glance 인증 서비스 keystone 컴퓨트 서비스 Nova #\r퍼블릭 클라우드: 오픈스택은 전 세계 사용자에에 IaaS를 제공하는 퍼블릭 클라우드를 지원 Nova, Glance, Keystone, Cinder, Neutron 같은 서비스를 제공 Swift를 사용해 오브젝트 스토리지 서비스를 제공, Designate는 DNSaaS(DNS as a Service)를 제공함 네트워크 서비스 Neutron 도메인 네임 서비스 Designate 블록 스토리지 서비스 Cinder 오브젝트 스토리지 서비스 Swift 이미지 서비스 Glance 인증 서비스 Keystone 컴퓨트 서비스 Nova #\r웹 서비스, 전자상거래: 이베이, 오버스톡닷컴, 베스트바이 등 많은 회사가 오픈스택을 이용해 웹 서비스도 하고 전자상거래의 백엔드로도 사용 상황에 맞춰 오픈스택 클라우드는 PCI 표준처럼 구성하기도 함 Trove는 내부 고객에게 데이터베이스 서비스인 DaaS를 제공, 네트워크 정의 소프트웨어 SDN은 Neutron을 제공 네트워크 서비스 Neutron 대시보드 서비스 Horizon 데이터베이스 서비스 Trove 블록 스토리지 서비스 Cinder 이미지 서비스 Glance 인증 서비스 Keystone 컴퓨트 서비스 Nova #\r컴퓨트 스타터 키트(Compute Starter Kit): 더 많은 사람이 오픈스택을 사용할 수 있도록 하는 것이 컴퓨터 스타터 키트라고 함 스타터 키트는 추가 기능으로 클라우드 확장할 수 있는 방법을 문서화로 제공하는 단순한 프로젝트를 의미함 네트워크 서비스 Neutron 이미지 서비스 Glance 인증 서비스 Keystone 컴퓨트 서비스 Nova #\r빅데이터: 다양한 리소스 데이터를 분석하는 빅데이터에도 활동 됨 빅데이터 분석 서비스인 Sahara 프로젝트는 오픈스택 위에 빅데이터 응용프로그램(Hadoop, Spark)을 간단하게 제공할 수 있음 네트워크 서비스 Neutron 대시보드 서비스 Horizon 베이메탈 서비스 Ironic 빅데이터 서비스 Sahara 이미지 서비스 Glance 인증 서비스 Keystone 컴퓨트 서비스 Nova #\rDBaaS: 대부분의 회사는 응용프로그램을 백업하려 데이터베이스에 크게 의존하며 일반적인 관리 자동화 및 스케일 아웃을 최우선으로 생각 오픈스택 Trove 프로젝트는 이 기능을 제공 및 여러 SQL 및 NoSQL 백엔드를 지원 Ironic 프로젝트는 데이터베이스의 성능을 극대화하려고 베어메탈 프로비저닝을 제공 네트워크 서비스인 Neutron 대시보드 서비스 Horizon 데이터베이스 서비스 Trove 도메인 네임 서비스 Designate 베어메탈 서비스 Ironic 블록 스토리지 서비스 Cinder 오브젝트 스토리지 서비스 Swift 이미지 서비스 Glance 인증 서비스 Keystone 컴퓨트 서비스 Nova #\r비디오 처리와 콘텐츠 전달: 제작 스튜디오나 주요 케이블 서비스 제공 업체 같은 곳의 비디오 처리(Video Processing), 콘텐츠 전달(Contents Delivery)은 오픈스택의 보편적인 사용 예시임 Keystone에서 선보인 인증 표준은 이제 동일한 대시보드와 인증을 사용해 프라이빗 클라우드 및 퍼블릭 클라우드에서 비디오 콘텐츠를 원할하게 이동시킬 수 있음 네트워크 서비스 Neutron 오브젝트 스토리지 서비스 Swift 인증 서비스 Keystone 컴퓨트 서비스 Nova #\r컨테이너 서비스: 가상머신, 컨테이너, 베어메탈에서 실행되는 워크로드를 단일 클라우드에서 운영할 수 있도록 개발되었음 Kubernetes, Mesos, Docker 같은 새로운 컨테이너 오케스트레이션 엔징(COE, container Orchestration Engices)와 통합하려고 Magnum 프로젝트에 엑세스 할 수 있음 네트워크 서비스 Neutron 대시보드 서비스 Horizon 베어메탈 서비스 Ironic 블록 스토리지 서비스 Cinder 이미지 서비스 Glance 인증 서비스 Keystone 컨테이너 서비스 Management 컴퓨트 서비스 Nova #\r오픈스택 적용사례\r#\r업종별·목적별 클라우드 활용 사례 웹 사이트에서 클라우드 활용 소셜 게임의 클라우드 활용 애플리케이션 개발/테스트 환경에서의 클라우드 활용 스타트업 기업에서의 클라우드 활용 BCP(비지니스 연속성 계획)의 클라우드 활용 ERP(통합 기간 업무 시스템)에서의 클라우드 활용 제조업의 클라우드 활용 지자체 클라우드 교육 분야의 클라우드 활용 농업 분야의 클라우드 활용 빅 데이터 이용을 위한 클라우드의 활용 IoT에서 클라우드 활용 인공 지능 등의 새로운 산업 영역에서의 클라우드 활용 참고 홈페이지\r#\r오픈스택 릴리스 웹 사이트 Nalee의 IT 이야기 #\r오픈스택 파운데이션과 커뮤니티 오픈스택 파운데이션: 나라별로 오픈스택 사용자 그룹을 운영하고 있다. 사용자 그룹은 공식 사용자 그룹과 일반 사용자 그룹으로 나뉨 오픈스택 사용자 그룹은 총 112개, 이중 공시기 사용자 그룹은 18개이며, 엠버서더로 활동하는 구성원은 총 12명, 아시아는 6명이다. 오픈스택은 버전별 컨트리뷰터 활동을 그래프와 표로 보여주는 http://stackalytics.com/을 운영한다. "},{"id":7,"href":"/cloud/docs/AWS/AWSSAA/SAA-2/","title":"2장 EC2와 EBS","section":"AWS SAA 시험정리","content":"\r#\r2장 Amazon Elastic Compute Cloud와 Amazon Elastic Block Store\r#\r#\r2장의 목표\r#\r복원력은 갖춘 아키텍처 설계 안정적이고, 복원력을 갖춘 스토리지를 선택 어떻게 고가용성 및/ 또는 내결함성을 갖춘 아키텍처를 설계할지를 결정 #\r성능이 뛰어난 아키텍처 정의 성능이 뛰어난 스토리지 및 데이터베이스를 선택 탄력성과 확장성을 갖춘 솔루션을 설계 #\r안전한 애플리케이션 및 아키텍처 설명 어떻게 애플리케이션 티어를 보호할지를 결정 어떻게 데이터를 보호할지 결정 비용에 최적화된 아키텍처 설계 어떻게 비용에 최적화된 스토리지를 설계할지를 결정 어떻게 비용에 최적화된 컴퓨팅을 설계할지 결정 #\r#\rEC2 인스턴스\r#\r#\rEC2는 물리 서버의 기능을 함축적으로 가상화한 실제 서버와 유사하게 작동\n스토라지, 메모리, 네트워크 인터페이스가 새로 설치 된 기본 드라이브가 제공\n#\r#\rEC2 Amazon Machin Image ( AMI )\r#\r#\rAMI란 EC2를 시작할 때, 루트 볼륨에 설치될 운영 체제와 소프트웨어를 기술한 템플릿 문서 AMI의 종류 종류 설명 Amazon 바른 시작 AMI 자주 이용되는 Linux, Windows 등이 등록되어지고, 최신 버전으로 업데이트, 공식적으로 지원하는 이미지 AWS Marketplace AMI AWS Marketplace AWS에서 공식적으로 지원하는 이미지이며, SAP, 시스코와 같은 공급업체가 제공 및 지원 Community AMI 100.000개 이상의 이미지가 제공디고 있으며, 특정한 요구에 맞게 커스터마이징 된 이미지 Private AMI 사용자가 자체 배포한 인스턴스에서 이미지를 생성해서 저장한 이미지, S3에 저장할 수 있으며, 이를 통해 As기능을 사용할 수 있다. #\r#\rEC2 Instacne Type\r#\r#\rAWS는 사용자가 선택한 하드웨어 프로파일, 즉 인스턴스 유형에 따라 하드웨어 리소스를 인스턴스에 할당한다. AWS를 이용하는 사용자는 자신의 니즈에 맞게 인스턴스의 유형을 사용함으로써 자원을 효율적으로 이용할 수 있다. 인스턴스의 유형은 자주 변경되며 AWS Instance Type에서 확인할 수 있다. EC2 인스턴스 유형 패밀리와 최상위 명칭 인스턴스 유형 패밀리 유형 범용 T3, T2, M5, M4 컴퓨팅 최적화 C5, C4 메모리 치적화 X1e, X1, R5, R4, z1d 가속화된 컴퓨팅 P3, P2, G3, F1 스토리지 최적화 H1, l3,D2 #\r범용 서비스 : 컴퓨팅, 메모리, 네트워크, 리소스를 균형 있게 제공하며, 리소스의 확장이 쉽다. M5, M4 : 주로 중소 규모 데이터 운영에 권장되며, M 인스턴스는 실제 호스트 서버에 물리적 연결된 내장 인스턴스 스토리지 드라이브와 함께 제공 컴퓨팅 최적화 : 대규모 요청을 받는 웹 서버와 고성능 머신 러닝 워크로드에 적합 메모리 최적화 : 처리량이 많은 데이터베이스, 데이터 분석, 캐싱 작업에 유용 가속화된 컴퓨팅 : 고성능 범용 그래픽 처리 장치(GPGPU)가 제공되어, 3D 시각화/ 렌더링, 재무 분석, 전산 유체역학 같은 고부하 워크로드 인스턴스에 적합 스토리지 최적화 : 지연시간이 짧은 대용량 인스턴스 스토리지 볼륨을 사용 #\r#\rAWS Region\r#\r#\r사용자는 AWS의 데이터 센터의 서버를 이용할 것이며, 이는 지리적 리전으로 구성되어 있다. EC2 리소스느 사용자가 선택한 리전에서만 관리할 수 있으며, 각 리전에 따라 서비스와 기능은 물론 비용도 다르므로 최신 공식 문서를 확인해야한다. #\r#\rVirtual Private Cloud ( VPC )\r#\r#\rVPC는 사용자가 사용할 네트워크 내부대역을 생성하는 것으로, 프로젝트 단위로 작업을 허용하기 유용하다. 다중 VPC를 생성해도 금액이 발생하지 않으며, NATgateway, VPN 서비스를 사용하는 경우에는 비용이 발생된다. #\r#\r태넌시\r#\r#\rEC2 인스턴스를 시작할 때, 테넌시 모델을 선택할 수 있다. 기본 설정은 공유 테넌시이며, 여러 인스턴스가 한 물리 서버에서 동시에 가상 머신으로 실행된다. #\r#\r인스턴스 동작 구성\r#\r#\r인스턴스를 생성할 때, 이를 부트스트랩이라 하며, 스크립트 파일을 작성하거나, CLI에서 user-data 값을 사용하면 필요한 상태로 인스턴스를 구성할 수 있다. #\r#\r인스턴스 요금\r#\r#\r세 가지 모델 중에서 하나를 선택해 EC2 인스턴스를 구매해서 사용할 수 있다. 요금 모델 설명 온 디맨드 사용자가 사용한 만큼만 비용이 발생하게 구성 예약 미리 사용량을 할당받아 정해진 만큼 지불하며, 1, 3년으로 구성 스팟 특정 리전에서 실행되는 인스턴스 유형에 대해 사용자가 최대 입찰 요금을 입력해서 인스턴스를 사용 #\r#\r리소스 태그\r#\r#\rAWS 계정에 리소스를 다수 배포할수록 추적이 어려워진다. 또한 다수의 VPC, 보안 그룸, 볼륨 등과 연계되면 복잡성은 한 층 더 강해진다. 이를 위해 AWS 계정에서는 리소스를 빠르게 식별할 수 있도록 리소스마다 목적 및 다른 리소스와의 관계 등을 정리할 수 있다. 리소스 태그는 키/ 값으로 구성된다. 키 값 production-server server1 production-server security-grouop1 staging-server server1 test-server security-grouop1 #\r#\r서비스 할당량\r#\r#\r한 리전당 생성할 수 있는 VPC의 수는 5개 허용된 키 페어의 수는 5.000개 그 외의 추가적인 제한은 AWS 최신 할당량 정보 #\r#\rEC2 Storage Voulme\r#\r#\r볼륨은 스토리지 드라이브로, 물리 드라이브를 가상으로 나눈 공간을 의미한다. AWS에서는 여러 유형의 볼륨 드라이브가 있으며, 각 유형이 동작하는 방식이 달라 이해가 필요하다. #\r#\rElastic Block Store Volume ( EBS )\r#\r#\rEBS는 필요한 수 만큼 인스턴스에 연결할 수 있으며, 물리 서버의 하드 드라이브, 플래시 드라이브, USB 드라이브와 유사하게 사용된다. 물리 드라이브에서와 같이 어떤 EBS 볼륨 유형을 선택하느냐에 따라 성능과 비용은 달라진다. AWS SLA에서 99.999%의 가용성으로 충분한 안정성을 가지고 있다. EBS의 볼륨 유형 볼륨 타입 설명 EBS 프로비저닝 된 IOPS SSD 고성능 I/O 작업이 필요할 때 최대 32.000 IOPS와 최대 500MB/s 처리량을 제공한다. EBS 범용 SSD 대다수 일반 서버 워크로드에서 사용되며, 이론적으로 짧은 징녀 시간 성능을 제공한다. 처리량 최적화 HDD 로그 처리와 빅 데이터 작업 등의 높은 처리량을 요구하는 워크로드에 적합한 성능을 저렴한 비용에 제공한다. 콜드 HDD 번번하게 엑세스하지 않는 대용량 작업에 콜드 HDD는 가장 낮은 가격에 제공한다. #\r#\rEBS 볼륨 기능\r#\r#\r모든 EBS 볼륨은 스냅샷을 통해 복사할 수 있고, 기존 스냅샷을 다른 인스턴스에 공유해서 연결할 수 있으며, AMI로 등록할 수 있는 이미지로 변경할 수 있다. EBS 볼륨은 암호화해서 EC2 인스턴스가 저장하거나 송수힌 하는 데이터를 보호할 수 있으며, EBS에서는 내부에서 암호화 키를 자동으로 관리하거나 AWS KMS에서 제공되는 키를 사용할 수 있다. #\r#\r인스턴스 스토어 볼륨\r#\r#\r인스턴스 슽어 볼륨은 EBS 볼륨과는 다른 임시 디스크로, 디스크가 연결된 인스턴스가 종료되었을 때, 영구히 삭제된다. EBS 대신 인스턴스 스토어 볼륨을 사용하는 경우는 다음과 같다. 인스턴스 스토어 볼륨은 인스턴스를 호스팅하고 있는 서버에 물리적 고속 NVMe 인터페이스로 연결된 SSD이다. 인스턴스 스토어 볼륨 요금은 인스턴스 요금에 포함되어 있다. 인스턴스 스토어 볼륨은 단기 역할 수행이나 외부에서 데이터를 가져와서 처리 후, 폐기하는 배포 모델에 적합하다. #\r#\rEC2 인스턴스 엑세스\r#\r#\rEC2 인스턴스는 네트워크에 연결된 모든 장치와 마찬가지로 고유한 IP로 식별 네트워크 인스턴스의 범위 #\r처음 주소 끝 주소 10.0.0.0 10.255.255.255 172.16.0.0 172.31.255.255 192.168.0.0 192.168.255.255 프라이빗 서브넷으로 생성된 인스턴스는 서브넷 내부에서만 통신할 수 있고, 인터넷에는 직접 연결할 수 없다. 다른 리소스와 연결등의 필요로 인스턴스에 여러 네트워크 인터페이스가 있어야 하는 경우, 하나 이상의 가상 탄력적 네트워크 인터페이스를 만들어 연결할 수 있다. #\r#\rEC2 인스턴스 보안\r#\r#\r사용자에게는 무단으로 EC2 인스턴스가 사용되지 않도록 적절하고 효과적으로 엑세스 제어를 구성해야할 책임이 있다. AWS는 이를 위해 보안 그룹, IAM 역할, NAT 인스턴스, 키 페어 등 네 가지 도구를 지원한다. #\r#\r보안그룹\r#\r#\rEC2 보안 그룹은 방화벽 역할을 한다. 보안 그룹의 기본 설정은 수신하는 모든 트래픽을 거부하며, 보안 그룹에 지정한 트래픽 유형만을 허용하는 정책 규칙을 설정한다. 보안그룹은 트래픽 유형만을 허용하는 정책 규칙을 설정하며, 네트워크에서 송수신하느 모든 데이터 패킷은 그 규칙에 따라 평가해서 허용 및 거부된다. #\r#\rIAM\r#\r#\rIAM이란 루트 계정이 아닌, 다른 사용자를 생성하여 역할(권한)을 부여함으로써, 사용가능한 범위를 분리시키는 것 IAM 역할을 사용해서 EC2 인스턴스를 비롯한 AWS 리소스에 엑세스 하는 것에 대한 제어가 가능 #\r#\rNAT 디바이스\r#\r#\r인터넷이 항상 필요한 것이 아닌, 업데이트 등의 주기적으로 필요할 때만 인스턴스에 인터넷을 연결하도록 하는 서비스 NAT 게이트 웨이 or NAT 인스턴스로 프라이빗 게이트웨이를 지정함으로써 사용할 수 있다. #\r#\r키 페어\r#\r#\r키 페어는 암호화방식으로 키 값을 생성 후, 페어에 맞는 키만이 인스턴스의 접속이 가능하도록 한다. #\r#\r기타 EC2 서비스\r#\r#\rAWS System Manager\r#\r#\rSystem Manager은 AWS 클라우드와 온프레미스 인프라를 운영하는 리소스를 모니터링 및 관리하기 위한 도구의 모음 #\r#\r배치 그룹\r#\r#\r배치 그룹은 지연 시간이 짧은 네트워크 상호 연결이 필요한 여러 EC2 인스턴스에 효율적으로 사용된다. 클러스터 그룹은 단일 가용 영역 안에서 물리적으로 접근 및 서로 연결된 인스턴스로 시작 분산형 그룹은 장애 관련 데이터나 서비스 손실 윟머을 줄이기 위해 물리적으로 분리된 하드웨어 인스턴스를 분산 #\r#\rAWS Elastic Container Service와 AWS Fargate\r#\r#\r대규모 Docker 컨테이너 기반에서 실행되는 애플리케이션은 본질적으로 AWS와 같은 플랫폼에 적합 미리 사용된 미리 구축된 Docker를 사용하여 다른 AWS 서비스와 연계하여 사용할 수 있음 #\r#\rAWS Lambda\r#\r#\r서버리스 애플리케이션은 프로그래밍 코드 기반으로 실행 서버에서 동작하지만 사용자가 서버를 제어하는 대신, 사전 설정된 이벤트로 Lambda 서버를 트리거해서 코드를 실행 및 구성 #\r#\rVM Import/ Export\r#\r#\rLocal의 VMware 이미지를 S3를 통해 AWS상에서 사용할 수 있게 하는 서비스 #\r#\rElastic Load Balancing과 Auto Scaling\r#\r#\r로드 밸런서는 효율적으로 트래픽을 관리하고 여러 EC2 인스턴스에 전송해 서버 리소스를 효율적으로 분산하여 사용하는 서비스 #\r#\r2장 요약\r#\r#\rAmazon머신 이미지 ( AMI )를 선택하고 시작할 때 스크립트나 user data를 입력해서 EC2의 기본 소프트웨어 스택을 정의\n인스턴스 유형으로 하드웨어 프로파일을 정하며, 태넌시 설정으로 다른 인스턴스와 물리적 호스트를 공유할 것인지를 결정\nEC2 인스턴스를 비롯한 모든 AWS 리소스에 시스템 전반의 명명 규칙에 따라서 쉽게 식별할 수 있게 태그를 부여할 수 있다.\n리소스의 제한이 있으머, 할당량을 넘는 리소스를 생성할 때에는 추가적인 신청을 해야한다.\n1년 이상 인스턴스를 실행할 때, 온디매드 대신 예약 인스터느를 구매하며 크게 비용을 절약할 수 있다.\n서비스가 끊끼는 게 중요하지 않은 경우, 스팟 인스턴스를 사용하는 것이 합리적이다.\nEBS에는 4가지 볼륨 유형이 있다.\n높은 IOPS와 짧은 지연 시간을 지원하는 두 가지 SSD 유형과 두 가지 기존 하드 디스크 드라이브 유형이 있다.\n볼륨 선택은 워크로드와 예산에 따라 결졍되며, 인스턴스 유형에는 임시 인스턴스 스토어 볼륨이 사용된다.\n일부 EC2 인스턴스 유형에는 임시 인스턴스 스토어 볼륨이 사용되는 데, 스토어 볼륨은 데이터 엑세스는 빠르지만 인스턴스가 종료되면 데이터가 종료된다.\n모든 EC2 인스턴스는 최소 하나의 프라이빗 주소를 가지고 있으며, 인터넷 엑스세가 필요하면 임시 퍼블릭 IP 주소를 할당한다.\nEIP를 통해 영구적인 IP를 할당할 수도 있다.\nEC2 인스턴스를 보호하기 위해서 보안 그룹이라고 하는 소프트웨어 방화벽으로 액세스를 허용하거나 차단하고, IAM 역할, NAT 인스턴스/ 게이트웨이, 키 페어 등이 사용된다.\n#\r#\r시험핵심\r#\r#\rEC2 인스턴스를 프로비저닝하고 시작하는 방법을 이해한다.\n워크로드에 적합한 하드웨어/ 소프트웨어 프로파일을 선택 방법을 이해한다.\nEC2 요금 모델과 필요에 맞는 요금 선택 방법을 이해한다.\n배포 프로파일에 맞게 보안과 액세스의 균형을 조절해서 보안 그룹을 구성하는 방법을 이해한다.\n실행 중인 인스턴스에 액세스하는 방법을 이해한다.\n스토리지 볼륨 유형의 기능과 작동을 이해한다.\n스토리지 볼륨에서 스냅샷 생성 방법과 다른 인스턴스에 스냅샷을 연결하는 방법을 파악한다.\n#\r"},{"id":8,"href":"/cloud/docs/AWS/AmazonWebService/AWS_Computing/","title":"AWS Computing","section":"AWS docs","content":"\rAWS 컴퓨팅 서비스\r#\rEC2 ( Elastic Compute Cloud )\r#\rEC2 공식 홈페이지 가상 컴퓨팅 서비스를 제공해주는 서버로 실제 물리서버와 똑같은 형태의 서비스를 제공 AMI를 통해 필요한 운영체제와 여러 소프트웨어를 쉽게 생성 가능 키 페어를 사용하여 로그린 정보 보호 SSH로 원격 연결이 가능 중지가 가능한 EBS 기반 인스턴스와 임시 스토리지를 제공하여 중지가 불가능한 Instance Store 기반 EC2로 분류 됨 ( 재부팅은 모두 가능 ) 인스턴스의 유형으로는 범용, 컴퓨팅 최적화, 메모리 최적화, 스토리지 최적화 등이 존재 #\rEC2 상태의 종류\r#\rPending : 인스턴스가 구동하기 위해 준비중인 상태, 요금 미청구 Runnung : 인스턴스가 실행하고 사용할 준비가 된 상태, 요금 청구 Stopping : 인스턴스가 중지 모드로 전환되려는 상태, 요금 미청구 Shutting-down : 인스턴스가 종료를 위해 준비중인 상태, 요금 미청구 Terminated : 인스턴스가 종료된 상태, 요금 미청구 #\rEC2 구매옵션\r#\rOn demand : 필요할 때 바로 생성하는 방식으로 1시간 단위로 과금이 이루어짐 ( 1분 사용시도 1시간 ) Spot : 경매방식의 인스턴스 기준가격보다 높은 가격 제시시 사용가능하며, 타인에 의해 불시로 종료되거나 정지될 수 있어 각종 테스트에 적합 Reserved : 12개월- 36개월 단위로 예약하여 사용하는 인스턴스로 On demandq비해 가격이 대폭 할인되며, 장기적으로 사용할 경우 효율이 좋지만, 예약된 인스턴스이기에 사용하지 않아도 과금이 부과되어짐 #\rLightsail\r#\rLightsail Site AWS에서 VPS ( Virtual Private Server : 가상 사설 서버 ) 를 시작하는 가장 쉽고 빠른 방법 가상 사설 서버, 영구적인 스토리지, 네트워킹을 포함 클릭 한 번으로 모든 과정을 생략, 쉽게 VPS를 생성 및 관리 확장가능 및 타 AWS Services에 접근 가능 고가용성 어플리케이션 생성 가능 저렴하고, 비용의 예측이 보다 쉬움 완전히 사전구성되어 있는 서버 ( BluePrint ) #\rLightsail의 유료 Plan\r#\r월간 무료 데이터 허용량 초과시, 퍼블릭 IP 주소를 사용ㅎ여 요금 청구 Lightsail 스냅샷 비용 : 인스턴스 스냅샷 + 디스크 스냅샷 1시간 이상 인스턴스에 연결되어 있지 않은 고정 IP ( Elastic IP ) 무료로 주어지는 3백만 개의 쿼리를 초과하는 경우 #\rLightsail\u0026amp; EC2\r#\rLightsail의 주 사용용도 웹 사이트 및 블로그 단순 앱 개발 및 테스트 환경 소수의 서버로 구성된 비즈니스 소프트웨어 EC2 빅데이터 분석 고성능 컴퓨팅 과학 분야 컴퓨팅 멀티\u0026rsquo;티어 애플리케이션 #\rECS ( Elastic Container Service )\r#\rAWS의 Virtual Machine, VM (가상 머신) 가상의 컴퓨터, 하나의 호스트에 안에 또다른 호스트를 만들어 사용하는 것 CPU, Memory와 같은 주요 하드웨어 부품을 소프트웨어로 완전 재현해내어 기능을 흉내내게 하고(에뮬레이션), 격리된 실행 환경(OS)를 만듬 즉 하드웨어를 직접 가상화 클러스터에서 도커 컨테이너를 손쉽게 관리하기 위해 컨테이너 관리 서비스 클러스터는 Task(작업) 또는 서비스로 일컬어지는 컨테이너들의 집합 #\r2가지 구성 요소로 시작 가능 EC2(Container Instance) : EC2를 생성하여 EC2 내에 Task(컨테이너가 수행할 작업) Fargate : EC2를 생성하거나 컨테이너를 실행하기 위한 Orchestration을 AWS가 맡아 하는 서비스로, 관리가 용이함 하나의 클러스터 내에 다수의 Task 혹은 컨테이너 인스턴스로 구성됨 또한 ELB, EBS 볼륨, VPC, IAM과 같은 기능을 사용하여 구성 가능 즉 ECS 각 작업의 권한, ECS 액세스를 IAM으로 조절하거나, EC2 유형의 컨테이너 인스턴스만이 OS에 액세스 가능한 특징 등을 갖게 됨 호스트의 OS(Operating System) 내에 또다른 실행환경의 OS가 존재함 윈도우 OS의 호스트 내에 리눅스, 우분투 등의 다양한 OS를 올릴 수 있음 다만 OS를 포함하기 때문에 용량을 많이 차지할 뿐더러, 사용자가 필요치 않는 기능까지 포함할 수 있으며 느림 #\rLinux Container\r#\rECS를 사용하는 목적이자 관리 대상 하드웨어가 아닌 OS를 가상화하여 커널을 공유하며 프로세스(컨테이너와 비슷)를 격리된 환경에서 실행하는 것 VM와 달리 달리 호스트의 OS에서 가상화를 실시하여, 이 OS 위에 프로세스들이 ‘컨테이너’로서 격리된 환경에서 실행됨 호스트의 입장에선 컨테이너는 프로세스에 불과하지만, 컨테이너 입장에서는 독립된 실행환경임 OS를 포함하지 않는만큼 가볍고, 하드웨어를 가상화하지 않기 때문에 빠름 #\rKernel\r#\rOperaintg System에서 가장 중요한 역할을 맡고 있는 핵심(核心) 커널이 각 프로세스(실행환경)에 하드웨어 자원(CPU 등)을 할당하고, 작업 스케쥴링(처리순서)를 담당하며, 프로세스 간 접근과 보안을 책임짐 과거에 커널이 없던 시절에도 컴퓨터는 존재할 수 있었으나 메모리를 초기화하기 위해서는 컴퓨터를 리부팅해야 하는 등, 자원관리/제어 주체의 필요성에 의해 탄생 #\rDocker\r#\r앞서 설명한 Linux Container 기술에 근간을 두는 오픈소스 컨테이너 프로젝트 ‘Docker’라는 단어 자체가 ‘부두에서 일하는 노동자’, 즉 컨테이너를 관리하는 존재임을 뜻함 Linux Container 기술을 사용하는 솔루션이므로 별도의 OS를 설치하지 않고 컨테이너를 생성하여 애플리케이션을 실행함 컨테이너를 생성할 이미지(서비스에 필요한 리소스를 모아둔 최소한의 단위)를 기반으로 운영함 이미지만 가지고 있다면 어느 시점에서든 동일한 리소스의 컨테이너를 생성할 수 있음 그 밖에 컨테이너간의 연결, 다양한 API 제공 등의 기능을 보유 #\rLambda\r#\rServerless Service 서버를 구축, 프로비져닝하고 필요한 패키지를 설치하는 등의 과정을 거치지 않고, 코드를 실행하는 서비스 사용자는 애플리케이션이나 백엔드 서비스를 관리할 필요 없이 코드를 실행할 수 있음 CloudWatch, ALB, DynamoDB 등을 트리거로 이용하여 특정 상황에서 코드를 실행시키고 것이 가능 API Gateway와 Lambda를 조합하여 요청별로 특정 코드를 수행하도록 구성 가능 15분을 초과하는 작업에 대해서는 Lambda 비적합 #\rLamda Function의 정의와 구성\r#\r코드를 실행하기 위해 호출할 수 있는 리소스 이벤트를 처리하는 코드, 계층, 트리거, 전달 대상 등으로 구성됨 함수코드 : 실제 호출되기 실행되는 코드, Runtime(코드 실행지원), IAM, VPC, Memory 등으로 구성됨 트리거 : 함수코드를 발동시키는 서비스(S3, SNS, SQS, DynamoDB, CloudWatch Event, Cloudwatch Log 등) SNS의 메시지 구독 대상에 Lambda를 포함시키면, 메시지 발송시 Lambda가 이를 전달받고 함수코드 실행 전달대상 : 함수가 비동기식으로 호출되거나, 레코드를 처리한 경우 전달될 대상 SNS, SQS, 또다른 Lambda, EventBridge 이벤트 버스로 전달가능 NS로부터 메시지를 전달받아 코드를 처리하고 이를 SQS로 보내 메시지 대기열에 적재할 수 있음 #\rEC2 vs Lambda\r#\rEC2 사용시 프로비져닝, 운영 체제, 네트워크 세부 설정, 보안 설정 등을 사용자가 원하는 방향으로 지정 가능 Lambda 사용시 프로비져닝 필요없이 AWS가 모니터링, 프로비져닝, 보안패치 적용, 코드 배포를 모두 수행함 #\rBatch\r#\r종합 관리형 서비스 한 리전 내의 여러 가용 영역에 걸쳐 배치 작업을 실행하는 과정을 간소화하는 리전 서비스 새 VPC 또는 기존 VPC에서 컴퓨팅 환경을 생성할 수 있음 AWS Batch를 사용하면 AWS 클라우드에서 배치 컴퓨팅 워크로드를 실행이 가능 배치 컴퓨팅 : 다수의 사람들이 수 많은 컴퓨터 리소스에 엑세스 할 때 일반적으로 사용하는 방법 #\rAWS Batch의 구성요소\r#\r작업 AWS Batch에 제출한 작업 단위 ( 쉘 스크립ㅌ, Linux 실행 파일, Docker 컨테이너 이미지 ) 작업에는 이름이 있으며, 파라미터를 사용하여 컴퓨팅 환경의 인스턴스에서 컨테이너화된 애플리케이션으로 실행 작업 정의 작업이 실행되는 방식을 지정하며 작업에 있는 리소스에 대한 블루프린트를 의미 IAM 역할을 제공하여 다른 AWS 리소스에 프로그래밍 방식으로 엑세스할 수 있으며 메모리 및 CPU 요구 사항을 모두 지정가능 작업 대기열 AWS Batch 작업이 대기열 예약되는 환경 우선 순위 갑 및 작업 대기열 전체에 우선 순위 할당 가능 컴퓨팅 환경 작업을 싱해하는 데 사용되는 관리형 또는 비관리형 컴퓨팅 리소스 세트 여러 세부 수준에서의 인스턴스 유형의 설정이 가능 #\rBatch Group\r#\r클러스터 : 인스턴스를 AZ 내에서 근접하게 배치, 결합된 노드 간 낮은 지연 시간의 네트워크 달성 가능 파티션 : 인스턴스가 담긴 그룹을 논리 세그먼트로 나누어 각 파티션에 배치, 최대 7개의 파티션을 가질 수 있으며, 각 파티션은 자체 랙 세트를 보유하고 자체 네트워크 전원을 보유 분산 : 파티션이 논리 세그먼트로 분리된 인스턴스 그룹인 것과 달리 분산은 인스턴스 개체 하나가 자체 랙에 분산 배치됨, AZ당 최대 7개의 인스턴스 배치 가능 #\rElastic Beanstalk\r#\rJava, NET, PHP, Node js, Python, Ruby, Go, Docker을 사용하여 Apache, Nginx, Passenger, llS와 같은 친숙한 서버에서 개발된 웹 어플리케이션 및 서비스를 간편하게 배포하고 조정 할 수 있는 서비스 EC2, ASG, RDS 등 AWS 리소스들을 조합하여 완성된 어플리케이션 플랫폼으로 PaaS의 일종 오토 스케일링, 로브 밸런싱, 버전 관리 등의 기능을 콘솔에서 몇 번의 클릭으로 생성 가능 실제 서비스가 아니기에 사용 요금이 없음 #\rElastic Beanstalk의 장점\r#\r간단한 서버 세팅 환경변수들을 쉽게 변경/ 관리가 가능 오토 스케일링이 용이 로그의 자동화 추가요금이 없음 #\r"},{"id":9,"href":"/cloud/docs/AWS/AWSTraining/","title":"AWS Training","section":"Amazon Web Services","content":"\rAmazon Web Service Training\r#\rAWS 시작하기\r#\rAWS 사용자 계정 생성\r#\rAWS CLI 활용\r#\rAWS 사용자 정의 VPC 생성\r#\rAWS EC2 생성\r#\rAWS AMI 생성\r#\rAWS Elastic IP 할당\r#\rAWS ELB ( 2 Tier ) 생성\r#\rAWS AutoScaling\r#\rAWS RDS 생성\r#\rAWS 3Tier 구현\r#\rAWS S3 생성\r#\r#\r#\r#\r#\r#\r"},{"id":10,"href":"/cloud/docs/AWS/AWSTraining/IAM/","title":"AWS 사용자 계정 생성","section":"AWS Training","content":"\rAWS 사용자 계정 생성\r#\r#\rAWS 사용자 계정 생성\r#\r#\r이번 시간에는 AWS 계정생성에 이어 AWS 사용자 계정을 생성해보도록 하겠습니다. IAM이 무엇인지는 AWS IAM을 참고해주세요. #\r#\r먼저 AWS에 로그인 후, IAM 서비스를 검색합니다. #\r#\rIAM 서비스에 진입하여, 메뉴에서 사용자를 클릭합니다. #\r#\r사용자 추가를 선택합니다. #\r#\r사용자의 이름을 기입하고, 엑세스 유형을 선택합니다. AccesskeyId와 SecreKey는 AWS CLI, API, SDK 등 기타 개발 도구의 사용되며, Login url, Password 콘솔창의 로그인시 사용됩니다. #\r유형 AccessKeyId SecreKey Login url Password 프로그래밍 방식 O O X X AWS Management Console Access 방식 X X O O #\r#\r여기서는 프로그래밍 방식 및 AWS Console 방식을 모두 체크하겠습니다. 체크가 완료되면, 편하게 사용할 수 있도록, 직접 암호를 입력합니다. #\r#\r다음으로 그룹에 사용자를 추가하기 위해 그룹을 생성합니다. #\r#\r그룹에는 AdminstratorAccess ( 관리자 권한 ) 역할을 추가합니다. 이 역할에 대해서는 끝에서 다시 한번 다루겠습니다. #\r#\r설정이 완료되면, 다음으로 진행하고, 마지막으로 사용자가 추가됨을 확인할 수 있습니다. 전에 선택한 엑세스 유형에 맞춰 csv 파일의 항목이 다르며, 두 가지를 전부 선택한 저는 엑세스 및 시크릿 키와 url이 전부 포함되어 있습니다. 여기서 다운받는 csv파일은 후에, 같은 값으로는 다운 받을 수 없으니, 삭제되지 않도록 잘 저장해야합니다. #\r#\rurl로 접속 후, 설정한 ID와 비밀번호를 입력하면 해당 User로 접속이 완료됩니다. 이를 통해 특정 유저에게 특정권한만을 주어, 해킹 및 실수 등을 예방 및 관리가 가능합니다. #\r#\rIAM 정책 커스터마이징\r#\r#\rIAM 계정을 생성하며, IAM 정책을 통해 생성그룹에 권한을 부여 했습니다. 그렇다면 IAM 정책을 커스터마이징할 수는 없을까요? 먼저, 정책은 json 파일 형식으로 되어 있으며, 이를 직접 만들기에는 까다로울 수 있지만, 있는 것을 복사한 뒤 수정하는 것은 그렇게 어렵지는 않습니다. ( 또한 최근에는 개념만 충분히 숙지하고 계시면 콘솔 창에서 클릭만으로도 가능합니다\u0026hellip; ) 이번에 이를 확인하여 보겠습니다. #\r#\r먼저 IAM 서비스의 메뉴에서 정책을 선택합니다. 그 후, User 계정을 생성할 때 사용했던 AdminstratorAccess를 선택합니다. #\r#\r그 후, 권한에서 { }json을 클릭 후 해당 내용들을 확인합니다. #\r옵션 Version Statment Effect Action Resource 의미 파일의 버전 파일 정책의 내용 허가 또는 거부 ( Allow or Deny ) 설정 대상 서비스와 대상 조작을 작성 설정 대상 리소스를 작성 즉, 여기에서는 \u0026ldquo;*\u0026rdquo; = 모든 대상 서비스와 대상에 대한 조작은 모두 허가한다는 것입니다. 이 의외에도 특정 IP에 대한 권한만을 주거나 할 수 있으며, 보다 자세한 사항은 IAM 정책 LINK을 참조하시길 바랍니다. #\r#\r그럼 이번에는 직접 정책을 생성해보도록 하겠습니다. 다시 정책으로 돌아와, 상단의 정책생성을 클릭합니다. #\r#\r상단을 보면, 시각적 편집기와 JSON 파일 형식을 확인할 수 있습니다. 여기서는 동일하게 S3에 대한 모든 권한을 가질 수 있는 정책을 생성해보도록 하겠습니다. #\r#\r다음으로는 이름과 설명을 기입 후, 정책을 생성합니다. #\r#\r정책이 생성되면, 정책 필터를 통해 확인이 가능합니다. #\r#\r생성된 정책에 진입하면, 작성했던 Json파일의 내용을 확인할 수 있습니다. #\r#\r다음으로는 다시 정책생성으로 돌아와 콘솔창을 통해 생성해 보도록 하겠습니다. 서비스 : S3\n작업 : 모든 S3 작업\n리소스 : 모든 리소스\n요청 조건 : 선택 안함\n#\r#\r다시 이름과 설명을 기입 후, 정책을 생성합니다. #\r#\r정책 필터를 통해 S3-User로 진입합니다. #\r#\rJson형식으로 확인해보면, Sid를 제외한 값이 모두 동일함을 확인할 수 있습니다. 이를 통해, 콘솔이나 json파일을 통해 동일한 값으로 생성할 수 있음을 알 수 있었습니다. 이에 대한 확인을 IAM을 통해 새로운 계정을 생성 후, 생성한 권한을 주어, S3에 진입 후, bucket을 생성하거나, 혹은 생성해 둔 bucket을 통해 알 수 있습니다. ( S3 권한만을 주었기 때문에, 다른 서비스에 대한 이용은 불가능합니다. ) #\r#\r예제\r#\r#\r예제 1.\r#\r관리자의 권한을 가졌지지만, 엑세스 ID와 비밀 엑세스 키만 가지고 있는 사용자를 만들어보세요.\r#\r예제 1. 답안\r↕\r사용자 계정을 생성할 시, 엑세스 유형에서 프로그래밍 방식 엑세스만을 선택합니다. 정책에서 admin의 권한을 선택 후 생성합니다. #\r#\r예제 2.\r#\r모든 EC2에 대한 읽기권한만을 가지고, 현재 IP만이 사용가능한 정책을 생성하세요.\r#\r예제 2. 답안\r↕\r편집기 사용시 서비스 : EC2\n작업 : 읽기\n리소스 : 모든 리소스 요청조건 : 소스 IP ( 자신의 IP )\n#\rJson 사용시 { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:GetDefaultCreditSpecification\u0026#34;, \u0026#34;ec2:DescribeTags\u0026#34;, \u0026#34;ec2:GetCoipPoolUsage\u0026#34;, \u0026#34;ec2:DescribeVpnConnections\u0026#34;, \u0026#34;ec2:GetEbsEncryptionByDefault\u0026#34;, \u0026#34;ec2:GetCapacityReservationUsage\u0026#34;, \u0026#34;ec2:DescribeVolumesModifications\u0026#34;, \u0026#34;ec2:GetHostReservationPurchasePreview\u0026#34;, \u0026#34;ec2:DescribeFastSnapshotRestores\u0026#34;, \u0026#34;ec2:GetConsoleScreenshot\u0026#34;, \u0026#34;ec2:GetReservedInstancesExchangeQuote\u0026#34;, \u0026#34;ec2:GetConsoleOutput\u0026#34;, \u0026#34;ec2:GetPasswordData\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:DescribeScheduledInstances\u0026#34;, \u0026#34;ec2:DescribeScheduledInstanceAvailability\u0026#34;, \u0026#34;ec2:GetEbsDefaultKmsKeyId\u0026#34;, \u0026#34;ec2:DescribeElasticGpus\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;IpAddress\u0026#34;: { \u0026#34;aws:SourceIp\u0026#34;: \u0026#34;자신의 IP\u0026#34; } } } ] } #\r#\r예제 3.\r#\r예제 2에서 생성한 정책을 편집하여 RDS에 대한 모든 권한을 주는 정책을 생성하고, EC2에서의 IP제한에 대한 설정을 제거해보세요..\r#\r예제 3. 답안\r↕\r예제 2에서 생성한 정책에 진입하여, 기존 정책을 편집 편집기 사용시 요청조건 : 소스 IP의 항목을 체크 제거\n#\rJson 사용시 { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:GetDefaultCreditSpecification\u0026#34;, \u0026#34;ec2:DescribeTags\u0026#34;, \u0026#34;ec2:GetCoipPoolUsage\u0026#34;, \u0026#34;ec2:DescribeVpnConnections\u0026#34;, \u0026#34;ec2:GetEbsEncryptionByDefault\u0026#34;, \u0026#34;ec2:GetCapacityReservationUsage\u0026#34;, \u0026#34;ec2:DescribeVolumesModifications\u0026#34;, \u0026#34;ec2:GetHostReservationPurchasePreview\u0026#34;, \u0026#34;ec2:DescribeFastSnapshotRestores\u0026#34;, \u0026#34;ec2:GetConsoleScreenshot\u0026#34;, \u0026#34;ec2:GetReservedInstancesExchangeQuote\u0026#34;, \u0026#34;ec2:GetConsoleOutput\u0026#34;, \u0026#34;ec2:GetPasswordData\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:DescribeScheduledInstances\u0026#34;, \u0026#34;ec2:DescribeScheduledInstanceAvailability\u0026#34;, \u0026#34;ec2:GetEbsDefaultKmsKeyId\u0026#34;, \u0026#34;ec2:DescribeElasticGpus\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, } ] } #\r예제 2에서 생성한 정책에 진입하여, 정책 편집을 클릭 후, 권한 추가 편집기 사용시 서비스 : RDS\n작업 : 모든 RDS에 대한 작업\n리소스 : 모든 리소스 요청조건 : 없음\n#\rJson 사용시 { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;RDS:*\u0026#34;, \u0026#34;ec2:GetDefaultCreditSpecification\u0026#34;, \u0026#34;ec2:DescribeTags\u0026#34;, \u0026#34;ec2:GetCoipPoolUsage\u0026#34;, \u0026#34;ec2:DescribeVpnConnections\u0026#34;, \u0026#34;ec2:GetEbsEncryptionByDefault\u0026#34;, \u0026#34;ec2:GetCapacityReservationUsage\u0026#34;, \u0026#34;ec2:DescribeVolumesModifications\u0026#34;, \u0026#34;ec2:GetHostReservationPurchasePreview\u0026#34;, \u0026#34;ec2:DescribeFastSnapshotRestores\u0026#34;, \u0026#34;ec2:GetConsoleScreenshot\u0026#34;, \u0026#34;ec2:GetReservedInstancesExchangeQuote\u0026#34;, \u0026#34;ec2:GetConsoleOutput\u0026#34;, \u0026#34;ec2:GetPasswordData\u0026#34;, \u0026#34;ec2:GetLaunchTemplateData\u0026#34;, \u0026#34;ec2:DescribeScheduledInstances\u0026#34;, \u0026#34;ec2:DescribeScheduledInstanceAvailability\u0026#34;, \u0026#34;ec2:GetEbsDefaultKmsKeyId\u0026#34;, \u0026#34;ec2:DescribeElasticGpus\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, } ] } "},{"id":11,"href":"/cloud/docs/OpenStack/OpenStack/Keystone/","title":"Keystone","section":"OpenStack docs","content":"\r인증을 관리하는 서비스 : Keyston\r#\r#\r인증을 관리하는 서비스 : Keystone\r#\r#\rKeystone은 인증 토큰을 비롯해 테넌트 및 사용자 관리, 서비스의 엔드포인트 URL 등을 관리하는 서비스 Keystone은 openstack의 백엔드에서 RBAD ( Role Based Access Control )을 통해 사용자의 접근을 제어하는 등의 인증 ( Identify ) 서비스로 사용되며 다음과 같은 기능으로 이루어져 있음 #\r#\rKeystone의 구성요소\r#\r#\r#\r구성요소 역할 user 사람 또는 오픈 스택 서비스를 이용하는 서비스 ( nova, neutron, cinder 등 )을 의미 User은 특정 프로젝트에 할당할 수 있으며, 증복을 허용하지 않음 Authentication 사용자의 신분을 확인하는 절차로, 특정 값을 통해 Keystone이 이를 검증 보통 인증을 위한 자료로는 ID, PW가 사용되며 Keystone은 인증확인 시 인증토큰을 방행 Token RBAD의 신분을 증명하기 위해 사용되는 텍스트 데이터 Token type fernet, uuid, pki, pkiz 어떤 자원에 접근이 가능한지 범위가 지정되어 있음 ( 시간 제한 있음 ) Project Keystone V2까지 Tenant라는 이름으로 사용 ( V3 이후 Project ) 어떤 자원이나 어플리케이션에 대한 권리를 가진 보안그룹 프로젝트는 특정 도메인에 의해 소유 Endpoint 사용자가 서비스를 이용하기 위해 연결정보를 제공하는 접근 가능한 네트워크 주소 ( URL ) EndPoint type admin, internal, public Role 사용자가 어떤 동작을 수행하도록 허용하는 규칙 사용자가 가지는 역할은 사용자에게 발행된 토큰을 통해 확인 사용자가 서비스를 호출하면, 서비스는 토큰에 저장된 사용자의 역할을 해석하여 허용유무 결정 Domain 구성요소를 효과적으로 관리하기 위한 사용자, 그룹, 프로젝트의 집합 사용자들은 한 도메인의 관리자의 권한 등을 부여받는 방식으로 역할을 부여가능 #\rDomain, Project, Group, User, Rule 개념과 관계\r#\rKeystone은 위에도 언급하였 듯이 사용자 인증 부분과 서비스 인증 부분을 관리 사용자일 때는 사용자 ID와 패스워드, 사용자 권한의 롤( Roll )을 등록 서비스일 때는 서비스를 등록하고 해당 서비스의 엔드포인트 URL을 등록 도메인(Domain)은 서로 분리되어 있음 각 도메인에는 프로젝트와 사용자가 있음 프로젝트는 사용자를 가질 수 있음 사용자에게는 롤이 있으며, 여러 프로젝트의 구성원이 될 수 있음 관리자 롤(Admin Role)을 가진 사용자끼리, 일반 사용자롤(Member Role)을 가진 사용자간의 그룹핑(Grouping)을 할 수 있음 #\r#\rKeystone의 논리 아키텍처\r#\r#\rKeystone의 논리 아키텍처는 토큰(Token), 카탈로그(Catalog), 정책(Poliy), 인증(Identity) 으로 구성 #\r구성요소 역할 Token Backend 사용자별 토큰을 관리 Catalog Backend 오픈스택에서 모든 서비스의 엔드포인트 URL을 관리 Policy Backend 테넌트, 사용자 계정, 롤 등을 관리 Identity Backend 사용자 인증을 관리 #\r#\rOpenstack에서 Keystone 위치\r#\r#\r#\rOpenstack Keystone은 모든 서비스를 관장하는 위치 모든 User, Service는 Keystone의 인증을 통해서만 요청, 응답이 가능 Keystone은 타인이나 해커에게서 시스템을 안전하게 보호하고 사용자 등록, 삭제, 권한 관리, 사용자가 접근할 수 있는 서비스 포인트 관리와 다른 API들의 인증 등의 전체적인 인증 프로세스를 관리하는 역할을 수행 #\r"},{"id":12,"href":"/cloud/docs/AWS/AWSSAA/SAA-3/","title":"3장 S3와 Glacier","section":"AWS SAA 시험정리","content":"\r3장 Amazon Simple Storage Service와 Amazon Glacier Storage Service\r#\r#\r3장의 목표\r#\r복원력을 갖춘 아키텍처 설계\n안정적이고/ 복원력을 갖춘 스로티리지를 선택한다. 어떻게 멀티 티어 아키텍처 솔루션을 설계할지 결정한다. 어떻게 고가용성 및 내결함성을 갖춘 아키텍처를 설계할지 결정한다. 성능이 뛰어난 아키텍처 정의\n성능이 뛰어난 스토리지 및 데이터베이스를 선택한다. 탄력성과 확장성을 갖춘 솔루션을 설계한다. 안전한 애플리케이션 및 아키텍처 설명\n어떻게 애플리케이션 티어를 보호할지 결정한다. 어떻게 데이터를 보호할지 결정한다. 비용에 최적화된 아키텍처 설게\n어떻게 비용에 최적화된 스토리지를 설계할지 결정한다. #\r#\rAmazon simple Storage Service ( 이하 S3 )\r#\r#\rS3는 개인 애플리케이션, 다수 AWS 서비스의 데이터를 보관하며,다음 워크로드를 위한 훌륭한 플랫폼이다.\nS3의 주요기능\n백업 아카이브 로그 파일, 재해 복구 이미지 유지 관리 분석을 위한 데이터 저장 정적 웹 사이트 호스팅 #\rS3는 객체 스토리지로, 전 장에서 배운 EC2는 인스턴스를 구동하는 반면 S3는 무제한 객체 스토리지 공간을 효과적으로 제공한다.\n객체 스토리지와 블록 스토리지의 차이점\nType 차이점 예시 블록 스토리지 물리적 디스크를 개별 블록으로 나눠 데이터를 저장하고 파일 시스템으로 관리 Window NTFS, Linux Btrfs, ext 등 객체 스토리지 구조화되지 않은 평면의 저장소에 데이터를 저장하여 무제한의 스토리지를 구현가능 S3, swift 등 S3에 파일을 쓸 때는 2KB 메타 데이터가 함께 저장되며, 이 메타 데이터는 세부 정보를 구성하는 키로 만들어지며, 데이터 사용 권한과 파일 시스템처럼 보여지는 중첩 버킷 내 위치 정보 등이 저장된다. #\r#\rS3 서비스 아키텍처\r#\r#\rS3 파일은 버킷으로 구성되며, AWS 계정당 기본으로 만들 수 있는 버킷은 100개이다.\n버킷 또한 할당량에 초과사용을 요청할 수 있다.\nS3 버킷은과 내용은 한 AWS 리전에만 존재하며, 버킷의 주소는 S3 글로벌 시스템 내에서 유일해야한다. ( 증복이 허용되지 않음 )\n이는 버킷에 보다 쉽게 접속하기 위해 규칙을 정해놓은 것이다.\n$ https://[ bucketname ].s3.[ region code ].amazon.com/[ filepath ] # 엑세스를 위한 URL $ s3://[ bucketname ]/[ filepath ] # CLI 환경에서의 엑세스 이론적으로 버킷에는 무한정의 대이터를 저장할 수 있지만, 단일 객체의 크기는 5TB를 넘을 수 없고, 한 번에 용량에 업로드할 수 있는 용량 크기는 최대 5GB이다.\n100MB보다 큰 객체를 업로드시에는 멀티 파트 업로드를 사용해서 데이터의 손실 및 업로드가 중지되는 위험을 줄일 수 있다.\n멀티 파워 업로드 : 데이터를 나눠서 업로드 하는 방식 ( ex : 분할 압축 ) 단, 상위 수준의 API에서는 멀티 파트 업로드가 자동이지만, 하위 수준에서는 수동으로 나눠야 한다.\n#\r#\r암호화\r#\r#\r웹 사이트와 같이 퍼블릭에서 엑세스하는 용도가 아니라면, S3에 저장할 데이터는 항상 암호화해야 한다.\nS3에 저장 중인 데이터를 보호하기 위해서 암호화 키를 사용할 수도 있고, S3에서 다른 위치로 전송하는 데이터를 보호하기 위해서 Amazon 암호화 API 엔드포인트 만을 사용할 수 있다.\n저장 중 데이터는 서버 측 암호화 혹은 클라이언트 측 암호화를 사용해서 보호할 수 있다.\n#\r서버 측 암호화 서버 측의 암오화는 S3 플랫폼 자체의 암호화를 의미하며, 데이터 객체를 암호화해서 적합한 인증으로 복호화하는 작업이 AWS에서 이루어진다. Amazon S3가 관리하는 암호화 키(SSE-S3)를 사용하면 AWS가 자체 엔터프라이즈 표준 키를 사용해 암호화 복호화 프로세스의 모든 단계를 관리한다. AWS KMS-관리형 키를 사용하는 서버 측 암호화(SSE-KMS)를 사용하면 SSE-S3가 제공하는 기능에 더해 완벽한 키 사용 추적과 봉투 키를 사용할 수 있다. 고객 제공 암호화 키에 의한 서버측 암호화(SSE-C)는 고객이 S3에 제공한 자체 키로 객체를 암호화 한다. #\r클라이언트 측 암호화 S3로 데이터를 전송하기 전에 암호화하는 것으로, AWS KMS-관리현 고객 마스터 키(KMS-CMK)를 사용하며, 업로드 전에 고유 키로 객체를 암호화한다. 복잡한 암호화 절차를 단순화하기 때문에 서버 측 암호화를 많이 사용하지만, 회사 내에서 암호화 키의 모든 권한을 가지고 있어야 하는 경우도 있을 때 주로 사용된다. #\r로깅 S3 이벤트 추적을 로그 파일에 저장하는 기능은 처음에는 비활성화 되어있다.\nS3 버킷에서 일어나는 많은 활동을 로그 데이터로 만들어 기록할 필요 없기 때문이며, 로그파일을 기록하는 것을 이를 로깅이라한다.\n로깅을 활성화 할 때는 원본 버컷과 대상 버킷을 지정해야 하며, 하나의 대상 버킷에 여러 원본 버킷 로그를 저장했을 때 쉽게 시벽할 수 있도록 구분 기호와 접두사를 사용한다.\nS3는 CloudWatch나 CloudTrail와 같은 AWS 서비스 및 다른 서버들의 로그저장하는 데에도 사용된다.\nS3 생성 로그는 구성화면, 잠시 후 다음과 같은 작업 상세 항목이 기본으로 나타난다.\n요청자 게정과 IP 주소 원본 버킷 이름 요청 동작(GET, PUT) 요청 개시 시간 응답 상태 ( 오류 코드 포함 ) #\r#\rS3 내구성과 가용성\r#\r#\r객체를 저장할 때 여러 S3 스토리지 클래스 중에서 선택할 수 있으며, 내구성, 가용성, 지출가능 비용에 따라 선택한다. 관련용어 설명 키워드 설명 내구성 데이터가 손실되지 않을 확률 가용성 객체가 사용 가능한 기간 지출가능 비용 사용시 지불해야하는 가격 #\r#\r내구성 내구성은 백분율로 측정되며, Amazon Glacier의 경우 99.999999999% 내구성을 보장하는 데 이는, 10.000.000개의 객체를 저장하면 1만 년 동안 객체가1개 손실될 확률을 의미한다.\n즉 S3 Standard/Glacier 플랫폼에 저장한 데이터를 인프라 장애로 손실할 가능성은 거의 없다고 볼 수 있다.\nS3는 최소 3개의 가용 영역에 데이터를 자동으로 복제하기 때문에, 높은 내구성을 보장할 수 있다.\n하지만 복원력이 없는 두 클래스도 존재하는 데, Amazon S3 One Zone-IA(Infrequent Access)은 단일 가용 영역에만 저장하며, RRS(Reduced Redundancy Storage)는 다른 클래스보다 적은 영역에 복제하기 때문에 99.99% 내구성만을 보장한다.\n#\rS3 스토리지 안정성 보장 표준 S3 Standard S3 Standard-IA S3 One Zone-IA RRS 내구성보장 99.999999999% 99.999999999% 99.9999999999% 99.99% 내결함성을 위한 동시 복제 시설 수 2 2 1 1 #\r#\r가용성 객체 가용성도 백분율로 측정하며, 1년 동안 해당 객체를 요청했을 때 즉시 응답할 수 있는 기간을 백분율로 나타낸다.\n만약 Amazon S3 Standard 클래스는 연간 99.99%의 가용성을 가지고 있는 데, 이는 1년 동안 중단 시간이 1시간 이내를 의미한다.\n#\r#\rS3 스토리지 표준 가용성 보장 S3 Standard S3 Standard-IA S3 One Zone-IA RRS 가용성 보장 99.99% 99.9% 99.5% 99.99% #\r데이터의 최종 일관성 S3는 데이터를 여러 장소에 복제하므로, 기존 데이터가 업데이트되면 시스템에 전파하느 동안에 지연시간이 발생할 수 있다. 단 이는 객첼르 생성(PUT) 할 때에는 객체 버전이 충돌할 가능성이 없으므로, 쓰기 후 읽기 일관성이 제공된다. #\r#\r객체 수명 주기\r#\r#\rS3에서 시작하는 워크로드는 대개 백업 아카이브와 관련이 있다.\n백업 아카이브는 주기적으로 저장되므로 이에 대한 관리가 필요한 데, S3버전 관리를 통해 해결이 가능하다\n#\r버전 관리 기본적으로 동일한 파일을 업로드 시키는 경우에는 덮어씌어지는 데, 이는 심각한 문제를 초래할 수 있다. S3도 이와 동일하게 작동하지만, 버킷 수준에서 버전 관리를 활성화하게 되면 이전 객첼르 보존할 수 있어, 기존 버전에 계속 엑세스 하는 것이 가능하다. #\r수명 주기 관리 버킷에서 수명 주기 규칙을 구성하면 지정한 기간이 경과했을 때 자동으로객체가 다른 스토리지 클래스로 옮겨진다. 예를 들면 첫 30일동안은 S3 Standard 클래스에서 보관되지만, 그 이후에는 보다 저렴한 One Zone IA으로 옮겨진다. 과거 버전을 지속저으로 유지해야하는 경우 장기 저장용 Storage 서비스 Glacier으로 365일 보관이 가능하다. #\r#\rS3 객체 엑세스\r#\r#\rS3에 데이터를 저장해서 사용하겠다고 결정했다면 중요성에 맞게 S3에 저장된 객체에 엑세스하는 방법과 업무의 보안상 필요에 맞는 요청만 엑세스하도록 제한하는 방법이 필요하다. #\r#\r엑세스 제어 외부 사용자는 버킷의 객체에 엑세스가 불가능하지만, ACL (엑세스 제어 목록), S3 버킷 정책, IAM 정책을 통해서 버킷이나 객체 수준에서 접근이 가능토록 할 수 있다. 위와 같은 ACL, S3 버킷 정책, IAM은 일부 중복되어 있으며, 이는 점차 서비스가 발전해오면서 새로운 기능이 추가된 서비스가 생성되었기 때문이다. 현재는 ACL대신 S3 버킷 정책이나 IAM을 사용하길 권장하고 있다. S3 버킷 정책 (JSON 형식으로 S3 버킷에 연결)은 외부 계정과 사용자가 S3 버킷에 엑세스하는 것을 제어할 수 있는 반면, IAM 정책은 IAM이 관리하느 계정, 즉 사용자와 역할이 S3를 비롯한 여러 리소스에 엑세스하는 방식을 제어하고자 할 때 사용된다. #\r#\r미리 서명된 URL 외부 엑세스가 제한된 프라이빗 객체에 임시로 엑세스할 수 있게 할 때, 미리 서명된 URL을 사용할 수 있다. 미리 서명된 URL은 시간 제한이 존재하며, 기간이 지나면 사용이 불가능해지며 프로그래밍 방식으로 객체에 엑세스가 가능하다. $ aws s3 presign s3://[ MybucketName ] /[ FilePath ] --expires-in [ second ] # second 만큼의 초 시간의 특정 File의 엑세스를 허용하는 CLI 명령어 #\r#\r정적 웹 사이트 호스팅\r#\r#\rS3 버킷은 정적 웹 사이트 HTML 파일 호스팅에도 사용 정적 웹 사이트는 웹 페이지와 스크립트를 랜더링할 때 서버가 아닌 클라이언트 시스템 서비스를 사용 $ aws s3api put-bucket-acl --bucket [ MybucketName ] --acl Public-read # 버킷의 호스팅 설정을 추가하는 CLI 명령어 $ aws s3 website s3://[ MybucketName ] --index-document index.html --error-document error.html $ 버킷의 정적 웹 사이트를 호스팅하며 메인 페이지와 에러 페이지를 설정한다. ( 수정 가능 ) #\r#\rS3 Select와 Glacier Select AWS는 S3나 Glacier에 저장한 데이터에 엑세스할 수 있는 또 다른 방법을 제공하는 데, 이를 Select이라 한다. 이를 사용하면 SQL와 유사한 쿼리로 저장된 객체에서 관련 데이터만 검색하는 것이 가능ㅎ다ㅏ. #\r#\rAmazon Glacier\r#\r#\rGlcanier는 S3 스토리지 클래스의 일부로 Glacier는 대부분 S3 클래스와 마찬가지로 99.999999999% 내구성을 보장하고, S3 구셩 주기에 통합할 수 있다. 단 S3와 다른 점은 S3는 단일 객체 최대 크기가 5TB인 반면, Glacier은 40TB까지의 대형 아카이브를 지원하고, S3에서는 암호화를 선택해야하지만, Glacier는 인간이 읽을 수 없는 ID가 주어진다. Glacier의 단점은 데이터를 가져오는 데 걸리는 시간으로 S3는 즉시 엑세스가 가능하지만, Glacier 아카이브에서 객체를 가져오려면 몇 시간이 걸릴 수도 있다. 이와 같이 Glacier의 목적은 데이터의 필요성과 사용빈도가 낮은 한경에서 장기적으로 데이터를 보관할 수 있는 저렴한 스토리지로 사용할 수 있다는 것이다. #\r#\r스토리지 요금\r#\r#\r스토리지 요금은 버전 관리와 객체 수명주기로 계속해서 파일이 이동하므로 과정이 복잡하다 할 수 있다. 서울 리전 스토리지 요금 예시 클래스 스토리지 용량 요금/GB/월 비용/ 월 Standard 20G $0.018 $0.36 Standard 65G $0.0144 $0.938 Standard 520G $0.005 $2.6 합계 $3.398 이 외에도 트래픽 관련 요금이 부과되며 기타 모든 요금에 대한 정보는 여기에서 확인할 수 있다. AWS 월 사용량 계산기 #\r#\r기타 스토리지 관련 서비스\r#\r#\rAWS에는 S3, Glacier 이외에도 다양한 Storage Service 있다. #\rAmazon Elastic File System ( EFS ) EFS자동 확장 가능한 공유 파일 스토리지 서비스. 동일 VPC 내의 Network File System ( NFS )으로 여러 EC2 인스턴스에 장착한다. AWS Direct Connect 연결로 온프레미스 서버에서 엑세스할 수 있도록 설계되어 있다. #\r#\rAWS Storage Gateway 온 프레미스의 로컬 백업과 아카이브 운영 요구 사항을 클라우드 스토리지 서비스를 사용해 해결하려면 복잡하진다. AWS Storage Gateway는 소프트웨어 형식의 게이트웨이로 VMware, EC2 ,Hyper-V 와 등에 사용하면 보다 쉽게 S3, EBS로 데이터의 이전이 가능하다. #\r#\rAWS Snowball 대용량 데이터 세트를 일반 인터넷 연결로 클라우드에 마이그레이션하려면 많은 시간과 대역폭이 필요로 한다. 테라 혹은 페타바이트 크기의 데이터를 옮길 때문 AWS에서 256비트로 암호화한 물리적 장치인 Snowball을 사용자에게 배송하며, 이를 AWS다시 수거해 S3에 올려준다. #\r#\r요약\r#\r#\rAmazon S3는 적은 유지 관리 노력으로 대용량 아키이브와 데이터 스토리지를 운영할 수 있도록 안정성과 고가용성을 갖춘 객체 스토리지를 제공한다.\n객체는 게층화 돼 있지 않은 버킷에 저장되어 있지만, 접두사를 사용해서 일반 파일 시스템에 있는 것처럼 보일 수 있다.\nAWS가 제공하는 암호화 키 또는 자체 암호화 키를 사용해 S3 자체 데이터를 암호화 할 수 있으며, 대개 필수로 데이터를 암호화한다.\n암호화의 종류로는 서버 측 암호화, 클라이언트 측 암호화로 저장 중 암호화가 이루어진다.\nS3는 데이터 복제 정도가 다른 여러 스토리지 클래스를 제공해서 사용자가 내구성, 가용성, 비용을 고려해서 선택할 수 있게 한다.\n기존 ACL, S3 버킷 정책, IAM을 통해 보안 주체, 대상, 시간을 제어할 수 있다. 일시적으로 제한된 데이터 엑세스를 제공하는 안전한 방법으로는 미리 서명된 URL을 사용한다.\nSQL과 유사한 S3 Select와 Glacier Select를 사용하면 데이터 요청 크기와 비용을 줄일 수 있으며, S3 버킷에 저렴하고 간단한 정적 웹 사이트를 만들 수도 있다.\nAmazon Claier은 데이터 아카이브를 볼트에 저장하고 가져올 때는 몇 시간이 걸리지만, S3 스토리지 클래스보다 비용이 저렴하다.\n#\r#\r시험 핵심\r#\r#\rS3 리소스 구성되는 방식을 이해한다. S3 객체는 버킷에 저장되는 데, 버킷 이름은 글로벌하게 고유해야 하며, 버킷은 Region과 연결된다. 객체는 구조화되지 않은 버킷에 저장되지만 접두사와 기호를 사용해서 데이터에 폴더 게층 구조를 나타낼 수 있다. #\r데이터 전송을 최적화하는 방법을 이해한다. S3 버킷에 저정하는 개별 객체의 크기는 5TB이며, 100MB보다 큰 객체는 멀티 파트 업로드를 사용해야 한다. 5TB보다 큰 객체는 멀티 파트 업로드 이외의 다른 업로드 방법이 없다. #\rS3 데이터 보안 방법을 이해한다. AWS에서 생성한 키 또는 비공개 키로 서버 측 암호화를 사용하면 S3 버킷 내에서 데이터를 보호할 수 있다. 클라이언트 측 암호화를 사용해 S3 전송되기 전에도 데이터를 암호화 할 수 있다. #\rS3 객체의 내구성과 가용성을 측정하는 방법을 이해한다. 다양한 S3 클래스와 Glacier는 여러 수준에서 인프라 안정성과 데이터 가용성을 약속한다. #\rS3 객체 버전 관리와 수명 주기 관리를 이해한다. 객체를 덮어 쓴 뒤에도 덮어쓰기 전 객체를 보존해서 액세스 할 수 있다. 지연 시간이 짧은 스토리지 클래스에 지연 시간이 긴 클래스로 자동 전환하는 방법은 오래된 객체를 관리할 수 있고, 최종적으로 삭제 예약 또한 가능하다. #\rS3 객체를 보호하는 방법을 이해한다. 기존 버킷과 객체 기반 ACL 규칙으로 엑세스를 제어할 수 있고, 더욱 유연한 S3 버킷 정책이나 곚어 수준 IAM 정책으로 엑세스를 제어할 수 있다. 미리 서명된 URL를 통해 임시로 엑세스를 허용할 수 있다. #\r정적 웹 사이트를 만드는 방법을 이해한다. S3에 HTML, 미디어 파일을 저장하고 Route 53과 CloudFront를 사용해서 DNS 도메인 이름으로 액세스 할 수 있는 암호화된 HTTPS 페이지 웹사이트로 제공할 수 있다. #\rS3와 Glacier의 차이를 이해한다. Glacier는 자주 요청되지 않으리라고 예상하는 데이터 아카이브를 위한 저렴한 장기 보존 스토리지이다. "},{"id":13,"href":"/cloud/docs/AWS/AWSTraining/Cli/","title":"AWS CLI 활용","section":"AWS Training","content":"\rAWS CLI 활용\r#\r#\rAWS CLI 활용\r#\r#\r이번 시간에는 AWS CLI을 활용하는 방법에 대해 알아보도록 하겠습니다. AWS CLI의 대한 개념과 설치는 AWS CLI를 참고해주세요. #\r#\rAWS CLI 기본설정\r#\r#\r먼저 여기서는 Window 10, Powershell에서 진행하도록 하겠습니다. Linux나 Mac 등 타 OS도 AWS CLI가 설치되어 있으면 모두 동일하니 똑같이 진행하셔도 문제없습니다. #\r#\r먼저 프롬프트 혹은 터미널을 실행 후, aws configure을 입력합니다. 그러면 엑세스 키와 시크릿 키, 리전 그리고 파일형식을 입력하는 값이 나오는 데, 만약 전 시간에서 사용자 계정을 만들면서 학습했던 프로그래밍 엑세스 방식이 생각나신다면, 한결 수월하게 해결하실 수 있습니다. 혹시 모르시거나 깜박하신 분들은 AWS IAM, AWS 사용자 계정 생성을 참고해주세요. #\r$ aws configure # aws 인증 값 등록 AWS Access Key ID [ AcceseeKeyId ]: ********* # 계정의 AccessKeyId를 입력 AWS Secret Access Key [ SecretAccessKey ]: ******** # 계정의 SecretAccesskey를 입력 Default region name [ Region ]: ap-northeast-2 # 리전의 이름을 입력 Default output format [ File format ]: json # 파일의 포맷 형식을 입력 $ aws ec2 describe-security-groups # 확인 ( 차후에 명령어에 대해 설명드리겠습니다. ) #\r#\rAWS CLI 사용방법\r#\r#\r그럼 이제 본격적인 CLI 사용방법에 대해 알아보도록 하겠습니다. #\rprofile을 설정\r#\r#\r위에서 configure을 통해 aws CLI을 사용하기 위한 인증을 마쳤습니다. 하지만 만약 인증을 마친 유저에 대한 권한이 다르다면, 또 다른 계정을 사용해야 한다면 어떻게 해야할까요? 이를 위해 AWS CLI에서는 \u0026ndash;profile 명령어를 통해 별도이 설정파일로 저장할 수 있습니다. #\r$ aws configure --profile [ User ] AWS Access Key ID ... : *** ... Default output format ... : *** # 개별 설정파일 등록 $ aws [ 명령어 ] --profile [ User ] $ [ User ]의 권한으로 명령어를 실행 위의 명령어를 통해 [ User ]의 profile을 지정 후 저장 후, \u0026ndash;profile [ User ] 옵션을 통해 사용합니다. 등록한 모든 설정파일은 보통 사용자계정 폴더 내부의 .aws에 생성됩니다. #\r#\rAWS CLI 기본적인 명령어 형태\r#\r#\rAWS CLI의 기본적인 명령어 형태는 다음과 같습니다. $ aws [ 서비스 이름 ] [ 리소스 조작 명령어 ] ------------------------------------------------------------------------------------------------- 옵션 | 처리 ------------------------------------------------------------------------------------------------- --profile | 설정한 profile로 명령어를 실행합니다. --region | 리전을 지정합니다. --output | 출력 형식을 지정합니다. --filters | 참조 계열 명령어를 사용할 때, 검색 조건을 지정해서 필터링 합니다. --query | 실행 결과 내용을 압축해서 출력합니다. #\r#\rRegion과 output 옵션을 사용한 검색 조건 지정\r#\r$ aws ec2 describe-security-groups --region ap-northeast-2 --output [ json, text, table ] # ap-northeast-2 리전에서 각 형식으로 ec2 보안그룹에 대한 정보를 참조 각 형식의 차이점을 확인해보세요. #\r#\rfilters 옵션을 사용한 검색 조건 지정\r#\r#\r\u0026ndash;filters 옵션을 사용하면 참조 계열 명령어를 실행할 때, 검색 조건을 지정할 수 있습니다. 지정할 수 있는 \u0026ndash;filters 옵션의 필터 이름은 서비스, 리소스에 따라 차이가 있어 AWS CLI 명령어 레퍼런스를 참고해주세요.. #\r$ aws [ 서비스 이름 ] [ 리소스 조작 명령어 ] --filters \u0026#34;Name=[ 필터 이름 A ], Values=[ 조건A1 ]\u0026#34; \u0026#34;Name=[ 필터 이름 B ], Values=[ 조건B1 ], [ 조건B2 ]\u0026#34; 위와 같이 \u0026ndash;filters의 사용방법은 1개의 필터에 큰 따옴표(\u0026quot;)를 감싸고, \u0026ldquo;Name=\u0026ldquo;에 필터이름, \u0026ldquo;Values=\u0026ldquo;에 필터 이름에 대응하는 조건을 작성하는 것으로, 쉼표(,)를 통해 복수의 조건을 작성하는 것 또한 가능합니다. #\r$ aws ec2 describe-instances --filters \u0026#34;Name=private-ip-address,Values=10.0.0.10\u0026#34; # 프라이빗 ip가 10.0.0.10인 ec2를 참조 $ aws ec2 describe-instances --filters \u0026#34;Name=instance-type,Values=t2.medium, m3.medium\u0026#34; # 인스턴스의 타입이 t2.medium, m3.medium인 인스턴스를 참조 $ ec2 describe-instances --filters \u0026#34;Name=tag:Project,Values=AWS Training\u0026#34; # 태그의 값이 AWS Training인 인스턴스를 참조 $ aws ec2 describe-instances --filters \u0026#34;Name=instance-type,Values=t2.medium, m3.medium\u0026#34; \u0026#34;Name=tag:Project,Values=AWS Training\u0026#34; # 2번째 조건과 3번째 조건을 함께 사용하는 인스턴스 참조 $ aws ec2 describe-images --filters \u0026#34;Name,Values=SampleAMI2020*\u0026#34; # AMI images 중에서 이름이 SampleAMI로 시작하는 모든 인스턴스를 참조 #\r#\rquery 옵션을 사용한 출력 결과 압축\r#\r#\rquery 옵션을 사용해서 명령어를 실행 할 때 실행 결과를 압축할 수 있습니다. filters와 마찬가지로 각 서비스에 따라 사용할 수 있는 query가 다르며 가능한 명령어들은 AWS CLI 명령어 레퍼런스를 참고해주세요. #\r$ aws [ 서비스 이름 ] [ 리소스 조작 명령어 ] --query \u0026#39;[ 쿼리 이름 ( 1계층 )[].쿼리 이름(2 계층)....\u0026#39;] query는 계층 구조로 되어 있습니다. 따라서 AWS CLI 명령어 레퍼런스를 참고해서 계층 구조와 출력할 항목을 query 옵션으로 지정해야 합니다. query은 추가로 json, table 형식으로 출력할 때는 쿼리 이름이 키 ( 별칭 )을 붙여야 하며, \u0026ndash;filter와 마찬가지로 조건을 지정할 수 있습니다. ( \u0026lt;, \u0026lt;=, ==, \u0026gt;=, \u0026gt;, !=) #\r$ aws ec2 describe-instances --query \u0026#39;Reservations[].Instances[].InstanceId\u0026#39; # 모든 인스턴스의 인스턴스 ID를 참조 $ aws ec2 describe-instances --query \u0026#39;Reservations[].Instances[].[InstanceId,PrivateIpAddress]\u0026#39; # 모든 인스턴스의 인스턴스 ID, 프라이빗 IP를 참조하는 방법 $ aws ec2 describe-instances --query \u0026#39;Reservations[].Instances[?InstanceType=\u0026#39;t2.small\u0026#39;].[InstanceId, PrivateIpAddress] --output json # 인스턴스 유형이 t2.small인 것의 인스턴스 ID, 프라이빗 IP를 json형식으로 출력 $aws ec2 describe-instances --query \u0026#39;Reservations[]. Instances[?InstanceType==\u0026#39;t2.small\u0026#39;].{IDLInstanceID,IP:PrivateIpAddress,Name:Tags[?Key==\u0026#39;Name\u0026#39;].Value}\u0026#39; --output json # 인스턴스 유형이 t2.small인 것의 인스턴스 ID, 프라이빗 ID에 ID, IP라는 키를 붙여 JSON 형식으로 출력하는 방법 #\r지금까지 기본적인 AWS CLI에 명령어에 대해 알아보았습니다. 하지만 아직, 인스턴스나 VPC, 각종 서비스에 대해 공부를 하지 않아 아직까지는 간단하게 어떻게 작동되는 지, 어떠한 형식을 가지고 있는 지만 익혀두시면 충분합니다. "},{"id":14,"href":"/cloud/docs/AWS/AmazonWebService/AWS_Database/","title":"AWS Database","section":"AWS docs","content":"\rAWS DataBase\r#\r#\rAmazon RDS ( Relational Database Service )\r#\r분산 관계형 데이터베이스 MariaDB, MySQL, PostgreSQL, Oracle 등을 AWS에서 제공해주는 것 애플리케이션 내에서 관계형 데이터베이스의 설정, 운영, 스케일링을 단순케 하도록 설계된 클라우드 내에서 동작하는 웹 서비스 데이터베이스 소프트웨어 패치하거나 데이터베이스를 백업하거나 시점 복구를 활성화하는 것과 같은 복잡한 관리 프로세스들은 자동으로 관리 스토리지와 연산 자원들을 스케일링 하는 것은 하나의 API 호출로 수행이 가능 관계형 데이터베이스를 AWS 상에서 사용할 수 있도록 지원하는 서비스 생성 후 서비스를 이용하기만 되므로 SaaS에 해당 MySQL, MariaDB, Postgre SQL, Oracle, MS SQL, Aurora 사용 가능 DB 인스턴스에 대한 shell 지원 불가 및 OS 제어 불가능 ( AWS 관리 ) 백업, 소프트웨어 패치, 장애 감지 및 복구를 AWS가 관리 Storage 용량에 대하여 Auto Scaling MariaDB, MySQL, Aurora는 서로 호환이 가능 #\r#\rDB Instance\r#\rRDS의 기본 구성요소로서 클라우드에서 실행하는 격리된 데이터베이스 환경을 의미, 인스턴스 내에서는 여러 사용자가 만든 데이터베이스가 포함되며 엑세스할 여러 도구와 앱 사용 가능 DB 인스턴스도 EC2처럼 다양한 클래스를 가지고 있음 ( db.m5, db.r5 등 ) RDS도 클라우드에서 실행되기 때문에 하나의 AZ에서 격리되어 인스턴스로서 실행 #\rDB Instance Storage\r#\r데이터베이스의 유지를 위패 EBS를 사용하며 필요한 스토리지 용량에 맞춰 자동으로 데이터를 여러 EBS 볼륨에 나누어 저장 스토리지의 유형 범용 SSD: 대부분의 워크로드에서 사용하는 기본적인 스토리지 프로비져닝 IOPS: 빠르고 일관적인 I/O 성능이 필요하고 일관적으로 낮은 지연시간이 요구될 경우 사용하는 스토리지 ( I/O input/ Output ) 마그네틱: 접속 빈도가 적은 워크로드에 적합한 스토리지 #\rMulti-AZ\r#\rRDS는 Multi-AZ라는 기능을 통해 고가용성을 지원 ( 다수의 AZ에 DB 인스턴스를 둠으로써 하나 혹은 그 이상의 AZ가 파괴되어 서브시가 불가능 할 때를 대비 ) 기본 인스턴스가 수행해야할 작업( 백업, 스냅샷 생성 ) 등을 대신하여 수행함으로서 기본 인스턴스의 부담을 줄임 RDS도 클라우드에서 실행되기 때문에 하나의 AZ에서 격리되어 인스턴스로서 실행 기본 인스턴스에서 스냅샷을 캡쳐한 후 다른 AZ에 복원하여 ‘동기식’ 예비 복제본을 생성 Active( AZ A )-Standby ( AZ B, C ) 구조를 형셩한 후 지속적으로 동기화 ‘ 예비 ‘ 복제본이기 때문에 읽기 및 쓰기 작업을 수행할 수 없음 Multi-AZ를 사용하는 경우, 단일 AZ 배포에 비해 쓰기 및 저장 지연 시간이 길어질 수 있음 ( 동기화 문제 ) #\rMulti-AZ\r#\rMulti-AZ를 활성화한 상태에서 DB 인스턴스에 문제가 발생하면 자동으로 다른 AZ의 예비 복제본 ( Standby )로 전환하며 서비스를 이어나감 전환에 사용되는 시간은 60- 120초 전환되는 상황 가용 영역( AZ ) 중단 기본 DB 인스턴스 오류 DB 인스턴스 서버 유형 변경 기본 DB 인스턴스 OS에서 소프트웨어 패치 실시 장애 조치 재부팅( Failover ) 실시 DB Instance Storage\r#\r데이터베이스의 유지를 위패 EBS를 사용하며 필요한 스토리지 용량에 맞춰 자동으로 데이터를 여러 EBS 볼륨에 나누어 저장 Read Replica\r#\r읽기 전용의 복제본, 기본 DB 인스턴스가 읽기와 쓰기를 담당한다면 Read Replica는 읽기 작업만을 담당하여 마스터 DB 인스턴스의 부하를 줄임 우선 DB 마그네틱: 접속 빈도가 적은 워크로드에 적합한 스토리지 #\rAutomated Backup\r#\rRDS의 자동백업으로 개별 데이터베이스를 백업하는 것이 아닌 DB 인스턴스 전체를 백업하는 것 매일매일 백업이 이루어지며, 기본 보존기간은 CLI로 생성시 1일\u0026amp; 콘솔로 생성시 7일이며 최저 1일부터 35일 까지 가능 특정시점을 지정하여 복원가능하며 복원 기간내로부터 최근 5분까지 특정시점을 지정하여 복원 가능 사용자가 백업시간에 자동적으로 백업되며, 백업 중에는 스토리지 I/O가 일시적으로 중단될 수 있음 ( Multi-AZ 사용시 Standby에서 백업 실시 ) 전환되는 상황 가용 영역( AZ ) 중단 기본 DB 인스턴스 오류 DB 인스턴스 서버 유형 변경 기본 DB 인스턴스 OS에서 소프트웨어 패치 실시 장애 조치 재부팅( Failover ) 실시 #\rEnhanced Monitoring\r#\rRDS의 지표를 실시간으로 모니터링하는 ‘ 강화된＇ 모니터링 모니터링 지표는 CloudWatchs Logs에 30일간 저장됨 일반 모니터링과의 차이점은 Enhanced Monitoring은 인스턴스 내 에이전트를 통해 지표를 수집하는 반면, 일반 모니터링은 하이퍼바이저에서 수집 ( 최대 1초 단위 ) #\rRDS vs DB in EC2\r#\rEC2 위에 데이터베이스를 직접 올리는 만큼 설정을 마음대로 변경할 수 있고, 커스터마이징 또한 가능 RDS와는 반대로 백업과 패치 등 관리를 직접해야 함 EC2에 설치하는 것이기에 SSH 접속 가능 #\rAmazon DynamoDB\r#\r종합 관리형 NoSQL 데이터베이스 서비스로, 원할환 확장성과 예측 가능한 성능을 제공 데이터 규모에 관계없이 데이터를 저장 및 검색하고, 어떤 수준의 요청 트래픽이라도 처리할 수 있는 데이터베이스 테이블의 생성이 가능 배포가 단순하고 신속, 설계를 해서 데이터베이스의 적용까지 많은 시간이 소요되지 않음 확장이 단순하고 신속, 단순한 인터페이스의 유리 온 디맨드 백업기능 제공 #\rDynamoDB의 특징\r#\r배포가 단순하고 신속 확장이 단순하고 신속, 수백만 IOPS 데이터는 자동으로 복제되어 있음 빠르고 일관된 응답시간, SSD, 10밀리초 미만 보조 인덱스를 통한 빠른 조회 사용한만큼 지불, 저장소 및 프로비저닝된 처리용량 #\rAmazon ElastiCache\r#\r#\rCache\r#\rCache는 CPU 칩 안에 들어가 있는 작은 메모리 ( 물리적 실체 ) 프로세서가 필요한 데이터가 있을 때마다 메인 메모리에 일일이 접근하여 속도가 지연되는 것을 막기 위해 자주 사용하는 데이터를 담아두는 곳 즉 처리 속도 향상을 위해 존재하는 작은 칩이자 메모리 L1,L2,L3로 나뉘며 숫자가 적을 수록 도달하는 속도가 빠름 Cache는 CPU와 메모리 사이 뿐만 아니라, 메모리와 디스크 사이에서도 발생함 후술할 In Memory Cache는 메모리와 디스크 사이의 Caching을 의미 #\rIn Memory Cache ( In Memory DataBase )\r#\r데이터 처리 속도를 향상시키기 위한 메모리 기반의 DBMS 메모리 위에 모든 데이터를 올려두고 사용하는 데이터베이스의 일종( ElastiCache가 AWS 카테고리에서 DB 부분에 있는 이유 ) 디스크에 최적화된 Database ( RDS 등 ) 에서 저장된 쿼리 결과나 자주 사용하는 데이터를 메모리에 적재하여 사용하는 것은 비효율적 즉 모든 데이터를 메모리 위에 올려두어 굳이 디스크 기반의 데이터베이스에까지 이동하여 데이터를 가져와 속도가 저하되는 것을 막음 데이터베이스의 데이터뿐만 아니라, 디스크, 세션, 기타 동적으로 생성된 데이터를 저장할 수 있음 메모리 기반의 데이터베이스이기 때문에, 휘발성 메모리라는 단점이 존재하며 전원 공급 차단시 모든 데이터가 유실되고 할당된 메모리에 한해 저장 가능 #\rElastiCache\r#\rAWS의 In Memory Cache Service Memcached와 Redis로 나뉨 Memached, Redis 모두 비관계데이터베이스형(NosQL) 서비스이며, Key-value 기반임 Memached, Redis 모두 이미 존재하는 서비스이며 AWS에서 사용가능하도록 구현한 것 ElastiCache는 Node로 구성되어 서비스를 제공하며, Node는 EC2처럼 다양한 Type을 가지고 유형에 따라 다양한 메모리 크기를 가짐 다양한 Type을 갖는 이유는 적은 양의 메모리가 필요할 경우, 작은 Type의 Node를 사용하여 비용을 적게 들게 하기 위함 유형이 결정된 Node들은 ‘고정된’ 메모리 크기를 가지며, 각자의 DNS로 이루어진 엔드포인트를 보유함 #\rMemcache\r#\rCluster로 구성되어 있으며, Cluster 내에는 Node들이 존재하여 인 메모리 캐시로서의 역할을 담당함 각 Node는 Type별로 메모리를 보유하며 서비스를 제공하며, 필요시 Node를 늘려 서비스 용량을 향상시킬 수 있음 각 Node별로 AZ를 따로 둘 수 있지만, 장애 조치(Failover)가 불가능하고 복제본을 둘 수 없음 Redis의 특징 기본적으로 Cluster로 구성되지는 않지만, Cluster로 구성이 가능하며 Shard와 Node를 가지고 있음 Shard는 여러 Node로 구성되며, 하나의 Node가 읽기/쓰기를 담당하고 나머지 Node는 복제본 역할을 함 Cluster로 구성되지 않은 Redis는 하나의 Shard만을 가지지만, Cluster로 구성될 경우 다수의 Shard를 갖게 됨 복제본을 가지므로, 장애조치(복제본을 기본 Node로 승격)가 가능하며 Multi-AZ 기능을 지원함 #\rAmazon Redshift\r#\r#\rRedshift\r#\rPostgreSQL를 기반으로 하는 AWS의 Data Warehouse Service 모든 데이터를 표준 SQL 혹은 BI 도구를 사용하여 효율적으로 분석할 수 있도록 지원 대량 병렬처리(MPP)를 통해 복잡한 쿼리라도 빠른 속도로 실행하여 대용량 처리 가능 열(Column) 단위 데이터 저장방식 COPY 명령어를 통해 Amazon EMR, Amazon DynamoDB, S3로부터 데이터를 병렬 로드 가능 Enhanced VPC Routing을 통해 클러스터와 VPC 외부의 COPY, UNLOAD 트래픽을 모니터링할 수 있음 WLM(Workload Management)를 통해 사용자가 작업 부하 내 우선 순위를 유연하게 관리하도록 지원 보존기간이 1일인 자동 백업을 지원하며, 최대 35일까지 설정 가능 단일 AZ 배포만을 지원함 #\rRedshift의 구성\r#\r클러스터 : Redshift의 핵심 요소로, 하나의 리더 노드와 다수의 컴퓨팅 노드를 가지고 있는 구성 요소 리더 노드 : 클라이언트 프로그램과 일어나는 통신을 비롯해 컴퓨팅 노드간의 모든 통신/작업 관리 컴퓨팅 노드 : 실제 작업을 수행하는 노드로, 각 노드마다 전용 CPU와 메모리 내장 디스크 스토리지를 따로 보유함 #\rData Warehouse(DW)\r#\r하나의 통합된 데이터 저장공간으로서, 다양한 운영 환경의 시스템들로부터 데이터를 추출, 변환, 통합해서 요약한 데이터베이스 데이터베이스가 관련 있는 업무 데이터는 잘 저장하나, 저장된 데이터들을 제대로 활용하지 못 하는 것에서 착안 기본적으로 관계형 데이터베이스가 있는 상태를 가정하여 DW를 구성하며, 동영상이나 음악처럼 DB에 저장할 수 없는 파일도 필요한 부분을 추출하여 보여주어야 함 #\rETL(Extract, Tranform, Load)\r#\r데이터를 추출하고, 변형하여, (Data Warehouse에) 적재하는 과정을 일컫는 말 #\rBI(Business Intelligence)\r#\r데이터 추출/통합/리포팅을 위한 기본도구 집합, DW에서 분석된 데이터를 통해 숨겨진 패턴을 찾아냄 == \u0026gt; ETL을 통해 뽑아낸 데이터를 DW에 적재하고, BI를 이용하여 분석하는 기본 과정을 거침 #\rRedshift vs RDS\r#\rRedshift는 보고 및 분석에 사용되지만, RDS는 OLTP(온라인 트랜잭션) 워크로드에 사용 Redshfit는 대용량 데이터 세트를 대상을 복합적인 분석 쿼리를 빠르게 실행하는 것에 목표를, RDS는 단일 행 트랜잭션에 목표를 둠 #\rAmazon Aurora\r#\r클라우드에서 데이터베이스를 처음부터 설계하자는 생각에서 출발한 DB 서비스 MySQL과 PostgreSQl과 호환이 가능 각 AZ마다 2개의 데이터 복사본을 자동으로 유지하며, 에러를 스스로 찾아내고 복구 Read Replica는 다른 DB 서비스와 달리 최대 15개 까지 가능하며, 백업과 스냅샷이 퍼포먼스에 영향을 주지 않음 #\r"},{"id":15,"href":"/cloud/docs/AWS/AWSSAA/","title":"AWS SAA 시험정리","section":"Amazon Web Services","content":"\rAmazon Web Service Certified Solutions Architect\r#\rAWS SAA의 개요\r#\r#\r1장 AWS의 핵심 서비스\r#\r2장 EC2와 EBS\r#\r3장 S3와 Glacier\r#\r4장 VPC\r#\r5장 데이터베이스\r#\r6장 인증과 권한\r#\r7장 AWS 관리도구\r#\r8장 DNS와 네트워크 라우팅\r#\r9장 안전성 핵심요소\r#\r10장 성능 효율성 핵심요소\r#\r11장 보안 핵심요소\r#\r12장 비용 최적화 핵심요소\r#\r13장 운영 우수성 핵심요소\r#\r14장 평가문제 정리\r#\r15장 기출문제 정리\r#\r#\r#\r"},{"id":16,"href":"/cloud/docs/AWS/AmazonWebService/AWS_Storage/","title":"AWS Storage","section":"AWS docs","content":"\rAWS Storage\r#\r#\rS3 ( Simple Storage Service )\r#\r#\r웹 서비스 인터페이스( HTTP ) 를 이용하여 웹에서 언제 어디서나 원하는 양의 데이터를 저장하고 검색할 수 있는 스토리지 버킷( Bucket )과 객체 ( Object )로 나뉘며, 저장하고자 하는 모든 요소는 하나의 객체로 저장되고, 객체를 담는 곳이 버킷 S3 자체는 글로벌 서비스이지만 버킷을 생성 할 때에는 리전을 선택해야 함 객체는 객체 데이터와 메타 데이터로 나뉘며, 각자의 고유한 URL을 가지며 해당 URL로 접속 가능 #\r버킷( Bucket )의 정의와 특징\r#\r객체를 담고 있는 구성 요소 크기는 무제한, 리전을 지정하여 버킷을 생성해야 함 버킷의 이름은 반드시 고유해야하며, 증복이 불가능 한번 설정된 버킷의 이름은 다른 계정에서 사용불가 #\r객체( Object ) 의 정의와 특징\r#\rS3에 업로드되는 1개의 데이터를 객체라 함 키, 버전 ID, 값, 메타데이터 등으로 구성 객체 하나의 최소 크기는 1(0) byte ~ 5TB 스토리지 클래스, 암호화, 태그, 메타데이터, 객체 잠금 설정 가능 객체의 크기가 매우 클 경우 멀티파트 업로드를 통해 신속하게 업로드 가능 #\r객체의 스토리지 클래스\r#\r객체의 접근빈도 및 저장기안에 따라 결정되는 객체의 특성 Standard Type : 클래스를 선택하지 않을 경우 선택되는 일반적인 클래스 Strandard_IA(Ifrequent Access ) : 자주 엑세스하지는 않지만 즉시 액세스할 수 있는 데이터여야하는 경우 선택되는 클래스 One Zone_iA : Standard_IA와 기능은 동일하나 Standard_IA의 경우 세 곳의 AZ에 저장되는 것과 달리 한 군데의 AZ에만 저장되어 해당 AZ가 파괴될 경우 정보 손실 가능성 존재 ( 저장 요금이 적음 ) Intelligent tiering : 엑세스 빈도가 불규칙하여 빈도를 가늠하기 어려운 경우 선택되는 클래스 Glancier : 검색이 아닌 저장이 주용도인 스토리지로 저장요금이 위 클래스들보다 훨씬 저렴한, 다만 저장이 주용도이기 때문에 검색이 3~ 5시간이 소요 Glacier Deep Archive : 10년 이상 저장할 데이터를 저장하는 스토리지 클래스 #\rS3 사용\r#\rS3 생성\r↕\r#\rS3 생성\r#\r1. S3를 선택합니다.\r#\r#\r2. S3 사용을 위해 버킷을 생성합니다.\r#\r#\r버킷 생성이 주의사항\r#\r버킷 이름에 대문자사용이 불가능 버킷 이름에 특수문자 사용 불가능 버킷 이름이 중첩될 수 없음 퍼블릭 엑세스 차단을 위한 버킷설정 S3 사용자의 설정에 따라 엑세스를 차단\u0026amp; 허용 설정이 가능 #\r3. Bucket의 생성되었습니다.\r#\r#\r4. 버킷을 선택하면 버킷을 사용할 수 있습니다.\r#\r#\r5. 버킷의 파일을 사용자의 옵션에 맞춰 업로드합니다.\r#\r#\r6. 업로드가 완료되었습니다.\r#\r#\r7. 업로드 파일을 선택하면, 퍼블릭 전환, 다운로드 링크 등의 기능을 사용가능합니다.\r#\r#\r8. 권한이 없는 사용자가 링크로 접근하면 다음과 같은 오류가 발생됩니다.\r#\r#\r#\r#\r윈도우 예약 작업과 S3 활용\r#\r윈도우 예약 작업과 S3 활용\r↕\r#\r윈도우 S3 연동\r#\r#\r1. 연동을 위해 Bucket의 backup 폴더를 생성합니다.\r#\r#\r2. 계정 생성을 위해 IAM 서비스로 이동합니다.\r#\rIAM이란 #\r3. 사용자 추가를 선택하여 사용자의 옵션에 맞춰 새로운 사용자를 생성합니다.\r#\r#\r4. 사용자 생성이 완료되었습니다.\r#\r사용자 생성 후, 연동을 위해 CLI를 설치합니다.\r#\r#\r5. 설치가 완료되면, cmd 창에서 configure를 입력 후, 다운받은 csv파일의 정보들을 입력합니다.\r#\rAWS Access Key ID : ex.csv 파일의 엑세스 ID 값 AWS Secret Access Key :ex.csv 파일의 보안 엑세스 키 값 Default region name : region 이름으로 ap-northeast-2 입력 Default output format : 포맷 형식으로 json을 입력 #\r6. aws s3 sync [ 저장한 윈도우의 경로 ] s3 [ 저장될 버킷의 경로 ]를 입력합니다.\r#\raws s3 sync c:\\backup s3://mybucketbucket/backup\r#\r#\r7. 자동화를 위해 .bat 파일을 생성합니다.\r#\r#\r8. bat 파일을 작업 스케줄러에 등록합니다.\r#\r#\r#\r#\r#\r9. 등록이 완료되었습니다. 확인을 위해 실행을 클릭합니다.\r#\r#\r#\rAmazon EFS ( Elastic File System )\r#\r#\rAWS 클라우드 서비스와 온프레미스 리소스에서 사용할 수 있는 탄력적인 완전 관리형 탄력적 NFS 파일 시스템 애플리케이션을 중단하지 않고 온디맨드 방식으로 구성 파일의 추가/ 제거 함에 따라 자동적으로 용량의 확장 및 축소 데이터 일관성 및 보안체계 제공 네트워크 파일 시스템( NFS v4 )를 사용하는 파일 스토리지 서비스 VPC 내에서 생성되며, 파일 시스템 인터페이스를 통해 EC2에 엑세스 수천 개의 EC2에서 동시에 엑세스 가능하며, 탄력적으로 파일을 추가하고 삭제함에 따라 자동으로 Auto Scaling 가능, 즉 미리 크기를 프로비저닝 할 필요가 없음 페타바이트단위 데이터까지 확장 가능 최대 1천개의 파일 시스템 생성 #\r스토리지 클래스\r#\rStandard Class : 자주 액세스하는 파일을 저장하는 데 사용하는 클래스 Infrequent Access( IA ) Class : 저장기간이 길지만 자주 액세스하지 않는 파일을 저장하기 위한 클라스 #\r가용성\r#\r여러 가용영역에서 엑세스 가능 여러 가용영역에 중복 저장되기 때문에 하나의 가용영역이 파괴되더라도 다른 AZ에서 서비스 제공 가능 IPSEC VPN 또는 Direct Connect를 통해 On-premise에서 접속 가능 #\r성능 모드/ 처리량 모드\r#\r성능 모드에 있어서 대부분의 파일시스템에 Bursting Mode를 권장하지만 처리량이 많을 경우, Provisioned Mode를 권장 #\r수명 주기 관리\r#\rStandard Class: 자주 액세스하는 클래스 #\r파일시스템 정책\r#\r여러 가용영역에서 엑세스 가능 여러 가용영역에 중복 저장되기 때문에 하나의 #\rAmazon Glacier\r#\r#\rGlacier는 자주 사용하지 않는 데이터로 \u0026ldquo;Cold Data\u0026quot;에 최적화된 스토리지 서비스 데이터 보관 및 백업을 목적으로 보안 기능과 함께 내구성 있는 저장 공간을 제공하는 매우 저렴한 스토리지 서비스 #\rGlacier의 종류\r#\r아카이브 Glacler에 데이터가 저장되는 최소 단위, 하나의 파일 볼트 Glacler에 생성할 수 있는 최상위 디렉토리, 볼트는 리전별로 생성해야 하며, 각 리전별로 최대 1000개까지 가능 볼트 인벤토리 볼트에 저장된 아카이브의 목록과 크기, 생성 날짜 등 아카이브 정보, 24시간에 한 번씩 업데이트 #\rStorage Gateway\r#\r#\rOn-premise 환경에서 Cloud 상의 Storage를 지원할 수 있게 하는 하이브리드 스토리지 이름이 Storage ‘Gateway’인 이유는 Storage Gateway 자체가 스토리지의 역할을 하는 것이 아닌 스토리지( S3 )의 Gateway 역할을 하기 때문 Volume Gateway의 Stored Volume을 제외하고 나머지 유형은 EC2를 Gateway로 활용하여 Mount Point로 활용 가능 모든 Storage Gateway는 말 그대로 ‘Gateway‘를 생성해야 함 그 대상은 EC2 혹은 하드웨어 어플라이언스가 해당될 수 있음 EC2의 공인 IP를 Mount point로 지정하여 외부 네트워크에서 연결 가능 일반 PC에 마운트하여 사용하는 둥, 다양한 용도로 사용 가능 #\rFile Gateway\r#\rFNFS와 SMB를 지원하는 Storage Gateway 유형 S3를 스토리지로 사용하며, Gateway( EC2 등 )을 통해 S3에 데이터를 저장하고 이를 직접 S3에서 엑세스 할 수 있음 하나의 파일을 하나의 오브젝트로 관리됨 S3에 오브젝트로 관리되는 만큼, S3의 다른 기능을 사용할 수 있음 #\rVolume Gateway\r#\riSCSI를 지원하는 Storage Gateway 유형 두 가지 유형으로 나뉨 Cached Volume: S3를 기본 데이터 스토리로 사용하되, 자주 엑세스하는 데이터를 온프레미스 스토리지 게이트웨이의 캐시 및 업로드 버퍼 스토리지에 보관 Stored Volume: On-premise 스토리지를 기본 데이터 스토리지로 사용하고, 해당 데이터를 EBS Snapshot 형식으로 S3에 비동기 백업을 실시 #\rTape Gateway\r#\rVTL ( Vitual tape Library )를 지원하는 Storage Gateway 가상 테이프데이터는 S3나 S3 Glacier에 저장될 수 있음 #\rEBS ( Elastic Block Stroe )\r#\r#\rEBS 지원 EC2가 갖는 블록 형태의 스토리지 애플리케이션의 기본 스토리지로 쓰거나 시스템 드라이브용으로 쓰기 적합 인스턴스 생성 시 루트 디바이스 볼륨이 생성되며 사용 중에는 언마운트할 수 없음, 추가로 여러 볼륨의 마운트가 가능하며, 추가볼륨에 대해서는 사용중이라도 마운트/ 언마운트가 가능 EBS를 특정 AZ에서 생성하더라도 다른 AZ의 인스턴스에 즉시 붙일 수 있음 인스턴스 스토어 볼륨과는 달리 EBS 기반 인스턴스는 중지 / 재시작이 가능 사용중인 EBS더라도 볼륨 유형과 사이즈를 변경할 수 있음( 사이즈의 축소는 불가 ) #\rEBS의 볼륨 유형\r#\r범용 SSD( gp2 ): 시스템 부트 사용 가능, 대부분의 워크로드에서 사용 프로비져닝된 IOPS SSD( io1 ): 지속적인 IOPS 성능이나 16.000 IOPS 이상의 볼륨당 처리량을 필요로 하는 경우 적합 ( DB 워크로드 ) 처리량 최적회돤 HDD( st1 ): 시스템 부트 사용 불가능, IOPS가 아닌 처리량을 기준으로 하며 자주 엑세스하는 워크로드에 적합한 저비용 HDD 볼륨, 빅데이터나 데이터 웨어 하우스에 사용 Cold HDD( sc1 ): 시스템 부트 사용 불가능, 자주 엑세스하지 않는 대용량 데이터 처리에 적합, 스토리지 비용이 최대한 낮아야 할 경우 사용 #\r"},{"id":17,"href":"/cloud/docs/OpenStack/OpenStack/Glance/","title":"Glance","section":"OpenStack docs","content":"\r이미지를 관리하는 서비스 : Glance\r#\r#\r이미지를 관리하는 서비스 : Glance\r#\r#\rCloud Computing을 사용하기 위해서는 Virtual Machine을 생성하기 위한 이미지가 필요로 하며, Glance는 Nova에서 생성하는 인스턴스의 운영체제에 해당하는 이미지를 관리하는 서비스 #\r#\rGlance의 구성요소\r#\r#\r#\rGlance는 위의 그림과 같이 3가지의 구성요소로 이루어져 있다 #\r구성요소 역할 Glance-api 이미지를 확인/ 복구/ 저장하는 등의 질의를 하기 이한 api 요청/ 응답을 담당 Glance-registry 이미지에 대한 메타데이터를 저장하고 처리하는 역할을 담당 및 Glance database에 저장된 데이터를 불러들이는 역할을 수행 Glance-database 이미지의 관련 정보들을 보관 #\r#\r논리 아키텍처의 Glance\r#\r#\rGlance 사용자들은 glance-api로 이미지를 등록, 삭제, 관리 glance-api는 glance-registry와 Glance database에서 이미지를 관리 이미지를 등록할 때는 glance-registry로 Glance database에 저장 등록된 이미지를 사용할 때는 Glance database에 바로 사용을 요청 관리자는 운영하려는 운영체제의 이미지를 glance-registry로 Glance database에 등록 #\r#\r가상 머신 이미지 포맷\r#\r#\raki: 아마존 커널 이미지 ami: 아마존 머신 이미지 ari: 아마존 ram 디스크 이미지 iso: 광학 디스크나 CD-ROM의 데이터 콘텐츠를 지원하는 아카이브 포맷 qcow2: QEMU 에뮬레이터가 지원하는 포맷, 동적으로 확장할 수 있으며, Copy on Write를 지원 raw: 구조화되지 않은 디스크 포맷 vdi: VirtalBox 모니터와 QEMU 에뮬레이터가 지원하는 디스크 포맷 vhd: VHD 디스크 포맷은 VMware, Xen 마이크로소프트, VirtualBox 같은 가상 머신 모니터가 사용하는 일반적인 디스크 포맷 vhdx: VHDX 디스크 포맷은 큰 디스크 크기를 지원하는 VHD 형식의 향상된 버전 vmdk: 일반적인 디스크 포맷으로 여러 가상 머신 모니터가 지원 #\r#\r컨테이너 포맷(container Format)\r#\r#\raki: 아마존 커널 이미지 ami: 아마존 머신 이미지 bare: 아마존 ram 디스크 이미지 docker: Docker 컨테이너 포맷 ova: tar 파일의 OVF 패키지 ovf: OVF 컨테이너 포맷 #\r#\r#\r#\rGlance 명령어\r#\r현재 이미지 목록 확인 openstack image list #\r특정 이미지의 자세한 정보 확인 openstack image show [이미지 이름] #\r이미지 삭제 openstack image delete [이미지 이름] #\r이미지 추가 openstack image create --public --container-format bare --disk-format qcow2 --file [경로를 포함한 이미지 파일 이름] [이미지 이름] #\r#\r커스텀 이미지 생성\r#\r#\rxming 윈도우에 설치 #\rCentOS 준비 후 CentOS에 가상머신 프로그램 설치 및 실행 $ yum install qemu kvm qemu-kvm libvirt virt-install bridge-utils virt-manager dejavu-lgc-sans-fonts virt-viewer $ systemctl restart libvirtd #\rISO 파일로 qcow2 각 이미지에 맞는 파일 생성 qemu-img create -f qcow2 [이미지 파일 위치] [이미지 파일 크기] qemu-img create -f qcow2 /test/centos7.qcow2 10G #\rISO로 가상머신 생성 $ virt-install --name centos \\ --ram 1024 --disk \\ [비어있는 이미지 파일 위치],format=qcow2 \\ --network network=default \\ --graphics vnc,listen=0.0.0.0 \\ --noautoconsole \\ --os-type=linux \\ --os-variant=centos7.0 \\ --location=[ISO 위치] #\r본체 윈도우에서 putty x11 설정 Putty -\u0026gt; SSH -\u0026gt; X11 -\u0026gt; Enable X11 Forwarding 체크 -\u0026gt; X display location : localhost:0 설정 후 접속 #\rvirt-manager 생성한 QEMU 가상머신 설정 SELINUX 끄기 acpid 설치 및 설정 cloud-init 및 cloud-utils 설치 및 설정 /etc/sysconfig/network qemu-guest-agent 설치 및 설정 grub 수정 #\r생성한 가상머신에서 이미지 작업 ( 커스터 마이징 ) #\r설치 후 설정 yum install -y /usr/bin/virt-sysprep virt-sysprep -d centos \u0026lt;-네트워크 장치의 MAC주소와 같은 정보를 삭제하는 작업 virsh undefine centos \u0026lt;-가상머신 삭제하는 작업 "},{"id":18,"href":"/cloud/docs/AWS/AWSSAA/SAA-4/","title":"4장 VPC","section":"AWS SAA 시험정리","content":"\r4장 Amazon Virtual Private Cloud\r#\r#\r4장의 목표\r#\r#\r복원력을 갖춘 아키텍처 설계 어떻게 멀티 티어 아키텍처 솔루션을 설계할지 결정한다. #\r안전한 어플리케이션 및 아키텍처 설계 단일 VPC 어플리케이션을 위한 네트워킹 인프라르 정의한다. 단일 VPC 애플리케이션을 위한 네트워킹 인프라르 정의한다. #\r#\rVirtual Private Cloud ( 이하 VPC )\r#\r#\rVPC란 EC2의 네트워크 계층으로, EC2 인스턴스를 비롯한 여러 AWS 서비스에 네트워크 리소스를 담을 수 있는 가상의 네트워크를 의미한다.\n모든 VPC는 기본적으로 다른 모든 네트워크와 격리되어 있지만, 필요할 때는 인터넷 및 다른 VPC와 연결이 가능하다.\nVPC는 한 리전안에서만 존재할 수 있으며, 한 리전에 만든 VPC는 다른 리전에서는 볼 수 없다.\nVPC에는 라우터, 스위치, VLAN과 같은 기존 네트워크 구성 요소들이 존재하지 않으며, 확장성을 실현하기 위해 소프트웨어 기능으로 추상화하였다.\n#\r#\rVPC CIDR 블록\r#\r#\r기존 네트워크와 동일하게 VPC는 하나 이상의 연속적인 IP 주소 범위로 구성되며, CIDR ( Classless Inter Domain Routing ) 블록으로 표시된다.\nVPC 내 인스턴스를 비롯한 리소스에 해당되는 IP 주소는 CIDR 블록으로 결정되며, VPC를 만들 때는 기본 CIDR 블록 주소의 할당이 필수이다.\n간략한 CIDR 설명\nIP 접두사라는 CIDR 블록의 /16 부분은 접두사의 길이를 의미하며, VPC CIDR 접두사의 길이는 /16부터 /28까지를 의미한다.. CIDR과 IP 주소는 반비레 관계이며 접두사의 길이가 작을 수록 CIDR의 IP 주소는 많아진다. 예를 드면 /28 접두사의 길이는 16개의 IP 주소만이 사용 가능하다. 주소 대역 할당 IP 대역 10.0.0.0 10.255.255.255 ( 10.0.0.0/8 ) 172.16.0.0 172.31.255.255 ( 172.16.0.0/12 ) 192.168.0.0 192.168.255.255 ( 192.168.0.0/16 ) #\rVPC는 온 프레미스 네트워크나 다른 VPC 등 다른 네트워크에 연결하려면 사용할 VPC CIDR과 다른 네트워크에 연결하려면 주소와 중복되지 않도록 해야 한다.\n기본 CIDR 블록은 변경할 수 없으므로 VPC를 만들기 전에 주소 요구 사항을 신중히 검토해야 한다.\n#\r#\r보조 CIDR 블록\r#\r#\rVPC를 만든 후에도 보조 CIDR 블록을 지정할 수 있다.\n보조 CIDR 블록은 기본 CIDR 주소 범위나 퍼블릭 라우팅이 가능한 범위 내에서 생성돼야 하며, 기본 블록 또는 다른 보조 블록과 겹치지 않아야 한다.\nVPC가 172.16.0.0/16일 경우 172.17.0.0/16으로 지정할 수 있지만, 192.168.0.0/16으로는 지정할 수 없다.\n#\r#\rIPv6 CIDR 블록\r#\r#\rVPC에 IPv6 CIDR을 할당 할 수 있으나, IP 접두사를 지정할 수 있는 기본 CIDR과는 달리 IPv6에서는 CIDR을 지정할 수 없다.\nAWS에 요청을 하면, AWS가 VPC에 IPv6을 할당한다.\nIPv6의 VPC CIDR의 접두사의 길이는 항상 /56이다.\n#\r#\r서브넷\r#\r#\r서브넷은 VPC 내 논리 컨테이너로 EC2 인스턴스를 배치하는 장소이다.\n서브넷으르 통해 인스턴스를 서로 격리하고, 인스턴스 간 트래픽 흐름을 제어하고, 인스턴스를 기능별로 모을 수 있다.\n인스턴스는 서브넷 안에 있어야 하며, 한 서브넷에 생성된 인스턴스는 다른 서브넷으로 이동이 불가능하다.\n#\r#\r서브넷 CIDR 블록\r#\r#\r서브넷의 CIDR은 VPC CIDR의 일부이면서, VPC 내에서 고유해야 한다.\n서브넷의 모든 IP의 첫 4개, 끝 1개는 사용할 수 없다.\n172.16.100.0 ~ 172.16.100.3 127.16.100.255 서브넷 CIDR 접두사의 길이 제한은 VPC CIDR과 동일할 수 있지만, 이리하면 공간이 남지 않기에 보통 서브넷의 CIDR은 VPC보다 길다.\nVPC는 보조 CIDR을 가질 수 있지만, 서브넷에는 하나의 CIDR만이 사용 가능하다.\n만약 VPC가 보조 CIDR을 가지고 있을 경우, 서브넷은 적합한 CIDR을 선택해 생성할 수 있다.\n#\r#\r가용 영역\r#\r#\r서브넷은 하나의 가용영역 ( Availability Zone 이하 AZ ) 내에서만 존재할 수 있으며, 가용 영역은 상대적으로 작은 지리적 위치, 데이터 센터의 개념이다.\nAWS 리전의 가용영역들은 서로 연결되어 있으며, 한 가용 영역에 잘애가 발생하더라도 다른 영역에 장애의 영향이 미치지 않도록 설게되어있다.\n즉, 서로 다른 가용영역에 서브넷은 만든 후, 인스턴스를 각각 생성하면 애플리케이션은 복원성을 사용가능하다.\nSubnet AZ Instance web-subnet1 us-east-1a web1 web-subnet2 us-east-1b web2 위와 같이 만약 us-east-1a의 생성된 web1의 인스턴스의 문제가 발생하더라도, web2 인스턴스의 서브넷은 다른 AZ에 속해있기 때문에 무중단 서비스가 가능하다. #\r#\rIPv6 CIDR 블록\r#\r#\rVPC에 IPv6 CIDR을 할당하면 해당 VPC 내 서브넷에 IPv6 CIDR을 할당할 수 있다. IPv6 서브넷의 접두사 길이는 /64로 고정되어있다. #\r#\r탄력적 네트워크 인터페이스\r#\r#\r탄력적 네트워크 인터페이스 ( Elastic Network Interface 이하 ENI )를 사용하면 인스턴스가 AWS 서비스, 다른 인스턴스, 온 프레미스 서버, 인터넷 등 다른 네트워크의 리소스와 통신할 수 있다.\n기본적으로 물리 서버의 네트워크 인터페이스와 동일한 기능을 수행한다.\n#\r#\r기본 프라이빗 주소와 보조 프라이빗 IP 주소\r#\r#\r각 인스턴스는 기본 프라이빗 주소를 가지고 있어야 하는 데, 그 주소는 서브넷 CIDR에서 지정한 범위 내 주소여야 한다.\n기본 프라이빗 IP 주소는 인스턴스의 기본 ENI에 연결되며 이 주소는 변경하거나 삭제가 불가능하다.\n보조 프라이빗 IP 주소에는 ENI를 할당할 수 있으며, 보조 주소는 ENI가 연결된 서브넷의 주소 내에서 할당된다.\nENI를 인스턴스에 추가해서 연결할 수 있고, 이 ENI를 다른 서브넷에 둘 수도 있지만, 해당 인스턴스와 같은 가용 영역에 있어야하며, ENI와 연결된 주소는 ENI가 있는 서브넷에서 가져와야 한다.\n#\r#\r탄력적 네트워크 인터페이스 연결\r#\r#\rENI는 인스턴스와 독립적으로 존재가 가능하며, 먼저 ENI를 생성한 후 인스턴스를 생성하고 할당할 수 있다. #\r#\r인터넷 게이트웨이\r#\r#\r인터넷 게이트웨이는 퍼블릭 IP 주소를 할당받은 인스턴스가 인터넷과 연결돼서 인터넷으로부터 요청을 수신하는 기능을 수행한다.\n처음 VPC를 생성하고, VPC에는 인터넷 게이트웨이가 연결되어 있지 않으므로, 직접 인터넷 게이트웨이를 만들어 VPC와 연결해야한다.\n인터넷 게이트웨이는 인터넷 서비스를 제공하는 업체의 온 프레미스에 설치하는 인터넷 라우터와 유사하지만, AWS에서 인터넷 게이트웨이는 라우터와 동일하게 동작하지는 않는다.\n기존 네트워크에서는 핵심 라우터의 주소를 인터넷으로 향하는 기본 게이트웨이 IP 주소로 구성해서 각 서버가 인터넷에 엑세스 할 수 있도록 한다.\n인터넷 게이트 웨이는 관리형 IP나 네트워크 인터페이스가 없는 대신, 식별을 위해 AWS 리소스 ID가 할당된다.\n인터넷 게이트 웨이는 igw-로 시작하며 그 뒤에는 영 숫자나 문자열이 온다.\n인터넷 게이트웨이를 사용하려면 인터넷 게이트웨이를 대상으로 하는 기본 라우팅을 라우팅 테이블에 만들어야 한다.\n#\r#\r라우팅 테이블\r#\r#\rVPC는 리소스 형태로 가상 라우터를 구성하지 않음, 소프트웨어 함수로 IP 라우팅을 구현한 내재된 라우터를 제공한다.\n사용자는 가상 라우터에서 인터페이스 IP 주소나 동적 라우팅 프로토콜을 구성하지 않고 내재된 라우터에서 라우팅 테이블만 관리하면 된다.\n각 라우팅 테이블은 하나 이상의 라우팅과 하나 이상의 서브넷의 연결로 구성되며, 기존의 라우터와 거의 동일한 방식으로 여러 서브넷에 연결되어 있다.\n라우팅 테이블과 서브넷은명시적으로 직접 연결하지 않더라도 서브넷에 암시적으로 기본 라우팅 테이블이 연결되므로, 모든 서브넷은 라우팅 테이블으로 연결된다.\n#\r#\r라우팅\r#\r#\r라우팅은 라우팅 테이블과 연결된 서브넷 내 인스턴스에서 트래픽을 저달하는 방법을 결정한다.\nIP라우팅은 원본 IP 주소가 아닌 대상 IP주소를 기반으로 작동하므로, 하위의 요소는 제공해야 한다.\n대상 주소 대상 IP 주소는 CIDR 표기법의 IP 접두사여야 하며, 대상에는 CIDR은 사용할 수 없고, 인터넷 게이트웨이, ENI 등의 AWS 리소스가 지정되어야한다.\n모든 라우팅 테이블에는 각각 다른 서브넷에 있는 인스턴스들이 서로 통신할 수 있게 하는로컬 라우팅이 포함되어 있다.\n#\r#\r기본 라우팅\r#\r#\r인스턴스가 인터넷에 액세스하게 하려면 인터넷 게이트웨이를 가리키는 기본 라우팅을 생성해야 한다. 대상 주소 대상 172.31.0.0/16 LOCAL 0.0.0.0/0 igw-xxxxxxxxx 인터넷 상의 모든 호스트 IP 주소를 표기할 때는 0.0.0.0/0 접두사를 사용하므로, 기본 라우팅 대상 주소로 0.0.0.0/0의 접두사를 등록해야 한다.\n인터넷 게이트웨이를 가리키는 기본 라우팅이 포함된 라우팅 테이블과 연결된 서브넷을 퍼블릭 서브넷이라 한다.\n이와 반해서 프라이빗 서브넷은 기본 라우팅을 포함하지 않는다. 0.0.0.0/0과 172.31.0.0/16이 증복되어 있을 때, 트래픽을 라우팅할 위치를 결정할 때 내재된 라우터는 가장 근접하게 일치된 항목을 기반으로 라우팅 한다.\nAWS docs에서는 VPC 당 내재된 라우터가 하나 존재한다고 기술되어 있으며, 이 라우터란 실제 개별 리소스가 아닌 IP 라우팅 기능을 추상화한 것으로 이해하면 된다.\n#\r#\r보안 그룹\r#\r#\r보안 그룹은 방화벽과 같은 기능을 제공하며, 인스턴스의 ENI의 송수신되는 트래픽을 허가해서 인스턴스를 오가는 트래픽을 제어해야 한다.\n모든 ENI에는 최소한 하나의 보안 그룹이 연결되어야 하고, 한 ENI에 여러 개의 보안 그룹을 연결할 수 있으며, 한 보안 그룹을 여러 개의 ENI에 연결할 수도 있다.\n실제 인스턴스는 ENI를 하나만 연결해서 사용하기 땜누에 하나의 인스턴스에 하나의 보안 그룹만이 연결되어 있다고 생각하기 쉬운데, 인스턴스에 ENI가 여러 개 있는 경우에는 반드시 확인이 필요하다.\n#\r#\r보안 그룹 인바운드 규칙\r#\r#\r인바운드 규칙은 연결된 ENI에 허용할 트래픽을 정의하는 것으로 아래의 3 가지의 필수 요소를 포함한다.\n출발 주소 ( source address ) 프로토콜 포트 범위 새로 생성한 보안 그룹에는 인바운드 규칙이 없으며, 연결한 인스턴스의 모든 트래픽을 차단한다.\n필요에 따라 특정 트래픽을 허용하려면 그 때마다 인바운드 규칙을 만들어야 하고, 이러한 이유로 보안 그룹에서 규칙의 순서는 중요하지 않다.\n아래의 항목은 HTTP와 SSH의 예시이다.\n원본 프로토콜 포트 범위 151.123.231.2 ( 자기자신이 사용하고 있는 특정 IP ) TCP ( SSH ) 22 0.0.0.0/0 ( 모두 접속할 수 있어야 하므로 ) HTTP 80 #\r#\r보안 그룹 아웃바운드 규칙\r#\r#\r아웃바운드 규칙은 인스턴스에 연결된 ENI르 통해 송수힐 수 있는 트래픽을 정의한 것으로, 아래의 세가 요소를 포함한다.\n목적지 주소 프로토콜 포트 범위 보안 그룹의 아웃바운드 규칙은 인바운드 규칙보다 제한이 적으며, 보안 그룹을 생성할 때, AWS는 기본적으로 하단의 표로 모든 프로토콜과 포트가 열려 있는 아웃 바운드 규칙을 생성한다.\n목적지 주소 프로토콜 포트 범위 0.0.0.0/0 모두 모두 #\r#\r원본과 대상 주소\r#\r#\r규칙의 원본이나 대상 주소에 CIDR 또는 보안 그룹의 리소스 ID를 지정할 수 있고, 보안 그룹에 연결된 모든 인스턴스 규칙이 적용된다. #\r#\r상태 저장 방화벽\r#\r#\r보안 그룹은 상태 저장 방화벽 역할을 수행한다.\n상태 저장이란 보안 그룹이 트래픽을 한 방향으로 전달되도록 허용할 때, 반대 방향의 응답 트래픽을 지능적으로 허용하는 것을 의미한다.\n#\r#\r기본 보안 그룹\r#\r#\r각 VPC엔느 삭제할 수 없는 기본 보안 그룹이 있으며, 필요하면 규칙을 수정할 수 있다.\n사용자 지정 봉나 그룹을 만들어 대신 사용하는 것도 가능하다.\n#\r#\r네트워크 엑세스 제어 목록 ( Network Access Contol List : 이하 NACL )\r#\r#\rNACL은 원본 또는 대상 주소 CIDR, 프로토콜, 포트를 기반으로 트래픅을 허용하는 인바운드와 아웃바운드 규칙을 포함한다.\nNACL은 보안 그롭, 방화벽의 기능을 수행하며, 각 VPC에는 삭제할 수 없는 NACL이 있다는 점도 보안 그룹과 유사하다.\n하지만 NACL은 보안그룹과 달리, ECI가 아닌 서브넷에 연결되며, 서브넷과 연결된 NACL은 해당 서브넷과 송수신되는 트래픽을 제어한다.\n즉, 서브넷 내의 인스턴스간 트래픽을 제어할 때는 NACL을 사용할 수 없으며, 보안 그룹을 사용해야한다.\n서브넷은 하나의 NACL만 연결할 수 있으며, VPC에 서브넷을 만들면 기본적으로 VPC의 기본 NACL이 연결된다.\n서브넷과 NACL이 같은 VPC에 있다면 하나의 NACL을 여러 서브넷에 연결하는 것이 가능하다.\n#\r#\rNACL 인바운드 규칙\r#\r#\r인바운드 규칙은 서브넷에 진입할 수 있는 트래픽을 정의하며, 다음 요소들을 포함한다.\n규칙 번호 프로토콜 포트 범위 출발 주소 동작 ( 허용/ 거부 ) IPv6 CIDR이 없는 VPC는 기본 NACL에는 표 4.5에 나열된 두 가지 인바운드 규칙이 포함되어있다.\n규칙번호 프로토콜 포트 범위 출발 주소 허용/ 거부 100 모두 모두 0.0.0.0/0 ALLOW * 모두 모두 0.0.0.0/0 DENY NACL 규칙은 규칙 번호의 오름차순으로 처리된다. #\r#\rNACL 아웃바운드 규칙\r#\r#\r아웃바운드 또한 인바운드 규칙과 거의 같은 형식을 따르며, 아래의 요소들을 포함한다.\n규칙 번호 프로토콜 포트 범위 대상 주소 동작 ( 허용/ 거부 ) 각 기본 NACL은 하단에 나열된 아웃바운드 규칙으로 제공되며, 아웃바운드 규칙은 대상 주소를 제외하고는 기본 인바운드 규칙과 동일하다.\n규칙번호 프로토콜 포트 범위 도착 주소 허용/ 거부 100 모두 모두 0.0.0.0/0 ALLOW * 모두 모두 0.0.0.0/0 DENY NACL은 상태 비저장이므로 응답 트래픽을 자동으로 허용하지 않기 때문에, 만약 인바운드에서 HTTPS의 트래픽을 허용한다면, 아웃바운드 규칙에서도 응답 트래픽을 명시적으로 허용해야한다. 기본적으로 최신 운영 체제에서는 49125-65535 범위의 임시 포트를 허용하지만, 이 범위는 충분하지않을 수 있다. #\r#\r네트워크 엑세스 제어 목록과 보안 그룹을 같이 사용\r#\r#\r사용자가 인스턴스를 시작할 때, 보안 그룹을 올바르게 지정해야 하는 부담을 줄이기 위해 보안 그룹과 NACL을 함께 사용할 수 있다.\nNACL은 서브넷에 적용되므로 NACL 규칙은 보안 그룹 구성 방법과 관계없이 서브넷에서 송수신하는 모든 트래픽에 적용된다.\nNACL이나 보안 그룹은 규칙을 변경하면 해당 변경 사항이 즉시 적용 ( 실제로는 몇 초 의 시간이 소요 )\nNACL에서는 원본 또는 대상 주소를 지정해야 CIDR을 사용할 수 있으며, 이는 보안 그룹의 원본이나 대상 주소를 다른 보안 그룹을 지정할 수 있는 보안 그룹 규칙과는 다른 점이다.\n#\r#\r퍼블릭 IP 주소\r#\r#\r퍼블릭 IP주소는 퍼블릭 인터넷으로부터 인스턴스에 엑세스하는 데 필수 요소로 인터넷이 아닌 프라이빗 네트워크 내에서만 통신할 수 있는 RFC 1918 주소와는 다르다 할 수 있다.\nAWS 외부에서 직접 인터넷을 통해 연결하려면 인스턴스에 퍼블릭 IP 주소가 필요하다.\n인스턴스에서 인터넷으로 전송만 하는 용도의 퍼블릭 IP 주소를 연결하는 방법도 있지만, 인스턴스 간에는 프라이빗 IP 주소로 통신하기 때문에, VPC 인프라 내에서 인스턴스 간 통신에는 퍼블릭 IP 주소가 필요하지 않다.\n퍼블릭 주소는 처음에만 할당이 가능하고, 생성 후에는 할당이 불가능하다.\n사용자가 재시작 하지 않았더라도, AWS 자체 유지보수 기능의 이해 변동 될 수 있다.\nIP 주소가 바뀌어도 무방한 인스턴스에는 퍼블릭 IP를 사용해도 되지만, 장기간 같은 IP 주소를 유지해야하는 인스턴스에는 탄력적 IP 주소를 사용하는 것이 좋다.\n#\r#\r탄력적 IP 주소 ( Elastic IP Address : 이하 EIP )\r#\r#\rEIP는 AWS에서 사용자의 요청하면 계정에 할당되는 퍼블릭 IP 주소로 계정에 EIP가 할당되면 사용자가 직접 해제하지 않는 한 해당 주소를 독점적으로 사용할 수 있다.\nAWS 외부에서 보면 EIP와 자동 할당된 퍼블릭 IP 간에는 차이점이 없다.\nEIP는 인스턴스에 연결되지 않은 상태로 할당된다.\n#\r#\r네트워크 주소 변환\r#\r#\rENI를 퍼블릭 IP 주소와 연결할 때는 ENI는 프라이빗 IP 주소를 그대로 유지한다.\n퍼블릭 IP를 ENI와 연결하더라도 ENI가 새로운 주소로 재구성되는 것이 아니며, 인터넷 게이트웨이는 네트워크 주소 변환이라는 프로세스를 활용해 퍼블릭 IP 주소와 ENI 프라이빗 주소를 연결한다.\n퍼블릭 IP가 있는 인스턴스에서 인터넷의 호스트로 연결하면 그 호스트는 인스턴스의 퍼블릭 IP에 있는 트래픽이 발생한 것으로 간주한다.\n예를 들면, 퍼블릭 IP가 있는 호스트에 프라이빗 IP 주소에 보내었다 해도 게이트 웨이를 지나 퍼블릭 IP를 통해 접속하게 된다.\n이 때 게이트웨이는 자동적으로 주소를 변화시키며, 사용자는 개입이 불가능하다.\n#\r#\r네트워크 주소 변환 장치\r#\r#\r네트워크 주소 변환은 인터넷 게이트웨이에서 이루어지지만, 다음 두 가지 서비스도 네트워크 주소변환을 수행한다.\nNAT 게이트웨이 NAT 인스턴스 AWS 서비스 속에서 이는 NAT 디바이스라 하며, 인스턴스가 인터넷에 액세스할 수 있게 되면서 인터넷상의 호스트에서는 인스턴스에 직접 도달하지 못하게 할 때 사용한다.\n이 기능은 이느턴스가 업데이트 패치를 받거나 데이터를 업로드할 때 인터넷에 연결할 필요는 있지만, 클라이언트 요청에 응답할 필요는 없을 때 유용하다.\nNAT 디바이스를 사용하면 인스턴스가 액세스 할 필요가 있더라도 퍼블릭 IP 주소를 할당하지 않으므로, 인터넷 상의 호스트가 인스턴스에 직접 액세스하는 것은 불가능하다.\nNAT 디바이스의 인터페이스는 퍼블릿 서브넷에 위치하면서 퍼블릭 IP가 연결된다.\n하단은 NAT 디바이스를 사용할 때의 IP 주소 구성이다.\n이름 서브넷 프라이빗 IP 퍼블릭 IP EC2-1 Private 10.0.0.10 EC2-2 Private 10.0.0.11 NAT 디바이스 Public 10.0.1.10 18.212.132.21 #\r#\rEC2-1, 2의 외부주소의 인터넷 호스트로 패킷을 전송하면 그 패킷은 먼저 NAT 디바이스로전달되고, NAT 디바이스에서는 아래와 같이 패킷을 변환한다. 원본 패킷의 원본 IP 주소 원본 패킷의 대상 IP 주소 \u0026ndash;\u0026gt; 변환 \u0026ndash;\u0026gt; 변환 패킷의 원본 IP 주소 변환 패킷의 대상 IP 주소 EC2-1 ( 10.0.0.10 ) 외부 주소 \u0026ndash;\u0026gt; 변환 \u0026ndash;\u0026gt; NAT 디바이스 ( 10.0.1.10 ) 외부 주소 #\r#\r내부 대역에서 NAT 디바이스와의 변환을 마치게 되면 하단과 같이 NAT 디바이스와 인터넷 게이트웨이로의 변환이 다시 한번 이루어진다. 원본 패킷의 원본 IP 주소 원본 패킷의 대상 IP 주소 \u0026ndash;\u0026gt; 변환 \u0026ndash;\u0026gt; 변환 패킷의 원본 IP 주소 변환 패킷의 대상 IP 주소 NAT 디바이스 ( 10.0.1.10 ) 외부 주소 \u0026ndash;\u0026gt; 변환 \u0026ndash;\u0026gt; NAT 디바이스 ( 18.212.132.21 ) 외부 주소 이와 같이 여러 인스턴스가 같은 NAT 디바이스를 사용할 수 있으므로 같은 퍼블릭 IP 주소를 공유해서 아웃 바운드에 연결할 수 있다. NAT 디바이스가 수행하는 기능을 포트 주소 변환 ( Port Address Translation : 이하 PAT )이라고 한다. #\r#\rNAT 디바이스를 사용한 라우팅 테이블 구성\r#\r#\r프라이빗 서브넷에서 트래픽이 인터넷으로 전송돼야 하는 경우, 트래픽이 NAT 디바이스를 향하도록 경로가 설정되어 있어야 한다.\nNAT 디바이스에서 트래픽이 인터넷으로 전송되야 할 경우, 트래픽은 인터넷 게이트웨이로 향하도록 경로가 설정되어야 한다.\n따라서 NAT 디바이스와 라우팅가 인스턴스의 기본 라우팅은 다르게 구성되어야 하며, 복수의 라우팅 테이블을 사용해야 하므로 이에 따라 서브넷도 분리되어야 한다.\n서브넷 대상 주소 대상 프라이빗 0.0.0.0/0 NAT 디바이스 퍼블릭 0.0.0.0/0 igw-0e538022a0fddc318 위의 표는 프라이빗과 퍼블릿의 기본 라우팅을 나타낸다. #\r#\rNAT 게이트웨이\r#\r#\rNAT 게이트웨이는 AWS에서 관리하는 NAT 디바이스이며, 인터넷 게이트웨이처럼 하나의 NAT 게이트웨이로 어떠한 용량의 요청도 수행할 수 있다.\n한 종류의 NAT 게이트웨아만 제공되고, 자동 확장해서 모든 대역폭 요구에 대응하므로 용량 관리를 위한 디바이스에 엑세스할 필요가 없다.\nNAT 게이트웨이를 생성할 때, EIP도 함께 할당해서 연결해야하고, 퍼블릭 서브넷 한 곳에 배포해서 인터넷에 엑세스할 수 있게 해야 한다.\nNAT 게이트웨이는 포함되어 있는 서브넷에서 프라이빗 IP주소를 할당받는다.\nNAT 게이트웨이를 생성 후에는 기본 라우팅을 만들어야 인스턴스의 인터넷 연결 트래픽이 NAT 게이트웨이로 전달된다.\nNAT 게이트웨이의 명칭은 nat-xxxxxxxxx\u0026hellip; 이며 기본 라우팅을 여러 개 만들 수 있다.\nNAT 게이트웨이는 ENI를 사용하지 않으므로 보안 그룹을 적용할 수는 없지만, 서브넷에 NACL을 적용해서 트래픽을 제어할 수 있다.\n#\r#\rNAT 인스턴스\r#\r#\rNAT 인스턴스는 사전 구성된 Linux 기반 AMI를 사용하는 일반적인 EC2 인스턴스로, 만들 때도 동일한 단게를 가진다.\nNAT 게이트웨이와 다방면에서 동일하다 할 수 있지만, 몇 가지 다른 점이 존재한다.\nNAT 인스턴스는 대역폭 요구가 증가하더라도 자동으로 확장되지 않는다. 즉, 적절한 성능을 갖춘 인스턴스를 초기에 맞게 생성해야한다.\nNAT 인스턴스는 ENI가 있으므로 보안 그룹을 적용해야 하며, 퍼블릭 IP주소를 할당해야 한다.\nNAT 인스턴스의 한 가지 이점은 배스천 호스트 ( Bastion Host : 점프 호스트 )로 사용해서 퍼블릭 IP가 없는 인스턴스에 연결할 수 있다는 것이며, NAT 게이트웨이로는 이 작업을 수행할 수 없다.\n인스턴스나 가용 영역에 장애가 발생하면 다른 NAT 인스턴스로 확장하는 정도로는 간단한 대처가 불가능하며, 이는 기본 라우팅에 여러 NAT 인스턴스를 대상으로 경로를 지정할 수 없기 때문이다.\n즉, 높은 탄력성이 요구되면 NAT 게이트웨이를 사용하는 것이 현명하다.\n#\r#\rVPC 피어링\r#\r#\rVPC 피어링을 구성하면 VPC의 인스턴스가 프라이빗 AWS 네트워크를 통해 다른 VPC와 통신하게 할 수 있다.\n다른 리전에 있는 인스턴스와 통신이 필요할 때에도 이와 같은 작업을 수행할 수 있으며, 한 계정의 인스턴스를 다른 계정의 인스턴스와 연결할 수 있다.\nVPC 피어링을 활성화하려면 두 VPC 사이에 VPC 피어링 연결을 설정해야 하며, VPC 피어링 연결은 아래와 같은 특징이 있다.\n두 VPC 사이의 지점간의 연결이다. 두 VPC 간에는 단 하나의 피어링만 설정할 수 있다. 두 VPC 간에는 서로 다른 CIDR을 사용해야 한다. VPC 피어링 연결은 인스턴스 간 통신만 허용된다. 즉, 한 VPC 인스턴스에서 피어링 된 다른 VPC사이의 지점간 연결이며, 두 VPC 간에는 단 하나의 피어링만 설정할 수 있고, 두 VPC의 CIDR 블록은 겹치지 않아야 한다.\n인터넷 게이트웨이나 NAT 디바이스는 VPC 피어링으로 공유해서 사용할 수 없지만, Networkk Load Balancer만은 예외적으로 공유할 수 있다.\n2개 이상의 VPC를 연결하려면 한 VPC와 다른 모든 VPC 각각 1:1 피어링 연결을 생성해야 하며, 데이지 체인 방식 ( 전이전 구성 )으로 라우팅은 불가능하다.\n피어링 연결을 사용할면 트래픽이 양방향으로 오가도록 두 VPC에 새로운 라우팅을 만들어야 하고, 각 라우팅의 대상이 될 접두사는 대상 VPC 범위 내에 있어야 한다.\n각 경로의 대상은 pcx-xxxxxxx로 시작되는 피어링 연결 식별자로 존재한다.\n원본 VPC CIDR 대상 VPC CIDR 대상 10.0.0.0/16 172.31.0.0/16 pcx-xxxxxxxxxxx 172.31.0.0/16 10.0.0.0/16 pcx-xxxxxxxxxxx 위에 표는 라우팅이 서로 반대로 설정된 것은 양방향으로 트래픽을 허용한다는 의미이다. 대상 CIDR은 대상 VPC CIDR과 정확히 일치할 필요는 없으며, 특정 서브넷 사이에서 피어링을 사용하려면 서브넷 CIDR을 대신 지정할 수 있다. #\r#\r요약\r#\r#\rVPC 서비스는 EC2 및 다른 AWS 서비스의 네트워크 인프라를 제공하는 서비스이다.\nAWS는 기존 네트워크보다 구성하기 쉽도록 일부 네트워크 구성 요소를 추상화했지만, 여전히 VPC를 설계하기 위해서는 네트워크 기초 지식이 필요하다.\nAWS 각 리전의 기본 VPC에 자동으로 기본 서브넷, 기본 라우팅 테이블, 기본 보안 그룹, 기본 NACL을 제공한다. 많은 이들이 기반부터 VPC를 구성하지 않고 기본 VPC를 장기간으로 사용하고 있다.\nAWS 아키텍트라면 가상 네트워크 인프라를 기반부터 구성하는 방법을 이해하는 것이 중요하다.\n기본 VPC에서 구축한 인프라를 수정할 수 없을 때가 많지만, 대신 VPC를 기초부터 구성해서 인프라를 복제해야 하는 임무를 받을 수도 있다.\n이 과정에서 여러 트러블을 해결하고 기초를 공부할 수 있고, 기능에 대한 이해의 학습을 도와준다.\n기존의 네트워크에서는 서버 IP주소를 자유롭게 구성하고, 다른 서브넷으로 이동하며, 다른 물리적 위치로 이동시킬 수도 있다. 즉, 중간에 네트워크 계획을 변경할 수 있는 유연성이 존재하지만, VPC 생성 시에는 불가능하며, 이를 위해 사전에 인프라를 신중하게 계획해야 하므로, 전체 VPC와 EC2 구성 요소를 맞추는 방법을 이해하는 것이 중요하다.\nCIDR로 표현되는 연속적 IP 주소 범위를 정하는 것으로 VPC를 생성하기 한다. 즉, CIDR의 범위를 사전에 모든 인스턴스들을 수용할 수 있을만큼 충분한 여유 주소를 넣어 두고 생성한다.\nVPC CIDR을 서브넷으로 나눌 때는, 한 가용 영역에만 있는 컨테이너이기 때문에 인스턴스를 어디에 배치할지 사전에 결정해둬야 한다.\n서브넷에 인스턴스를 만들고 난 인스턴스를 다른 서브넷으로 옮길 수 없다.\n인스턴스를 시작하기 전에 보안 그룹을 구성할 필요가 있으며, 모든 인스턴스의 ENI에 보안 그룹을 하나 이상 연결해야 하며, 네트워크 엑세스 제어 목록은 상대적으로 변경이 가능해 유연성을 가지고 있으며, NACL은 언제든지 서브넷에 연결할 수 있고 제거가 가능하다.\n인터넷에서 인스턴스에 엑세스할 수 있게 하려면 기본적으로 인터넷 게이트웨이를 프로비저닝하고 기본 라우팅과 퍼블릭 IP 주소를 할당시켜야 한다.\nNAT 게이트웨이나 인스턴스 혹은 VPC 피어링 연결을 사용하기로 했다면 여러 라우팅 테이블을 수정해야 한다.\n#\r#\r시험 핵심\r#\r#\rVPC나 서브넷에 필요한 IP 주소의 수를 기반으로 올바른 CIDR 블록 접두사 길이를 결정할 수 있어야 한다. 접수다의 길이는 /16- /28까지 허용되며, 접두사의 길이가 길수록 사용할 수 있는 IP 주소 수는 줄어든다. #\r서브넷의 중요성을 이해한다. 서브넷은 EC2 인스턴스가 있는 논리적 컨테이너이다.\n각 서브넷의 CIDR 블록은 그 서브넷에 속해 있는 VPC CIDR의 일부다.\n한 서브넷에 속한 인스턴스는 그 서브넷의 CIDR 범위 내에서 프라이빗 IP주소를 가져온다.\n모든 서브넷에 처음 4개의 IP 주소와 마지막 IP 주소는 AWS에서 예약하기 때문에 인스턴스에 할당이 불가능하다.\n#\r가용 영역 장애가 미치는 영향을 파악한다. 한 영역에 장애가 발생하면 해당 영역의 모든 서브넷과 해당 서브넷의 모든 인스턴스가 함께 중단된다.\n한 영역에 장애가 일어나더라도 서비스의 중단을 피하려면 인스턴스를 여러 영역에 배포해 중복해서 구축한다.\n#\r탄력적 네트워크 인터페이스(ENI)를 생성하고 사용하기 위한 규칙을 이해한다. 모든 인스턴스에는 기본 프라이빗 IP 주소를 사용하는 기본 네트워크 인터페이스가 존재하야 하며, 인스턴스에 연결하는 추가 ENI는 기본 ENI와 같은 서브넷에 존재해야한다. #\r라우팅 테이블을 생성, 수정, 사용할 수 있어야 한다. VPC의 기본 라우팅 테이블의 목적과 VPC의 서브넷의 관계를 알아야 한다. 인터넷 게이트웨이와 기본 라우팅 테이블을 사용해 퍼블릭 서브넷을 만드는 방법 또한 이해해야 한다. #\r보안 그룹과 네트워크 엑세스 제어 목록 간의 차이점을 파악한다. 상태 저장 보안 그룹과 상태비저장 NACL이 같은 결과를 얻기 위해서 각각 다르느 규칙을 사용해야 하는 이유를 이해한다. #\r네트워크 주소 변환이 어떻게 작동되는 지 이해한다. 인터넷 게이트웨이에서의 네트워크 주소 변환과 NAT 디바이스에서의 네트어크 주소 변환의 차이점을 이해한다. NAT 디바이스에서의 네트워크 주소 변환은 포트 주소변환(PAT)라 하며, 여러 인스턴스가 한 NAT 디바이스의 단일 퍼블릭 IP 주소를 공유할 수 있다. #\r여러 VPC 간에 VPC 피어링을 만들고 구성할 수 있어야 한다. VPC 피어링 연결의 제한을 파악한다. VPC 피어링 연결은 전이 라우팅과 IPv6를 지원하지 않는다. 일부 리전에서는 리전 간에도 피어링할 수 있다. #\r"},{"id":19,"href":"/cloud/docs/AWS/AmazonWebService/AWS_Network/","title":"AWS Network","section":"AWS docs","content":"\rAWS Network\r#\rAmazon VPC ( Virtual Private Cloud )\r#\rAWS 상에 프라이빗 네트워크 공간을 구축할 수 있는 서비스 VPC를 이용하면 논리적인 네트워크 분리가 가능하고 라우팅 테이블과 각종 게이트웨이의 설정이 가능 AWS의 계정 전용 가상 네트워크 서비스 VPC 내에서 각종 리소스 ( EC2, RDS, ELB 등 )을 시작할 수 있으며 다른 가상 네트워크와 논리적으로 분리되어 있음 S3, Cloudfront 등은 다른 VPC 서비스로 VPC 내에서 생성되지 않음 각 Region 별로 VPC 가 다수 존재할 수 있음 VPC 하나의 사설 IP 대역을 보유하고, 서브넷을 생성하며 사설IP 대역 일부를 나누어 줄 수 있음 허용된 IP 블록 크기는 /16( IP 65536개 )- / 28 (IP 16개 ) 권고하는 VPC CIDR 블록 ( 사설 IP 대역과 동일 ) 10.0.0.0- 10.255.255.255( 10.0.0.0/8 ) 172.16.0.0- 172.31.255.255( 172.16.0.0/12 ) 192.168.0.0- 192.168.255.255( 192.168.0.0/16 ) #\rRegion\r#\r리전이란 AWS가 서비스를 제공하는 거점 ( 국가와 지역 )을 나타냅니다. 이는 모두 같은 방법 ( AWS 매니지먼트 콘솔, SDK, CLI )로 사용이 가능하며, 이를 통해 해외의 특정 서비스에 인프라 구축이 필요할 경우 큰 장점이 될 수 있음. AWS에서 사용하는 일종의 IDC의 집합으로 거의 모든 클라우드 서비스가 탑재되는 것으로 다수의 Availability Zone( 가용영역 )으로 구성됨 한 곳의 AZ의 기능이 마비되어도 다른 AZ가 기능을 수행 전 세계 주요 대도시에는 분포되어있음 AWS 사용자는 각 Region 마다 별도의 클라우드 망을 구축할 수 있음 #\rAvailability zone\r#\r가용 영역은 데이터 센터와 같은 의미라고 할 수 있습니다. 중국을 제외한 각각의 리전에는 2개 이상의 AZ가 존재하며, AWS 사용자가 원하는 AZ를 선택해서 시스템을 구축하는 것이 가능합니다. 즉, On Premise 구성으로 구현하기 힘든 여러 개의 데이터 센터를 사용한 시스템 구성 ( 한 국가 내부의 DR ) 구성 등을 쉽게 구현할 수 있습니다. #\rVPC Peering\r#\rVPC 간의 트래픽을 전송하기 위한 기능 Source VPC와 같은 / 다른 리전의 VPC를 Destination으로 선택하여 Peering 요청을 보낸 후, 수락시 Peering 가능 요청과 수락이 필요한 이유는 다른 계정의 VPC도 연결 가능하기 때문 Peering 생성 후 라우팅 테이블에 해당 peering을 집어넣으면 통신 시작 VPC peering은 Transit Routing 불가 ( 재가의 VPC가 하나의 VPC를 통해 통신하는 것 ) #\rVPC Endpoint\r#\rVPC 내 요소들과 비 VPC 서비스( S3, CloudWatch, Athena 등 )을 외부인터넷을 거치지 않고 아마존 내부 백본 네트워크를 통해 연결하는 방법 그러므로 후술한 Direct Connect와 같은 전용선 서비스나 VPN, 인터넷 게이트웨이와 같은 외부 연결이 되어 있지 않는 서브넷에서 아마존의 여러 서비스를 연결가능 간단히 말하면 아마존 서비스 전용선 VPC 엔드포인트에는 Interface Endpoint, Gateway Endpoint 두 종류가 존재 Gateway Endpoint는 S3와 Dynamo DB만 가능 #\rSubnet\r#\rVPC 내 생성된 분리된 네트워크로 하나의 서브넷은 하나의 AZ ( Avaiability Zone ) 에 연결 VPC가 가지고 있는 사설 IP 범위 내에서 ‘서브넷’을 쪼개어 사용가능 실직적으로 리소스들을 이 서브넷에서 생성이 되며 사설 IP를 기본적으로 할당받고 필요에 따라 공인 IP를 할당받음 하나의 서브넷은 하나의 라우팅 테이블과 하나의 NACL( Network ACL ) 을 가짐 서브넷에서 생성되는 리소스에 공인 IP 자동할당 여부를 설정할 수 있음 이 기능을 통해 Public Subnet과 Private Subnet을 만들어 커스터마이징 가능 서브넷 트래픽이 후술할 인터넷 게이트웨이로 라우팅이 되는 경우 해당 서브넷을 Public Subnet, 그렇지 않은 서브넷의 경우 Private Subnet이라 함 각 서브넷의 CIDR 블록에서 4개의 IP 주소와 마지막 IP 주소는 예약 주소로 사용자가 사용할 수 없음, 예를 들어 서브넷 주소가 172.16.1.0/24일 경우 172.16.1.0: 네트워크 주소 ( Network ID ) 172.16.1.1: VPC Router용 예약 주소 ( Gateway ) 172.16.1.2: DNS 서버의 IP주소 172.16.1.3: 향 후 사용할 예약 주소 172.16.1.255: 네트워크 브로드캐스트 주소 #\rVPN ( Virtual Private Network )\r#\rAWS의 IPSEC VPN 서비스 이 VPN을 통해 AWS와 On-premise의 VPN을 연결하는 것이 가능 고객 측 공인 IP를 뜻하는 ‘Customer Gateway’와 AWS 측 게이트웨이인 ‘Virtual Private Gateway’ 생성 후 터널을 생성하면 사용 가능 반드시 VPC에서 VPN 터널 쪽으로 라우팅을 생성해야 함 #\rDirect Connect\r#\rAWS의 데이터센터 및 오피스 네트워크와의 전용선 서비스 표준 이더네세 광섬유 케이블을 이용하여 케이블 한쪽을 사용자 내부 네트워크의 라우터에 연결하고 한 쪽을 Direct Connect 라우터에 연결하여 내부 네트워크 AWS VPC를 연결 보통 On-premise의 네트워크와 VPC를 연결할 때 사용 VPN보다 더 안전하고 빠른 속도를 보장 받고 싶을 때 사용 ( 백업 등 ) 전용선 열결\n#\rVPC 사용한 Public Subnet\u0026amp; Private Subnet 생성 실습\r#\r#\rAmazon CloudFront\r#\r#\r.html, .css, .js 및 이미지 파일과 같은 정적 및 동적 웹 콘텐츠를 사용자에게 더 빨리 배포하도록 지원하는 웹 서비스 전 세계에 배치된 Edge location을 이용하여 효율적인 컨텐츠 배포 구조를 제공하는 것 Cloud Front는 HTTP/ HTTPS를 이용하여 S3 및 ELB, EC2, 외부 서버 등을 캐시하고 보다 빠른 속도로 콘텐츠를 전달하는 캐시 서버 Distribution은 Edge Location의 집합을 의미 Edge Location은 주변 Origin Server의 콘텐츠를 Edge Location에 캐싱하고 각 Edge Location 간 공유를 통해 콘텐츠를 전달 S3, ELB, EC2 등의 AWS 서비스뿐만 아니라 외부의 서버도 캐싱 가능 ( Custom Orgin ) TTL을 조절하여 캐시 주기를 통제할 수 있음 #\rAWS Direct Connect\r#\r온 프레미스에서 AWS로 전용 네트워크 연결을 쉡게 설정할 수 있는 클라우드 서비스 솔루션 AWS와 사용자 데이터 센터, 사무실 등의 환경 사이에 프라이빗 연결이 가능 #\rDirect Connect의 이점\r#\r대역폭 비용 감소\n대역폭 사용량이 많은 워크로드를 AWS에서 실행하려는 경우, AWS에서는 데이터를 직접 송수신하므로, 인터넷 서비스의 대한 의존도를 줄일 수 있음 전용 연결을 통해 전송되는 데이터 요금은 인터넷 데이터 전송 요금이 ㅇ닌 보다 저렴한 AWS Direct Connect 데이터 전송 요금으로 부과되어짐 일관된 네트워크 성능\n데이터와 데이터의 라우팅 방식이 선택되면 인터넷 기반 연결에서 효율적인 네트워크 환경의 제공이 가능 모든 AWS 서비스와 호환 가능\nAWS Direct Connect는 네트워크 서비스의 일종으로, 인터넷을 통해 액세스 할 수 있는 모든 AWS 서비스와 연동 AMAZON VPC로 프라이빗 연결\nAWS Direct Connect를 사용하여 온프레미스 네트워크에서 직접 Amazon VPC로 프라이빗 가상 인터페이스를 설정함으로써 네트워크와 VPC 간에 네트워크 연결을 제공할 수 있음 여러 가상 인터페이스를 사용하면 네트워크 격리를 유지하면서 여러 VPC 프라이빗 연결을 설정할 수 있음 탄력성\nAWS Direct Connect를 사용하면 요구 사항에 맞게 연결을 용량을 손쉽게 조정이 가능 간편성\nAWS Direct Connect는 직접 설치하는 것이 아닌, 설정하는 것으로 간편함 #\rAWS Route 53\r#\r#\rAWS의 DNS 서비스 ( 도메인 등록, DNS 라우팅, Health check ) 도메인 등록시 약 12.000원 정도 지불해야 하며, 최대 3일 정도 걸림 해당 도메인을 AWS 내 서비스 ( EC2, ELB, S3 등 ) 와 연결 할 수 있으며 AWS 외 요소들과도 연결 가능 도메인 생성 후 레코드 세트를 생성하여 하위 도메인을 등록할 수 있음 레코드 세트 등록시에는 IP 주소, 도메인, ‘Alias’ 등을 지정하여 쿼리를 라우팅할 수 있음 도메인 레지스트라 서비스를 통해 도메인 구매부터 정보 설정까지 Route 53으로 한번에 관리가 가능합니다. 장애 허용 아케텍처를 통해 시스템에 이상이 발생한 경우, 일시적으로 다른 서버로 전환하는 것이 가능합니다. DNS\r↕\rDNS ( Domain Name System )\r#\rDNS란 도메인네임서버를 일컫으며, 인터넷은 서버들을 유일하게 구분할 수 있는 IP주소 체계를 보다 인간이 읽게 쉽게 하기 위해 계발되었다. 흔히 우리가 알고 있는 naver.com, google.com, daum.net 모두 DNS이다. AWS에서는 Route 53을 활용해 도메인 서비스를 지원한다. #\rRoute 53의 라우팅 정책\r#\rSimple : 동일 레코드 내에 다수의 IP를 지정하여 라우팅 가능, 값을 다수 지정한 경우 무작위로 반환함 Weighted : Region 별 부하 분산 가능, 각 가중치를 가진 동일한 이름의 A 레코드를 만들어 IP를 다르게 줌 Latency-based : 지연 시간이 가장 적은, 즉 응답시간이 가장 빠른 리전으로 쿼리를 요청 Failover : A/S 설정에서 사용됨, Main과 DR로 나누어 Main 장애시 DR로 쿼리 Geolocation : 각 지역을 기반으로 가장 가까운 리전으로 쿼리 수행, 레코드 생성시 지역을 지정할 수 있음 Geo-proximity : Traffic flow를 이용한 사용자 정의 DNS 쿼리 생성 가능 Multi-value answer : 다수의 IP를 지정한다는 것은 simpl와 비슷하지만 health check가 가능 ( 실패시 자동 Failover ) #\rAWS Route 사용방법\r...\r#\rAWS Route 사용방법\r#\rAWS 서비스에 route를 검색 후 Route 53을 선택한다.\r#\r#\rRoute 53의 원하는 서비스를 선택한다.\r#\r#\r#\r각 서비스의 간략한 설명\r#\r#\r도메인 등록\r#\r단순 도메인을 구입하여 등록한다. #\r트래픽 흐름 처리\r#\r트래픽 처리 등의 룰을 추가한다. #\rDNS 관리\r#\r호스트 도메인을 등록한다 #\r모니터링 서비스는 DNS 흐름 프로세스를 모니터링 하는 서비스\r#\r#\rAWS 콘솔 SSL/ TLS 설치\r...\r#\rAWS 콘솔 SSL/ TLS 설치\r#\r#\rAWS 서비스에서 certificate 검색\r#\r#\r인증서를 만들 것인지 혹은 사설 인증기관을 사용할 것인지를 선택\r#\r#\r프로비저닝이 선택할 경우\r#\r기존의 다른 업체에서 이미 발급받은 경우 Certificate Manager을 통해 등록이 가능하며, 무료로 발급도 가능 #\r적용시킬 도메인 이름 선택\r#\r#\rDNS 검증 : Certificate Manager에서 제시하는 특정 레코드를 추가해서 본임임을 인증 이메일 검증 : 해당 도메인의 관리자 계정으로 이메일을 보내서 본임임을 인증, 이 방법을 이용하기 위해서는 해당 도메인의 메일 서버에 연동되어 있어야 가능 #\r검증방법 선택\r#\r요청이 완료되면 해당 도메인에 다음과 같은 이름과 값으로 CNAME 기록을 추가 해야 하며, AWS가 아닌 업체를 통해서 했다면 해당 업체의 사이트에서 레코드를 추가하면 되며, Route 53을 통해 자동으로 레코드 생성이 가능 #\r발급한 인증서를 로드 밸런서의의 기존에 생성했던 리스너를 추가시킨 후, 인증서를 추가하면 추가가 완료된 것을 확인할 수 있으며, http://가 아닌 https:// 접속이 가능한 것을 확인할 수 있다. #\r"},{"id":20,"href":"/cloud/docs/AWS/AWSTraining/VPC/","title":"AWS 사용자 정의 VPC 생성","section":"AWS Training","content":"\rAWS 사용자 정의 VPC 생성\r#\r#\rAWS 사용자 정의 VPC 생성\r#\r#\r이제 본격적으로 AWS 서비스들에 대해서 다루어 보겠습니다. 그 중, AWS 서비스의 근간이 VPC를 생성해 보도록 하겠습니다. VPC 중요한 개념이므로, VPC에 대한 개념이 부족한 분들은은 AWS VPC를 참고해주세요. #\r#\rGUI 환경에서의 사용자 정의 VPC 생성\r#\r기본적인 VPC 생성의 순서\n1. VPC 네트워크 생성 2. Internet Gateway 설정\n2. Subnet 설정\n3. Route Table 설정\n5. Network ACL 설정\n6. Security Group 설정 여기에서는 ACL은 기본 값, Security Group에 대한 설정은 인스턴스를 생성할 때 설정하였습니다.\n#\rAWS 서비스에서 VPC를 검색합니다. #\r#\rVPC 대시보드에서는 VPC서비스의 전체적인 서비스 상태를 확인할 수 있습니다. 좌측 메뉴에서 VPC 생성을 위해 VPC를 선택합니다. #\r#\rAWS 가입시 기본적으로 기본 VPC가 생성되며, Custom VPC를 생성하기 위해 VPC 생성을 클릭합니다. #\r#\rVPC 생성을 위해 VPC의 이름과 주소대역을 CIDR 형식으로 작성합니다. #\r#\r생성이 완료되었습니다. 이제 인터넷에 연결하기 위해 인터넷 게이트웨이로 이동합니다. #\r#\r인터넷 게이트 웨이를 생성합니다. #\r#\r인터넷 게이트 웨이 생성 후, VPC를 연결합니다. #\r#\r이제 서브넷 대역을 생성하기 위해 서브넷을 선택합니다. #\r#\r현재 기본 VPC의 서브넷 대역이 3개가 존재합니다. 새로 생성한 Custom-VPC의 서브넷을 생성하기 위해 서브넷 생성을 클릭합니다. #\r#\r저는 퍼블릭 대역 10.0.0.0/24와 프라이빗 10.0.10.0/24의 서브넷 대역을 생성해보겠습니다. #\r#\r생성이 완료된 후, 라우팅 설정을 위해 라우팅 테이블을 클릭합니다. #\r#\r퍼블릭, 프라이빗 라우팅 테이블을 생성합니다. #\r#\r퍼블릭에서 하단에 서브넷 연결을 클릭 후, 서브넷 연결 편집에서 퍼블릭 서브넷을 등록시킵니다. 이와 동일하기 프라이빗 라우팅 테이블에 프라이빗 서브넷을 등록시킵니다. #\r#\r서브넷 생성을 완료 후, 서브넷 연결의 좌측에 라우팅 편집을 클릭합니다. #\r#\r퍼블릭과 프라이빗을 인터넷 게이트웨이에 연결시킵니다. 이것으로 GUI를 통한 VPC의 생성이 완료되었습니다. 다음 장에서 생성된 VPC대역에 인스턴스를 생성해보겠습니다. #\r#\rAWS CLI로 VPC 생성\r#\r이번에는 VPC를 CLI 환경을 통해 생성해보도록 하겠습니다. CLI환경 또한 동일한 순서로 생성을 진행하겠습니다. #\r$ aws ec2 create-vpc --cidr-block 10.0.0.0/16 # 10.0.0.0/16의 CIDR을 가진 VPC를 생성합니다. $ aws ec2 modify-vpc-attribute --vpc-id [ VPC-ID ] --enable-dns-hostnames # [ VPC-ID ]를 가진 VPC에 DNS를 사용하도록 설정합니다. $ aws ec2 create-vpc --cidr-block 10.0.0.0/16 --instance-tenancy dedicated # 만약 vpc 네트워크의 Tenanacy를 Dedicated로 생성한다면 다음의 명령어를 통해 실행시킵니다. VPC를 생성 및 설정합니다. #\r#\r$ aws ec2 create-internet-gateway # 인터넷 게이트웨이를 생성합니다. $ aws ec2 attach-internet-gateway --internet-gateway-id [ igw ID ] --vpc-id [ VPC ID ] # VPC ID에 해당하는 VPC에 igw ID에 해당하는 인터넷 게이트웨이를 연결시킵니다. 인터넷 게이트웨이를 생성합니다. #\r#\r$ aws ec2 create-subnet --vpc-id [ VPC-ID ] --availability-zone ap-northeast-2a --cidr-block 10.0.0.0/24 # VPC-ID에 해당하는 VPC에 ap-northeast-2a에 가용영역에서 10.0.0.0/24에 subnet을 생성합니다. $ aws ec2 create-subnet --vpc-id [ VPC-ID ] --availability-zone ap-northeast-2c --cidr-block 10.0.10.0/24 # VPC-ID에 해당하는 VPC에 ap-northeast-2c에 가용영역에서 10.0.10.0/24에 subnet을 생성합니다. subnet을 생성 및 설정합니다. #\r#\r$ aws ec2 create-route-table --vpc-id [ VPC-ID ] # VPC-ID에 해당하는 VPC에 route table을 생성합니다. $ aws ec2 associate-route-table --route-table-id [ rtb-id ] --subnet-id [ subnet-id ] # rtb-id에 해당하는 route table에 subnet-id에 해당하는 subnet을 등록시킵니다. $ aws ec2 create-route --route-table-id [ rtb-id ] --destination-cidr-block 0.0.0.0/0 --gateway-id [ igw-id ] # rtb-id에 해당하는 route table에 모든 게이트웨이를 [ igw-id ]에 연결합니다. Route table을 생성 및 설정합니다. #\r#\r$ aws ec2 describes-vpcs --vpc-id [ VPC-id ] $ aws ec2 describes-subnets --subnet-id [ subnet-id ] $ aws ec2 describes-internet-gateway --inernet-gateway-id [ igw-id ] $ aws ec2 describes-route-tables --route-table-id [ rtb-id ] # 생성 및 설정 확인 생성 및 설정을 확인합니다. #\r다음 장에서는 이번에 생성한 VPC를 사용하여, EC2를 생성해보도록 하겠습니다. "},{"id":21,"href":"/cloud/docs/OpenStack/OpenStack/Nova/","title":"Nova","section":"OpenStack docs","content":"\r가상의 서버를 생성하는 서비스 : Nova\r#\r#\r가상의 서버를 생성하는 서비스 : Nova\r#\r#\rNova는 compute 서비스의 핵심 compute 서비스란, 가상머신이 필요한 자원을 할당하고, 관리하는 서비스로 하이퍼바이저, 메시지 Queue, 인스턴스 접속을 하는 콘솔 등의 다양한 기능이 유기적으로 연결되어 가상 서버를 생성할 수 있는 시스템을 구성하는 시스템 #\r#\rNova 서비스의 고려사항\r#\r#\r고려사항 설명 CPU compute 서비스가 동작할 호스트 시스템의 cpu가 기본적으로 자체 하드웨어 가상화를 지원이 필수 Hypervisor 서비스에 사용할 하이퍼바이저를 맞게 설정해야 하며, 기본적으로 사용하는 Hypervisor은 KVM/QEMU Storage compute 서비스를 통해 인스턴스가 생성되면서 시스템의 디스크 용량의 제한을 가할 수 있음, 이를 위해 넉넉한 공간이 필요 Overcommit 기본적으로 자원을 할당하는 경우 1:1이 아닌 CPU는 16:1, Memory는 1.5:1로 할당 되어짐 네트워킹 생성된 인스턴스의 경우 nova가 독자적으로 구현하는 것이 아닌 다른 network 서비스를 연게해서 사용해야하며, 주로 Neutron 네트워크 서비스와 함께 사용 #\r#\rNova의 논리 아키텍처\r#\r#\r#\r서비스 역할 nova-api 최종 사용자즈이 API콜을 통해 서비스 간 질의 응답을 담당 nova-compute 가상화 API를 이용하여 가상 머신 인스턴스를 생성하고 종료하는 역할을 수행 nova-scheduler compute host가 다수인 경우 큐를 통해 받은 메시지를 누구에게 명령할 것인지를 결정 nova-conductor 코디네이션과 데이터베이스 쿼리를 지원하는 서버 데몬 nova-cert X509 인증서에 대한 Nova Cert서비스를 제공하는 서버 데몬 nova-consoleauth 데몬, 콘솔 프록시를 제공하는 사용자에 대한 인증 토큰 제공 Guest Agent 실제 compute 시스템 상에 구축된 인스턴스로 Nova-compute 서비스에 의해 제어되어짐 nova-api-metadata 인스턴스의 메타데이터의 요청을 처리 nova-novncproxy VNC 콘솔화면을 제공 nova-novaclient: nova REST API를 사용하는 클라이언트 프로그램 nova-network | 인스턴스의 네트워크 기능을 수행 nova-compute-kvm | 인스턴스(가상 머신)와 관련된 모든 프로세스를 처리 python-guestfs | 파일 생성 기능을 지원하는 Python 라이브러리 qemu-kvm | KVM 하이퍼바이저\n#\r위와 같이 많은 서비스들이 존재 #\rNova는 대시보드나 콘솔에서 호출하는 nova-api에서 시작 Queue를 이용해 nova-compute에 인스턴스를 생성하라는 명령을 전달 nova-compute는 하이퍼바이저 라이브러리를 이용해 하이퍼바이저에 인스턴스를 생성하려는 명령어를 전달 Hypervisor을 통해 인스턴스를 생성 생성된 인스턴스는 nova-api로 접근할 수 있으며 Nova의 모든 기능은 메시지 Queue로 처리할 수 있음 #\r#\rNova가 지원하는 하이퍼바이저의 종류\r#\r기본 하이퍼바이저는 KVM과 QEMU 프로바이더가 테스트하는 Hyper-V, VMware, XenServer, Sen via libvirt 몇 번의 테스트만 하는 하이퍼바이저 드라이버인 베어메탈, Docker, LXC via libvirt #\r"},{"id":22,"href":"/cloud/docs/AWS/AWSSAA/SAA-5/","title":"5장 데이터베이스","section":"AWS SAA 시험정리","content":"\r5장 데이터베이스\r#\r#\r5장의 목표\r#\r#\r복원력을 갖춘 아키텍처 설계 안정적이고/ 복원력을 갖춘 스토리지를 선택한다.\n어떻게 AWS 서비스를 사용해 결합 해제 매커니즘을 설계할지 결정한다.\n어떻게 멀티 티어 아키텍처 솔루션을 설계할지 결정한다.\n어떻게 고 가용성 및/ 내결함성을 갖춘 아키텍처를 설계할지 결정한다.\n#\r성능이 뛰어난 아키텍처 정의 성능이 뛰어난 스토리지 및 데이터베이스를 선택한다. 탄력성과 확장성을 갖춘 솔루션을 설계한다. #\r#\r데이터베이스\r#\r#\r데이터베이스를 사용하면 어플리케이션을 데이터를 저장하고 구성하며, 신속하게 검색할 수 있다.\n단층 파일(Flat File)에 데이터를 저장할 수도 있지만, 데이터양이 증가하게 디면 검색 속도가 느려지는 단점이 있으며, 개발자는 데이터를 저장하고 검색하기 위해 직접 파일 시스템에서 작업하는 대신, 데이터베이스로 작업을 수행함으로써 애플리케이션 개발에 집중하는 것이 가능하다.\n데이터베이스에 기반한 애플리케이션을 구현할 때, 애플리케이션의 가용성과 성능은 데이터베이스 선택과 구성 방법에 다려 있으며, 데이터베이스는 관계형과 비관계형 두 가지로 나뉘어 지며, 사용자는 데이터 저장, 구성, 검색 방법에 따라 애플리케이션에 가장 적합한 데이터베이스를 선택할 수 있다.\n데이터베이스에 장애가 발생할 때 데이터를 보호 및 복구하는 방법 뿐이 아닌, 애플리케이션의 필요한 수준의 성능과 안정성을 얻기 위해 AWS가 제공하는 데이터베이스 서비스를 학습한다.\n#\r#\r관계형 데이터베이스\r#\r#\r관계형 데이터베이스는 하나 이상의 테이블을 포함한 열과 행이 있어 스프레드시트로 시각화가 가능한 데이터베이스를 의미한다.\n관계형 데이터베이스 테이블에서 열은 속성, 행은 레코드 또는 튜플이라고 한다.\n#\r열과 속성\r#\r#\r관계형 데이터베이스 테이블에 데이털르 추가하기 전에, 각 열의 이름과 입력될 데이터의 형식을 사전에 정의해야 한다.\n열에는 순서가 있으며, 테이블을 생성한 후에는 이 순서를 변경할 수는 없다.\n열의 순서를 정하려면 테이블에 있는 속성 간에 관계를 만들어야 하며, 여기에서 관계형 데이터베이스라는 용어가 등자하게 되었다.\n하단은 테이블의 예시를 나타낸다.\n사원 ID(숫자) 부서(문자열) 성(문자열) 이름(문자열) 셍일(날짜) 101 전산 Smith Charlotte 7-16-87 102 마케팅 Colson Thomas 7-4-00 데이터는 각 열에서 정의된 형식에 반드시 일치해야 하며, 이와 다르게 숫자에 문자열을 입력하는 등의 작업을 진행할 경우 오류가 발생하게 된다. 관계형 데이터베이스의 이점은 데이터를 어떻게 쿼리할지 이해할 필요가 없다는 것이며, 데이터가 일관된 형식으로 존재하는 한 필요한 데이털르 원하는 방식으로 얻기 위해 여러 쿼리를 가공할 수 있다. 관계형 데이터베이스는 임의의 열에 데이터를 쿼리하고 사용자가 데이터를 제공 방식을 지정해야 하는 애플리케이션에 적합하다. #\r#\r다중 테이블 사용\r#\r#\r모든 데이터를 단일 테이블에 저장하면 불피요한 중복이 생기기 때문에 데이터베이스가 불필요하게 커지고 쿼리 속도가 느려지므로, 일반적으로 애플리케이션은 다중 테이블을 연결해서 사용한다.\n하단은 상단의 테이블을 원하는 자료를 모아 생성한 테이블이다.\n부서 ID(숫자) 부서명(문자열) 10 전산 20 마케팅 사원 테이블의 각 사원 레코드에 부서명을 입력하는 대신 부서 테이블에 레코드를 하나를 생성한 후, 사원 테이블의 사원 ID를 통해 각 부서를 참조하는 것이 가능하다. 이러한 관계에서 부서 테이블은 상위 테이블(Prarent Table)이며, 사원 테이블은 하위 테이블(Child Table)이다. 사원 테이블의 부서 열에 있는 값은 부서 테이블의 부서 ID를 참조한다. 여기서 부서 ID는 기본 키(Primary Key)라 하며, 기본 키는 행을 고유하게 식별하기 위해서 테이블 내에서 유일해야 한다. 사원 테이블은 부서 ID를 외래 키(Foregin Key)로 참조한다. 데이터베이스가 여러 테이블의 열이 어떻게 연관됐는지 알 수 있도록 기본 키와 외래 키를 반드시 정해야 하며, 데이터베이스는 외래 키 제약 조건을 활성화해 하위 테이블이 외래 키를 참조할 때 해당 키가 상위 테이블에도 존재하는 지 확인해야 한다. #\r#\rSQL\r#\r#\r관계형 데이터베이스에서는 구조화 질의 언어 SQL(Structured Query Language)를 사용해 데이터를 저장하고 쿼리하고 유지 관리 작업을 수행하므로 SQL 데이터베이스라고 불린다.\nSQL문은 관계형 데이터베이스 관리 시스템(RDBMS, Relational Database Management System) 마다 조금씩 차이가 있으며, 이는 주요 프로그래밍 언어들에 SQL 문을 만들고 데이터베이스에 입출력하는 라이브러리가 이기 때문으로, AWS 아키텍처로써 SQL까지는 알 필요는 없지만 AWS 관리형 데이터베이스에 작업하기 위한 일반적인 SQL 용어의 개념은 이해할 필요가 있다.\n#\r#\r데이터 쿼리\r#\r#\rSELECT 문은 SQL 데이터베이스에서 데이터를 쿼리하는 데 사용되며, 데이터베이스에서 조회하고 싶은 특정 열을 지정할 뿐 아니라 모든 열에서 값을 기반으로 쿼리가 가능하다.\n테이블의 에측 가능한 구조와 외래 키 제약 조건을 사용해서 SELECT 문과 함께 JOIN 절을 사용해 여러 테이블의 데이터를 결합할 수 있다.\n#\r#\r데이터 저장\r#\r#\rINSERT 문을 사용하면 테이블에 직접 데이터를 삽입할 수 있으며, 대량의 레코드를 저장해야 할 때 COPY 명령을 사용하면 적절하게 형식을 ㅁ맞춘 파일에서 지정한 테이블로 데이터를 복사할 수 있다. #\r#\r온라인 트랙잭션 처리와 온라인 분석 처리\r#\r#\r관계형 데이터베이스는 구성에 따라 온라인 트랜잭션 처리(OLTP, OnLine Transaction Processing)과 온라인 분석 처리(OLAP, Online Analytical Processing) #\r#\rOLTP\r#\r#\rOLTP 데이터베이스는 초당 몇 회씩 순차적으로 데이터를 버번하게 읽고 쓰는 애플리케이션에 적합하며, OLTP 데이터베이스는 빠른 쿼리에 최적화 되어 있다.\nOLTP 데이터베이스는 정기적이고 예측 가능한 경향이 있으며, 요구조건에 따라 메모리가 상당량 필요할 수 있으며, 이는 빠른 액세스를 위해 자주 사용하는 테이블의 일부를 메모리에 저장하기 때문이다.\nOLTP 데이터베이스는 1분당 수백 건의 주문을 처리해야 하는 온라인 주문 시스템을 지원하는 데 적합하다.\n#\rOLAP\r#\r#\rOLAP 데이터베이스는 복잡한 대형 데이터 세트 쿼리에 최적화 되어 있으며, 상단하 스토리지와 컴퓨팅이 필요하여 데이터웨어하우징 애플리케이션으르 구축하여 여러 OLTP 데이터베이스를 단일 OLAP 데이터베이스로 모으는 것이 일반적이다.\n보통 대형 OLAP 데이터베이스에서는 복잡한 쿼리로 인한 컴퓨팅 부하를 여러 데이터베이스 서버가 나눠 처리하며, 파티셔닝이라는 프로세스에서 각 서버는 데이터베이스 일부를 맡아 처리한다.\n#\r#\rAmazone Relational Database Server ( 이하 RDS )\r#\r#\rRDS는 클라우드에서 관계형 데이터베이스 시스템을 실행할 수 있게 하는 관리형 데이터베이스 서비스로, 데이터베이스 시스템 설정, 백업 수행, 고 가용성 보장, 데이터베이스와 기반 운영체제 패치 적용 등과 같은 작업을 수행한다.\nRDS를 사용하면 데이터베이스 장애로부터 복구, 데이터 복원, 데이터베이스 확장을 쉽게 사용하여 애플리케이션이 요구하는 수준의 가용성과 성능을 달성할 수 있다.\nRDS를 사용해 데이터베이스를 배포할 때, 격리된 데이터베이스 환경인 데이터베이스 인스턴스 구성에서부 시작한다. 데이터베이스 인스턴스는 지정한 가상 프라이빗 클라우드(VPC)에 존재하나, EC2 인스턴스와는 다르게 AWS가 전적으로 데이터베이스 인스턴스를 관리한다. SSH를 사용해 엑세스할 수 없으며, EC2 인스턴스 사이에서도 보이지 않는다.\n#\r데이터베이스 엔진 데이터베이스 엔진은 데이터베이스에 데이터를 저장, 구성, 반환하는 소프트웨어이며, 데이터베이스 인스턴스는 하나의 데이터베이스 엔진만 실행한다.\nRDS는 다음 여섯 가지 데이터베이스 엔진 중에서 선택할 수 있다.\nMySQL MySQL은 블로그 및 전자상거래와 같은 OLTP 애플리케이션으로 설계되었으며, RDS는 5.5, 5.6, 5.6 등 최신 MySQL Community Edition 버전을 제공한다. MySQL은 myISAM과 InnoDB 두 가지 스토리지 엔진에서 하나를 선택할 수 있지만, 유일하게 RDS 관리형 자동 백업과 호환할 수 있는 엔진은 InnoDB이다. #\rMaria DB Maria DB는 MySQL과 바이너리 수준의 호환성을 가지면서 기능을 향상한 데이터베이스이다. Maria DB는 오라클이 MySQL을 개발한 회사를 인수한 이후, MySQL의 미래를 우려해서 개발되었으며, MariaDB는 XtraDB와 InnoDB 스토리지 엔진을 지원하지만, AWS에서는 RDS와의 호환성을 최대화하기 위해 InnoDB를 사용할 것이 권장된다. #\rOracle Oracle은 가장 널리된 DBMS로 일부 애플리케이션은 데이터베이스사양으로 Oracle을 데이터베이스로 명시하기도 한다. RDS는 다음 Oracle 데이터베이스 에디션을 제공한다. Standare Edition One(SE1) Standare Edition Two(SE2) Standare Edition(SE) Enterprise Edition One(SE) #\rPostgreSQL PostgreSQL은 Oracle과 호환되는 오픈 소스 데이터베이스이며, Oracle 기반으로 애플리케이션을 제작하였어도, 비용을 위해 PostgreSQL을 선택하기도 한다. #\rAmazone Aurora Amazon Aurora는 Amazon이 MySQL과 PostgreSQL과 바이이너리 수준의 호환성을 가지면서 기능을 향상시킨 데이터베이스이며, 가상 스토리지 계층을 사용해서 하부 스토리지 쓰기 횟수를 줄이기 때문에 MySQL, PostgreSQL보다 쓰기 성능이 우수하며 하단의 세 가디 에디션을 제공한다. MySQL 5.6-compatible MySQL 5.7-compatible PostgreSQL compatible Aurora는 에디션에 따라서 PostgreSQL이나 MySQL과 부러오기/ 내보내기 도구, 스냅샷에서 호환되며, 두 오픈 소스 데이터베이스에서 언할하게 마이그레이션 할 수 있도록 설게되어 있다. Aurora는 MySQL 호한 에디션에서 InnoDB 스토리지 엔진만 지원하며, MySQL에서 사용할 수 있는 Aurora Backtrack 기능으로 데이터베이스를 지난 72시간 이내 특정 시점으로 단 몇 초 만에 복구가 가능하다. #\rMicrosoft SQL Server 여러 Microsoft SQL Server과 Express, Web, Standard, Enterprise 에디션을 사용할 수 있으며, 다양한 기능을 사용해서 데이터베이스 업그레이드를 수행하지 않고도 온프레미스에 배포된 기존 SQL 데이터베이스를 RDS로 마이그레이션 할 수 있다. #\r라이센스 고려사항 RDS는 데이터베이스 엔진을 실행하는 데 필요한 두 가지 소프트웨어 라이선스 모델을 제공하며, 라이센스가 포함된 모델은 RDS 인스턴스 요금에 라이센스 비용이 포함되여 제공된다.\n기존 보유 라이센스 사용(BTOL : Bring Your Own License)모델을 선택하려면 실행 중인 데이터베이스 엔진의 라이센스를 확보해야 한다.\n라이센스가 포함된 모델 MariaDB나 MySQL은 GNU GPL(General Public License)v2.0을 사용하며, PostgreSQL은 PostgreSQL 라이선스를 사용하고, 별도의 라이선스 비용은 없다.\nRDS에서 실행하는 Microsoft SQL 서버의 모든 버전과 에디션은 라이선스를 포함하며, Oracle Database Standard Edition One과 Oracle Database Standard Edition Tow도 라이선스를 포함하고 있다.\n#\r데이터베이스 옵션 그룹 데이터베이스 엔진은 데이터베이스 관리와 보안 향상을 지원하는 다양한 기능을 제공한다.\n옵션 그룹은 옵션이라는 관리 및 보안 기능을 지정해서 하나 이상의 인스턴스에 적용할 수 있게 한다.\n옵션을 사용하려면 메모리가 더 필요하므로 인스턴스에 충반한 메모리가 있는지 확인하고 필요한 것만 활성화 해야한다.\n옵션 그룹에서 사용 가능한 옵션들은 데이터베이스 엔진마다 다르며, Microsoft SQL Server와 Oracle은 TDE를 제공해 스토리지에 쓰기를 수행하기 전에 엔진이 데이터를 암호화하게 한다.\nMySQL과 MariaDB는 데이터베이스 사용자 로그인 쿼리 활동을 기록하게 하는 감사 플러그인을 제공한다.\n#\r데이터베이스 인스턴스 클래스 데이터베이스 인스턴스를 시작할 때 처리 성능, 메모리, 네트워크 대역폭, 디스크 처리량이 어느 정도 필요한지를 결정해야 하며, RDS는 여러 데이터베이스를 다양한 성능 요구 사항을 충족하기 위해 다양한 데이터베이스 인스턴스 클래스를 제공한다.\n선택을 잘못 했거나 요구 사항이 변경될 때 인스턴스를 다른 클래스로 전환할 수도 있으며, RDS 데이터베이스 인스턴스 클래스를 다음의 세 가지 유형으로 분류한다.\n#\r표준 256G 메모리 64v CPU 25Gbps 네트워크 대역폭 10.000Mbps(1.280Mbps) 디스크 처리량 #\r메모리 최적화 (대용량의 처리량) 3.940GB 메모라 128 vCPU 25Gbps 네트워크 대역폭 14.000Mbps(1.750P 디스크 처리향 #\r순간확장 가능 (개발 및 테스트 용도) 32GB 메모리 8 vCPU #\r스토리지 데이터베이스 인스턴스에 적합한 스토리지 선택은 충분한 디스크 공간 확보 이상으로 중요하다.\n데이터베이스 기반 애플리케이션의 성능 요구사항을 충족하기 위해서는 얼마나 빠른 스토리지를 선택할지도 판단해야 한다.\n#\rIOPS의 이해 AWS는 초당 입력/ 출력 작업(IOPS, Input/ Output Operations Per Second)를 사용해 스토리지 성능을 측정한다.\n입출력 작업은 스토리지 읽기 또는 쓰기 작업으로 다른 모든 조건이 같을 때, IOPS가 큰 데이터베이스는 데이터를 저장하고 검색하는 속도가 더 빠르다.\nRDS는 스토리지 타입에 따라 IOPS를 할당할 수 있으나, 임계 값을 초과할 수는 없다.\n데이터베이스 스토리지의 속도는 할당된 IOPS 수에 제한되며, 단일 I/O 작업에서 전송할 수 있는 데이터의 양은 데이터베이스 엔진이 사용하는 페이지 크기에 달려 있어, 요구되는 IOPS 수준을 파악하려면 먼저 필요한 디스크 처리량을 확인해야 한다.\nMySQL과 MariaDB의 페이지 크기는 16KB이므로, 디스크에 16KB의 데이터 쓰기가 하나의 I/O 작업을 구성한다.\n반면 Oracle, PostgreSQL, Microsoft SQL Server는 8KB 크기의 페이지를 사용하며, 이 경우 16KB의 데이터를 쓰면 I/O 작업이 두 번 이루어진다.\n페이지 크기가 클수록 단일 I/O 작업에서 더 많은 데이터를 전송할 수 있다.\n페이지의 크기가 16KB라고 하고, 데이터베이스가 초당 102,400KB(100MB)의 데이터를 읽어야 한다고 할 때, 이러한 성능 요구를 달성하려먼 데이터베이스는 매초 16KB 페이지 크기로 6,400 페이지를 읽어여 하며, 페이지 당 I/O 작업 하나로 계산하기 때문에 스토리지와 인스턴스 클래스는 6,400 IOPS를 유지해야 한다. 이 때, IOPS 수와 페이지 크기는 반비례 관계이며, 페이지가 클 수록 같은 처리량을 달성하는 데 필요한 IOPS는 작아진다.\n#\r스토리지 유형에 따라 IOPS 수가 달라지며, RDS는 다음 세가 유형의 스토리지를 제공한다. 범용 SSD 데이터베이스의 대부분은 범용 SSD(gp2) 스토리지로 충분하다.\n범용SSD 스토리지는 속도가 빠르고 한 자릿수 밀리초 지연 시간을 제공하며, 최대 16TB의 보륨을 할당할 수 있다.\nRDS는 기본적으로 기가바이트당 3 IOPS 성능을 볼륨에 할당하며, 최대 10,000 IOPS까지 볼륨을 할당할 수 있다.\n볼륨이 커지면 성능이 향상되며, 데이터베이스 엔진의 따라 만들 수 있는 스토리지 볼륨의 최소 크기는 다르다.\ngp2 스토리지 유형의 최대 처리량은 1,280(160MB)이며, 최대 처리량을 만족하기 위해서는 인스턴스가 적어도 1,280(160MB) 이상의 디스크를 지원할 수 있어여 하며, 처리량을 유지하기 위해 IOPS를 할당해야 한다.\n예시로 Maria DB를 16KB 페이지 크기로 실행한다고 가저하였을 때, 1,280Mbps 디스크 처리량을 유지하는 데 필요한 IOPS 수는 1,280MBPS/0.128MB = 10,000 IOPS이다.\n즉, 볼륨에서 1,280Mbps의 디스크 처리량을 달성하려면 10,000 IOPS가 할당되어야 하며, 이것은 gp2에서 할당 가능한 최대 IOPS 수라는 것에 주목한다. 이것을 다시 계산해보면 이 정도의 IOPS를 확보라혀면 볼륨 크기가 3,333,3GB(3.34TB)가 되어야한다.\n최대 3,000 IOPS가 필요하지만 그렇게 큰 스토리지가 필요하지 않을 때, 필요한 IOPS를 얻기 위해서는 스토리지를 과도하게 할당할 필요는 없다. 1TB보다 작은 볼륨은 일시적으로 3,000 IOPS까지 순간 확장이 가능하며, 순간 확장 지속 시간은 다음과 같은 공식으로 결정된다.\n순간 확장 지속시간(초) = (Credit 잔약)/[3,000 - 3 X (저장용량(GB))]\n데이터베이스 인스턴스를 처음 부팅할 때, 5,400,000 IOPS의 Credit 잔액을 갖게 되며 인스턴스가 기준치 이상으로 IOPS를 사용하면 그 만큼 Credit 잔액이 차감된다.\nCredit 잔액이 고갈되면 순간 확장 기능을 사용할 수 없으며, 예를 들어 200GB 볼륨의 순간 확장 지속시간은 2,250초(37.5분)이다.\nCreidt 잔액은 1초마다 IOPS 기준치가 보충된다.\n#\r프로비저닝된 IOPS SSD(io1) 앞에 나온 식이 복잡하다면 프로비저닝된 IOPS SSD를 사용하면 인스턴스를 만들 때 필요한 IOPS 수를 간단하게 할당할 수 있다.\nio1 스토리지에서는 순간 확장의 개념이 없으며, 프로비저닝된 IOPS 수는 사용 여부와 관계없이 일정한 성능이 제공되고 그에 따른 비용이 청구되므로, 일관된 짧은 지연 시간에 성능이 필요한 OLTP 데이터베이스에 유용하다.\n표준 또는 메모리 최적화 인스턴스 클래스를 사용할 때, RDS는 프로비저닝된 IOPS의 성능 변동 범위가 10% 이내로 유지되는 기간을 1년의 99.9%로 보장한다.\n즉 지정한 IOPS 수보다 낮은 성능이 제공되는 기간이 1년 동안 약 2시간 45분밖에 안 된다는 의미이기도 하다.\n4,000Mbps 처리량의 표준 인스턴스와 16KB 페이지 크기의 데이터베이스 엔진을 사용한다고 가정하면 최대 31,250 IOPS를 달성할 수 있으며, 이러한 성능을 달성하려면 인스턴스를 생성할 때 32,000 IOPS를 프로비저닝해야 하며, 프로비전이된 IOPS는 1,000단윈로 지정할 수 있다.\n데이터베이스 엔진에 따라 달성할 수 있는 최대 IOPS 수와 할당할 수 있는 스토리지 크기가 다르며, Oracle, PostgreSQL, MariaDB, MySQL, Aurora를 사용하면 100GB ~ 16TB의 스토리지를 선택할 수 있고, 1,000~ 4,000 프로비저닝된 IOPS를 할당할 수 있다.\nMicrosoft SQL Server는 최대 16TB 스토리지를 제공한고 1,000~ 32,000 범위의 프로비저닝된 IOPS를 제공한다.\nIOPS 기가바이트 비율은 최소 50:1(IOPS:GB)이어야 하며, 32,000 IOPS가 필요하다면 최소 640GB의 스토리지를 제공해야 한다.\n#\r마그네틱 스토리지 마그네틱 스토리지는 RDS 구형 인스턴스의 호환성을 위해 제공되며 최대 크기는 4TB, 최대 성능은 1,000 IOPS이다. #\r#\r읽기 전용 복제본\r#\r#\r데이터베이스 인스턴스가 성능 요구 사항을 충족하지 못할 때, 병목 현상 발생 위치에 따라 해결 방법을 적용할 수 있다.\n만약 메모리, 컴퓨팅, 네트워크 속도, 디스크 처리량에 문제가 발생 시에 인스턴스 클래스를 업그레이드 하여 데이터베이스를 확장할 수 있는 데 이를 수직확장(Scale Up)이라 한다.\n리소스를 증가시키는 수직확장 외에 읽기 전용 복제본이라는 추가 데이터베이스 인스턴스를 생성하는 작업을 수행하는 것을 수평확장(Scale Out)이라 한다.\n수평확장은 Oracle과 Microsoft SQL Server를 제외한 모든 데이터베이스 엔진에 읽기 전용 복제본을 지원하며, Aurora에는 Aurora 복제본이라는 특정 유형의 읽기 전용 복제본이 존재한다.\n읽기 전용 복제본은 데이터베이스 쿼리만 제공하는 데이터베이스 인스턴스로, 마스터 데이터베이스 인스턴스의 쿼리 부하 부분을 맡는다.\n즉 마스터 데이터베이스 인스턴스는 데이터 쓰기만을 책임지게 되므로, 읽기 작업량이 매우 많은 애플리케이션에 적합하다.\nRDS는 최대 5개 읽기 복제본을 둘 수 있으며, Aurora에서는 최대 15개까지 가능하다.\n마스터로부터 모든 읽기 복제본에 비동기로 복제되므로, 데이터가 마스터 데이터베이스에 저장되는 시점과 그 데이터가 복제본에 저장되는 시점에는 지연이 발생한다.\n지연이 발생하는 이유로 읽기 전용 복제본은 재해 복구에는 적합하지 않으며, MySQL의 경우 복제 지연 시간을 설정이 가능하다.\nRDS는 읽기 전용 복제본을 만들면 도메인 이름을 제공하며, 이를 읽기 전용 엔드포인트라고 한다.\nRDS의 읽기 전용 복제본이 다수 존재할 경우, 해당 복제본 중 하나에 연결해 로드 밸런싱하므로, 사용자는 데이터를 읽기만을 하는 분석 도구만 있다면 그 도구에 읽기 전용 엔드포인트를 지정해 주면 된다.\n읽기 전용 복제본과 마스터는 서로 다른 가용 영역에 둘 수 있으며, 다른 리전에도 두는 것이 가능하다.\n마스터 인스턴스는 장애가 발생했을 시에, 읽기 전용 복제본을 마스터로 승격시킬 수는 있지만, 비동기 복제의 특성이 존재하므로 어느 정도의 손실은 감수해야 한다.\n#\r#\r고 가용성(다중-AZ)\r#\r#\r데이터베이스 인스턴스가 중단되어도 데이터베이스를 계속 운영하려면, RDS의 다중 AZ배포를 통해 여러 가용 영역에 데이터베이스 인스턴스를 다수 배포한다.\n다중 AZ 배포를 사용하면 한 가용 영역에 읽기 및 쓰기를 처리하는 기본 데이터베이스 인스턴스를 두고, 다른 가용 영역에는 예비 데이터베이스 인스턴스를 두게 되며, 기본 인스턴스가 중단되면 보통 2분 이내에 예비 인스턴스로 장애 조치가 수행된다.\n하단은 인스턴스 중단의 대표적인 이유를 나타낸다.\n가용 영역 중단 데이터베이스 인스턴스 유형 변경 인스턴스의 운영 체제 패치 데이터베이스 인스턴스를 만들 때나 만든 후라도 다중 AZ를 구성할 수 있다.\n모든 데이터베이스 엔진은 다중 AZ를 지원하지만 구현 방식은 약간씩 다르며, 인스턴스를 만든 후에 다중 AZ를 활성화하면 성능이 상당히 떨어지므로 유지 관리 주기를 짧게 설정해야 한다.\n#\rOracle, PostgreSQL, MariaDB, MySQL, Microsoft SQL Server의 다중-AZ 다중 AZ 배포시, 모든 인스턴스가 같은 리전에 존재해야 하며, RDS는 주 인스턴스에서 예비 인스턴스로 데이터를 동기식(Synchronously)으로 복제하며, 이 때 지연시간이 발생할 수 있으므로, EBS 최적화 인스턴스와 프로비저닝된 IOPS SSD 스토리지를 사용해야 한다.\n예비 인스턴는 읽기 전용 복제본이 아니므로, 읽기 트래픽 처리가 불가능하다.\nOracle과 같이 기존 보유 라이선스(BYOL) 모델을 사용할 경우, 기본 인스턴스와 예비 인스턴스 모두 라이선스를 보유하고 있어야 한다.\nMySQL과 MariaDB는 다른 리전에서 다중 AZ 읽기 전용 복제본을 만들 수 있으며, 다른 리전으로 장애 조치를 수행할 수 있다.\n#\rAmazon Aurora에서 다중-AZ Amazon Aurora의 다중 AZ 구현 방식은 위에서 설명한 방식과는 차이가 있으며, Amazon Aurora 클러스트는 기본 인스턴스로 구성되며, 항상 기본 인스턴스를 가리키는 클러스터 엔드폰이트를 함께 제공한다.\nAurora 클러스터에는 Aurora 복제본도 포함될 수 있으며, 기본 복제본과 모든 복제본은 단일 클러스터 볼륨을 공유한다.\n이 클러스터 볼륨은 3개 가용 영역에 동시에 복제되며, 필요에 따라 최대 64TB까지 자동으로 확장된다.\n기본 인스턴스에 자애가 발생했을 때, Aurora 복제본이 없으면 Aurora는 새로운 기본 인스턴스를 생성하고, Aurora 복제본이 있으면 Aurora는 복제본을 기본 복제본으로 승격시킨다.\n#\r#\r백업과 복구\r#\r#\rRDS는 데이터베이스 인스턴스의 EBS 볼륨 스냇샷 기능을 제공한다. 일단 EBS 스냅샷처럼 인스턴스에 기반한 모든 데이터베이스는 스냅샷을 생성하여 S3에 저장할 수 있으며, 스냅샷은 중복성을 위해 같은 리전 여러 영역에 보관된다.\nMicrosoft SQL Server 이외의 데이터베이스 엔진에서는 다중 AZ를 사용하지 않는한 스냅샷을 하면 몇 초 동안 모든 I/O 작업이 일시 중단되므로 사용량이 적은 시간에 스냅샬을 생성해야 한다.\n백업 및 복구가 필요할 때 고려해야할 두가지 지표가 존재한다.\n복구 목표시간(Recovery Time Objective 이하 RTO)으로 장애 후 데이터르르 복구하고 처리를 재개하는 데까지 최대의 최대 허용시간을 의미한다. 복구 목표 지점(Recovery Point Object 이하 RPO)으로서 데이터 손실을 허용할 수 있는 최대 기간을 의미하며, RDS 백업 옵션을 선택할 때는 RTO, RPO 요구를 모두 고려해야 한다. RDS 스냅샷을 복수할 때 스냅샷을 새 인스턴스로 복구하는데, 복구 시간은 몇 분정도도 걸리며 크기에 따라 차이가 존재한다.\n새 인스턴스에 더 빠른 성능의 프로비저닝된 IOPS를 할당하면 복구 시간이 빨라진다.\n#\r#\r자동화된 스냅샷\r#\r#\rRDS는 매일 30분 백업 기간에 인스턴스 스냅샷을 자동 생성할 수 있으며, 이 기간은 사용자가 지정할 수도 있고 RDS가 자동으로 수행하게 할 수도 있다.\n스냅샷을 진행하면 성능에 영향을 주기 때문에 데이터베이스가 가장 적게 사용되는 시간에 진행하는 것이 좋으며, RDS 백업을 진행하도록 설정하면, 리전마다 다르게 8시간 간격으로 80분 백업을 진행한다.\n자동 백업을 사용하면 특정 시점 복구가 가능해지며, 데이터베이스 변경 로그를 5분마다 S3로 저장한다.\n장애 이벤트가 발생하면 최대 5분 불량의 데이터만 손실이 발생하며, 특정 시점 복구는 몇 시간이 걸릴 수도 있으며, 트랜잭션 로그에 있는 데이터의 양에 따라 차이가 있다.\nRDS는 자동화된 스냅샷을 일정 기간동안 유지하고, 기간이 지나면 삭제한다. 사용자는 1일에서 35일 사이의 보존 기간을 선택할 수 있으며, 기본 값은 7일이다.\n자동 스냅샷을 사용하지 않으려면 보존 기간을 0으로 설정하고, 자동 스냅샷을 비활성화하면 기존의 자동화된 스냅샷 모두가 즉시 삭제되고, 특정 시점 복구가 비활성화된다.\n보존 기간을 0에서 다른 값으로 변경하면 즉시 스냅샷이 트리거된다.\n데이터베이스 인스턴스에 대해 수동으로 스냅샷을 수행할 수 있으며, 자동화된 스냅샷과 달리 수동 스냅샷은 삭제할 때까지 유지된다. 인스턴스를 삭제하면 사용자는 RDS의 최종 스냅샷 작업 수행 여부와 자동 스냅샷 여부를 선택하야 하고, 최종 스냅샷과 모든 수동 스냅샷은 유지되지만, 자동 백업을 유지하지 않기로 선택한다면 자동 스냅샷은 즉시 삭제된다.\n#\r#\r유지 관리 항목\r#\r#\rRDS는 관리형 서비스이므로 패치 및 업그레이드 처리는 AWS가 책임지며, 데이터베이스 인스턴스에서 운영 체제 보안과 안정성 패치 등의 유지 관리를 몇 달에 한 번씩 정기적으로 수행한다.\n유지 관리 기간 동안 데이터베이스 엔진을 업그레이드 할 수도 있으며, AWS에서 새 버전의 데이터베이스 엔진을 지원하게 되면, 사용자는 새 버전 업그레이드를 결정할 수 있다.\n메이저 버전 업그레이드는 이전 버전과 호환하지 않는 데이터베이스 변경 사항이 포함되어 있을 수 있으므로, 메이저 버전 업그레이드는 사용자가 직접 적용해야 한다.\nAWS는 데이터베이스를 다시 빌드할 필요가 없는 nonbreaking 마이너 버전 번경을 적용한다.\n유지 관리 기간을 매주 30분으로 지정해 유지 관리 작업이 수행되는 시기를 결정할 수 있으며, 유지 관리와 백업을 같은 기간에 지정할 수 있다. 유지 관리 기간을 30분으로 설정해도 작업은 유지 관리 기간을 넘어서 진행될 수도 있다.\n#\r#\rAmazon Redshift\r#\r#\rRedshift는 OLAP 데이터베이스를 위해 설계된 PostgreSQL 기반의 관리형 데이터베이스 웨어하우스 솔루션으로 RDS와는 별개의 서비스로 존재한다.\nRedshfit는 열 기반 스토리지를 사용하므로, 저장 속도와 효율성이 향상되고 개별 열의 데이터를 더 빨리 쿼리할 수 있다.\nRedshift는 ODBC와 JDBC 데이터베이스 커넥터를 지원한다.\nRedshift는 압축 인코딩을 사용해 각 열의 스토리지에서 차지하는 크기를 줄이며, 수동으로 열 단위 압축을 수행할 수 있다.\nCOPY 명령을 사용해 파일에서 Redshift 데이터베이스로 데이터를 가져올 때 Redshift는 어떤 열을 압축할지 선택할 수 있다.\n#\r#\r컴퓨팅 노드 Redshift 클러스터에는 두 가지 범주로 나눠진 하나 이상의 컴퓨터 노드가 있다. 고밀도는 컴퓨팅 노드의 마그네틱 스토리지에 최대 326TB 데이터를 저장할 수 있고, 고밀도 스토로지 노드의 고속 SSD에 최대 2PB 데이터를 저장할 수 있다.\n둘 이상의 컴퓨팅 노드가 있을 때, Redshift에는 클라이언트와 통신하고 컴퓨팅 노드 간의 통신을 조정하는 리더 노드가 포함되어 있다. 이 리더 노드의 추가 비용은 없다.\n#\r데이터 분산 스타일 Redshift 데이터베이스의 행은 컴퓨팅 노드에 걸쳐 분산되며, 데이터가 분산되는 방식은 분산 스타일에 따라 다르다.\nEVEN 분산은 기본 스타일이며 리더 노드가 데이터를 모든 컴퓨팅 노드에 걸쳐 고르게 분산시킨다.\nKEY 분산은 열 1개 값에 따라 데이터를 분산시키며, 값은 값을 가진 열은 같은 노드에 저장된다.\nALL 분산에서는 테이블이 컴퓨팅 노드에 분산된다.\n#\r#\r비관계형 데이터베이스 No-SQL\r#\r#\r비관계형 데이터베이스는 초당 수만 개의 트랜잭션을 일관성 있게 처리하도록 설계되어 있다.\n관계형 데이터베이스에서 다룰 수 있는 데이터를 저장할 수 있다 하더라도 비관계형 데이터베이스는 비정형 데이터라고 하는 것에 최적화 되어있다.\n비정형의 데이터는 정형의 데이터가 아니라는 것을 설명하기 위해 사용되지만, 더 정확한 표현은 다중-정형 데이터라고 할 수 있다.\n이와 같이 비관계형 데이터베이스에 저장하는 데이터의 형태는 다양하고 계속변경할 수 있다.\n비관계형과 관계형 데이터베이스에는 공통된 요소가 존재핸다.\n비관계형 데이터베이스는 No-SQL 데이터베이스라 불리며, 컬렉션으로 구성된다. 컬렉션은 때로는 테이블이라 불리기도 하며 관계형 데이터베이스에서 행 또는 튜플 개념과 유사한 항목이 테이블에 저장된다.\n각 항목은 하나 이상의 속성으로 구성되며, 이 속성은 SQL 데이터베이스의 칼럼에 해당한다.\n속성은 키, 데이터 형식, 값이라고 하는 고유한 이름으로 구성되며, 속성은 키-값 페어라고도 불린다.\n#\r데이터 저장 비관계형 데이터베이스가 관계형 데이터베이스와 다른 점은 스키마가 없으며, 테이블의 모든 항목이 같은 속성을 갖도록 요구하지 않는다는 것이다.\n각 항목에는 테이블 내에서 고유한 값이 있는 기본 속성이 있어야 하는 데, 기본 키는 항목을 고유하게 식별하고 값에 따라 정렬하기 위해서 사용된다.\n비관계형 데이터베이스는 저장 데이터 형식이 유연할 때 사용하며, 테이블을 만들 때 기본 키 속성 이외에는 속성을 미리 정의하지 않아도 되며, 항목을 작성하거나 수정할 때 바로 속성을 작성하는 데, 이 때 속성은 순서가 없고 서로 관계도 없으므로 비관계형이라고 부른다.\n비관계형 데이터베이스에서는 여러 테이블에 걸쳐 데이터를 나눈 뒤 이 데이터를 병합해서 쿼리할 수 있는 방법이 없으므로, 애플리케이션은 모든 데이터를 하나의 테이블에 보관하는 경우가 많으며, 이는 중복으로 이어지고 데이터베이스가 커지면서 심각한 스토리지 비용을 발생시킬 수 있다.\n#\r데이터 쿼리 비관계형 데이터베이스는 비정형 데이터를 저장할 수 있는 유연성이 있지만, 쿼리가 제한돼 있다는 단점이 따르며, 기본 키 기반의 쿼리에 최적화 되어 있다.\n다른 속성을 쿼리할 때 속도가 더 느려지므로 비관계형 데이터베이스는 복잡하거나 임의의 쿼리에는 적합하지 않으며, 테이블을 만들기 전에 데이터에 어떠한 쿼리를 수행할지 정확히 이해해야 한다.\n하단의 표는 데이터 쿼리의 예시이다.\n키 형식 값 사원 ID(기본 키) 숫자 101 부서 문자 전산실 성 문자 Smith 이름 문자 Charlotte 비관계형 데이터베이스에서 Charlotte라는 사원이 있는 모든 부서의 목록을 조회하는 것은 어려울 수 있으며, 사원 ID로 항목이 정렬되어 있으므로, 이름의 값이 Charlotte인 항목을 찾으려면 시스템은 모든 항목을 검색해야하는 문제점이 존재한다. 각 항목의 데이터들은 정형화되어 있지 않기 때문에, 모든 속성마다 검색해서 부서 속성이 포함된 항목을 판별해야 하며, 이러한 쿼리는 느릴 뿐 아니라 컴퓨팅 자원도 상당히 소모한다. #\r비관계형 데이터베이스 유형 비관계형 데이터베이스가 키-값 저장소, 문서 지향적 저장소, 그래프 데이터베이스 등으로 분류되며, 기본적으로는 모든 비관계형 데이터베이스는 키-값 저장소 데이터베이스이다.\n문서 지향적 저장소는 값으로 지정된 문서의 내용을 분석하고 메타 데이터를 추출하는 특정한 비관계형 데이터베이스 애플리케이션이다.\n그래프 데이터베이스는 여러 항목에 있는 속성 간의 관계를 분석하며, 이는 레코드간의 관계를 묶는 관계형 데이터베이스와는 다르다. 그래프 데이터베이스는 비정형 데이터에서 이와 같은 관계를 찾아낸다.\n#\r#\rDynamoDB\r#\r#\rDynamoDB는 초당 수천 개 읽기 및 쓰기를 처리할 수 있는 관리형 비관계형 데이터베이스 서비스로, 데이터를 여러 파티션에 걸쳐 분산시켜서 이러한 성능을 얻는다.\n파티션은 테이블용 스토리지 할당으로, 여러 가용 영역의 SSD에 백업된다.\n#\r파티션/ 해시 키 테이블을 만들 때 기본 키와 데이터 형식을 지정해야 한다.\n기본 키는 테이블의 항목을 고유하게 식별하므로, 값이 테이블 내에서 유일해야 하며, 하단과 같이 두 가지의 유형의 기본 키를 생성할 수 있다.\n파티션 키는 해시키라고도 하며 단일 값을 가지는 기본 키며, 파티션 키만 기본 키로 사용할 때 이를 단순 기본 키라고 한다.\n이메일 주소, 고유 사용자 이름, 임의로 생성한 ID 식별자 등이 파티션 키로 사용하기에 적합하며, 파티션 키로 저장할 수 있는 최대 크기는 2.048 바이트이다.\n기본 키로 파티션 키와 정렬 키를 조합해서 사용할 수도 있으며, 이를 복합 키라 한다.\n파티션 키는 고유할 필요는 없지만, 파티션 키와 정렬 키의 조합은 고유해야 하며, 사람이 성을 파티션 키로 이름을 정렬 키로 쓰는 예를 살펴보자. 이 방법으로 하면 테이블용 복합 키로 다음 값을 사용할 수 있디.\n성(파티션 키) 이름(정렬 키) Lewis Clive Lewis Warren Williams Warren 성 Lewis나 이름 Warren은 이 테이블에서 유일하지 않지만, 파티션 키와 정령 키를 함께 사용하면 고유한 기본 키를 생성 할 수 있다.\nDynamoDB는 기본 키를 기반으로 파티션에 걸쳐 항목을 배포한다.\n앞의 예에서 보면 성이 Lewis인 항목은 모두 같은 파티션에 저장되며, DynamoDB는 정렬 키를 사용해서 오름차순으로 항목을 정렬하고, 정렬 키로 저장할 수 있는 최대 크기는 1,024바이트이다.\n대량의 읽기 쓰기 작업이 발생하는 파티션을 핫 파티션이라 하며, 이는 성능에 악영향을 끼친다.\n핫 파티션이 되는 것을 피하려면 파티션 키를 최대한 고유하게 생성해야 한다.\n#\r속성과 항목 각 키-값 페어는 속성을 구성하고, 하나 이상의 속성은 항목을 구성한다. DynamoDB가 저정할 수 있는 항목의 최대 크기는 400KB이며, 이는 대략 50,000개의 영어 단어 수와 동일하다.\n모든 항목은 최소한 기본 키와 키에 해당하는 값을 가지고 있으며, 속성을 생성할 때는 데이터 형식을 정하고, 하단과 같이 세 가지 범주로 정할 수 있다.\n스칼라\n문자열 데이터 형식은 UTF-8 인코딩을 사용해 최대 400KB의 유니코드 데이터를 저장할 수 있고, 문자열 길이는 0보다 커야 한다.\n숫자 데이터 형식은 최대 38자리의 양수나 음수를 저장하며, DynamoDB는 앞과 끝의 0을 자른다.\n바이너리 데이터 형식은 바이너리 데이터를 Base64 비트 인코딩 형식으로 저장하며, 문자열 형식과 마찬가지로 최대 항목 크기는 400KB로 제한한다.\n부울 데이터 형식은 ture 또는 false 값을 저장할 수 있다.\nnull 데이터 형식은 정의되지 않았거나 알려지지 않은 속성을 나타내며, null 데이터 형식에는 null 값이 포함되어야 한다.\n집합\n집합 데이터 형식은 수서가 없는 스칼라 값 목록을 담고 있으며, 값은 집합 내에서 고유해야 하고, 집합에는 하나 이상의 값이 포함되어 있어야 하며, 숫자 집합, 문자열 집합, 바이너리 집합의 작성이 가능하다. 문서\n문서 데이터 형식은 스칼라 집합 데이터 형식의 제약을 벗어나는 여러 형식의 데이터를 담을 수 있도록 설계되어 있으며, 최대 32레벨의 문서 형식을 중첩할 수 있다. 목록 문서 형식은 순서가 지정된 모든 형식의 값 모음을 저장할 수 있다. 하단은 목록 문서의 예시를 나타낸다 Chroes : [\u0026#34;Make coffee\u0026#34;, Groceries : [\u0026#34;milk\u0026#34;, \u0026#34;eggs\u0026#34;, \u0026#34;cheese\u0026#34;], \u0026#34;Pay bills\u0026#34;, Bills:[water: [60], electric:[100]]] # Chroes 목록에는 문자열 데이터, 숫자 데이터, 중첩 목록이 포함되어 있다. 맵 데이터 형식 맵 데이터 형식은 정렬되지 않은 키-값 페어의 집합을 JSON과 유사한 형식으로 저장할 수 있으며, 목록형식과 마찬가지로 포함할 수 있는 데이터 형시에는 제한이 없다. 하단은 맵 데이터 형식의 예시을 나타낸다. { Day: \u0026#34;Friday\u0026#34;, Chores: [ \u0026#34;Make coffee\u0026#34;, \u0026#34;Groceries\u0026#34;, { Milk: { Quantity: 1}, eggs: { Quantity: 12}, } \u0026#34;Mow the lawn\u0026#34;], } #\r처리용량 테이블을 만들 때 애플리테이션에 필요한 초당 읽기 및 쓰기 횟수를 지정해야 하며, 이를 프로비저닝된 처리량이라 한다.\nDynamoDB는 테이블을을 만들 때 지정한 읽기 용량 단위 (Read Capacity Unitss : RCU) 및 쓰기 용량 단위 (Write Capacity Units : WCU) 갯수로 파티션을 예약한다.\n최대 4KB 크기의 항목을 기준으로 할 때, 1개의 RCU는 1개의 강력한 일관된 초당읽리를 제공하며, 일관된 읽기를 매초 8KB를 읽으려면 2개의 RCU가 필요하다.\n1개의 RCU는 초당 2개의 최종적 일관된 읽기를 제공하며, 최종적 일관된 읽기를 매초 8KB 항목을 읽으려면 1개의 RCU만 있으면 된다.\n데이터 쓰기의 경우, 1개의 WCU는 최대 1KB 크기의 항목 1개 쓰기를 제공하며, 1KB 미만인 항목을 초당 100개 쓰기 해야 한다면, 100개 WCU가 필요하다. 2KB 항목을 초당 10개 쓰기 위해서는 20개의 WCU가 필요하다.\nDynamoDB가 제공하는 최대 처리 용량은 사용자가 지정하며, 이를 초과하면 DynamoDB요청을 차단하고, \u0026lsquo;HTTP 400(bad request)\u0026rsquo; 오류를 발생시킬 수 있다. AWS SDK는 조정 후 요청 재시도 기능을 지원하므로, 요청을 조정해서 애플리케이션이 데이터를 읽거나 쓰는 것을 막을 수는 있지만, 애플리케이션의 반응 속도는 느려지게 된다.\n#\rAuto Scaling 테이블에 얼마만큼 처리량을 프로비저닝해야 할지 정확하지 않거나 시간에 따라 처리량의 요구가 달라질 것으로 예상할 때, Auto Scaling을 구성해서 정해 놓은 임계치에 가깝게 도달하면 자동으로 프로비저닝된 처리량을 증가하게 할 수 있다.\nAuto Scaling을 구성할 때 최소/ 최대 RCU와 WCU를 지정하고, 목표 사용률을 지정한다.\nDynamoDB는 RCU와 WCU를 자동으로 조정해서 이 목표 사용률에 따라 사용률을 유지한다.\n예를 들어 70%, 최소 10 RCU, 최대 50 RCU로 설정하는 경우, 21 RCU를 소비할 때 Auto Scaling은 프로비저닝된 용량을 약 30 RCU로 조정한다.\n소비자가 14 RCU로 떨어지면 Auto Scaling은 프로비저닝된 처리량을 20 RCU로 축소한다.\n적절한 사용률을 설정하면 작업에 균형을 이룰 수 있으나, 사용률을 높게 설정할수록 프로비정된 용량을 초과할 가능성은 커지고, 요청이 제한될 수 있다.\n반면 사용률을 너무 낮게 설정하면 필요하지 않은 용량에 비용을 지급하게 된다.\n#\r예약 용령 100 이상의 WCU나 RCU가 필요할 때 예약 처리 용량을 구매해서 비용을 절약할 수 있다. RCU와 WCU를 별도로 예약해야 하며, 각각 100,000유닛으로 제한되 있으며, 1년이나 3년 사용 기간을 약정하고 선불로 지급한다. #\r데이터 읽기 DynamoDB는 테이블에서 두 가지 방식으로 데이터를 읽는다.\n스캔은 모든 테이블 항목을 나열하며, 읽기 집약적 작업이므로 프로비저닝된 용량 단위를 모두 사용할 가능성이 있다.\n쿼리는 파티션 키값을 기반으로 항목을 반환하며, 쿼리를 수행할 때 검색하는 파티션의 키의 값은 항목의 갑과 정확히 일치해야 한다.\n테이블에 정렬 키가 포함되어 있으면, 정렬 키로도 쿼리할 수 있다.\n정렬 키를 사용하면 정확한 값, 키보다 크거나 작은 값, 값의 범위, 값의 시작 등으로 더 유연하게 검색을 수행할 수 있다.\n#\r보조 인덱스 보조 인덱스는 DynamoDB에서 데이터를 쿼리할 때 발생하는 두 가지 문제를 해결한다.\n사용자는 특정 항목을 쿼리할 때 파티션 키를 정확하게 지정해야한 한다.\n보조 인덱스를 만들 때 기본 테이블에서 인덱스로 복사할 속성을 선택할 수 있는 데, 이를 프로젝션된 속성 (Projected Attributes)라고 한다.\n보조 인덱스는 항상 기본 테이블의 파티션 키와 정렬 키 속성을 포함하며, 파티션 키와 정렬 키, 키 값만은 선택해서 복사하거나 키 값에 다른 속성을 추가해서 필요한 방식으로 데이터를 추출할 수 있다.\n#\r글로벌 보조 인덱스 테이블을 만든 후에 언제든지 글로벌 보조 인덱스 (Global Secondary Index)를 만들 수 있다.\n글로벌 보조 인덱스에서 파티션 키와 해시 키는 기본 테이블과 다를 수 있지만, 기본 키 선택과 같은 규칙이 여전히 적용된다.\n인덱스의 기본 키는 고유하게 유지해야 하고, 복합 기본 키를 사용하면 파티션 키에서 같은 값을 가진 항목이 같은 파티션에 저장된다.\n글로벌 보조 인덱스에서 읽을 때는 항상 읽기 일관성이 유지되며, 항모을 테이블에 추가하더라도 즉시 보조 인덱스로 복사되지 않을 수 있다.\n#\r로컬 보조 인덱스 로컬 보조 인덱스 (Local Secondary Index : LSI)는 기본 테이블과 동시에 만들어져야 하며 일단 만들면 삭제할 수 없다.\n파티션 키는 항상 기본 테이블과 같아야 하지만, 정령 키는 다룰 수 있다.\n예를 들어 기본 테이블에 LastName이 파티션 키이고 FirstName이 정렬 키이면, 파티션 키를 LastName이고 정렬 키를 BirthYear로 하는 로컬 보조 인덱스를 만들 수 있다.\n로컬 보조 인덱스의 읽기 시간을 얼마에 지정하냐에 ㄸ라 강력한 일관성 또는 최종적 일관성이 될 수 있다.\n#\r#\r요약\r#\r#\r관계형 데이터베이스 또는 비관계형 데이터베이스의 사용 여부는 애플리케이션의 속성에 달려 있다.\n관계형 데이터베이스는 오랫동안 사용되어 왔으며, 많은 애플리케이션 개발자들은 기본적으로 관게형 데이터베이스에 맞게 데이터를 설계한다.\n애플리케이션은 특정 데이터베이스의 SDK를 사용해 데이터베이스와 상호 작용하므로 애플리케이션의 요구에 따라 특정 데이터베이스 엔진이 필요하게 된다.\n이러한 이유로 AWS RDS는 가장 널리 사용되는 6개 데이터베이스 엔진과 광범위한 버전 호환성을 지원함, 이는 애플리케이션을 변경하지 않고 기존 데이터베이스를 가져와서 RDS로 옮길 수 있도록 하려는 것이다.\n비관계형 데이터베이스는 최근에 창안되었으며, DynamoDBsms Amazon이 소유권을 가지고 있는 비관계형 데이터베이스 서비스이다.\n보통 관계형 데이터베이스용으로 설계된 애플리케이션과는 달리 온프레미스에서 배포해 사용하던 비관게형 데이터베이스용 애플리케이션은 대부분 코드를 변겨해야 DynamoDB로 이식할 수 있다.\n따라서 DynamoDB를 사용하는 애플리케이션을 개발하거나 재개발할 때 개발자에게 데이터베이스를 설계하는 법을 자문할 수도 있다.\n이 경우 파티션 키, 정렬 키, 데이터 형식을 선택하는 방법과 애플리에키션 성능 요구를 충족하기 위해 처리 용량을 할당하는 법을 이해하는 것이 중요하다.\nAWS 아키텍트는 적절한 데이터베이스와 AWS 서비스를 사용해서 성능 및 가용성 요구사항을 결정하고 올바르게 구현해야 한다.\n#\r#\r시험핵심\r#\r#\r관계형 데이터베이스와 비관계형 데이터베이스의 차이점을 이해한다. 관계형 데이터베이스에서는 테이블을 생성하기 전에 속성을 정해야 한다.\n테이블에 입력하는 모든 데이터는 사전에 정한 속성과 부합해야 한다.\n데이터를 읽고 쓰는 데 SQL을 사용하므로 이를 SQL 데이터베이스라고도 한다.\n비 관계형 데이터베이스에서 테이블을 만들 때 요구하는 것은 기본 키 속성뿐이다.\n테이블의 모든 항목은 기본 키를 포함해야 한다는 것만 제외하면 속성을 다양하게 가질 수 있다는 유연성도 있다.\n비관계형 데이터베이스 또는 NoSQL 데이터베이스는 비정형 데이터를 저장한다.\n#\rRDS가 지원하는 여러 데이터베이스 엔진을 파악하자 RDS는 MySQL, MariaDB, Oracle, PostgreSQL, Amazon Aurora, Microsoft SQL Server와 같이 많이 사용되는 대부분 데이터베이스 엔진을 지원한다.\n기본 보유 라이센스 사용과 라이센스 포함된 모델의 차이점을 이해해야 하며, 어떤 데이터베이스 엔진이 어떤 라이센스 모델을 지원하는 지 파악해야 한다.\n#\r특정 스토리지 요구 사항에 맞는 인스턴스 클래스와 스토리지 유형으르 선택할 수 있어야 한다. 메모리와 스토리지가 관계형 데이터베이스의 제약 요인이 되는 경향이 있으므로 데이터베이스의 성능 요구 사항을 기반으로 올바른 인스턴스 클래스와 스토리지 유형을 선택하는 방법을 알고 있어야 한다.\n표준, 메모리 최적화, 순간 확장 가능의 세 가지 인스턴스 클래스를 파악해야 하며, 또한 세 클래스의 범용 SSD(gp2), 프로비저닝된 IOPS SSD(io1), 마그네틱 세 가지 스토리지 유형과 어떤 관련이 있는지 알아야 한다.\n#\r다른 AZ와 읽기 전용 복제본의 차이점을 이해한다. 다중 AZ와 읽기 전용 복제본 모두 추가 데이터베이스 인스턴스를 만든다는 점에서는 연관되지만, 몇 가지 주요 차이점이 존재한다.\n읽기 전용 복제보은 쿼리를 처리할 수 있지만, 다중 AZ 배포에서 예비 인스턴스는 불가능하다.\n마스터 인스턴스는 읽기 전용 복제본에 비동기로 복제하지만, 다중 AZ 구성에서는 기본 인스턴스에서 예비 인스턴스로 동기로 데이터 복제가 이루어 진다.\nAuroa 복제본은 작동 방식과 Aurora 다중 AZ가 다른 데이터베이스 엔진의 AZ와 어떻게 다른지 이해해야 한다.\n#\rDynamoDB 테이블에 적합한 기본 키 형식을 결정할 수 있어야 한다. DynamoDB 테이블은 두 가지 종류의 기본 키를 제공한다.\n단순 기본 키 파티션 키로만 구성되며 단일 값을 가지고 있다. DynamoDB는 파티션 키의 값에 따라 항목을 파티션에 분산시킨다.\n단순 기본 키를 사용할 때 파티션 키는 테이블 내에서 고유해야 하며, 복합 기본 키는 파티션 키와 정렬 키로 구성된다.\n파티션 키는 고유할 필요는 없지만, 파티션 키와 정렬 키의 조합은 고유해야한다.\n#\rDynamoDB 처리 용량이 어떻게 작동하는지 파악한다. 테이블을 생성할 때 쓰기 용량 단위와 읽기 용량 단위로 처리용량을 지저해야 한다.\n다음 두 가지의 따라 읽기 작업이 읽기 용량 단위를 얼마나 소모할지 결정된다.\n읽기 작업이 강력하게 읽관적인지 최종적으로 일관적인지와 1초에 읽을 데이터의 용량이다. 최대 4KB 크기 항모글 강력한 일관된 읽기 작업을 할 때 하나의 읽기 용량을 단위로 사용한다. 최종적으로 일관된 읽기작업은 그 절반을 소비한다. 쓰기 용량 단위 하나를 사용해 쓰기 작업을 하면 초당 하나의 1KB 항목을 쓸 수 있다. #\r"},{"id":23,"href":"/cloud/docs/AWS/AWSTraining/EC2/","title":"AWS EC2 생성","section":"AWS Training","content":"\rAWS EC2 생성\r#\r#\rAWS EC2 생성\r#\r#\r이번 장에서는 저번 장에서 생성했던 사용자 정의 VPC의 대역에 EC2를 생성해 보도록 하겠습니다. EC2 또한 중요한 개념이므로, EC2에 대한 학습을 원하는 분들은 AWS EC2를 참고해주세요. #\r#\rEC2 ( Elastic Compute Cloud ) 생성\r#\r기본적인 EC2 생성의 순서\n1. AMI ( Amazon Machin Image ) 선택 2. Instance type 선택\n2. Instance Network 설정\n3. Storage 설정\n5. Tag 설정\n6. Security Group 설정 여기에서는 처음에는 기본 VPC, 후에는 전장에서 생성했던 VPC에 생성해보도록 하겠습니다.. 검색에서 EC2를 입력후 인스턴스로 들어갑니다. #\r#\r대시보드에서 현재 사용량을 확인할 수 있습니다. 인스턴스 생성을 위해 좌측 메뉴에 인스턴스를 클릭합니다. #\r#\r인스턴스 시작을 클릭합니다. #\r#\rAMI 선택에서는 이미지 파일을 선택할 수 있습니다. 여기에서는 Amzon Linux를 생성하겠습니다. 또한 AMI는 직접 만들 수 있으며, AWS Marketplace를 통해서 타 유저의 이미지를 구매할 수도 있습니다. #\r#\rAWS 인스턴스 유형에서는 cpu, ram 스토리지의 유형과 사양 등을 선택할 수 있습니다. 여기에서는 과금이 발생하지 않게 t2.micro를 선택하겠습니다. #\r#\r인스턴스 세부 정보 구성에서는 인스턴스의 수, VPC 서비넷 대역, 용량 예약, IAM 역할 등 세부 정보를 설정할 수 있습니다. 여기서는 기본 값으로 생성하겠습니다. 설정 항목 설명 인스턴스 갯수 기동할 인스턴스의 수를 나타냅니다. 구매 옵션 구매 옵션을 선택합니다. 체크 시 스팟 인스턴스로 구입할 수 있습니다. 네트워크 인스턴스를 기동할 VPC를 나타냅니다. 서브넷 인스턴스가 소속될 서브넷을 나타냅니다. 퍼블릭 IP 자동 할당 자동적으로 퍼블릭 IP를 부여할지 설정합니다. 배치 그룹에 인스턴스 추가 배치 그룹을 선택합니다. 체크 시 배치 그룹에서 인스턴스를 생성합니다. 용량 예약 용량 예약은 특정 가용 영역에서 인스턴스가 시작되도록 예약합니다. IAM 역할 EC2 인스턴스에 부여할 IAM권한을 설정합니다. 종료 방지 EC2 인스턴스의 삭제를 막습니다. 모니터링 CloudWatch를 통한 모니터링 서비스를 활성화합니다. 화성화하면 1분 간격으로 CloudWatch에 데이터가 전송됩니다. ( 일반적으로 5분 간격을 설정 ) 테넌시 하드웨어 점유 옵션으로, Shred를 선택시 공유, Dedicated를 선택하면 완전 점유합니다. 사용자 데이터 인스턴스 실행시 셀 스크립트 또는 cloud-init 디렉티브를 작성할 수 있습니다. #\r#\r스토리지 추가에서는 볼륨을 추가할 수 있습니다. #\r#\r태그 추가에서는, 인스턴스에 대한 세부사항을 정의할 수 있습니다. 여기서는 기본 값으로 생성하겠습니다. #\r#\r보안 그룹에서는 생성되는 EC2에 대한 보안 그룹을 지정합니다. 현재는 접속을 위해 TCP 22번 포트만 열어둔 상태로 생성하겠습니다. #\r#\r검사에서는 현재까지의 설정을 확인할 수 있습니다. 인스턴스 시작을 누르면 키 페어를 선택창이 등장합니다. 여기서는 키 페어를 하나 생성하도록 하겠습니다. #\r#\r리눅스 운영체제를 통할 때에는 pem 파일을, Window를 사용할 때에는 ppk 파일을 사용하기에, 여기서는 pem 파일을 Putty key generator를 이용해 변경시켰습니다. #\r#\r생성이 완료되면, 인스턴스로 돌아와 생성되어진 인스턴스를 확인합니다. 기본적으로 Pendig은 생성, Running은 실행가능, stop은 중지상태, shuttinf-down은 삭제 중, Terminated는 삭제된 상태를 의미하며, Running 상태에서만 요금이 부과됩니다. 상단에는 간략한 EC2들의 정보를 나타내며, 하단에는 상세 정보를 나타냅니다. 여기서 접속을 위해 IPv4 퍼블릭 IP를 복사합니다. #\r#\rPutty를 사용해 퍼블릭 IP와 프라이빗 키를 등록하면 접속이 가능합니다. 기본적으로 기본 계정은 AWS Linux : EC2-user, Ubuntu : ubuntu Centos : centos 입니다. #\r#\r생성된 인스턴스에서 정상적으로 핑이 나가는 것을 확인하실 수 있으나, Window에서는 핑이 가지 않는 것을 확인하실 수 있습니다. 이는 전에 선택한 보안그룹으로 22번/TCP 포트밖에 사용하지 않았기 때문으로, 만약 보안그룹에 ICMP를 열어둔다면, Ping이 가능하게 할 수 있습니다. 이와 같이 보안그룹은 AWS에서 다방면으로 매우 중요한 역할을 수행합니다. #\r#\r이어서 인스턴스의 상태변경은 인스턴스를 선택후 작업, 혹은 오른쪽마우스로 가능합니다. 저는 삭제를 위해 종료를 클릭하겠습니다. #\r#\r삭제가 완료되었습니다. #\r#\r사용자 정의 VPC 대역에 EC2 생성\r#\r#\r저번 장에서 생성했던 VPC 대역에 EC2를 생성해보도록 하겠습니다. 인스턴스의 Network 설정까지는 동일하며, 그 후는 아래와 같습니다. #\r인스턴스의 Network 설정에서 네트워크, 서브넷, 퍼블릭 IP 자동할당을 설정합니다. 단, 두 개의 인스턴스를 생성하며, 하나의 인스턴스는 IP 자동할당 활성화, 다른 인스턴스는 IP자동할당을 비활성화인 채로 생성합니다. 여기에서는 저번장에서 생성한 2개의 서브넷을 사용했습니다. Pulbic : 할당 활성화, Private : 할당 비활성화 또한 위와 같이 ssh의 접속이 가능하게 보안그룹을 설정합니다. #\r#\r생성이 완료되었습니다. #\r#\r이제 Putty를 통해 퍼블릭과 프라이빗에 접속합니다. 하지만, 프라이빗 대역은 퍼블릭 IP를 할당받지 않아 접속이 불가능합니다. #\r#\r하지만 퍼블릭 서브넷의 인스턴스는 공통의 라우팅 테이블로 igw를 사용하기 때문에 프라이빗 IP를 알수 있어 접속이 가능합니다. 또한 이와 같은 방법으로 보안그룹을 ssh접속이 가능한 한 컴퓨터만 혹은 서브넷이나 그룹등을 지정하거나, gateway를 특정 인스턴스로 지정하여 보안성을 높이는 것이 가능합니다. #\r#\rCLI를 통한 인스턴스 관리\r#\r#\r#\r$ aws ec2 help aws ec2에 명령어를 알려줍니다. #\r#\r$ aws ec2 create-key-pair --key-name [ 키 페어 이름 ] --query \u0026#39;KeyMaterial\u0026#39; --output text | out-file \u0026gt; [ 키 페어 경로 ].pem # KeyMaterial은 키의 값입니다. $ impkey=\u0026#39;cat~/[ import 시킬 키 파일의 경로 ]\u0026#39; $ aws ec2 import-key-pair --key-name [ 키 페어 이름 ] --public-key-material ${impkey} # 외부 키 페어 임포트 방법 # AWS 콘솔 EC2-Key Pairs -\u0026gt; Import Key Pair로도 가능합니다. 키 페어를 생성합니다. #\r#\r$ aws ec2 delete-key-pair --key-name [ 키 페어 이름 ] 키 페어를 삭제합니다. #\r#\r$ aws ec2 create-security-group --group-name [ 보안 그룹 이름 ] --description [ 보안 그룹 설명 ] --vpcid [ VPC ID ] 보안 그룹을 생성합니다. #\r#\r$ aws ec2 authorize-security-group-ingress \\ --group-id [ Security-group-id ] \\ --protocol tcp \\ --port 22 \\ --cidr 0.0.0.0/0 # Security-group-id의 보안 그룹의 22/tcp의 모든 접속이 가능하게 설정을 추가합니다. $ aws ec2 describe-security-groups \\ --group-ids [ Security-group-id ] \\ --output json 보안 그룹을 생성합니다. #\r#\r$ aws ec2 describe-security-groups --group-ids [ 보안 그룹 ID ] 보안 그룹의 상세 설명을 출력합니다. #\r#\r$ aws ec2 create-security-group --group-name [ 보안 그룹 이름 ] --description [ 보안 그룹 설명 ] EC2를 생성할 때, 보안 그룹을 생성합니다. #\r#\r$ aws ec2 run-instances \\ --image-id [ 이미지 이름 ] \\ --count [ 인스턴스 수 ] \\ --instance-type [ falvor ] \\ --key [ 키 페어 이름 ] \\ --security-group-ids [ 보안 그룹 ID ] --subnet-id [ 서브넷 ID ] \\ --associate-public-ip-addres # 퍼블릭 IP 할당 유무 --user-data file://[ 파일경로 ] # 인스턴스를 생성합니다. $ aws ec2 create-tags \\ --resources [ 인스턴스 id ] --tags Key=name,Value=[ 태그 내용 ] # 인스턴스에 태그 등록 인스턴스를 생성합니다. #\r#!/bin/bash apt install -y apache2 #cloud-config packages: - apache2 user data 사용시 사용가능한 형식 #\r#\raws ec2 describe-instances --filters \u0026#34;[ 필터 값 ], Value=[ 값1, 값2 ]\u0026#34; 특정 ec2를 나열합니다. #\r#\raws ec2 start-instances --instance-ids [ 인스턴스 ID ] aws ec2 stop-instances --instance-ids [ 인스턴스 ID ] aws ec2 terminate-instances --instance-ids [ 인스턴스 ID ] 인스턴스의 상태를 변경합니다. #\r#\r예제\r#\r#\r예제 1.\r#\r다음의 인스턴스를 생성해보세요.\r#\r1. OS : Ubuntu18.04\n2. Instance-type : t2.micro\n3. Instance-count : 2\n4. Network : 기본 VPC 및 기본 Subnet\n5. Security-Group : 80/tcp, 22/tcp의 포트가 모두 접속할 수 있게 설정해주세요.\n6. 새로운 Key-pair를 생성하여 접속 후, Apache2를 설치하세요.\n7. 각각의 인스턴스에 접속하여 확인합니다.\n#\r#\r예제 2.\r#\r다음의 인스턴스를 생성해보세요.\r#\r1. OS : Ubuntu16.04\n2. Instance-type : t2.micro\n3. Instance-count : 1\n4. Network : 사용자 생성 VPC 및 Subnet\n5. User-data에 값을 입력하여 자동으로 Apache가 설치되게 설정하세요.\n6. Security-Group : 80/tcp 포트만 모두 접속할 수 있게 설정해주세요.\n7. 기존에 Key-pair로 생성하세요.\n8. 인스턴에 접속하여 확인합니다.\n"},{"id":24,"href":"/cloud/docs/AWS/AmazonWebService/AWS_Migrate/","title":"AWS Migrate","section":"AWS docs","content":"\rAWS Migrate\r#\r#\rAWS Application Discovery Service\r#\r#\rAWS Application Discovery Service는 서버로부터 구성, 사용 및 동작 데이터를 수집하여 제공함으로써 워크로를 효율적 관리를 도와주는 서비스 기업의 고객이 사내 데이터 센터에 대한 정보를 수집하여 마이그레이션 프로젝트를 계획하는 데 도움을 줌 데이터 센터 마이그레이션을 계획하는 작업에는 상호 의존성이 높은 수천 개의 워크로드가 수반 되어지는 짐 수집된 데이터는 AWS Application Discovey Service 데이터 스토어에 암호화된 형태로 보관되어짐 #\rAWS Application Discovery Service의 이점\r#\r마이그레이션 계획 수립을 위한 신뢰할 수 있는 검색 Application Discovey Service는 서버 사양 정보, 성능 데이터, 실행 프로세스 및 네트워크 연결 세부 정보를 수집, 이러한 데이터는 AWS로 마이그레이션하기 전에 상세한 비용 추정을 수행하거나 계획을 위해 서버를 애플리케이션으로 그룹화하는 데 사용될 수 있음 Migration Hub와 통합 AWS Application Discovery Service는 AWS Migration Hub와 통합되므로 마이그레이션 추적이 간소화 및 Hub를 통한 마이그레이션 상태 추적이 가능 암호화로 데이터 보호 AWS Application Discovery Service는 수집한 데이터를 AWS로 전송할 때와 Application Discovery Service 데이터 스토어에 저장할 때 모두 암호화 마이그레이션 전문가의 지원 AWS Professional Services와 APN 마이그레이션 파트너는 수많은 엔터프라이즈 고객이 클라우드로의 마이그레이션을 성공적으로 완료하도록 지원 #\rAWS DMS ( Database Migration Service )\r#\r#\rAWS Database Migration Service는 데이터베이스를 AWS로 빠르고 안전하게 마이그레이션할 수 있도록 지원하는 서비스 이그레이션하는 동안 소스 데이터베이스가 변함없이 운영되어 해당 데이터베이스를 사용하는 애플리케이션의 가동 중지 시간을 최소화 AWS Database Migration Service는 Oracle에서 Oracle로의 마이그레이션과 같은 동종 마이그레이션뿐 아니라 Oracle 또는 Microsoft SQL Server에서 Amazon Aurora로의 마이그레이션과 같은 이기종 데이터베이스 플랫폼 간의 마이그레이션도 지원 데이터베이스를 Amazon Aurora, Amazon Redshift, Amazon DynamoDB 또는 Amazon DocumentDB(MongoDB 호환 가능)로 마이그레이션하는 경우 6개월 동안 DMS를 무료로 제공 #\rAWS DMS의 이점\r#\r간편한 사용 AWS Management Console에서 클릭 몇 번으로 데이터베이스 마이그레이션을 시작 마이그레이션이 시작되면, 마이그레이션 프로세스 도중에 소스 데이터베이스에 발생한 데이터 변경을 자동으로 복제하는 것을 비롯하여 마이그레이션 프로세스의 모든 복잡성을 DMS에서 관리 최소한의 가동 중단 AWS Database Migration Service는 사실상 가동 중단 시간 없이 데이터베이스를 AWS로 마이그레이션하도록 지원 마이그레이션하는 동안 소스 데이터베이스에 발생한 모든 데이터 변경 사항은 지속적으로 대상 데이터베이스에 복제되므로, 마이그레이션하는 동안 소스 데이터베이스가 변함없이 운영 널리 사용되는 데이터베이스 지원 AWS Database Migration Service를 사용하면 가장 널리 사용되는 상용 및 오픈 소스 데이터베이스 플랫폼에서 또는 이를 대상으로 데이터를 마이그레이션 가능 저렴한 비용 마이그레이션 프로세스 중에 사용한 컴퓨팅 리소스와 추가 로그 스토리지에 대한 비용만 지불 라바이트 규모의 데이터베이스를 3 USD라는 저렴한 비용 빠르고 쉬운 설정 마이그레이션 태스크는 AWS Database Migration Service가 마이그레이션을 실행하는 데 사용할 파라미터를 정의하는 곳 마이그레이션 태스크에는 소스 및 대상 데이터베이스에 대한 연결 설정과 더불어 마이그레이션 프로세스를 실행하는 데 사용할 복제 인스턴스 선택이 포함 동일한 태스크를 사용하여 실제로 마이그레이션을 수행하기 전에 테스트를 실행가능 안정성 AWS Database Migration Service는 복원력과 자가 복구 기능 존재 소스 및 대상 데이터베이스, 네트워크 연결성 및 복제 인스턴스를 지속적으로 모니터링 #\rAWS SMS ( Server Migration Service )\r#\r#\rAWS Server Migration Service는 온프레미스 VMware vSphere, Microsoft Hyper-V/SCVMM 및 Azure 가상 머신을 AWS 클라우드로 자동으로 마이그레이션하는 서비스 AWS SMS는 서버 VM을 Amazon EC2에 바로 배포할 수 있는 클라우드 호스팅된 Amazon 머신 이미지(AMI)를 증분 방식으로 복제하는 서비스 #\rAWS SMS의 이점\r#\r클라우드 마이그레이션 프로세스가 단순화 마이그레이션이 시작되면 AWS SMS은(는) 복잡한 마이그레이션 프로세스를 관리하여 라이브 서버 볼륨의 AWS로 복제하고 새로운 AMI를 정기적으로 생성하는 작업 등을 자동화 여러 서버 마이그레이션 조율 AWS SMS는 복제 일정을 예약하고 애플리케이션을 구성하는 서버 그룹에 대한 진행 상황을 추적할 수 있도록 하여 서버 마이그레이션을 조율가능 서버 마이그레이션 증분 테스트 증분 복제 지원 기능을 통해 AWS SMS은(는) 마이그레이션된 서버에 대한 테스트를 신속하게 수행하고 확장가능 AWS SMS은(는) 증분 변경 사항을 온프레미스 서버에 복제한 후 그 차이만 클라우드로 전송하기 때문에 일부 변경 사항만 반복적으로 테스트를 통해 절약 가능 가장 많이 사용되는 운영 체제 지원 Windows 및 대표적인 몇 가지 Linux 배포판을 포함하는 운영 체제 이미지 복제를 지원 가동 중지 최소화 증분 AWS SMS 복제는 최종 전환 중 애플리케이션 가동 중지로 인한 비즈니스 영향을 최소화 AWS SMS 제한사항\n고객이 한도 증가를 요청하지 않는 한, 계정당 50개의 VM을 동시에 마이그레이션 VM의 최초 복제부터 시작하여 VM당(계정당 아님) 90일의 서비스 사용 기간. 고객이 한도 증가를 요청하지 않는 한, 90일 후에는 진행 중인 복제를 종료 정당 50개의 동시 애플리케이션 마이그레이션 ( 각 애플리케이션에 대해 그룹 10개 및 서버 50개 제한 ) #\rAWS Snowball Edge\r#\r#\rAWS Snowball Edge는 데이터 마이그레이션 및 엣지 컴퓨팅 디바이스이며, 두 가지 옵션으로 제공 페타바이트급 대용량 데이터를 전송하기 위한 서비스 Snowball Edge는 특정 Amazon EC2 인스턴스 유형과 AWS Lambda 함수를 지원하므로 고객은 AWS에서 개발하고 테스트한 후 원격 위치의 디바이스에 애플리케이션을 배포하여 데이터를 수집, 사전 처리 및 반환가능 서비스와 더불어 물리적인 실체가 있는 장비가 존재하여 AWS에 요청하면 Snow ball를 배송받고 On-premise의 데이터를 빠르게 Snowball로 이동시킨 뒤, 작업이 완료되면 이 물리 장비를 다시 AWS로 배송하고 S3 Bucket에 저장함 스토리지 용량은 최대 80TB까지 저장 가능 #\rSnowball 이외에 기능이 추가된 Snowball Edge가 사용하는 경우\r#\r페타바이트 규모의 데이터를 AWS로 이송하는 경우 적합 VPN, Direct Connect, S3를 통한 직접적인 전송을 이용하기엔 데이터의 양이 많을 경우 Snowball을 사용하는 것이 좋음 또한 물리적으로 격리된 환경이거나 인터넷 환경이 좋지 않을 경우 사용 평균적으로 AWS로 데이터를 업로드하는데 1주일 이상이 소요되는 경우 Snowball 사용을 검토함 #\rAWS Snoball의 이점\r#\r용이한 데이터 이동 Snowball Edge는 약 1주 만에 테라바이트 규모의 데이터를 이동 네트워크 조건이 AWS에서 대규모 데이터를 송수신하는 데 현실적으로 적합하지 않은 경우, 이를 사용하여 데이터베이스, 백업, 아카이브, 의료서비스 레코드, 분석 데이터 세트, IoT 센서 데이터 및 미디어 콘텐츠를 이동 간편한 사용 AWS에서 사전에 프로비저닝된 Snowball Edge 디바이스를 고객 위치로 자동으로 배송 디바이스를 반환할 준비가 되면, 전자 잉크 선적 레이블이 자동으로 업데이트되고 화물 운송업체가 업로드가 시작되는 올바른 AWS 시설로 운송 로컬에서 데이터 처리 및 분석 EC2 AMI를 실행하고 AWS Lambda 코드를 Snowball Edge에 배포하여 기계 학습 또는 다른 애플리케이션을 통한 로컬 처리나 분석을 실행 개발자와 관리자는 네트워크 연결 없이 일관된 AWS 환경으로 디바이스에서 직접 애플리케이션을 실행가능 독립형 스토리지 Snowball Edge 디바이스는 NFS(파일 공유 프로토콜) 또는 객체 스토리지 인터페이스(S3 API)를 통해 기존 온프레미스 애플리케이션에 로컬 스토리지를 제공 보안 Snowball Edge 디바이스는 변조 방지 엔클로저, 256-비트 암호화, 그리고 데이터의 보안 및 관리의 연속성을 보장하도록 설계된 업계 표준 Trusted Platform Module(TPM)을 사용 확장성 Snowball Edge 디바이스는 테라바이트 규모의 데이터를 전송할 수 있으며, 여러 대의 디바이스를 병렬로 사용하거나 함께 클러스터링하여 AWS에서 페타바이트 규모의 데이터를 송수신 "},{"id":25,"href":"/cloud/docs/OpenStack/OpenStack/Neutron/","title":"Neutron","section":"OpenStack docs","content":"\r네트워크를 관리하는 서비스: Neutron\r#\r#\r네트워크를 관리하는 서비스: Neutron\r#\rNeutron은 네트워크 서비스로 여러 노드에 여러 프로세스를 배치하는 독립형 서비스 프로세스는 서로 및 다른 OpenStack의 서비스와 상화 작용 #\r#\rNeutron의 논리 아키텍처\r#\r#\r#\r구성요소 기능 neutron-server network api의 기능 및 네트워크 확장 기능을 서비스하며, 각 포트의 대한 모델 및 Pfmf 지정, AMQP를 사용하여 데이터베이스와 통신하는 플러그인을 통해 수행 neutron-L2-agent OVS 가상 Bridge 사이에서데이터 패킷을 전달하기 위한 중계장치 neutron-l3-agent 태넌트 네트워크에서 VM의 외부 네트워크 엑세서를 위한 L3/ NAT 전달을 제공 neutron-dhcp-agent 테넌트 네트워크에 DHCP 서비스를 제공, DHCP agent는 메시지 큐에 엑세스할 수 있는 권한이 필요 Queue 다른 서비스 간의 통신의 역할을 수행 Neutron Database Neutron 서비스를 수행하기 위한 일련의 정보들은 보관, 관리하는 DB Neutron 3rd Party Plugin Neutron 서비스의 안정적인 통신 역할을 수행 plugin agent 각 compute node에서 실행되며 로컬 vswitch을 구성 및 관리 network provider services 테넌트 네트워크에 추가 네트워킹 서비스를 제공 #\rNeutron은 다양한 네트워크 플러그인이나 네트워크 모델을 지원 사용자는 Neutron API를 이용해 neutron-server로 IP 할당을 요청 neutron-server 들어온 요청을 Queue로 다시 요청 Queue는 neutron-dhcp-agent와 Neutron 3rd Party plugin으로 IP 할당 지시를 내림 neutron-dhcp-agent와 Neutron 3rd Party Plugin은 지시 받은 작업 수행을 시작 neutron-server는 수시로 작업 상태를 Neutron database에 저장 할당된 IP를 인스턴스에서 사용 가능 #\r#\rNeutron의 네트워킹 프로세스\r#\r#\rneutron-server에 의해 명령을 요청을 받음 plugin을 토대로 Messae queue를 통해 각 agent의 기능을 수행 이와 함께 SDN 서비스를 수행 #\r#\rNeutron network의 종류\r#\r#\r#\r네트워크의 종류 기능 Management network OpenStack 구성 요소 간의 내부 통신에 사용, 기본적으로 IP 주소는 데이터 센터 내에서만 사용이 가능 Guest network 클라우드 배포 내에서 인스턴스 데이터 통신에 사용되며, 네트워킹 플러그인 및 테넌트가 만든 가상 네트워크의 구성 선택에 따라 변동 External network 외부에서 인스턴스에 대한 엑세스를 위해 제공되는 네트워크 API network OpneStack API를 외부에 노출시키는 네트워크 #\r#\rNeutron과 VRRP, DVR\r#\r#\rVRRP(Virtual Router Redundancy Protocl)로 랜에서 정적으로 설정된 기본 라우터를 사용할 때, 하나 이상의 백업 라우터를 사용하는 방법을 제공하는 인터넷 프로토콜\nDVR(Distributed Virtual Router)이란 VRRP 기능을 향상시키고, 분산 라우팅 기능과 HA(High Availability), 로드밸런싱 기능을 사용할 수 있음\n기존 레거시 HA 라우터와 마찬가지로 DVR/ SNAT(Static NAT), HA 라우터는 다른 노드에서 실행되는 L3 Agent의 백업 DVR/ SNAT 라우터에서 SNAT 서비스 장애를 빠르게 해결 가능\n#\r#\r네트워크 관련 명령어\r#\r$ openstack network list # 네트워크 확인 $ openstack network show [네트워크 이름] # 네트워크 정보 조회 $ ip netns # 라우터 정보 조회 $ ip netns exec [라우터이름] [리눅스 명령어] netstat -r arp -an ifconfig ping # 라우터의 자세한 정보 조회 $ openstack network create --provider-network-type [타입] [네트워크 이름] # 네트워크 생성 # openstack subnet create --network [네트워크 이름] --gateway [GW주소] --subnet-range [서브넷 범위] [서브넷 이름 # 서브넷 생성 $ openstack router list # 라우터 목록 확인 $ openstack router show [라우터 이름] # 라우터 정보 조회 $ openstack router add subnet [라우터 이름] [서브넷 이름] # 라우터에 서브넷 추가 $ openstack port create --network [네트워크 이름] --fixed-ip subnet=[서브넷 이름] [포트 이름] # 포트 생성 $ openstack router add port [라우터 이름] [포트 이름] # 라우터에 포트 추가 #\rfixed-ip, floating-ip\r#\r#\rIP 역할 Fixed IP 가상머신에 할당되는 내부 IP를 의미 Floating IP 클라우드 내의 가상머신이 인터넷 외부망과 연결되기 위해 배정 받는 IP를 의미 #\rSecurity Group\r#\r#\r인스턴스에 대한 인바운드 및 아웃바운드 트래픽을 제어하는 가상의 네트워크 방화벽 하나의 인스턴스에 여러 개의 보안 그룹 적용도 가능 #\r#\r#\r"},{"id":26,"href":"/cloud/docs/AWS/AWSSAA/SAA-6/","title":"6장 인증과 권한","section":"AWS SAA 시험정리","content":"\r6장 인증과 권한 부여 - AWS Identity and Access Management\r#\r#\r6장의 목표\r#\r#\r안전한 애플리케이션 및 아키텍처 설명 어떻게 애플리케이션 티어를 보호할지 결정한다.\n어떻게 데이터르 보호하맂 결정한다.\n#\r#\rAWS 리소스는 기업의 소중한 자산이므로 엄격하게 보호돼야 한다.\n그렇다고 관리자와 고객조차 액세스 할 수 없을 정도로 보안 수준을 높일 수도 없다.\n높은 보안 수준을 유지하면서 관리자와 고객의 액세스는 허용할 수 있는 완벽한 절충점이 IAM이다.\nIAM은 사용자의 요청을 인증 (Authentification),해서 정당하게 사용하는 것을 확인하고 권한 부여 (Authorization)로 필요한 만큼 정확하게 액세스 할 수 있게 할 수 있다.\nAWS는 주로 IAM으 통해 자격을 인증학 권한을 부여한다.\n6장에서는 IAM 자격증명, 보안 주체를 학습하며 자격 증면은 AWS의 사용자의 역할을 나타내고, 여기서의 역할이란 애플리케이션 서비스, 사용자, 그룹에 일시적으로 할당할 수 있는 자격 증명을 의미한다.\n자격증명은 다른 서비스와 연동해서 사용할 수 있으며, AWS 계정 외부의 사용자나 애플리케이션을 인증하고, AWS 리소스에 임시 액세스하는 데 Kerberos, Microsoft Active Directory, LDAP (Lightweight Directory Access Protocol)과 같은 외부 서비스를 사용할 수 있다.\n정책을 통해서 AWS 계정의 모든 리소스아 상호 작용할 수 있는 방법을 정교하게 정의해서 자격 증명을 제어할 수 있다.\n정책은 보안 주체(Principal, 자격 증명 기반) 또는 리소스에 연결한다.\n계정에서 보안 주체의 작업을 자세히 통제하기 위한 정책 수립\n보안 주체의 자격을 증명하기 위해 사용되는 다양한 종류의 키 또는 토큰 관리\n자격 증명 연동을 사용해서 IAM을 외부 공급자와 통합하기 위한 Single Sign-On 솔루션 제공\n리소스를 적절하게 보호하기 위해 계정과 역할을 구성하는 모범 사례 구현\n#\r#\rIAM 자격 증명\r#\r#\r새 AWS 계정을 만들면 하나의 자격 증명이 같이 만들어지며, 이 자격 증명은 루트 사용자이다.\n루트는 기본적으로 계정에 연결된 서비스와 리소스 전체에 완전한 권한을 가지고 있으며, 오직 루트 사용자만이 모든 서비스에 완벽하게 액세스 할 수 있다.\n루트의 모든 권한을 가지고 있는 사용자는 해커에 공격에 매우 위험하며, 이 경우 계정 전체가 위험에 빠질 수 있다.\nAWS는 보안 취약점 노출을 줄이기 위해 루트 계정을 철저하게 보호하고 일상적 작업에 필요한 구체적 권한을 다른 사용자에게 위임하는 것을 제안한다.\n#\rIAM 정책 "},{"id":27,"href":"/cloud/docs/AWS/AWSTraining/AMI/","title":"AWS AMI 생성","section":"AWS Training","content":"\rAWS AMI 생성\r#\r#\r저번 장에서는 EC2를 생성해보았습니다. 이번 Marketplace에서 AMI를 사용해서 인스턴스를 만들고, 생성한 인스턴스를 사용해서 AMI를 만들어 보도록하겠습니다. AMI에 대한 학습을 원하는 분들은 AWS AMI를 참고해주세요. #\rAWS AMI 생성\r#\r#\r#\r먼저 EC2 생성을 위해 인스턴스 시작을 클릭 합니다. #\r#\rAMI 선택화면이 나오면 AWS Marketplace에서 CentOS를 입력 후, 선택합니다. 이와 같이 Marketplace에서는 사람들이 만들어둔 이미지를 사용할 수 있습니다. ( 단, 유료도 있으니 주의가 필요합니다. ) #\r#\rAMI를 선택 후, EC2를 생성합니다. 혹시 생성방법을 모르시는 분들은 EC2 생성 를 참조해주세요 인스턴스의 생성이 완료되면 퍼블릭 IP로 접속합니다. #\r#\r$ sudo yum install -y httpd $ sudo systemctl enable httpd Apache 설치 및 자동시작을 등록합니다. 퍼블릭 IP로 접속하여 확인해보세요. #\r#\r이제 AMI를 만들어보겠습니다. AWS Console 환경에서 AMI를 만들 인스턴스를 우 클릭 후, 이미지 -\u0026gt; 이미지 생성을 클릭합니다. #\r#\r이미지 이름과 설명을 입력 후, 원하는 볼륨을 설정하여 이미지를 생성합니다. #\r#\r메뉴바의 이미지에서 AMI를 클릭하면, 현재 만든 AMI를 확인할 수 있습니다. #\r#\r만든 AMI의 상태가 available이 되면, 다시 인스턴스 생성으로 돌아와 AMI 선택에서 이번에는 AWS Marketplace가 아닌, 나의 AMI를 선택하여 생성합니다. 생성 후, 퍼블릭 IP로 접속하면 Apache가 설치되어 있는 것을 확인 할 수 있습니다. #\r이와 같이 AMI를 사용하면, 보다 편리하고 빠르개 인스턴스를 생성할 수 있습니다. #\r#\rAWS CLI로 AMI 생성\r#\r#\rAMI 또한 AWS CLI를 통해 생성이 가능합니다. #\r$ aws ec2 create-image \\ --instance-id [ 인스턴스 ID ] --name \u0026#34;[ AMI 이름 ]\u0026#34; --description \u0026#34;[ AMI 설명 ]\u0026#34; # 인스턴스 ID를 가진 인스턴스를 AMI 이름과 AMI 설명을 가진 AMI 이미지로 생성합니다. $ aws ec2 describe-images \\ --image-id [ AMI ID ] # AMI ID를 가진 AMI에 대한 정보를 알려줍니다. #\r#\r예제 1.\r#\rUbuntu18.04의 OS에서 Apache2가 설치되어 있고, 자동시작되는 AMI를 생성해보세요. ( 단, Putty로 접속하여 설치하면 안됩니다. )\r#\r예제 1. 답안\r↕\rUser data를 사용하여, 자동 설치 후 AMI를 생성합니다.\n"},{"id":28,"href":"/cloud/docs/AWS/AmazonWebService/AWS_Developer/","title":"AWS Developer","section":"AWS docs","content":"\rAWS_Developer\r#\r#\rAWS CodeBuild\r#\r#\rAWS CodeBuild는 소스 코드를 컴파일하는 단계부터 테스트 실행 후 소프트웨어 패키지를 개발하여 배포하는 단계까지 마칠 수 있는 완전관리형의 지속적 통합 서비스 CodeBuild는 지속적으로 확장되며 여러 빌드를 동시에 처리 사전 패키징된 빌드 환경을 사용하면 신속하게 시작할 수 있으며 혹은 자체 빌드 도구를 사용하는 사용자 지정 빌드 환경제작 가능 AWS CodeBuild는 코드를 실행하고 아티팩트를 Amazon S3 버킷에 저장 CodeBuild에서는 사용한 컴퓨팅 리소스에 대한 분당 요금이 청구 #\rAWS CodeCommit\r#\r#\rAWS CodeCommit은 안전한 Git 기반 리포지토리를 호스팅하는 완전관리형 소스 제어 서비스 뛰어난 확장성의 안전한 에코시스템에서 여러 팀이 협업하여 코드 작업을 수행가능 CodeCommit을 사용하면 소스 코드에서 바이너리까지 모든 항목을 안전하게 저장할 수 있고 기존 Git 도구와 원활하게 연동 에코시스템\n자연계의 생태계처럼 관련 기업이 협력하여 공생하는 시스템을 의미 IT 분야의 여러 기업이 몇몇 리더 기업을 중심으로 경쟁과 협력을 통해 공생하고 함께 발전해 나가는 모습을 지칭 #\rAWS CodeDeploy\r#\r#\rAWS에서 제공하는 배포 자동화 서비스 EC2 인스턴스들에 코드를 배포하는 과정을 자동으로 진행시켜 줌 카피스트라노 ( Capistrano )나 젠킨스 ( Jenkins ) 같은 서드파티 배포 자동화도구 보다 AWS 내 다양한 서비스와 손쉽게 연동이 가능하다. CodeDeploy는 무중단 배포 기법들인 IDP/ BGD를 둘다 지원한다. CodeDeploy란 단순히 명령어를 적어두고 프로그램이 그 명령을 순차적으로 실행하는 것 뿐이다. 단순히 우리가 해주는 일을 대신 해주는 Auto Scaling과 같은 개념 CodeDeploy로 배포하고자 한다면 EC2 인스턴스에 반드시 설치되어 있어야 하며 *.yml파일에 있는 절차를 따라서 배포를 진행한다. CodeDeploy 구성요소\r#\r#\rAppSpec.yml\r↕\rvesion: 0.0 os: linux # 윈도우, 리눅스 등 어떤 OS를 위한 배포 파일인지를 명시한다. # CodeDeploy Agent는 배포 명령을 받으면 코드 저장소에 있는 프로젝트 전체를 서버의 임시 결로로 내려 받는다. # 내려받은 프로젝트를 서버 내 어느 경로로 이동시킬지 명시할 수 있다. files: - source: / destination: /var/www # AppSpec.yml에서는 배포 시 발생하는 다양한 생명주기마다 원하는 스크립트를 실행할 수 있게 후크를 제공해준다. # 배포 시 사용하는 스크립트들은 훤하는 곳에 둬도 되며, 보통은 프로젝트에 AppSpec.yml 파일을 포함하듯이 함께 포함한다. # 이 예시에서는 프로젝트 최상단에 scripts라는 디렉터리를 만들어 그 안에 스크립트들을 보관해 둔다. hooks: # 코드 저장소에서 프로젝트를 낼받은 뒤 인스턴스 내 배포를 원하느 경로에 파일들을 옮기기 전이며, 예시에서 사용한 스크립트의 이름을 보면 리소스 데이터 번들을 압축 해제하는 것으로 추축할 수 있다. BeforeInstall: - location: scripts/UnzipResourceBundle.sh - location: scripts/UnzipDataBundle.sh # 파일을 모두 이동한 후 실행되는 스크립트들이다. # 파일 이름을 봐서 리소스 파일들이 제대로 존재하는 지 테스트하는 것으로 추측할 수 있다. # 또한 Timeout 옵션을 두어 180초 이내에 스크립트가 완료되지 않으면 배포에 실패한 것으로 간주한다. AfterInstall: - location: scripts/RunResourceTests.sh timeout: 180 # 애플리케이션을 시작할 때 사용하는 스크립트들이다. # 예시에서는 서버를 재시작하고 최대 240초 동안 기다리는 것을 알 수 있다. ApplicationStart: - location: scripts/RestartServer.sh timeout: 240 # 서비스를 재시작한 후 실제로 서비스가 올바르게 실행됐는 지 확인 할 때 사용한느 스크립트들이다. # runas 옵션을 주어 기본 사용자인 ec2-user가 아닌 codedeployuser라는 다른 user로 실행하게 했다. ValidateService: - location: scripts/ValidateService.sh timeout: 30 runas: codedeployuser #\r스크립트 파일들에 실행 권항을 추가해서 Git에 올리고 싶다면 다음과 같은 명령어를 이용하면 된다. git update-index --chmod=+x \u0026lt;스크립트 파일 이름\u0026gt; CodeDeploy 작동절차\r...\r#\rCodeDeploy 작동절차\r#\r#\rAppSpec.yml 파일을 추가한 후, 프로젝트를 코드 저장소인 GitHub 혹은 AWS S3에 업로드한다. #\rCodeDeploy에 프로젝트의 특정 버전을 배포해 달라 요청한다. #\rCodeDeploy는 배포를 진행할 EC2 인스턴스들에 설치되어 있는 CodeDeploy Agent들과 통신하며 Agent들에게 요청받은 버전을 배포해 달라고 요청한다. #\r요청을 받은 CodeDeploy Agent들은 코드 저장소에서 프로젝트 전체를 서버로 내려받는다. 그리고 내려받은 프로젝트에 있는 AppSpec.yml 파일을 읽고 해당 파일에 적힌 절차대로 배포를 진행한다. #\rCodeDeploy Agent를 배포를 진행할 후 성공/ 실패 등 결과를 CodeDeploy에게 전달한다. #\r#\rAWS CodePipeling\r#\r#\rAWS CodePipeline은 빠르고 안정적인 애플리케이션 및 인프라 업데이트를 위해 릴리스 파이프라인을 자동화하는 데 도움이 되는 완전관리형 지속적 전달 서비스 코드 변경이 발생할 때마다 사용자가 정의한 릴리스 모델을 기반으로 릴리스 프로세스의 빌드, 테스트 및 배포 단계를 자동화 AWS CodePipeline을 GitHub 또는 자체 사용자 지정 플러그인과 같은 타사 서비스와 손쉽게 통합가능 사용한 만큼만 비용을 지불합니다. 선결제 금액이나 장기 약정이 존재하지 않음 #\rAWS X-Ray\r#\r#\rAWS X-Ray는 개발자가 마이크로 서비스 아키텍처를 사용해 구축된 애플리케이션과 같은 프로덕션 분산 애플리케이션을 분석하고 디버그하는 데 도움을 주는 서비스 X-Ray를 사용해 자신이 개발한 애플리케이션과 기본 서비스가 성능 문제와 오류의 근본 원인 식별과 문제 해결을 올바로 수행하는지 파악가능 X-Ray는 요청이 애플리케이션을 통과함에 따라 요청에 대한 엔드 투 엔드 뷰를 제공하고 애플리케이션의 기본 구성 요소를 맵으로 제시 3-티어 애플리케이션에서부터 수천 개의 서비스로 구성된 복잡한 마이크로 서비스 애플리케이션에 이르기까지 개발 중인 애플리케이션과 프로덕션에 적용된 애플리케이션 모두 분석가능 "},{"id":29,"href":"/cloud/docs/OpenStack/OpenStack/Cinder/","title":"Cinder","section":"OpenStack docs","content":"\r블록 스토리지 서비스 : Cinder\r#\r#\r블록 스토리지 서비스 : Cinder\r#\r#\rCinder은 bloack storage 서비스로 storage를 가상화 시켜 여러 스토리지로 사용하거나, 공유할 수 있는 서비스 Cinder은 하나 이상의 노드에서 실행되도록 설계되었으며, SQL 기반 중앙 데이터베이스를 사용 Cinder은 집계 시스템을 사용하여 여러 데이터 저장소로 이동이 가능 #\r#\rCinder 구성요소\r#\r#\r#\r구성요소 역할 DB 데이터저장을 위한 SQL 데이터베이스로, 모든 구성요소에서 사용 Web Dashboard API와 통신할 수 있는 외부 인터페이스 api http 요청을 받고 명령을 변환하여 대기열 또는 http를 통해 다른 구성요소와 통신 Auth Manager 사용자/ 프로젝트/ 역할에 따라, 리소스의 대한 허용을 결정 Scheduler 볼륨을 가져올 호스트를 결정 volume 동적으로 부착 가능한 블록 장치를 관리 backup 블록 저장 장치의 백업을 관리 #\r외부 인터페이스인 dash-board에서 요청을 보내면, Cinder-api가 keyston에게 인증을 확인하기 위해 요청을 보낸다. 인증이 완료되면 DB를 읽어 알맞은 리소스를 생성, 혹은 할당하는 프로세스를 가진다. #\r#\rCinder의 논리 아키텍처\r#\r#\r#\r구성요소 역할 Cinder-api 요청에 따라 storage를 할당, 확장하는 기능을 수행 Queue 각 구성요소 간의 통신기능을 수행 Cinder database Cinder 서비스를 수행하기 위한 일련의 정보들은 보관, 관리하는 DB cinder voulme Cinder 서비스를 통해 가상화되어진 Storage voulme, voulme을 관리 및 업데이트 volume provider storage volume을 생성, 확장하는 서비스 cinder scheduler 요청이 다수인 경우 큐를 통해 받은 메시지를 수행 #\rNova에서 생성된 인스턴스에서 확장해서 사용할 수 있는 저장 공간을 생성, 삭제하고 인스턴스에 연결 할 수 있는 기능을 제공 Cinder는 물리 하드 디스크를 LVM(Logical Volume Manager)으로 설정 설정된 LVM은 cinder-conf와 nova.conf의 환경을 설정해서 cinder-volume을 할당 cinder-api로 생성된 볼륨은 단일 인스턴스 또는 여러 인스턴스에 할당 할 수 있음 #\r#\rCinder driver type\r#\r#\rCinder 기본 블록 스토리지 드라이버는 iSCSI 기반의 LVM LVM이란 하드 디스크를 파티션 대신 논리 볼륨으로 할당하고, 디스크 여러 개를 좀 더 효율적이고 유연하게 관리할 수 있는 방식을 의미 #\r블록 장치는 물리 볼륨으로 초기화해야 하며, 논리 볼륨으로 생성하려면 물리 볼륨을 볼륨 그룹으로 통합해야 함 #\r"},{"id":30,"href":"/cloud/docs/AWS/AWSTraining/EIP/","title":"AWS Elastic IP 할당","section":"AWS Training","content":"\rAWS Elastic IP 할당\r#\rAWS Elastic IP ( 이하 EIP )란 인스턴스의 IP를 고정적으로 할당시킨 IP를 뜻합니다. 만약 인스턴스를 생성할 시, 퍼블릭 IP를 활성화 하면, 인스턴스를 자동 실행시마다 유동적으로 IP가 변화하여 문제가 되는 데, 이러한 문제들을 해결할 수 있습니다. #\rAWS Elastic IP 할당\r#\r#\r#\rEIP를 생성하기 위해 메뉴에서 EC2 서비스에서 네트워크 및 보안 -\u0026gt; 탄력적 IP를 선택합니다. 탄력적 IP 주소 할당을 클릭합니다. #\r#\rAmazon의 IPv4 주소 풀로 할당 받습니다. #\r#\rEIP의 생성이 완료되면, 할당을 위해 Actions -\u0026gt; EIP 주소 연결을 클릭합니다. #\r#\rEIP의 연결 대상을 인스턴스 혹은 네트워크 인터페이스로 설정하여 연결을 진행합니다. 사실상, 인스턴스를 체크하여도 선택된 인스턴스의 네트워크 인터페이스에 EIP를 할당 하는 것입니다. #\r#\rEIP를 할당한 인스턴스를 선택하면 퍼블릭 IP주소가 탄력적 IP로 바뀐 것을 확인할 수 있습니다. #\r#\rEIP를 삭제하기 위해서는 EIP에 연결된 인터페이스가 없어야 하며, 삭제를 위해서는 EIP 주소 릴리스를 선택해줍니다. #\r프리티어에서도 EIP 한개의 사용이 무료이지만, 할당하고있는 EIP만 무료이며, 만약 할당받지 않은 채로 유지되면 과금이 부과되어 주의가 필요합니다. #\r#\rAWS CLI로 EIP 할당\r#\r#\r$ aws ec2 allocate-address EIP를 할당 받습니다. #\r#\r$ aws ec2 associate-address \\ --instance-id [ 인스턴스 ID ] \\ --allocation-id [ EIP ID ] 인스턴스 ID를 가진 인스턴스에 EIP ID를 가진 EIP를 할당합니다. #\r#\r"},{"id":31,"href":"/cloud/docs/AWS/AmazonWebService/AWS_Management/","title":"AWS Management","section":"AWS docs","content":"\rAWS Management\r#\r#\rAmazon CloudWatch\r#\r#\rAWS 클라우드 리소스와 AWS에서 실행되는 애플리케이션을 위한 모니터링 서비스 리소스 및 애플리케이션에 대해 측정할 수 있는 변수인 지표를 수집하고 추적 가능 사용중인 모든 AWS 서비스에 대한 지표가 자동적으로 표시디며, 사용자 지정 대시보드를 통해 사용자 지정 애플리케이션에 대한 지표를 표시하고 지정 집합 표시 가능 지표는 Cloudwatch에 게시된 시간 순서별 데이터 요소 세트이며, 모니터링할 변수 ( 가령 EC2의 CPU 사용량은 EC2가 제공하는 하나의 지표 ) 기본 모니터링과 세부 모니터링으로 나뉘며, 가각 5분과 1분 주기로 수집함 기본 모니터링은 자동활성화이지만, 세부 모니터링은 선택사항 기본적으로 CPU, Network, Disk, Status Check 등을 수집 ( Memory 항목이 없음 ) 지표 데이터의 보존기간 기간 60초 미만의 경우, 3시간 기간 60초의 경우, 15일 기간 300초의 경우 63일 기간 3600초의 경우, 455일 AWS CLI 혹은 API를 이용하여, Cloudwatch에 사용자 정의 지표 게시 가능 경보기능을 사용하여 어떤 지표가 일정기간동안 일정값에 도달할 경우 각 서비스가 취해야할 행동을 정의할 수 있음 모니터링하기로 선택한 측정치가 정의한 임계값을 초과할 경우 하나 이상의자동화 작업을 수행하도록 구성 EC2의 경우, 경보에 따라, 인스턴스 중비, 복구, 종료, 재부팅 가능 #\rCloudwatch Agent\r#\rEC2에 Agent를 설치하게 되면 더 많은 시스템 수준 지표를 수집할 수 있음 온프레미스 서버 또한 Cloudwatch Agent 사용 가능 Memory 항목 포함 Cloudwatch Agent는 로그를 수집할 수 있으며, 후술할 Cloudwatch Logs 기능 사용 가능 #\rCloudwatch Logs\r#\rEC2( Agent에서 수집된 ), CloudTrail, Route 53, Route 53, VPC flow Log 등 기타 소스에서 발생한 로그 파일을 모니터링, 저장 및 엑세스하는 기능 Cloudwatch Agent를 사용하여 로그를 수집 Cloudwatch Log Insights를 사용하여 CloudWatch Logs에서 로그 데이터를 대화식으로 검색해 분석할 수 있음 Agent는 기본적으로 5초마다 로그 데이터를 전송 #\rCloudwatch Events\r#\rAWS 각 서비스의 이벤트가 사용자가 지정한 이벤트패턴과 일치하거나 일정이 트리거될 경우, 사용자가 월하는 기능을 발동시키도록 하는 기능 이번트 소스와 대상으로 나뉨 이벤트 소스: AWS 환경에서 발생하는 이벤트이며, 가령 S3의 경우 오브젝트 등록, 삭제 등을 들 수 있음 대상: 이벤트 발생시 해야할 행동을 정의하는 것이며, SNS 전송 혹은 람다, SQS 게시 등을 설정할 수 있음 이벤트 소스에 해당하는 규칙이 트리거될 경우 대상에 해당하는 서비스를 실행시킴 이벤트가 시스템에 생성해 둔 규칙과 일치하는 경우, AWS Lambda 함수를 자동으로 호출하고, 해당 이벤트를 Amazon Kinesis 스트림에 전달하고, Amazon SNS 주제를 알림\u0026rsquo; having 1=1## #\rAWS CloudFormation\r#\r#\r인프라를 관리 간소화를 목적으로 하는 서비스 AWS의 리소스를 일일이 설정하지 않고 해당 서비스의 프로비져닝과 설정을 미리 구성하여 반복작업을 줄이도록 도와주는 역할 EC2, Auto Scaling Group으로부터 ELB, RDS, S3 등을 사전에 구성하여 한 번의 클릭으로 다수의 서비스를 빠르게 생성할 수 있음 생성된 리소스 모음은 다른 계정 혹은 다른 리전에 옮겨 사용 가능 #\rStack\r#\r하나의 단위로 관리할 수 있는 AWS 리소스들의 모음 스택을 생성, 업데이트 또는 삭제하여 리소스 모음을 생성, 업데이트, 삭제가 가능 스택에서 실행중인 리소스를 변경해야 하는 경우 스택을 업데이트할 수 있는 데, 이 업데이트된 세트를 변경세트라 칭함 스택을 삭제하는 경우 삭제할 스택을 지정하면 해당 스택과 스택 내 모든 리소스를 삭제 AWS에서 리소스를 삭제할 수 없는 경우 스택이 삭제 스택의 리소스 중 하나라도 성공적으로 생성되지 않은 경우 성공적으로 생성한 모든 리소스를 모두 삭제함 ( Automatic rollback on error ) #\rTemplate\r#\r스택을 구성하는 AWS 리소스를 JSON 혹은 YAML 형식으로 선언한 텍스트 파일\n템플릿은 로컬 혹은 S3에 저장되며, 템플릿을 불러올 때 S3 bucket을 지정할 수 있음\n템플릿을 \u0026ldquo;Designer\u0026quot;을 통해 생성할 수도 있으며, S3 bucket에 저장된 것을 불러와 생성이 가능\n#\rTemplate의 여러 요소\r#\rParameter : 선택 섹션, 스택 생성 및 업데이트 시 템플릿에 전달하는 값, 사용자가 선택하는 여러 요소들 ( EC2 유형 - t2.micro 등 )\nConditions : 선택 섹션, 조건문, 리소스가 생성되는 조건을 만들어 조건 충족시에만 리소스를 만들 수 있또록 하는 요소\nResources : 필수 섹션, CLoudformation에 포함될 리소스\nMetadata : 선택 섹션, 템플릿에 대한 세부 정보를 제공하는 임의의 JSON, YAML 객체\nMappings : 선택 센셕, 프로그래밍 언어로 따지만 \u0026lsquo;Switch\u0026rsquo; 조건문에 해당하며, \u0026lsquo;키\u0026rsquo;에 해당하는 값 세트를 생성하고 해당하는 키가 있으면 값 세트에 맞춰 리소를 생성\n#\rAWS CloudTrail\r#\r#\rCloudTrail의 이벤트는 AWS 계정에서의 활동 기록을 의미 용자, 역할 또는 CloudTrail에서 모니터링이 가능한 서비스에 의해 수행되는 작업, AWS Management 콘솔, AWS SDK, 명령줄 도구 및 기타 AWS 서비스를 통해 수행되는 API 계정 활동과 비 API 계정 활동 모두에 대한 기록을 제공 CloudTrail에는 로깅할 수 있는 두 가지 유형의 이벤트가 존재 관리 이벤트 : 기본적으로 로깅 데이터 이벤트 : 기본적으로 로깅을 하지 않음 관리 이벤트와 데이터 이벤트 모두 동일한 CloudTrail JSON 로그 형식을 사용 #\r관리 이벤트\r#\rAWS 계정의 리소스에 대해 수행되는 관리 작업에 대한 정보를 제공하며, 이를 제어 영역 작업이라 함 관리 이벤트 예시\n보안 구성 디바이스 등록 데이터 라우팅 규칙 구성 로깅 설정 #\r데이터 이벤트\r#\r데이터 이벤트는 리소스 상에서, 또는 리소스 내에서 수행되는 리소스 작업에 대한 정보를 제공하며, 이를 데이터 영역 작업이라 함 관리 이벤트 예시\nAmazon S3 객체 수준 API활동 AWS Lambda 함수 실행 활동 #\rInsights events\r#\rCloudTrail Insights 이벤트는 AWS 계정에서 비정상적인 활동을 캡처 Insights events을 활성화하고 CloudTrail가 비정상적인 활동을 감지한 경우, Insights events는 다른 폴더나 트레일에 대한 대상 S3 버킷의 접두사에 로깅 Insights events은 계정 API 사용량 변화가 계정의 일반적인 사용 패턴과 크게 다르다는 것을 CloudTrail가 감지한 경우에만 로깅 #\rCloudTrail 이벤트 기록\r#\rCloudTrail 이벤트 기록은 CloudTrail 이벤트에 대한 지난 90일간의 기록으로 확인, 검색 및 다운로드가 가능 AWS Management 콘솔, AWS SDK, 명령줄 도구 및 기타 AWS 서비스를 통해 수행되는 AWS 계정 활동에 대한 가시성을 확보가능 CloudTrail 콘솔에서 어떤 열이 표시되는지를 선택하여 이벤트 기록 보기를 사용자 지정가능 #\r추적\r#\r추적은 Amazon S3 버킷, CloudWatch Logs 및 CloudWatch 이벤트에 CloudTrail 이벤트를 제공할 수 있는 구성 추적을 사용하여 제공하고자 하는 CloudTrail 이벤트를 필터링하고, AWS KMS 키로 CloudTrail 이벤트 로그 파일을 암호화하며, 로그 파일 제공을 위해 Amazon SNS 알림을 설정이 가능 #\r조직 추적\r#\r조직 추적은 조직의 마스터 계정과 모든 멤버 계정의 CloudTrail 이벤트를 동일한 Amazon S3 버킷, CloudWatch Logs 및 CloudWatch 이벤트에 전달할 수 있도록 하는 구성을 의미 #\rAWS Config\r#\r#\rAWS Config는 AWS 리소스 구성을 측정, 감사 및 평가할 수 있는 서비스 Config는 AWS 리소스 구성을 지속적으로 모니터링 및 기록하고, 원하는 구성을 기준으로 기록된 구성을 자동으로 평가 #\rAWS OpsWorks\r#\r#\rAWS OpsWorks는 Chef 및 Puppet의 관리형 인스턴스를 제공하는 구성 관리 서비스 Chef 및 Puppet은 코드를 사용해 서버 구성을 자동화할 수 있게 해주는 자동화 플랫폼 OpsWorks를 사용하면 Chef 및 Puppet을 통해 Amazon EC2 인스턴스 또는 온프레미스 컴퓨팅 환경 전체에서 서버가 구성, 배포 및 관리되는 방법을 자동가 가능 #\rAWS Managed Services\r#\r#\rAWS Managed Services(AMS)는 안전하고 규정을 준수하는 AWS Landing Zone을 제공하고 고객 대신 AWS를 운영하는 서비스 AWS Managed Services는 인프라를 유지 관리하기 위한 모범 사례를 구현하여 운영 오버헤드와 위험을 줄일 수 있도록 지원 AWS Managed Services는 변경 요청, 모니터링, 패치 관리, 보안, 백업 서비스 등과 같은 일반적인 활동을 자동화하고 인프라를 프로비저닝, 운영 및 지원하기 위한 전체 수명 주기 서비스를 제공 Landing Zone\r#\r검증된 엔터프라이즈 운영 모델이자 지속적인 비용 최적화 및 일상적인 인프라 관리 수단 #\rAWS Service Catalog\r#\r#\rAWS Service Catalog를 사용하는 조직은 AWS에서 사용이 승인된 IT 서비스 카탈로그를 생성하고 관리하는 서비스 서비스에는 가상 머신 이미지, 서버, 소프트웨어 및 데이터베이스에서 멀티 티어 애플리케이션 아키텍처를 완성하는 모든 서비스가 포함 AWS Service Catalog를 사용하면 일반적으로 배포된 IT 서비스를 중앙에서 관리할 수 있고 일관된 거버넌스를 달성하고 규정 준수 요건을 충족하는 데 도움이 되는 동시에 사용자가 필요로 하는 승인된 IT 서비스만을 신속하게 배포가능 #\rAWS Service Catalog의 핵심개념\r#\rService Catalog 서비스 카탈로그는 하나의 AWS account에 종속됩니다. 관리자가 관리하며 하나 이상의 포트폴리오(Portfolios)를 포함 Administrtor 관리자는 서비스 카탈로그 안에 있는 프로덕트 포트폴리오(Portfolios of Products)를 업로드하고 관리 User 사용자는 서비스 카탈로그의 포털페이지를 접속하여 여러 포트폴리오를 찾아보고, 관심있는 프로덕트를 선택 Portal 포탈은 서비스 카탈로그의 창문(View)인데요, 특정 사용자가 접속할 수 있는 포트폴리오와 제품만 보여주도록 맞춤제작 가능 Portfolio 포트폴리오란 서비스 카탈로그 아래 버전관리 중인 프로덕트들의 모음 Product 프로덕트는 AWS리소스들의 모음 ( EC2 인스턴스, 애플리케이션 서버, 데이타베이스 )들로 이 단위 별로 프로덕트를 런치하고 관리 #\rAWS TrustedAdvisor\r#\r#\rAWS Trusted Advisor는 AWS 모범 사례에 따라 리소스를 프로비저닝하는 데 도움이 되도록 실시간 지침을 제공하는 온라인 도구 #\rAWS TrustedAdvisro의 분석 카테고리\r#\r"},{"id":32,"href":"/cloud/docs/OpenStack/OpenStack/Ceilometer/","title":"Ceilometer","section":"OpenStack docs","content":"\r리소스의 사용량과 부하를 관리하는 서비스 : Ceilometer\r#\r#\r리소스의 사용량과 부하를 관리하는 서비스 : Ceilometer\r#\r#\r#\rCeilometer은 각 서비스들의 예상 부하에 따라 추가 작업과 노드를 관리하는 역할을 수행 클라우드에서 배포된 자원의 사용량과 성능을 측정해 사용자가 자원 상태를 모니터링 할 수 있는 기능을 제공 Ceilomete는 리버티 버전에서 기존에 알람 서비스를 하던 부분을 aodh로 분리 #\r핵심 서비스 역할 Polling agent OpenStack 서비스를 폴링하고 미터를 빌드하도록 설계된 데몬 프로세스 Notification agent 메시지 큐에서 알림을 듣고 이벤트 및 샘플로 변환하며 파이프 라인 조치를 적용하도록 설계된 데몬 프로세스 #\rCeilometer로 표준화 및 수집 된 데이터는 다양한 대상으로 전송 Gnocchi는 이러한 스토리지 및 쿼리를 최적화하기 위해 시계열 형식으로 측정 데이터를 캡처하도록 개발 Aodh는 사용자 정의 규칙이 깨졋을 때 경고를 보낼 수 있는 경보 서비스 Ceilomter은 이와 같이 리소스를 감시 및 예상하여 다른 작업을 수행할 수 있도록 하는 서비스를 의미 #\r#\r데이터 수집\r#\r#\r#\r위의 그림과 같이 Polling agents에서 각 서비스들의 API의 리소스를 읽어 데이터를 수집 Notification agents는 Polling agents에서 수집한 데이터들을 토대로 Ceilomter 서비스 혹은 Events로 변환하는 역할을 수행 #\r#\r데이터 처리\r#\r#\r#\r수집된 데이터를 토대로 Notification bus를 통해 엔드 포인트로 재분배하여 이벤트 및 샘플로 처리하느 역할을 수행 #\r#\r데이터 요청\r#\r#\r#\r데이터의 요청은 수집된 자료들을 토대로 서로 데이터를 주고 받으며, Polling agents라는 클라우드 컨트롤러에서 처리되며, 여러 플러그인을 사용하여 데이터를 통신합니다. #\r#\r데이터 처리 및 변형\r#\r#\r#\r#\r위의 그림은 수집된 데이터를 수집, 분석 및 변형 배포하는 과정을 나타낸 그림으로 Ceilomter은 각 서비스들의 데이터를 수집하여, 변형시키는 여러 소스를 제공 #\r#\rOpenStack에서의 Ceilomter의 위치\r#\r#\r#\r구성요소 역할 Ceilometer-colletcor 중앙 관리서버에서 실행되며, Queue 모니터링 하는 서비스 Ceilometer-agent-notification ceilometer-collector와 함꼐 중앙 관리서버에서 실행, Queue를 이용해 이벤트와 미러링 데이터를 기록 Ceilometer-agent-compute 각 컴퓨팅 노드에 설치해서 실행, 자원 활용 통계로 사용 Ceilometer-account-central 중앙 관리 서버에서 실행, 인스턴스에 연결되지 않은 자원이나 컴퓨터 노드의 활용 가능한 자원 통계를 폴링 Ceilometer-alarm-evaluator 하나 이상의 중앙 관리 서버에서 실행, 슬라이딩 시간대에 임계 값을 추가할 때 발생하는 경보 시점을 결정 Ceilometer-alarm-nottifier 하나 이상의 중앙 관리 서버에서 실행되며, 샘플을 수집하는 임계 값 평가에 따라 알람을 설정 Ceilometer database 수집한 데이터를 저장할 Ceilometer 데이터 베이스 Ceilometer-api 하나 또는 그 이상의 중앙 관리 서버에서 실행되며 데이터베이스에서 데이터 엑세스를 제공 #\r"},{"id":33,"href":"/cloud/docs/AWS/AWSTraining/ELB/","title":"AWS ELB ( 2 Tier ) 생성","section":"AWS Training","content":"\rAWS ELB 생성\r#\r#\r이번 장에서는 생성된 인스턴스들을 로드밸런싱하는 방법에 대해 알아보도록 하겠습니다. ELB 또한 중요한 개념이니, ELB에 대한 학습을 원하는 분들은 AWS ELB를 참고해주세요. #\rAWS ELB 생성\r#\r#\rELB에 대한 생성 순서은 아래의 순서대로 진행합니다. 1. 인스턴스 생성\n2. 대상그룹 생성\n3. 로드 밸런서 생성\n#\r인스턴스 생성\r#\r#\r먼저 기본 VPC에 가용영역 a와 c에 한 대씩, 총 두 대의 인스턴스를 생성해주세요. 보안 그룹은 80은 모두에게, 8009는 서로간만 통신이 가능하게 설정해주세요. 그 후, a,c 인스턴스에 Apach와 Tomcat을 설치 및 연동시켜주세요. #\r$ apt-get -y update $ apt-get -y upgrade $ apt-get install -y apache2 # apache2 설치 $ systemctl enable apache2 $ ufw allow 80/tcp # apache2 자동시작 및 방화벽 허용 등록 $ apt-get install -y libapache2-mod-jk # 연동 모듈 $ vi /etc/apache2/workers.properties workers.tomcat_home=/usr/share/tomcat8 workers.java_home=/usr/lib/jvm/java-8-openjdk-amd64 worker.list=tomcat8 worker.tomcat8.port = 8009 worker.tomcat8.host = [ 서로 다른 인스턴스 IP ] worker.tomcat8.type = ajp13 worker.tomcat8.lbfactor = 1 # 워커 파일 생성 $ vi /etc/apache2/mods-available/jk.conf JkWorkersFile /etc/libapache2-mod-jk/workers.properties --\u0026gt; JkWorkersFile /etc/apache2/workers.properties $ vi /etc/apache2/sites-available/000-default.conf DocumentRoot /var/www/html --\u0026gt; DocumentRoot /var/lib/tomcat8/webapps/ROOT SetEnvIF Request_URI \u0026#34;/*.html\u0026#34; no-jk JkMount /*.jsp tomcat8 # jsp 파일만 tomcat에서 실행 $ vi /var/www/html/index.html 각 인스턴스에 따라 apache1 and apache2를 입력합니다. $ systemctl restart apache2 Apache 설치 #\r$ apt -y update $ apt -y upgrade $ apt-get install lrzsz # JAVA 간편 다운로드를 위한 Irzsz 설치 $ apt-get install -y openjdk-8-jre $ apt-get install -y openjdk-8-jdk # JAVA 설치 $ which javac $ readlink -f /usr/bin/javac # 자바 위치 확인 $ vi /etc/profile export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64 export PATH=$JAVA_HOME/bin/:$PATH export CLASS_PATH=$JAVA_HOME/lib/:$CLASS_PATH $ source /etc/profile # 환경변수 설정 $ echo $JAVA_HOME $ $JAVA_HOME/bin/javac -version # 확인 $ apt-get install tomcat8 -y # tomcat8 설치 $ /usr/share/tomcat8/bin/version.sh # tomcat 설치 확인 $ ufw allow 8080/tcp $ ufw allow 8009/tcp # 방화벽 포트 열기 $ systemctl enable tomcat8 # tomcat 자동시작 $ apt-get install -y libapache2-mod-jk # 연동 모듈 설치 $ vi /etc/tomcat8/server.xml \u0026lt;Connector port=\u0026#34;8009\u0026#34; protocol=\u0026#34;AJP/1.3\u0026#34; redirectPort=\u0026#34;8443\u0026#34; /\u0026gt; 주석 헤제 $ systemctl restart tomcat8 $ vi /var/lib/tomcat8/webapps/ROOT/index.jsp \u0026lt;%@ page language=\u0026#34;java\u0026#34; contentType=\u0026#34;text/html; charset=utf-8\u0026#34;%\u0026gt; \u0026lt;!-- 로컬 정보 --\u0026gt; Local IP : \u0026lt;%= request.getRemoteAddr() %\u0026gt;\u0026lt;br\u0026gt; Local Host : \u0026lt;%= request.getRemoteHost() %\u0026gt;\u0026lt;br\u0026gt; \u0026lt;!-- 서버의 기본 경로 --\u0026gt; Context : \u0026lt;%= request.getContextPath() %\u0026gt; \u0026lt;br\u0026gt; URL : \u0026lt;%= request.getRequestURL() %\u0026gt; \u0026lt;br\u0026gt; URI : \u0026lt;%= request.getRequestURI() %\u0026gt; \u0026lt;br\u0026gt; Path : \u0026lt;%= request.getServletPath() %\u0026gt;\u0026lt;br\u0026gt; Server Port : \u0026lt;%= request.getServerPort() %\u0026gt;\u0026lt;br\u0026gt;\u0026lt;br\u0026gt; 서버 Root 경로 : \u0026lt;%= application.getRealPath(\u0026#34;/\u0026#34;) %\u0026gt;\u0026lt;br\u0026gt; 서버 Root 경로 : \u0026lt;%= request.getRealPath(\u0026#34;/\u0026#34;) %\u0026gt;\u0026lt;br\u0026gt; \u0026lt;% String strServerIP = request.getServerName(); // 서버 ip String strServerPort = Integer.toString(request.getServerPort()); // 서버 port String serverRootUrl = \u0026#34;http://\u0026#34;+ strServerIP +\u0026#34;:\u0026#34;+ strServerPort +\u0026#34;/\u0026#34;; // Root 경로 out.println(serverRootUrl ); %\u0026gt; Tomcat 설치 #\r#\rApplication Load Balancer 생성 ( 이하 ALB )\r#\r#\rALB에 대한 설명은 ALB Link를 참조해주세요. #\rALB를 생성하기 위해 메뉴에서 로드 밸런서 -\u0026gt; 로드밸런서 생성을 클릭합니다. #\r#\r로드 밸런서의 유형 중 ALB를 선택합니다. #\r#\r위의 그림과 같이 ALB의 구성에 대한 설정을 진행합니다. 체계의 인터넷 연결은 외부대역과의 통신을 위한 설정이고, 내부는 서브넷끼리의 통신을 위한 설정입니다. 리스너는 로드 밸런서에서 읽은 포트를 설정합니다. 가용 영역은 로드 밸런서가 활성화될 가용 영역을 지정합니다. #\r#\r보안그룹은 외부와의 통신을 위해 80/tcp를 모두에게 개방하게 설정합니다. #\r#\r위의 그림과 같이 라우팅 구성에 대한 설정을 진행합니다. 대상 유형은 라우팅의 대상이 될 서비스를 지정하는 설정입니다. 프로토콜과 포트는 대상 유형의 라우팅을 지정하는 설정입니다. 상태검사는 경로로 접속하였을 때, 접속이 가능하면 Health, 불가능하면 Unhealth로 나타냅니다. #\r#\r설정이 끝나면, 대상 등록에 인스턴스를 등록합니다. #\r#\r#\rELB의 생성이 완료되면, DNS 접속을 통해 확인할 수 있습니다. #\r#\r또한 대상 그룹으로 이동하여 healthy 상태를 체크할 수 있습니다. #\r#\rNetwork Load Balancer 생성 ( 이하 NLB )\r#\rNLB에 대한 설명은 NLB Link를 참조해주세요. #\r#\rNLB 생성을 위해 다시 로드밸런서로 돌아와, 로드 밸런서 생성을 클릭합니다. #\r#\r로드 밸런서 유형에서 NLB를 선택합니다. #\r#\rNLB의 구성을 위와 같이 설정합니다. 8009 포트는 톰캣과 아파치이 연동을 위한 포트 입니다. #\r#\r라우팅 테이블을 구성합니다. #\r#\r프라이빗 주소의 8009 포트로 인스턴스들을 등록합니다. #\r#\r$ vi /etc/apache/workers.properties worker.tomcat8.host = [ NLB DNS ] Apache의 워커 파일은 NLB의 DNS로 설정합니다. #\r#\r설정해 두었던 ALB로 접속하여 index.jsp로 접속하면 톰캣을 통해 jsp로 접속하는 것을 확인 할 수 있습니다. #\r#\r대상그룹 또한 healthy를 확인할 수 있습니다. #\r#\rClassic Load Balancer 생성 ( 이하 CLB )\r#\rCLB에 대한 설명은 CLB Link를 참조해주세요. #\rCLB를 생성하기 위해 다시 로드 밸런서 생성을 클릭하세요. #\r#\r로드 밸런서 유형 중 CLB를 클릭하세요. #\r#\rELB와 동일하게 외부대역으로 설정합니다.. #\r#\r보안그룹 또한 기존 ELB-sg를 사용합니다. #\r#\r상태검사를 설정합니다. #\r#\r인스턴스를 추가하고, 로드 밸런싱을 활성화합니다. #\r#\rCLB의 DNS로 접속해보면, ELB와 같은 결과를 얻을 수 있습니다. #\r#\rCLB또한 상태검사가 가능합니다. #\r#\r예제 1.\r#\r서로 다른 Public 서브넷 2개, Private 서브넷 2개를 생성하여 각각 인스턴스를 생성한 후, ELB로 접속이 가능하게 구현하세요.\r#\r예제 1. 답안\r↕\rVPC를 생성 후, ALB와 NLB를 사용합니다. "},{"id":34,"href":"/cloud/docs/AWS/AmazonWebService/AWS_Security/","title":"AWS Security","section":"AWS docs","content":"\rAWS Security\r#\r#\r기본적으로 AWS의 보안적 요소는 설비, 인프라 등과 관련된 물리적인 부분과 네트워크 인프라 등은 AWS가 책임을 지고 보안 대책을 수행합니다. 이러한 인프라 위의 OS, 애플리케이션, 네트워크 설정, 계정 관리 등은 사용자가 책임을 져야 하는 공유 책임 모델의 구조를 띄고 있습니다. #\rAWS가 제공하는 기본적인 보안 서비스 #\rAWS 제공 서비스 서비스 개요 통신 경로 암호화 AWS 매니지먼트 콘솔로의 접속 또는 API를 사용할 때 HTTPS를 사용해 데이터를 암호화합니다. Security Group\u0026amp; NetworkACL 인스턴스들의 보안 그룹과 서브넷들의 통신 허가/ 거부 설정을 하는 네트워크 ACL을 사용해 예상하지 못하는 통신을 사전차단합니다. Identity and Access Management( IAM ) 사용자의 역할을 분리하고 최소한의 권한만을 부여하여 보안을 유지합니다. Multi Factor Authentication ( MFA ) AWS 계정 또는 IAM 계정에 일회성 비밀번호 인증을 추가합니다. Virtual Private Cloud ( VPC ) 퍼블릭 클라우드에 프라이빗 환경을 구축합니다. 다른 거점에서 VPN으로 접속할 수도 있습니다. Direct Connect ( 전용선 연결 ) On Premise 환경에서 AWS 전용선을 통해 직접 연결하여 데이터 도청, 변조 등의 위험을 줄일 수 있습니다. 데이터 암호화 EBS, S3, Glacier, Redshift, RDS에 저장하고 있는 데이터 또는 객체를 암호화할 수 있습니다. Hardware Security Module ( CloudHSM ) 암호화 키를 안전하게 저장하고 관리합니다. Trusted Advisor AWS 지원이 제공하는 서비스 중에 하나로, 각종 서비스의 설정과 운용 상황을 확인해서 개선할 부분을 제공해줍니다. #\rAmazon Inspector\r#\r#\rAmazon Inspector는 AWS에 배포된 애플리케이션의 보안 및 규정 준수를 개선하는데 도움이 되는 자동 보안 평가 서비스 모범 사례로부터 애플리케이션의 노출, 취약성 및 편차를 자동으로 평가 심각도 수준에 따라 우선순위가 지정된 상세한 보안 평가 결과 목록을 생성 Amazon EC2 인스턴스의 의도하지 않은 네트워크 접근성과 이 EC2 인스턴스의 취약성을 확인 Amazon Inspector 평가는 일반 보안 모범 사례 및 취약성 정의에 매핑된 사전 정의 규칙 패키지로 제공 #\rAWS Artfact\r#\r#\rAWS Artifact는 자신에게 해당되는 규정 준수와 관련된 정보를 제공하는 신뢰할 수 있는 중앙 리소스 AWS 보안 및 규정 준수 보고서와 엄선된 온라인 계약에 대한 온디맨드 액세스를 제공 보고서에는 SOC(Service Organization Control) 보고서와 PCI(Payment Card Industry) 보고서, 그리고 여러 지역의 인정 기구와 규정 준수 기관에서 AWS 보안 제어의 구현 및 운영 효율성을 입증하는 인증서가 포함 #\rAWS CertificateManager\r#\r#\rAWS Certificate Manager는 AWS 서비스 및 연결된 내부 리소스에 사용할 공인 및 사설 SSL/TLS(Secure Sockets Layer/전송 계층 보안) 인증서를 손쉽게 프로비저닝, 관리 및 배포할 수 있도록 지원하는 서비스 AWS Certificate Manager는 SSL/TLS 인증서를 구매, 업로드 및 갱신하는 데 드는 시간 소모적인 수동 프로세스를 대신 처리 SSL/ TLS, HTTPS\r#\rSSL/ TLS, HTTPS\r↕\rSSL/ TLS ( Secure Soket Layer, Transport Layer Security )\r#\r상위 계층 메시지를 분할, 압축하고 메시지 인증 코드 ( MAC )추가 및 암호화하는 작업을 수행하는 프로토콜 Handshake 프로토콜에서 클라이언트와 서버는 상대방을 확인하고 사용할 키 교환 방식, 암호화 방식, 생성에 필요한 값 등을 전달하여 암호화 채널 수립을 위한 항목들을 협상 단말 ( PC, server 등 )과 단만간의 암호화 통신을 위한 프로토콜 SSLv1은 최초의 버전으로서 문제가 많아 발표되지 않고 사장됨 SSLv2부터 공개가 되었으며 보다더 나은 버전인 SSLv3가 나왔으면 이를 기반으로 TLSv1 생성 TLSv1.0 v1.1, v1.2, v1.3이 나왔지만 아직 많은 브라우저에서 TLSv3을 지원하지 않음 #\rSSL handshake\r#\rClient Hello: Client가 Server에게 자신이 사용가능한 Random byte( 대칭키 생성에 사용됨 ), Session ID, S니/ TLS 버전이 포함된 Cipher suite list를 전달 Server Hello: Server 가 Client가 보낸 Cipher suite List 중 하나를 선택해 전달 Client Key exchange: 키 교환 실시 ( 실제 데이터 암호화에 사용할 키를 전달하여, S니 인증서에서 추출된 공개키로 암호화 ) Server certificate: 서버의 인증서를 클라이언트에게 전송 Sever hello done: 서버 전달 종료 Change cipher Specs, Finished: 이후 보내는 메시지들은 협상된 암호화 알고리즘에 따라 보낼 것임을 통보 Finished, Change cipher Specs: 클라이언트가 보낸 메시지를 확인 후, handshake를 종료하고 하나의 대칭키로 통신한다고 통보 #\r#\rAWS CloudHSM\r#\r#\rAWS CloudHSM은 AWS 클라우드에서 자체 암호화 키를 손쉽게 생성 및 사용할 수 있도록 지원하는 클라우드 기반 하드웨어 보안 모듈(HSM) 사용자를 위해 하드웨어 프로비저닝, 소프트웨어 패치, 고가용성, 백업 등 시간 소모적인 관리 작업을 자동화하는 완전관리형 서비스 CloudHSM에서는 FIPS 140-2 레벨 3 인증 HSM을 사용하여 자체 암호화 키를 관리가능 모든 키를 대부분의 상용 HSM으로 내보내기 가능 CloudHSM을 사용하면 선결제 비용 없이 온디맨드로 HSM 용량을 추가 및 제거하여 신속하게 확장/축소가능 CloudHSM\r↕\r사용방법\r#\rAWS CloudHSM은 자체 Amazon Virtual Private Cloud(VPC)에서 실행되므로, Amazon EC2 인스턴스에서 실행되는 애플리케이션에 손쉽게 HSM을 사용 CloudHSM에서는 표준 VPC 보안 제어 기능을 사용하여 HSM에 대한 액세스를 관리가 가능 애플리케이션은 HSM 클라이언트 소프트웨어가 설정한 상호 인증된 SSL 채널을 사용하여 HSM에 연결 HSM은 고객의 EC2 인스턴스와 가까운 Amazon 데이터 센터에 위치하므로, 온프레미스 HSM과 비교하여 애플리케이션과 HSM 간 네트워크 지연 시간을 줄일 수 있음 업무 분리 및 역할 기반 액세스 제어는 AWS CloudHSM의 설계에 내제 AWS에서 하드웨어 보안 모듈(HSM) 어플라이언스를 관리하지만, 고객의 키에 대한 액세스 권한이 없음 고객이 자체 키를 제어하고 관리 애플리케이션 성능이 개선 다중 AZ(가용 영역)에 제공되는 변조 방지 하드웨어에 키를 안전하게 저장 고객의 HSM은 고객의 Virtual Private Cloud(VPC)에 상주하며 다른 AWS 워크로드와 격리 #\rAWS DirectoryService\r#\r#\rAWS Directory Service는 다른 AWS 서비스에서 Amazon Cloud Directory 및 Microsoft Active Directory(AD)를 사용할 수 있는 몇 가지 방법을 제공하는 서비스 사용자, 그룹 및 디바이스에 대한 정보를 저장하고, 관리자는 이를 사용하여 정보 및 리소스에 대한 액세스를 관리 AWS Directory Service는 클라우드에서 기존 Microsoft AD 또는 LDAP(Lightweight Directory Access Protocol)–인식 애플리케이션을 사용하려는 고객에게 다양한 디렉터리 선택 옵션을 제공 #\rAWS IAM\r#\r#\rAWS 리소스에 대한 엑세스를 안전하게 제어할 수 있는 서비스로 IAM을 사용하여 리소스를 사용하도록 권한을 부여하거나 인증된 대상을 제어 IAM 정책은 \u0026ldquo;Action ( 어떤 서비스에 )\u0026rdquo;, \u0026ldquo;Resource ( 어떤 기능 또는 범위를 )\u0026rdquo;, \u0026ldquo;Effect ( 허가할 것인가 )\u0026ldquo;라는 3가지 규칙을 기반으로 AWS 서비스를 사용하는 데 필요한 권한을 설정 주요기능 AWS 계정에 대한 공유 엑세스 서비스별 세분화된 권한 제공 가능 EC2에서 실행되는 앱을 위한 AWS 리소스 엑세스 권한 제공 멀티 팩터 인증 ( MFA ) 자격 증명 연동 AWS 서비스들은 IAM Role을 할당받아 권한을 부여받을 수 있음 Access Key와 Secret Access Key를 직접 입력하지 않고 권한 부여 가능 IAM 사용자 계정을 만들어 사용자에게 적절한 권한을 부여하고 사용 가능한 서비스를 제한할 수 있음 사용자와 그룹은 N : N 의 관계가 성립이 가능 #\r정책 ( Policy )\r#\rUser, Group, Role이 사용할 수 있는 권한의 범위를 지정하는 것 S3FullAccess, Administrator Access 등 다양한 엑세스 권한이 이미 정의되어 있으며 이를 ‘AWS 관리형 이라 함 사용자 정의 정책 생성 JSON 형식 또는 직접 선택을 통해 사용자 정의 정책 선택 가능 #\r역할 ( Role )\r#\r특정 권한을 가진 계정에 생성할 수 있는 IAM 자격증명 역할에는 다음과 같은 주체가 있음 AWS 계정의 IAM 사용자 AWS의 서비스 ( EC2, RDS, ELB 등 ) 외부 자격 증명 공급자 서비스에 의해 인증된 외부 사용자 역할 생성시 IAM 사용자, 서비스, 외부 사용자 등 주체를 정해야 함 하나의 역할에는 다수의 정책을 연결할 수 있음 생성된 역할을 서비스 혹은 IAM 사용자 등에 연결 Region에 국한되지 않고 사용 가능 신규 유저는 생성시 아무런 권한이 없으며 Access Key와 Secret Access Key가 할당 각 키는 최초 생성시에만 볼 수 있으며 즉시 보관해야 함 #\r그룹\u0026amp; 사용자\r#\r사용자는 IAM 사용자를 의미하여 관리자 계정에 의해 부여받은 권한에 한해 제한된 서비스에 접근할 수 있는 계정을 의미 콘솔 로그인과 프로그래밍 엑세스 가능 여부를 선택하여 생성 가능 콘솔 로그인이 승인된 경우, 별도의 링크를 통해 콘솔에 로그인 할 수 있음 각 사용자마다 정책을 부여할 수 있음 사용자 모두에게 일일이 부여하기 힘들거나 그룹단위로 통제하고 싶은 경우, Group을 사용할 수 있음 그룹은 이미 생성된 사용자와 권한을 설정할 수 있으며, 그룹 내 모든 사용자는 그룹의 권한을 적용받음 #\r특징\r#\r권한 AWS의 서비스나 자원에 어떤 작업을 할 수 있는지 명시해두는 규칙 \u0026quot; 서울 리전에 있는 모든 EC2를 조회할 수 있다\u0026rdquo; 와 같은 항목이 하나의 권한을 칭한다. 정책 권한들의 모음으로, 사용자나 권한들에 직접 적용은 불가능하며, 권한들로 만든 정책을 적용 정책은 사용자, 그룹, 역할에 적용할 수 있다. 사용자 사용자는 AWS의 기능과 자원을 이용하는 객체, 사용자별로 어떤 권한을 가졌는지 세분화해서 지정할 수 있으며, 사용자는 AWS Console에 접근할 수 있는 사람일 수도 있고, 자동화되어 실행되는 프로그램일 수도 있다. 접속하는 사용자인 경우에는 비밀번화가 제공되지만, 프로그램인 경우에는 액세스 키 ID와 비밀 엑세스 키가 제공된다. 그룹 여러 사용자에게 공통으로 권한을 부여할 수 있게 만들어진 개념이다. 하나의 그룹에 여러 명의 사용자를 지정이 가능 역할 어떤 행위를 하는 객체에 여러 정책을 적용한다는 점에서 사용자와 비슷ㅎ자ㅣ만 객체가 사용자가 아닌 서비스나 다른 AWS 계정의 사용자라는 점에서 차이가 있다. 사용자가 아닌 특정 서비스에서 생성한 객체에 권한을 부여하는 데 사용 인스턴스 프로파일 사용자가 사람을 구분하고 그 사람에 권한을 주기 위한 개념이었따면, 인스턴스 프로파일은 EC2 인스턴스를 구분하고 그 인스턴스에 권한을 주기 위한 개념 #\rAmazon Cognito\r#\r#\rAmazon Cognito는 웹 및 모바일 앱에 대한 인증, 권한 부여 및 사용자 관리를 제공 사용자는 사용자 이름과 암호를 사용하여 직접 로그인하거나 Facebook, Amazon, Google 또는 Apple 같은 타사를 통해 로그인가능 Cognito를 사용한 사용자 인증과 접속허가 종류 Identity Provider를 사용한 인증 Cognito를 사용한 Credential 발행 IAM 규칙 Cognito는 SQLite 데이터베이스를 사용, 시간적으로 마지막에 수정된 데이터를 우선적으로 하는 방침을 가짐 Cognito는 Identity Pool 단위를 사용 #\rAWS KMS ( Key Management Service )\r#\r#\rAWS Key Management Service(AWS KMS)는 데이터 암호화에 사용하는 암호화 키인 고객 마스터 키(CMK)를 쉽게 생성하고 제어할 수 있게 해주는 관리형 서비스 #\rAWS Organizations\r#\r#\rAWS Organizations는 AWS의 워크로드가 증가하고 확장됨에 따라 환경을 중앙에서 관리하는 서비스 계정 생성을 자동화하고, 비즈니스 요구를 반영하도록 계정 그룹을 생성하고, 거버넌스를 위해 이러한 그룹에 정책을 적용이 가능 AWS 계정에 대해 단일 결제 방법을 설정하여 결제 과정을 간소화가 가능 WS Organizations는 모든 AWS 고객이 추가 비용 없이 사용가능 #\rAWS Shield\r#\r#\r분산 서비스 거부 공격( DDoS )으로부터 웹 어플리케이션을 보호하는 서비스 Cloudfront와 통합되어 있기 때문에 AWS의 서비스가 아니더라도 Cloudfront의 origin이라면 보호가 가능 #\rShield의 종류\r#\rShield Stanard 기본적으로 적용되는 서비스로 설정을 하지 않아도 AWS 서비스에 활성화 되어있음 Shield Advanced 추가 비용을 내고 추가적인 서비스를 제공받는 것으로 L7 트래픽 모니터링, 사후 분석 등의 기능을 제공 #\rAWS WAF ( Web Application Firewall )\r#\r#\r웹 방화벽으로 Cloudfront와 ALB를 통해 서비스를 제공 ( ALB와 Cloudfront를 직접 지정하여 웹방화벽을 제공 ) WAF을 활용하면 다양한 종류의 웹 공격에 대한 정보를 지닌 Rule을 선택하여 활성화하거나, 특정 Ip의 요청을 막을 수 있음 웹방화벽\r#\r방화벽이 L4/ L4 Layer의 방어 ( IP와 Port 차단 )을 이용 웹 방화벽은 L7( HTTP 헤더, HTTP 본문, URI 문자열, SQL 명령어, 스크립팅 )을 이용한 공격을 방어 "},{"id":35,"href":"/cloud/docs/Azure/AzureTraining/","title":"Azure Training","section":"Microsoft Azure","content":"\r#\rAzure\r#\r#\rAzure Training\nAzure\nAzure\nAzure\n#\rAzure Docs\nAzure\nAzure\nAzure\n#\r"},{"id":36,"href":"/cloud/docs/OpenStack/OpenStack/Horizon/","title":"Horizon","section":"OpenStack docs","content":"\r외부 인터페이스 대시보드 서비스 : Horizon\r#\r#\r외부 인터페이스 대시보드 서비스 : Horizon\r#\r#\r#\r사용자가 웹 UI로 인스턴스 생성, 삭제, 관리 등을 쉽고 빠르게 처리할 수 있게 지원 Horizon은 아파치 웹 서버를 사용 및 Python, Django 프레임워크로 구현 #\r#\r논리 아키텍처의 Horizon\r#\r#\r논리 아키텍처에서 보이는 Horizon은 단순히 Horizon 자체 모듈만 존재 모든 서비스의 API와 연동해서 사용자에게 웹 서비스를 제공 "},{"id":37,"href":"/cloud/docs/OpenStack/OpenStack/Swift/","title":"Swift","section":"OpenStack docs","content":"\r오브젝트 스토리지 관리 서비스 : Swift\r#\r#\r다른 서비스와는 다르게 단독으로 구성되며, 클라우드 스토리지 서비스 ( ex : 네이버 클라우드 ) Swift 서비스는 Object Storage 서비스 중 하나 분산 구조의 Object 데이터의 저장 스토리지 체계로 구성 빠른 성능 및 대용량 저장공간이 필요 할 때 사용 동영상, 이미지, 디스크 이미지 등의 대용량, 비정형 데이터를 파일과 메타데이터로 저장하여 분산 관리 #\r#\r오브젝트 스토리지 관리 서비스 : Swift\r#\r#\r#\rSwift의 논리 아키텍처\r#\r#\r구성요소 역할 swift-proxy-server 사용자가 서비스를 다루기 위한 REST API 서비스 swift-account-server 계정 정보 및 사용자 정보를 관리하고 각 컨테이너 별 정보를 관리하기 위한 데몬 프로세스 swift-container-server 사용자 게정의 컨테이너를 간리하는 서비스 swift-object-server 실제 데이터를 저장하고 관리하는 서비스 어카운트, 컨테이너는 별도의 메타데이터가 데이터베이스로 관리 오브젝트는 저장 공간에 직접 저장되는 방식으로 구성 swift-proxy-server는 오픈스택의 Object API를 제공 사용자는 API를 사용해 데이터를 사용 #\r#\rSwift의 논리적 구성 요소\r#\r#\rSwift서비스는은 스토리지 공간 여러 개를 합쳐 하나의 커다란 공간으로 가상화하고, 그 안에서 사용자만의 별도 스토리지 공간이 있는 것처럼 다시 가상화\nswift-proxy-server는 스토리지 노드 여러 개를 관리하며 사용자 인증을 담당, 최근에는 Keystone으로 인증을 처리하며, 프록시 서버와 함께 설치\n기본적으로 스토리지 노드에는 swift-account-server, swift,compute-server, swift-object-server가 실행되며 실제 메타데이터파일이나 오브젝트에 해당하는 데이터 파일을 저장\nSwift 역시도 Nova를 구성할 떄와 마찬가지로 스토리지 노드가 여러 호스트로 구성이 가능\n각 스토리지 노드에는 swift-account-server, swift-container-server, swift-object-server가 실행\n서버들은 관리자가 설정한 해당 포트로 서로 통신\n스토리지 노드 중 하나라도 손상이 되면 데이터를 잃지 않도록 데이터 복제(Replica)프로세스가 함께 실행\n#\r#\rSwift Ring\r#\r#\r스토리지 파일은 자신이 관리하는 데이터를 서로 공유하려고 Ring인 파일이 어느 노드에, 어떤 데이터가 들어 있는 지를 인지 이를 확인하기 위해 사용도는 것이 Ring 파일 Ring파일은 프록시 노드에서 생성해 모든 스토리지 노드가 동일하게 소유 Ring 파일에는 디바이스 정보 디바이스를 구분하는 ID 존(Zone) 번호 스토리지 노드 IP 포트 디바이스 이름 디바이스 비중 기타 디바이스 정보 #\r#\rSwift의 데이터 관리 방법\r#\r#\rSwift는 사용자 게정을 관리하는 어카운트, 디렉터리 개념의 컨테이너, 실제 파일을 표현하는 오브젝트로 구성\nSwift는 어카운트가 컨테이너를 포함하고, 컨테이너가 오브젝트를 포함하도록 관리\n기본적으로 Swift에서는 프록시 노드 한 대에 스토리지 노드 다섯 대를 구성하기를 권장\n프록시 노드들은 로드밸런서로 묶여 있어 사용자는 특정 URL 하나만 호출해도 스토리지 서비스를 자유롭게 사용가능\n파일을 올릴 때는 설정된 리플리카로 여러 스토리지 노드로 분산해서 저장, 다운로드 시 그 중 한 곳을 사용\n#\r#\rSwift와 Keystone\r#\r#\rSwift에는 SwAuth를 이용하는 인증 방법과 Keystone을 이용\n최근에는 Keystone을 이용해서 주로 인증하며, Keystone에는 프로젝트, 사용자, 롤이 있음\n관리자(admin, swiftoperator)는 사용자와 컨테이너를 생성, 삭제할 수 있음\n관리자는 오브젝트도 올리기, 내려받기, 삭제를 할 수 있음\n일반 사용자(member)은 사용자와 컨테이너를 생성할 수 없음\n일반 사용자는 관리자가 미리 생성해서 권한을 준 컨테이너만 사용할 수 있음\n일반 사용자는 관리자가 설정한 권한으로 오브젝트 목록을 확인할 수 있음\n일반 사용자는 관리자가 설장한 권한으로 데이터를 올리고 내릴 수 있음\n특정 사용자에게 관리자(admin) 권한을 부여하려면 리셀러어드민(ResellerAdmin) 롤을 주어야 함\n해당 사용자는 관리자가 할 수 있는 기능을 모두 사용할 수 있음\n#\r#\rSwift의 이레이저 코딩(Eraure Coding) 기능과 스토리지 정책\r#\r#\r스토리지 저장 공간을 효율적으로 관리하는 것이 이레이져 코딩\n다양한 물리 스토리지 디바이스를 정책별로 사용할 수 있게 지원하는 스토리지 정책(Storage Policy)기능이 있음\n이레이져 코딩은 HDFS, RAID 외의 스토리지에서 데이터 저장 공간의 효율성을 높이려고 설계된 데이터 복제 방식\n이레이져 코딩은 이레이져 코드를 사용해 데이터를 인코딩하고, 데이터가 손실되면 디코딩 과정을 거쳐 원본 데이터를 복구하는 기법 중 하나\n이레이저 코드와 각 코드마다 사용하는 알고리즘은 다양한데 이런 알고리즘에 Reed-Solom on Code, Tahoe-Lafs, Weaver Code 등이 있음\n스토리지 정책은 여러 오브젝트링을 생성해 다양한 목적으로 클러스터를 세그먼트화 할 수 있음\n수정된 해시링을 통해 클러스터에서 데이터가 있어야 할 위치를 결정\n이레이저 코드를 사용해 콜드 스토리지(Cold Storage: 저전력 스토리지)도 정의 할 수 있음\n#\r"},{"id":38,"href":"/cloud/docs/AWS/AmazonWebService/AWS_Analysis/","title":"AWS Analysis","section":"AWS docs","content":"\rAWS Analysis\r#\r#\rAmazon Athena\r#\r#\r#\rAmazon CloudSearch\r#\r#\r#\rAmazon EMR\r#\r#\r#\rAmazon ES\r#\r#\r#\rAmazon Kinesis\r#\r#\r#\rAmazon QuickSight\r#\r#\r#\rAWS DataPipeline\r#\r#\r#\r"},{"id":39,"href":"/cloud/docs/AWS/AWSTraining/AS/","title":"AWS AutoScaling","section":"AWS Training","content":"\rAWS AutoScaling\r#\r#\r이번 장에서는 CloudComputing의 꽃이라고도 할 수 있는 AutoScaling 서비스를 구축해보겠습니다. AutoSacling의 대한 개념은 AutoScaling을 참조해주세요. #\rAWS AutoScaling ( 이하 As )\r#\r#\r#\rAs 그룹 생성을 위해 AWS에 접속 합니다. 인스턴스를 생성하여, Apache가 자동시작되어있게 설정 후, AMI를 생성합니다. AMI 생성 참고 #\r#\rAMI 생성 후, As 그룹 생성을 위해 좌측의 메뉴에서 Auto Scaling \u0026gt; Auto Scaling 그룹 생성을 클릭합니다. #\r#\rAs그룹에서 시작하기를 클릭합니다. #\r#\r내 AMI에서 생성한 AMI를 선택합니다. #\r#\rAMI 선택이 완료되면 기본적인 시작 구성들을 입력합니다. 보안 그룹을 기존의 80번 포트가 열려있는 보안그룹을 사용했습니다. #\r#\r기본 구성이 완료되면, 바로 As 그룹생성으로 이동됩니다. 그룹 생성에서 위의 그림과 VPC와 서브넷을 설정합니다. 여기서 시작구성에서 선택한 보안그룹과 선택한 보안그룹이 일치하지 않으면 에러가 발생합니다. #\r#\rAs 그룹생성에서 정책을 설정합니다. #\r#\r평균 cpu의 사용이 5분간 30%이상이면 증가하는 정책을 생성합니다. 이와 동일하기 평균 cpu의 사용이 5분간 30%미만이면 삭제되는 정책을 생성합니다. #\r#\r생성이 완료되면 As 보안그룹을 통해 인스턴스의 수, 최소, 최대 용량을 확인할 수 있습니다. #\r#\r인스턴스가 생성된 것을 확인 할 수 있습니다. #\r#\r$ apt -y update $ apt -y install stress $ stress -c 1 이제 As 확인을 위해 stress를 설치 후 작동시킵니다. #\r#\rstress를 실행 후, 설정시간이 경과하면 인스턴스가 증가됨을 확인할 수 있습니다. #\r#\r이와 같이 As를 통해 인스턴스를 정책에 따라 자동적으로 증가\u0026amp; 감소 시키는 것이 가능합니다. 또한 저번 장에서 구축했던 ELB에 As 그룹을 등록하면, 자동적으로 로드 밸런싱을 되어 유동적인 자원관리가 가능해집니다. #\r#\rAWS CLI를 통한 생성\r#\r#\r$ aws autoscaling create-launch-configuration \\ --launch-configuration-name launch-config-sample \\ --image-id [ AMI ID ] \\ --key-name [ key name ] \\ --no-ebs-optimized \\ --instance-type [ instance type ] \\ --instance-monitoring Enabled=true \\ --security-groups [ 보안그룹 ID ] \\ --associate-public-ip-address #\rAs 주요 설정 파라미터\n#\r항목 이름 설명 Auto Sacling Group Name As 그룹명 Launch Configuration As 그룹에서 사용할 Launch Configuration Load Balancers As 그룹에서 사용할 ELB Desired As 그룹조건에 해당하지 않는 일반적인 인스턴스의 수 Min As 그룹에서 사용할 인스턴스의 최솟값 Max As 그룹에서 사용할 인스턴스의 최댓값 Health Check Type As 그룹에서 사용할 헬스 체크 판단 유형 ( EC2 or ELB ) Health Check Period As 그룹의 헬스 체크가 시작될 때 까지의 초 Termination Policies As 그룹에 속한 인스턴스의 삭제방침 Availability Zone As 그룹이 사용할 가용영역 Subnet As 그룹이 사용할 서브넷 Default Cooldown 스케일링 처리 후에 새로운 스케일링 처리를 받을 때 까지의 시간 Placemenet Group 낮은 레이턴시 ( Latency ) 환경과 논 블로킹 통신이 가능한 Placement Group을 선택 Suspended Processes 처리를 일시적으로 정지시킬 프로세스 목록 ( AWS CLI의 suspend-processes 명령어로 설정 ) Enabled Metrics CloudWatch 에서 활성화 되어 있는 매트릭스 목록 #\r#\rScaling Policy 유형\n#\r유형 설명 ChangelnCapacity 그룹의 현재 용량을 지정한 수의 인스턴스만큼 늘리거나 줄입니다. ExactCapacity 그룹의 현재 용량을 지정된 수의 인스턴스로 변경합니다. PercentChangelnCapacity 그룹의 현재 용량을 지정된 비율만큼 늘리거나 줄입니다. #\r#\rScaling Policy의 주요 파라미터\n#\r항목 이름 설명 Scaling policy Name 이름 지정 Execute policy when 실행할 조건 ( CloudWatch의 Alram으로 설정 ) Take the action Auto Scaling Group의 목표 인스턴스 수를 설정 And than wait 다른 스케일링 처리가 실행되고 있을 때 대기할 시간 "},{"id":40,"href":"/cloud/docs/AWS/AWSTraining/RDS/","title":"AWS RDS 생성","section":"AWS Training","content":"\rAWS RDS 생성\r#\r#\rAWS RDS는 우리가 흔히 아는 Database ( Oracle db, Mysql, MariaDB )와 동일한 역할을 수행하지만, 보다 편리하고 안전하게 관리가 가능합니다. AWS RDS는 중요한 개념이므로, RDS에 대한 개념이 학습이 필요한 들은 AWS RDS를 참고해주세요. #\rAWS RDS 생성\r#\r#\r#\r먼저, RDS의 생성을 위해 AWS의 접속하여 RDS를 검색 후 클릭합니다. #\r#\r데이터베이스 생성 -\u0026gt; 데이터베이스 생성을 클릭합니다. #\r#\r여러 DB와 옵션을 사용할 수 있지만, 여기에서는 프리 티어 내에서 사용할 수 있도록 성정하도록 하겠습니다. 프리 티어의 체크 및 MySQL을 선택합니다. #\r#\rRDS도 원리는 인스턴스에 DB가 설치된 것으로, CPU와 RAM이 존재합니다. DB 엔진 버전 : DB의 버전을 설정하는 옵션입니다. DB 인스턴스 클래스 : DB 인스턴스의 타입을 설정하는 옵션입니다. 다중 AZ 배포 : 서로 다른 가용영역에 배포하는 옵션 입니다. 스토리지 자동 조정 : DB의 용량이 할당된 용량을 초과하면, 자동적으로 스토리지의 량이 증가하게 할 수 있는 옵션입니다. DB 인스턴스 식별자 : RDS의 이름입니다. 마스터 사용자 이름 : RDS 접속 시 사용할 사용자입니다. #\r#\r네트워크 및 보안 설정에서는 RDS가 생성될 VPC와 Subnet 및 퍼블릭 엑세스가 가능하게 할지 결정할 수 있습니다. 보안그룹은 기존 보안그룹을 사용해도 되지만, 여기서는 새로운 VPC 보안 그룹을 만들어 사용하겠습니다. #\r#\rRDS 내의 DB의 이름 및 포트, 파라미터 그룹 등을 설정합니다. #\r#\rRDS를 자동 백업 및 스냅샷에 대한 설정입니다. 읽기 복제본을 위해서는 설정이 되어있어야 합니다. #\r#\r모니터링 서비스 및 발신 로그 유형을 선택합니다. 여기서는 선택하지 않습니다. #\r#\rRDS의 유지관리 및 삭제방지의 대한 설정입니다. RDS는 자동적으로 업데이트가 가능하고, 삭제 방지의 대한 설정이 가능합니다. #\r#\rRDS의 생성이 완료되면 RDS \u0026gt; 데이터베이스에서 확인이 가능합니다. #\r#\rRDS에 접속을 위해 생성한 RDS를 클릭하여 연결\u0026amp;보인 \u0026gt; 보안그룹을 클릭하여 수정하겠습니다. #\r#\r인 바운드 규칙을 그림과 같이 수정합니다. 혹은 접속한 동일 VPC의 서브넷의 IP대역으로 수정도 가능합니다. #\r#\r이제 다시 RDS에 돌아와 파라미터 그룹을 생성 하겠습니다. 파라미터 그룹을 생성하는 그본 파라미터 그룹을 사용하면 한글 사용시 에러가 발생하기 때문입니다. 그림과 같이 파라미터 그룹 \u0026gt; 파라미터 그룹 생성을 클릭합니다. #\r#\r파라미터 그룹을 생성합니다. #\r#\r파라미터 그룹을 수정하기 위해 생성한 파라미터 그룹을 클릭 후, 편집을 진행합니다. #\r#\rcharcter을 검색 후, character-set-client-handshake, skip-character-set-client-handshake, validate_password_special_char_count를 제외한 모든 값을 utf8로 설정합니다. charcter과 동일하게 collation을 검색 후, collation_connection, collation_server의 값을 utf8_unicode-ci로 설정합니다. #\r#\r파라미터 그룹이 생성되면, 다시 데이터베이스로 돌아와 수정을 클릭합니다. #\r#\r데이터베이스 옵션에서 DB 파라미터 그룹을 생성한 파라미터 그룹으로 수정합니다. #\r#\r즉시 적용을 선택합니다. #\r#\rRDS가 수정중임을 확인할 수 있습니다. #\r#\r수정이 완료되면, 생성한 RDS를 클릭하여 연결\u0026amp;보안에서 엔드포인트를 확인합니다. #\r#\r$ apt -y install mysql-client 이후 동일한 VPC 내에서 인스턴스를 하나 생성해 mysql-client를 설치 후 접속을 진행합니다. mysql -u [ 생성시의 마스터 이름 ] -p -h [ RDS의 엔드포인트 ]를 통해 접속을 진행합니다. RDS 생성시에 설정한 DB로 접속이 가능함을 확인할 수 있습니다. #\r$ mysql\u0026gt; show variables like \u0026#39;c%\u0026#39;; # Variable 확인 $ mysql\u0026gt; set session [ Variable_name ]=[ 변경 값 ] # Variable 변경 #\r위 처럼 직접변경 또한 가능합니다. #\r이것으로 기본적인 RDS에 대한 생성을 마치겠습니다. #\r"},{"id":41,"href":"/cloud/docs/OpenStack/OpenStack/Heat/","title":"Heat","section":"OpenStack docs","content":"\r오케스트레이션 서비스 : Heat\r#\r#\rHeat\r#\r#\rHeat는 탬블릿과 Stack을 사용하여 자동으로 인스턴스의 리소스를 추가하거나 줄이는 서비스 오케스트레이션은 자원 관리, 배치, 정렬을 자동화하는 것 오케스트레이션은 인스턴스 생성에 대한 일련의 과정을 자동화해서 인프라를 쉽게 배포할 수 있도록 하는 탬플릿 기반 엔진 오케스트레이션에서 사용되는 템플릿 언어는 인프라, 서비스, 응용프로그램, 프로비저닝, 자동화 컴퓨팅, 스토리지, 네트워킹, 자동 스케일링 등에 사용 가능 #\rHeat의 논리 아키텍처\r#\r#\r#\r구성요소 역할 heat-api RPC heat 엔진에 전송해서 요청된 API를 처리한 REST API를 제공 heat-api-cfn AWS CloudFormation과 호환되는 AWS 타입의 Query API를 제공 heat-engine 템플릿을 생성하고, Consumer(API를 사용하려고 접근하는 애플리케이션이나 서비스)를 다시 이벤트로 제공하는 오케스트레이션의 주 작업을 수행 queue 각 서비스들이 통신을 하기 위한 서비스 #\r"},{"id":42,"href":"/cloud/docs/AWS/AWSTraining/3Tier/","title":"AWS 3Tier 구현","section":"AWS Training","content":"\r****\r#\r#\r****\r#\r#\r#\r예제 1.\r#\r다음의 인스턴스를 생성해보세요.\r#\r예제 1. 답안\r↕\r사용자 계정을 생성할 시, 엑세스 유형에서 프로그래밍 방식 엑세스만을 선택합니다. 정책에서 admin의 권한을 선택 후 생성합니다. "},{"id":43,"href":"/cloud/docs/Azure/AzureTraining/Azure00/","title":"Az-900 : CloudComputing","section":"Azure Training","content":"\rAz-900 : CloudComputing\r#\r#\r클라우드 컴퓨팅\r#\r#\r클라우드 컴퓨팅은 스토리지 공간이나 CPU 주기와 같은 리소스를 다른 회사의 컴퓨터에 대여하는 서비스이며 사용한 만큼의 요금만을 지불합니다.\n클라우드 공급 기업은 작업을 싱행하는 데 필요한 실제 하드웨어와 이 하드웨어를 최신 상태로 유지할 책임이 존재하며, 제공되는 컴퓨팅 서비스는 클라우드 공급자에 따라 달라지며, 일반적으로는 하단의 항목이 기본적으로 포함됩니다.\n#\rCompute power : 리눅스 서버나 웹 프로그램\nStorage : 저장 및 데이터베이스 역할\nNetworking : 클라우드 제공사와 우리 회사의 사이의 안전한 연결\nAnalytics : 이치 혹은 성능 데이터를 시각화\n#\r#\r클라우드 컴퓨팅 서비스\r#\r#\r클라우드 컴퓨팅의 목적은 소규모 신생 기업이든 대기업이든 상관없이 비즈니스를 보다 쉽고 효율적으로 운영할 수 있도록 만드는 것으로, 이러한 요구를 충족시키기 위해 클라우드 컴퓨팅 공급자는 광범위한 서비스를 제공합니다. #\r#\r컴퓨팅 기능\r#\r#\r이메일을 보내거나, 인터넷에서 예약을 하거나, 온라인으로 지불을 하거나, 심지어 Microsoft 학습 모듈을 사용할 때도 각 요청을 처리하고 응답을 반환하는 클아우드 기반 서버와 상호작용하게 되며, 기본적으로 인터넷을 구성하는 다양한 클라우드 공급 기업이 제공하는 컴퓨팅 서비스를 사용합니다.\n클라우드 컴퓨팅을 사용하여 솔루션을 빌드하는 경우 리소스 및 요구 사항에 따라 작업을 수행하는 방법을 선택할 수 있습니다.\n여기에서 컴퓨팅 기능의 종류에는 기본적으로 VM, 컨테이너, 서버리스 컴퓨팅으로 분리할 수 있습니다.\n#\rVM\nVM은 클라우드 기업의 물리적 서버에서 가상 머신을 생성하여 해당 서버를 직접 사용하여 생성하는 서비스입니다. #\r컨테이너\n컨테이너는 애플리케이션에 일관적이고 격리된 실행 환경을 제공하며, 게스트 운영체제가 필요하지 않은 점에서는 VM과 흡사하지만, 대신 애플리케이션과 몯느 해당 종속성이 컨테이너에 패키지된 다음, 표준 런타임 환경이 앱을 실행하는 데 사용됩니다.\n기본적으로 VM과의 가장 큰 차이는 운영체제의 유무에 대한 차이입니다.\n#\r서버리스 컴퓨팅\n서버리스 컴퓨팅은 서버를 생성, 구성, 유지관리하지 않고 애플리케이션 코드를 실행하는 것이 가능합니다.\n서버리스 컴퓨팅의 핵심개념은 애플리케이션이 일부 작업에 의해 트리거될 때 실행되는 별도의 기능으로 분리된다는 점이며, 이는 자동화 작업에 이상적입니다.\n서버리스 모델은 기본적으로 사용하는 처리 시간에 대해서만 페이를 지불한다는 점에서 VM과 컨테이너와 성격이 다릅니다.\n#\r컴퓨팅 서비스 비교 다이어그램 #\r#\r스토리지\r#\r#\r대부분의 디바이스 및 애플리케이션은 데이터를 읽고 사용합니다. 이러한 모든 경우의 데이터는 데이터를 읽거나, 쓰여지며 이에 딸느 데이터이 유형 및 저장방식은 경우의 마다 다를 수 있습니다.\n일반적으로 클라우드 공급자는 이러한 모든 유형의 데이터를 처리할 수 있는 서비스를 제공하며, 클라우드 기반 데이터 스토리지는 사용자의 요구 사항에 맞게 확장할 수 있다는 장점이 있습니다.\n예를 들면 자동적으로 저장공간을 확장 및 줄일 수 있으며 백업 파일을 저장할 수도 있습니다.\n#\r#\r왜 클라우드 서비스인가? (클라우드 컴퓨팅의 혜택)\r#\r#\r기본적으로 클라우드 서비스를 사용하는 것은 기존 비즈니스의 인프라 및 관리 비용을 점가하기 위해 사용하지만, 이는 순전히 선택사항입니다. 하단은 클라우드 서비스를 사용하는 이점을 나타냅니다. #\r#\r비용효과적\n클라우드 컴퓨팅은 종량제 또는 사용량 기반 가격 책정 모델을 제공합니다.\n즉, 선불 인프라 비용이 없으며, 사용하지 않는 경우 비용이 청구되지 않아 비용을 절약할 수 있습니다.\n#\r확장가능\n주말과 같은 특정 시간의 수요 또는 워크로드에 따라 사용되는 리소스와 서비스를 늘리거나 줄일 수 있습니다.\n클라우드 서비스는 수직적, 수평적 크기 조정을 둘다 지원하며 수직적 크기 조정은 Scale UP, 수평적 크기 조정은 Scale OUT이라 합니다.\nScale UP은 한 서버에 리소스 추가시키는 것을 의미하며, Scale OUT은 서버를 여러 대 생성하여 트래픽을 분산시키는 것을 의미합니다.\n이와 같은 기능들을 자동적으로 수행됩니다.\n#\r탄력적\n수요 급증 또는 급감으로 인해 워크로드가 변경되면 클라우드 컴퓨팅 시스템은 자동으로 리소스를 추가하거나 제거하여 보정이 가능합니다. #\r최신상태\n클라우드를 사용하면 애플리케이션을 빌드하고 배포하는 중요한 작업에 집중할 수 있습니다. 클라우드를 사용하면 소프트웨어 패치, 하드웨어 설치, 업그레이드 및 기타 IT 관리 작업을 유지 관리해야하는 부담을 줄일 수 있습니다. #\r안정적\n클라우드는 컴퓨팅 공급자가 안정적으로 데이터를 유지할 수 있도록 백업, 재해 복구 및 데이터 복제 서비스를 제공하며, 장애가 발생하면 백업 구성 요소가 댓니 사용되며, 이를 내결함성이라 합니다. #\r전 세계 어디서든 사용가능\n클라우드 공급 기업은 전 세계의 다양한 지역에 완벽하게 증복된 데이터 센터를 갖추고 있으며, 이로 가능한 최적의 응답 시간을 제공할 수 있습니다. #\r안전함\n클라우드 공급자는 대부분의 조직에서 달성할 수 있는 것보다 더 낭느 보안을 제공할 수 있는 광범위한 정책, 기술, 제어 및 전문 기술을 제공합니다. #\r이를 온-프레미스의 환경과 비교해보면 하단의 장점들을 가지고 있습니다.\n온-프레미스 환경은 고정비용이지만 퍼블릭 환경은 유동적으로 비용우위를 가질 수 있다.\n온-프레미스 환경에서는 테스트 서버의 세팅에 많은 시간이 걸리지만, 퍼블릭 환경에서는 빠른 시간 내에 세팅이 가능한 생산성의 우위를 가질 수 있다.\n이미 퍼블릭환경에서는 패키지로 플랫폼을 제공하기 때문에 직접 설치할 필요가 없어 진입장벽이 온-프레미스 환경에 비해서 낮다.\n#\r이와 같이 Azure는 여러 규정 준수 조건 및 요구 사항을 각 나라의 맞춰 설계되어있습니다.\n규정 준수 참조\n#\r#\r클라우드 컴퓨팅의 주요 개념 및 용어\r#\r#\r위와 같이 클라우드 컴퓨팅의 가장 큰 특징은 탄력적이라는 면에 있으며, 과거 보안적인 문제도 점차 해결되어 가고 있습니다.\n하단의 개념들은 현재 클라우드 컴퓨팅의 핵심이 되는 개념들을 나열한 것입니다.\n#\r내결함성 (Fault tolerance) : 특정 문제가 발생시에 에러를 복구하는 정도 #\r고 가용성 (High availability) : 문제가 발생시에도 적은 다운타임으로 서비스를 제공할 수 있는 개념 #\r재해 복구 (Disaster recovery) : 물리적으로 자연재해의 영향을 미치지 않는 장소에 서비스에 영향을 주지 않도록 구성하는 개념 #\r확장성 (Scalability) : 서비스의 추가 자원이 필요할 시 보다 쉽게 자원을 추가하여 서비스를 제공할 수 있는 개념 #\r민첩성 (Agility) : 특정 서비스의 필요 자원에 따라 자원을 추가\u0026amp; 감소를 빠른 속도로 이루는 개념 #\r탄력성 (Elasticity) : 확장성과 비슷하다 할 수 있지만, 확장성과의 차이는 여유분의 자원이 남는 서비스의 자원을 수축하여 자원을 효율적으로 관리할 수 있는 개념 #\r글로벌 지원(Global reach) : 해외의 데이터 센터들을 활용하여 해외의 서비스를 제공할 수 있다는 개념 #\r응답 속도(Customer latency) : 해외의 여러 엔드 유저들에게도 적절한 리소스를 배치시켜 빠른 속도로 서비스를 제공해 줄 수 있는 개념 #\r예측 비용(Predictive cost): 클라우드는 기본적으로 사용한 만큼의 과금할 수 있는 구조로 이루어져있어, 적절하게 비용의 에측이 가능하다는 개념 #\r보안 (Security) : 각 나라의 지역적인 규제나 정책, 준수사항 등을 만족하도록 구현한다는 개념 #\r#\r규모의 경제\r#\r#\r규모 경제의 개념은 작은 규모로 운영하는 것에 비해 큰 규모로 운용할 때 효율적으로 작업을 수행할 수 있는 능력을 제공하는 개념입니다.\n클라우드는 큰 규모로 진행하기에, 낮은 비용 대비 고효율의 제공이 가능하는 것이 가능합니다.\n#\r#\rCapEx vs OpEx\r#\r#\r자본 지출 : Capital Expenditure (CapEx)\n물리적 인프라에 대한 지출을 선불로 지불\n시간이 지남에 따라 세금 계산서에서 비용을 공제\n높은 초기 비용, 투자 가치는 시간이 지남에 따라 감소\n기본적으로 일반적으로 CapEx 온-프레미스 데이터 센터에는 다음과 같은 비용이 포합됩니다.\n서버 비용\n스토리지 비용\n네트워크 비용\n백업 및 보관 비용\n조직 연속성 및 재해 복구 비용\n데이터 센터 인프라 비용\n기술 인력\nOpEx 클라우드 컴퓨팅 비용\n임대 소프트에어 및 사용자 지정된 기능\n고정 하드웨어나 용량 대신 사용/ 수요에 따라 요금을 조정\n사용자 또는 조직 수준의 청구\n이와 같이 CapEx는 시작 단계에서 비용을 계획하기 때문에, 제한된 예산으로 인해 프로젝트를 시작하기 전에 비용을 예측해야 하는 경우에 유용합니다.\n#\r운영 비용: Operational Expenditure (OpEx)\n수요의 따른 시간, 비용 그래프 CapEx와 달리 초기 비용이 아닌, 필요에 따라 서비스 또는 제품에 지출되고 즉시 청구\n같은 해에 세금 계산서에서 비용을 제공\n선 결제 비용이 없고, 종량제 사용\n#\r#\r클라우드의 소비 기반 모델\r#\r#\r소비 기반 모델 : Consumption-based model\n선 결제 비용이 존재하지 않음\n비용이 많은 드는 인프라를 구매하고 관리할 필요가 없음음\n필요할 시에만 사용하며, 필요하지 않으면 서비스를 중지할 수 있음\n#\r#\r클라우드 서비스의 종류\r#\r#\r퍼블릭 클라우드\r#\r#\r클라우드 서비스 또는 호스팅 공급자가 소유\n여러 조직과 사용자에게 리소스와 서비스를 제공\n보안 네트워크 연결을 통해 접근 (일반적으로 인터넷으르 통해 접근)\n중요한 데이터 등의 대한 관리문제가 존재할 수 있음\n특징\nCapEx 없음\n응용 프로그램에 빠르게 엑세스가 가능한 민첩성을 가질 수 있음\n클라우드 공급자가 일정 부분의 책임을 짐\n소비 기반 모델\n제한적인 요소로 인해클라이언트의 요구사항을 충족할 수 없는 경우가 발생할 수 있음\n완전 자유롭게 관리하는 것이 사실상 불가능\n#\r#\r프라이빗 클라우드\r#\r#\r클라우드 리소스를 사용하는 조직이 소유 및 운영을 관리\n조직은 자신들만의 데이터 센터에 클라우드 환경을 구축\n조직에게 본인들이 제공하는 서비스를 운영할 책이 존재\n특징\n제어력\n보안\n초기의 CapEx 비용이 존재하며, 유지 관리를 위해 하드웨어를 추가구매할 경우가 발생\n추가구매로 인한 민첩성이 제한을 받음\n프라이빗 클라우드는 기본적으로 전문적인 IT 기술 및 전문 지식이 필요\n#\r#\r하이브리드 클라우드\r#\r#\r공용 및 사설 클라우드를 결합하여 응용 프로그램이 가장 적합한 위치에서 실행되도록 하는 클라우드 서비스\n비용적인 측면에서는 높을 수 있음\n특징\n유동성\n준수성\n설정 및 관리가 복잡해질 수 있으며 전문적인 인재가 필요\n#\r#\r클라우드 서비스의 유형\r#\r#\r공동 관리 책임 (Shared responsibility model) #\r공동 관리 책임의 범위\r#\r#\r#\rOn Premises\r#\r온-프레미스는 모든 책임을 사용자가 가짐\n이아스는 네트워킹, 스토리지, 컴퓨팅 외에는 모든 책임을 사용자가 가짐\nPaaS\n사스는 대부분 클라우드 벤더에서 책임을 지며 데이터와 접근권한만을 책임을 가짐\n#\r#\rInfrastructure as a Server (IaaS)\r#\r#\r가장 기본적인 클라우드 컴퓨텅 서비스의 범주 (흔히 우리가 아는 Vm)\n클라우드 공급자로부터 가상머신, 스토리지, 네트워크 및 운영 체제를 대여\n네트워크를 통해 프로비저닝 받는 서비스\n#\r#\rPlatform as a Server (PaaS)\r#\r#\r소프트웨어 응용 프로그램을 개발, 테스트 미 배포하기 위한 환경을 제공하는 서비스\n기본적으로 개발환경과 비슷하며 인프라 관리에 신경쓰지 않고, 응용 프로그램을 신속하게 만들 수 있도록 제공하는 서비스\n#\r#\rSoftware as a Server (SaaS)\r#\r#\r최종 사용자를 위해 중앙에서 호스팅 되고 관리되는 소프트웨어\n인터넷을 통해 클라우드 기반 앱에 연결하여 사용\n#\r#\r각 클라우드 유형의 특징\r#\r#\rIaaS(유동성)\nIaaS는 가장 유연한 클라우드 서비스\n애플리케이션을 실행하는 운영체제를 구성하고 관리할 수 있는 제어력을 가지고 있음\n#\rPaaS(생산성)\n사용자는 응용 프로글매 개발에만 집중할 수 있음\n플랫폼 관리는 클라우드 공급자가 처리\n#\rSaaS(종량제)\n사용자는 자신의 서비스에서 사용하는 소프트웨어에 대한 비용만 지불 #\r"},{"id":44,"href":"/cloud/docs/Azure/MicrosoftAzure/Azure00/","title":"Azure Computing","section":"Azure docs","content":"\rAzure Computing\r#\r#\rAzure Computing은 클라우드 기반의 애플리케이션을 실행하기 이한 주문형 컴퓨팅 서비스로 가상 머신 및 컨테이너를 통해 멀티 코어 프로세서, 슈퍼 컴퓨팅 리소스를 제공합니다.\nAzure Computing은 애플리케이션 및 서비스를 호스팅하는 다양한 옵션을 제공합니다.\n#\r#\rAzure Virtual Machines\r#\r#\r#\r가상 머신 또는 VM은 무리적 컴퓨터의 소프트웨어 에뮬레이션입니다.\nVM에는 가상 프로세서, 메모리, 스토리지 및 네트워킹 리소스가 포함됩니다.\n#\r#\rAzure Virtual Machine Scale Sets\r#\r#\rAzure에서 호스팅되는 Windows 또는 Linux VM의 크기 조정 서비스로 부하 분사된 동일한 가상 머신 그룹을 만들고 관리할 수 있습니다.\nScale Sets를 사용하면 몇 분 안에 많은 수의 가상 머신을 중앙에서 관리, 구성 및 업데이트 하므로 고가용성 애플리케이션을 제공할 수 있습니다.\n#\r#\rAzure Kubernetes Service\r#\r#\r컨테이너화된 서비스를 실행하는 VM 클러스터 관리를 사용하도록 설정 #\r#\rAzure Service Fabric\r#\r분산형 시스템 플랫폼. Azure 또는 온-프레미스에서 실행 #\r#\rAzure Batch\r#\r#\rAzure Batch를 통해 수십, 수백 또는 수천 개의 가상 머신으로 확장할 수 있을 뿐 아니라 대규모 작업을 예약하고 컴퓨팅을 관리하는 서비스 입니다.\n병렬 및 고성능 컴퓨팅 애플리케이션을 위한 관리 서비스\n#\r#\rAzure Container Instances\r#\r#\r애플리케이션을 실행하기 위한 사상화 환경으로, 컨테이너는 가상 머신과 마찬가지로 호스트 운영 체제에서 실행됩니다.\n하지만 서버 또는 VM을 프로비저닝하지 않고 Azure에서 컨테이너화된 앱 실행하며 기존 호스트 OS를 사용하는 데 필요한 라이브러리와 구성 요소를 포함합니다.\n#\r#\rAzure Functions\r#\r#\r이벤트 기반의 서버리스 컴퓨팅 서비스로 클라우드에 호스트된 실행 환경이지만, 기본 호스팅 환경을 완전히 추상화합니다.\n가장 큰 특징으로는 인프라 구성 또는 유지 관리가 필요하지 않거나 허용되지 않습니다.\n#\r#\rAzure App Service\r#\r#\rAzure App Service를 사용하면 인프라를 관리할 필요 없이 원하는 프로그래밍 언어로 웹앱, 백그라운드 작업, 모바일 백 엔드 및 RESTful API를 빌드하고 호스트할 수 있습니다. #\r"},{"id":45,"href":"/cloud/docs/OpenStack/OpenStack/","title":"OpenStack docs","section":"OPENSTACK","content":"\rOpenStack\nOpenStack의 개요\nKeyston : 인증을 관리하는 서비스\nGlance : 이미지를 관리하는 서비스\nNova : 가상의 서버를 생성하는 서비스\nNeutron : 네트워크를 관리하는 서비스\nCinder : 블록 스토리지 서비스\nCeilometer : 리소스의 사용량과 부하를 관리하는 서비스\nHorizon : 외부 인터페이스 대시보드 서비스\nSwift : 오브젝트 스토리지 관리 서비스\nHeat : 오케트스트레션 서비스\nTrove : 데이터베이스 서비스\nSahara : 데이터 프로세싱 서비스\nIronic : 베어메탈 서비스\n#\r#\rOpenStack Training\nOpenStack Ussuri\nOpenStack Ussuri : Overview\nOpenStack Ussuri : 환경설정\nOpenStack Ussuri : Keystone\nOpenStack Ussuri : Glance\nOpenStack Ussuri : Nova\nOpenStack Ussuri : Neutron\nOpenStack Ussuri : Cinder\nOpenStack Ussuri : Horizon\nOpenStack Ussuri : Swift\nOpenStack Ussuri : Heat\nOpenStack Ussuri : Gnocch\nOpenStack Ussuri : Trove\nOpenStack Ussuri : Designate\nOpenStack Ussuri : Brabican\nOpenStack Ussuri : Rally\nOpenStack Ussuri : Manila\n#\rOpenStack Stain #\rDevStack #\rPackStack #\r#\r"},{"id":46,"href":"/cloud/docs/AWS/AWSTraining/S3/","title":"AWS S3 생성","section":"AWS Training","content":"\rAWS S3 생성\r#\r#\r이번 장에서는 S3를 생성해보도록 하겠습니다. S3 또한 중요한 개념이니, S3에 대한 학습을 원하는 분들은 AWS S3를 참조해주세요. #\rAWS S3 생성\r#\r#\r#\rAWS 서비스에서 S3를 검색합니다. #\r#\r버킷 생성을 클릭합니다. #\r#\r버킷의 이름과 리전을 선택합니다. 참고로 S3는 VPC에 영향을 받지 않습니다. #\r#\r옵션을 선택합니다. 여기서는 기본 값으로 생성을 진행합니다. #\r#\rS3에 대한 권한을 설정합니다. 기본적으로 차단되어 있는 것이 좋으며, 경우에 따라 설정 값을 변경합니다. #\r#\r생성이 완료되면 버킷을 클릭합니다. #\r#\r버킷을 클릭한 후, IMG 폴더를 생성합니다. #\r#\rIMG 폴더로 진입하여 jpg 이미지 파일을 업로드 합니다. #\r#\r이미지 파일을 선택하면 다운로드 링크, URL 링크를 확인할 수 있습니다. 여기에서는 URL 링크로 진입하여 보겠습니다. #\r#\r링크로 진입하여도, 그림이 나타나지 않습니다. 이는 초기 버킷을 생성할 때, 퍼블릭 엑세스를 차단하였기 때문입니다. #\r#\r이에 대한 수정을 위해 버킷에서 퍼블렉 엑세스 설정을 편집을 클릭합니다. #\r#\r퍼블릭 엑세스 차단을 해제 후 저장합니다. #\r#\r다시 파일을 선택하여 퍼블릭 설정을 클릭합니다. #\r#\rURL로 접속하면 이미지가 나타납니다. #\r#\r#\rCLI S3 생성\r#\r#\r#\r$ aws s3 help $ aws s3api help s3에 대한 명령어를 출력합니다. #\r#\r$ aws s3 mb s3://[ 버킷 이름 ] 버킷을 생성합니다. #\r#\r$ aws s3 ls $ aws s3 ls s3://[ 버킷 이름 ]/path 버킷 및 폴더를 나열합니다. #\r#\r$ aws s3 rb s3://[ 버킷 이름 ] $ aws s3 rb s3://[ 버킷 이름 ] --force 버킷을 삭제합니다. #\r#\r$ aws s3 cp file.txt s3://my-bucket/ --grants [ 권한 ] #\r#\r$ aws s3 sync [ local path ] s3://[ bucket path ]/[ path ] [ local path ]에서 [ bucket ]의 [ path ]에 모든 것을 Pull ( 다운로드 ) 합니다. #\r#\r$ aws s3 sync s3://[ bucket path ]/[ path ] [ local path ] [ local path ]에서 [ bucket ]의 [ path ]에 모든 것을 Push ( 업로드 ) 합니다. #\r#\r"},{"id":47,"href":"/cloud/docs/Azure/AzureTraining/Azure01/","title":"Az-900 : Region","section":"Azure Training","content":"\rAzure 글로벌 인프라 아키텍처\r#\r#\rMicrosoft Geography\r#\r#\r#\rAzure는 전 세계를 지정학적 경계 또는 국가 경계로 정의되는 지리적 위치로 분할합니다.\nAzure Geography란 일반적으로 데이터 상주성 및 규정 준수 경계를 유지하는 두 개 이상의 Azure 지역을 포함하고 있는 별도의 시장을 의미합니다.\nAzure Geography을 사용하면 아래와 같은 이점을 가질 수 있습니다.\n지리적 위치를 통해 특정 데이터 상주성 및 규정 준수 요구 사항이 있는 고객은 데이터와 애플리케이션을 가깝게 유지할 수 있습니다.\n지리적 위치는 지리적 경계 내에서 데이터 상주성, 주권, 규정 준수 및 복원력 요구 사항이 지켜지도록 보장합니다.\n지리적 위치는 전용 대용량 네트워킹 인프라 전체에 걸쳐 발생하는 Azure 지역 전체 장애를 견디는 내결함성을 갖고 있습니다.\nAzure의 Geography는 아래와 같이 4개로 분류됩니다.\n아메리카\n유럽\n아시아 태평양\n중동 및 아프리카\n#\r#\rAzure Region\r#\r#\r#\rAzure Region은 서로 가까운 곳에 있고 대기 시간이 짧은 네트워크를 통해 연결된 데이터 센터를 하나 이상 포함하고 있는 지리적 영역을 의미합니다.\nAzure는 전 셰계에 위차한 데이터 센터로 구성\n최소 한 개 이상의 데이터 센터를 포함\n데이터 센터는 서로 근접한 위치에 있어 네트워크의 대기 시간이 짧은 특징을 가짐\nRegion은 각 지역에 맞는 Geography에 구성됩니다.\n#\rRegion Pairs #\r각 Azure 지역은 300마일 이상 떨어져 있는 동일한 지리적 위치(예: 미국, 유럽 또는 아시아) 내의 다른 Azure 지역과 항상 쌍을 이룹니다.\nRegion Pairs를 통해 한 지리적 위치에서 가상 머신 스토리지 같은 리소스를 복제할 수 있으며, 이렇게 하면 두 Azure 지역에 동시에 영향을 주는 자연재해, 내전, 정전 또는 물리적 네트워크 중단 등의 이벤트 때문에 서비스가 중단될 가능성을 줄일 수 있습니다.\n각 Azure region은 다른 region과 페어링 연결되어 있습니다.\n특정 서비스는 paired region 사이의 자동 복제기능을 제공\nregion 장애 시, paired 된 리전을 복제하는 것이 우선시 되어짐\n#\r특수 Azure Region\nUS DoD 중부, US Gov 버지니아, US Gov 아이오와 등 : 미국 정부 기관 및 파트너를 위한 물리적 및 논리적 네트워크로 격리된 Azure 인스턴스입니다. 이러한 데이터 센터는 선별된 미국인이 운영하며 추가 규정 준수 인증서를 포함하고 있습니다.\n중국 동부, 중국 북부 등 : 이러한 지역은 Microsoft 및 21Vianet 간의 고유한 파트너십을 통해 사용할 수 있으며, Microsoft에서 데이터 센터를 직접 관리하지 않습니다.\n#\rRegion을 사용하는 이유\n보다 쉽게 확장이 가능하게 하는 확장성\n한 리전에 문제가 발생시 다른 리전에서 서비스가 가능토록 하는 가용성\n한국 중부, 한국 남부는 짝꿍 리전으로 한 리전이 오류가 발생 시 다른 리전에서 대신 서비스하도록 설정되어 있음\n#\r#\r가용성 옵션 ( Availability Options )\r#\r#\r#\r가용성 영역은 Azure 지역 내에서 물리적으로 분리된 데이터 센터입니다.\nVm을 나눠서 생성함으로써, 끊어지지 않는 연속적인 서비스가 가능토록 하는 개념\n프로미엄 스토리지를 사용하면 99.9%의 연결성을 보장해주지만, 일반적인 경우에는 가용성 집합 혹은 가용성 영역을 생성하는 것이 권장되어짐\n#\r가용성 집합 (Availability sets)\n유지 관리 혹은 하드웨어 오류 발생 시에도 응용 프로그램을 온라인 상태로 유지하는 서비스\nUpdate domains (US) : 예약된 유지관리, 성능 또는 보안 업데이트는 업데이트 도메인을 통해 순서가 정해짐\nFault domains (FD) : 데이터 센터 내에서 여러 하드웨어서 워크로드르 물리적으로 분\n#\r가용성 영역 ( Availability zones )\nAzure Region 내에서의 물리적으로 분리된 영역\n가용성 영역보다 한 단게 확장된 개념\n하나 혹은 이상의 데이터센터로 구성되고 독립된 전원, 쿨링, 네트워크를 가짐\n독립된 영역으로 동작\n#\r#\rAzure SLA (서비스 수준 계약)\r#\r#\rMicrosoft는 포괄적인 운영 정책, 표준 및 관례를 준수함으로써 고객에게 우수한 품질의 제품 및 서비스를 제공하기 위해 최선을 다하고 있습니다.\nAzure 제품 및 서비스의 SLA는 세 가지 주요 특징을 가지고 있습니다.\n#\r성능 목표\nSLA는 Azure 제품 또는 서비스의 성능 목표를 정의합니다. SLA가 정의하는 성능 목표는 각 Azure 제품 및 서비스로 한정됩니다. 예를 들어 일부 Azure 서비스의 성능 목표는 작동 시간 보증 또는 연결률로 표현됩니다. #\r작동 시간 및 연결 보증\n- **일반적인 SLA는 해당하는 각 Azure 제품 또는 서비스의 성능 목표 약정을 99.9%(\u0026quot;3개의 9\u0026quot;)에서 99.999%(\u0026quot;5개의 9\u0026quot;) 사이에서 지정합니다. 이러한 목표는 서비스의 작동 시간 또는 응답 시간 같은 성능 기준에 적용할 수 있습니다.**\r- SLA % |\t주간 가동 중지 | 시간\t월간 가동 중지 시간 |\t연간 가동 중지 시간\r\u0026mdash; | \u0026mdash; | \u0026mdash; | \u0026mdash; 99 | 1.68시간 | 7.2시간 | 3.65일 99.9 | 10.1분 | 43.2분 | 8.76시간 99.95 | 5분 | 21.6분 | 4.38시간 99.99 | 1.01분 | 4.32분 | 52.56분 99.999 | 6초 | 25.9초 | 5.26분\n#\r서비스 크레딧\n또한 SLA는 Azure 제품 또는 서비스가 관련 SLA 사양을 수행하는 데 실패할 경우 Microsoft에서 어떻게 대응할 것인지를 설명합니다.\n99.9 -\u0026gt; 10\n99 -\u0026gt; 25\n95 -\u0026gt; 100\n#\r#\rAzure SLA를 통한 앱 안정성 향상\r#\r#\rSLA를 사용하여 Azure 솔루션이 클라이언트와 사용자의 비즈니스 요구 사항 및 수요를 얼마나 충족하는지 평가할 수 있습니다.\n고유한 SLA를 만들어서 고객의 특정 Azure 애플리케이션에 맞는 성능 목표를 설정할 수 있습니다. 이 접근 방식을 애플리케이션 SLA라고 합니다.\nSLA를 사용한 이점\n#\r앱 요구 사항 이해\n효율적이고 신뢰할 수 있는 Azure 솔루션을 빌드하려면 워크로드 요구 사항을 알아야 합니다. #\r복원력\n복원력은 오류를 복구하여 계속 작동하는 시스템 기능입니다. 오류를 방지하는 것이 아니라 가동 중지 또는 데이터 손실을 방지하는 방법으로 오류에 대응하는 것입니다. #\r비용 및 복잡성과 고가용성\n가용성이란 시스템이 정상적으로 작동하는 시간을 말합니다. 가용성을 최대화하려면 가능한 서비스 오류를 방지하는 수단을 구현해야 합니다. #\r애플리케이션 SLA를 정의할 때 고려할 사항\n플리케이션 SLA에서 정의하는 성능 목표가 4개의 9(99.99%)인 경우 수동 작업으로 오류를 복구하면 SLA를 충족하기에 충분하지 않을 수 있습니다. Azure 솔루션이 자체적으로 진단하고 자체적으로 복구해야 합니다.\n4개의 9보다 높은 SLA 성능 목표를 충족하도록 신속하게 오류에 대응하기는 쉽지 않습니다.\n애플리케이션 SLA 성능 목표를 측정할 시간 범위를 신중하게 고민해야 합니다. 시간 범위가 짧을수록 허용 오차도 작습니다. 애플리케이션 SLA를 시간 단위 또는 일 단위 가동 시간으로 정의하는 경우 허용 오차가 작으면 성능 목표를 달성하지 못할 수 있다는 점을 이해해야 합니다.\n#\r"},{"id":48,"href":"/cloud/docs/Azure/MicrosoftAzure/Azure01/","title":"Azure Networking","section":"Azure docs","content":"\rAzure Networking\r#\r#\rAzure Networking은 컴퓨팅 리소스를 연결하고 애플리케이션에 대한 액세스를 제공하는 것으로 Microsoft Azure 데이터 센터의 서비스 및 기능을 외부 환경에 연결하는 다양한 옵션이 포함되어 있습니다. #\r#\rAzure Virtual Network\r#\r#\r수신 VPN(가상 사설망) 연결에 VM을 연결합니다. #\r#\rAzure Load Balancer\r#\r#\r#\rAzure Load Balancer는 사용자를 위한 유지 관리를 Azure에서 담당하는 서비스 입니다.\n인바운 및 아웃바운드의 시나리오에 맟춰 해당 TCP, UDP 포트로 접근하는 각 트래픽을 부하분산합니다.\n단, 가상 머신에서 일반저인 부하 분산 장치를 소프트웨어를 수동으로 구성하는 경우 추가로 시스템을 유지 관리해야 하는 단점이 존재합니다.\n#\r#\rAzure Application Gateway\r#\r#\r#\rAzure Applicatin Gateway는 모든 트래픽이 HTTP인 경우 URL 기반의 라우팅 규칙을 통해 부하 분산을 진행합니다.\nAAG의 장점은 하단과 같습니다..\n쿠키 선호도\n동일한 백 엔드 서버에서 사용자 세션을 유지하려는 경우에 유용합니다. #\rSSL 지원\nSSL 인증서를 통해 암호화가 가능합니다. #\r웹 애플리케이션 방화벽\nWAF를 지원합니다. #\rURL 규칙 기반 경로\nURL 패턴, 대상 IP 주소 및 포트에 해당하는 원본 IP 주소 및 포트에 따라 트래픽을 라우팅 할 수 있습니다. #\rHTTP 헤더 수정\n각 요청의 인바운드 및 아웃바운드 HTTP 헤더에서 저옵를 추가하거나 제거가 가능합니다. #\r#\rAzure VPN Gateway\r#\r#\r고성능 VPN 게이트웨이를 통한 Azure 가상 네트워크에 액세스합니다. #\r#\rAzure DNS\r#\r#\r#\rAzure DNS는 사용자에게 친숙한 Domain을 통해 해당 IP 주소를 매핑하는 방법입니다.\nAzufre DNS는 매우 빠른 DNS 응답과 매우 높은 도메인 가용성을 제공합니다.\n#\r#\rAzure Content Delivery Network\r#\r#\r전 세계 고객에게 고대역폭 콘텐츠를 제공합니다. #\r#\rAzure DDoS Protection\r#\r#\r#\rAzure에서 호스트되는 애플리케이션을 DDoS(배포된 서비스 거부) 공격으로부터 보호합니다. #\r#\rAzure Traffic Manager\r#\r#\rTraffic Manager는 사용자에게 가장 가까운 DNS 서버를 사용하여 사용자 트래픽을 전역적으로 분산된 엔드포인트로 보냅니다.\n전 세계 Azure 지역에 네트워크 트래픽을 분산합니다.\n#\r#\rAzure ExpressRoute\r#\r#\r고대역폭 전용 보안 연결을 통해 Azure에 연결합니다. #\r#\rAzure Network Watcher\r#\r#\r시나리오 기반 분석을 사용하여 네트워크 문제를 모니터링하고 진단합니다. #\r#\rAzure Firewall\r#\r#\r확장성에 제한이 없고 보안 수준이 높은 고가용성 방화벽을 구현합니다. #\r#\rAzure 가상 WAN\r#\r#\r로컬 사이트와 원격 사이트를 연결하는 통합 WAN(광역 네트워크)을 구축합니다. #\r"},{"id":49,"href":"/cloud/docs/OpenStack/OpenStackTraining/","title":"OpenStack Training","section":"OPENSTACK","content":"\rOpenStack Training\nOpenStack Ussuri\nOpenStack Ussuri : Overview\nOpenStack Ussuri : 환경설정\nOpenStack Ussuri : Keystone\nOpenStack Ussuri : Glance\nOpenStack Ussuri : Nova\nOpenStack Ussuri : Neutron\nOpenStack Ussuri : Cinder\nOpenStack Ussuri : Horizon\nOpenStack Ussuri : Swift\nOpenStack Ussuri : Heat\nOpenStack Ussuri : Gnocch\nOpenStack Ussuri : Trove\nOpenStack Ussuri : Designate\nOpenStack Ussuri : Brabican\nOpenStack Ussuri : Rally\nOpenStack Ussuri : Manila\n#\rOpenStack Stain #\rDevStack #\rPackStack #\r#\rOpenStack\nOpenStack의 개요\nKeyston : 인증을 관리하는 서비스\nGlance : 이미지를 관리하는 서비스\nNova : 가상의 서버를 생성하는 서비스\nNeutron : 네트워크를 관리하는 서비스\nCinder : 블록 스토리지 서비스\nCeilometer : 리소스의 사용량과 부하를 관리하는 서비스\nHorizon : 외부 인터페이스 대시보드 서비스\nSwift : 오브젝트 스토리지 관리 서비스\nHeat : 오케트스트레션 서비스\nTrove : 데이터베이스 서비스\nSahara : 데이터 프로세싱 서비스\nIronic : 베어메탈 서비스\n#\r#\r"},{"id":50,"href":"/cloud/docs/OpenStack/OpenStack/Trove/","title":"Trove","section":"OpenStack docs","content":"\r데이터베이스 서비스 : Trove\r#\rTrove는 관계형 데이터베이스 기능을 활용 클라우드 사용자와 데이터 베이스 관리자는 필요에 따라 Trove를 통해 데이터베이스 인스턴스를 제공, 관리 서비스 #\rTrove의 논리 아키텍처\r#\r#\r#\r구성요소 역할 python-troveclient 클라이언트에서 콘솔로 trove-api를 실행할 수 있게 지원 trove-api RESTful API 방식의 JSON을 지원, Trove인스턴스를 관리하고 프로비저닝 trove-taskmanager 인스턴스 프로비저닝을 지원, 라이프 사이클 관리 및 운영하는 작업을 수행 trove-conductor 호스트에서 실행되는 서비스로 호스트 정보를 업데이트 및 게스트 인스턴스 메시지를 수신 trove-guestagent 게스트 인스턴스 안에서 실행, 데이터 베이스 작업을 실행, 관리 "},{"id":51,"href":"/cloud/docs/Azure/MicrosoftAzure/Azure02/","title":"Azure Mobile","section":"Azure docs","content":"\rAzure Mobile\r#\r#\rAzure Mobile은 개발자가 iOS, Android 및 Windows 앱용 모바일 백 엔드 서비스를 쉽고 빠르게 만들 수 있게 해줍니다. Azure Mobile의 기능은 다음과 같습니다. 오프라인 데이터 동기화\n온-프레미스 데이터 연결\n푸시 알림 브로드캐스트\n비즈니스 요구 사항과 일치하도록 자동 크기조정\n#\r"},{"id":52,"href":"/cloud/docs/Azure/AzureTraining/Azure02/","title":"Az-900 : 관리옵션","section":"Azure Training","content":"\rAzure 관리옵션\r#\r#\rAzure 관리옵션의 다양한 종류\r#\r#\rAzure의 관리는 다양한 도구 및 플랫폼을 사용하여 Azure을 구성하고 관리할 수 있습니다.\n명령줄, 언어별 SDK, 개발자 도구, 마이그레이션 도구 등에 제공되는 여러 도구가 있습니다.\n하단은 가장 일상적으로 사용되는 관리 및 조작에 주로 사용되는 도구들입니다.\nAzure Portal : GUI를 통해 Azure 조작\nAzure PowerShell 및 Azure CLI : 명령줄 및 자동화 기반으로 Azure 조작\nAzure Cloud Shell : 웹 기반 명령줄 인터페이스\n모바일 디바이스에서 리소스를 모니터링하고 관리하기 위한 Azure 모바일 앱\n#\r#\rAzure Portal\r#\r#\r#\rAzure Portal은 몯느 웹 브라우저를 통해 엑세스할 수 있는 공용 웹 사이트로, Azure 계정으로 로그인하여 Azure의 서비스를 사용, 관리 및 모니터링이 가능합니다. #\r#\rAzure PowerShell\r#\r#\rAzure PowerShell은 Windows,Linux 또는 macOS에서 실행되는 PowerShell의 플랫폼 간 버전인 Windows PowerShell또는 PowerShell Core를 설치할 수 있는 모듈입니다.\nAzure PowerShell 명령어를 통해 Azure 서비스를 사용, 관리하는 것이 가능합니다.\nNew-AzVM ` -ResourceGroupName \u0026#34;MyResourceGroup\u0026#34; ` -Name \u0026#34;TestVm\u0026#34; ` -Image \u0026#34;UbuntuLTS\u0026#34; ` ... #\r#\rAzure CLI\r#\r#\rAzure CLI는 Azure에 연결하고 Azure 리소스에서 관리 명령을 실행하는 플랫폼 간 명령줄 프로그램입니다. 플랫폼 간이란 Windows, Linux 또는 macOS에서 실행합니다. az vm create \\ --resource-group MyResourceGroup \\ --name TestVm \\ --image UbuntuLTS \\ --generate-ssh-keys \\ ... #\r#\rAzure Cloud Shell\r#\r#\r#\rAzure Cloud Shell은 Azure 리소스를 관리하기 위한 인증된 대화형 셸로, 브라우저에서 엑세스할 수 있습니다.\n기본적으로는 Azure CLI로 설정되어 있지만 pwsh를 통해 PowerShell Core로 전환이 가능합니다. 또한 owerShell 환경에는 두 CLI 도구가 사전 설치되어 있으며 여러 도구의 사용 또한 가능합니다.\n#\r개발자 도구\n.NET Core\nPython\nJava\nNode.js\n편집기\n코드(Cloud Shell 편집기)\nvim\nnano\nemacs\n기타 도구\ngit\nmaven\nmake\nnpm\n#\r#\rAzure 모바일 앱\r#\r#\r#\rMicrosoft Azure 모바일 앱을 사용하면 iOS나 Android 휴대폰 또는 태블릿에서 모든 Azure 계정과 리소스를 액세스, 관리 및 모니터링할 수 있습니다. 설치되면 다음 작업을 수행할 수 있습니다. #\r"},{"id":53,"href":"/cloud/docs/Azure/MicrosoftAzure/Azure10/","title":"Azure DataBase","section":"Azure docs","content":"\rAzure DataBase\r#\r#\rAzure DataBase는 기존 스토리지 문제를 해결하기 위해 클라우드에 데이터를 저장하는 것을 고려합니다.\n하지만 보안, 백업 및 재해 복구에 대한 우려가 존재합니다.\nAzure에서는 다양한 형식과 볼륨의 데이터를 저장하도록 여러 데이터베이스 서비스를 제공합니다.\n#\r#\rAzure Database의 특징\r#\r#\rAzure Database의 이점\n자동화된 백업 및 복구\n전 세계에서 복제\n데이터 분석 지원\n암호화 기능\n다양한 데이터 형식\n가상 디스크의 데이터 스토리지\n스토리지 계층\n데이터 형식\n정형 데이터 (Structured data)\n정형 데이터는 스키마를 준수하는 데이터이므로 모든 데이터에 동일한 필드 또는 속성이 존재합니다.\n정형 데이터는 테이블의 한 행을 다른 테이블의 또 다른 행에 있는 데이터와 연결하는 방법을 나타내며, 이를 관계형 데이터라고도 합니다.\n#\r반정형 데이터 (Semi-structured data)\n반정형 데이터는 테이블, 행, 열에 제약받지 않으며, 대신 태그 혹은 키 값을 사용합니다.\n반정형 데이터는 비관계형 데이터 혹은 NoSQL이라고도 합니다.\n#\r비정형 데이터 (Unstructured data)\n비정형 데이터는 지정된 구조가 없는 데이터를 포괄합니다.\n데이터의 종류에 대한 제한이 없다는 것은 PDF, JPG, JSON와 같은 형식을 모두 포함하고 있습니다.\n#\r스토리지 서비스 암호화\nAzure는 암호화 및 복제 기능을 통해 봉나 및 고가용성을 데이터에 제공합니다.\n미사용 데이터에 대한 Azure SSE (스토리지 서비스 암호화)를 사용하면 조직의 보안 및 규정준수를 충족하도록 데이터를 보호할 수 있습니다.\n클라이언트 쪽의 암호화를 통해 클라이언트 라이브러이에 데이턱 ㅏ이미 암호화되어 있어, 검색 중에 이를 해독합니다.\n#\r스토리지 가용성 복제\n복제 유형은 스토리지 계정을 만들 때 설정됩니다.\n복제 기능은 데이터가 내구성이 있으며 항상 사용할 수 있는 지 확인합니다.\n#\r#\rAzure Cosmos DB (NoSQL)\r#\r#\r#\rAzure Cosmos DB는 글로벌 분산형 데이터베이스 서비스로, 지속적으로 변경되는 데이터를 지원하기 위해 응답성이 뛰어난 Always On 애플리케이션을 빌드할 수 있는 스키마 없는 데이터 (NoSQL)을 지원합니다. #\r#\rAzure SQL Database\r#\r#\r#\rAzure SQL Database는 안정적으로 Microsoft SQL Server 데이터베이스 엔진으로 관계형 DaaS (Databases as a Service)입니다.\n완전 관리형 데이터베이스로, 인프라를 관리할 필요 없이 선택한 프로그래밍 언어와 옵티마이저를 통해 최적의 빌드가 가능합니다.\n기존 local 환경의 데이터베이스와 마이그레이션이 가능하며 이 때 Microsoft Data Migration Assistant를 사용합니다.\n자동 크기 조정과 필수 인텔리전스, 강력한 보안을 통해 완벽하게 ### 관리되는 관계형 데이터베이스입니다.\n#\r#\rAzure Blob Storage\r#\r#\r#\rAzure Blob Storage는 비정형 데이터베이스로 포함될 수 있는 데이터의 종류에 제한이 없습니다.\n수천 개의 동시 업로드, 대용량 비디오 데이터, 끊임없이 증가하는 로그 파일을 관리할 수 있으며, 어디서나 인터넷을 통해 연결할 수 있습니다.\n일반적으로 파일 형식으로 제한되지 않으며, 최대 8TB의 가상 머신용 데이터를 저장할 수 있습니다.\n#\r#\rAzure Data Lake Storage\r#\r#\r#\rAzure Data Lake Storage는 개체 스토리지의 확정성 및 비용 혜택이 빅 데이터 파일 시스템 기능의 안정성 및 성능과 결합되어 있습니다. #\r#\rAzure Files\r#\r#\r#\rAzure Files는 산업 표준 SMB 프로토콜을 통해 엑세스할 수 있는, 클라우드에서 완전 관리형 파일 공유를 제공합니다.\nAzure File 공유는 Windows, Linux 및 macOS의 클라우드 또는 온-프레미스 배포를 통해 동시에 탑재될 수 있으며 공유 또한 가능합니다.\n#\r#\rAzure Queue Storage\r#\r#\r#\rAzure Queue Storage는 전 세계 어디에서나 엑세스할 수 있는 많은 수의 메시지를 저장하기 위한 서비스입니다.\n유연한 애플리케이션을 구축하고 기능을 분리하여 대용량 워크로드 전반에서 내구성을 향상 시킬 수 있습니다.\n비동기식 메시지 대기열 기능을 제공합니다.\n기본적으로 하나 이상의 송신기 구성 요소와 하나 이상의 수신기 구성 요소가 존재합니다\n#\rQueue Storage를 사용하여 하단의 작업들의 수행이 가능합니다.\n작업의 백로그를 만들고 다른 Azure 웹 서버 간에 메시지를 전달합니다.\n여러 웹 서버/ 인프라 간에 로드를 배포하고 트래픽 증가를 관리합니다.\n여러 사용자가 동싱에 데이터에 엑세스할 때 구성 요소 오류에 대한 복원력을 빌드합니다.\n#\r#\rDisk Storage\r#\r#\r#\rDisk Storage는 가상 머신, 애플리케이션 및 기타 서비스가 온-프레미스 시나리오와 마찬가지로 필요에 따라 엑세스하여 사용할 수 있는 디스크를 제공합니다.\nDisk Storage는 데이터를 연결된 가상 하드 디스크에서 영구적으로 저장 및 엑세스가 가능하며, 디스크는 Azure 혹은 사용자가 직접 관리가 가능합니다.\nDisk Storage의 종류에는 SSD, HDD 등 종류가 다양합니다.\n#\r#\rAzure Synapse Analytics\r#\r#\r추가 비용 없이 모든 수준에서 필수 보안을 제공하며 완벽하게 관리되는 데이터 웨어하우스입니다. #\r#\rAzure Database Migration Service\r#\r#\r애플리케이션 코드변경 없이 클라우드로 데이터베이스를 마이그레이션합니다. #\r#\rAzure Cache for Redis\r#\r#\r자주 사용하는 정적 데이터를 캐시하여 데이터 및 애플리케이션 대기 ### 시간을 줄입니다. #\r"},{"id":54,"href":"/cloud/docs/Azure/MicrosoftAzure/Azure03/","title":"Azure Storage","section":"Azure docs","content":"\rAzure Storage\r#\r#\rAzure Storage는 기본적인 스토리지 서비스를 제공하며 다음과 같은 특성을 가지고 있습니다..\n중복 및 복제 기능을 갖추고 있어 내구성과 가용성이 뛰어납니다.\n자동 암호화와 역할 기반 액세스 제어를 통해 보안을 유지합니다.\n사실상 스토리지에 제한이 없으므로 확장성이 뛰어납니다.\n유지 관리 및 사용자에 대한 중요한 문제를 관리하고 처리합니다.\nHTTP 또는 HTTPS를 통해 전 세계 어디에서든 액세스할 수 있습니다.\n#\r#\rAzure Blob Storage\r#\r#\r비디오 파일이나 비트맵 같은 대규모 개체를 위한 스토리지 서비스 #\r#\rAzure File\r#\r#\r스토리지 파일 서버처럼 액세스하고 관리할 수 있는 파일 공유 #\r#\rAzure Queue\r#\r#\r스토리지 애플리케이션 간 메시지를 큐에 넣고 안정적으로 전달하기 위한 데이터 저장소 #\r#\rAzure Table\r#\r#\r스토리지 스키마와 관계없이 비정형 데이터를 호스팅하는 NoSQL 스토리지 #\r"},{"id":55,"href":"/cloud/docs/Azure/AzureTraining/Azure12/","title":"Az-900 : 서비스","section":"Azure Training","content":"\rAz-900 : 서비스\r#\r#\r서비스는 Link를 참조하세요. #\rIOT 솔루션 (Internet of Things)\r#\r#\rAzure IoT Central 보다 손 쉬운 IOT 서비스 구축을 위한 SaaS 형태의 관리형 서비스, (디바이스 연결, 모니터 그리고 관리 및 확장 지원) #\rAzure IoT Hub 클라우드 기반의 IOT 관리 플랫폼 서비스 (중앙 메시지 허브, 양방향 통신 및 관리) #\r#\r빅 데이터 분석 솔루션 (Big data and analytics)\r#\r#\rAzure Sysnapse Analytics 클라우드 기반의 수십 페타의 데이터를 MPP기반으로 빠르게 처리할 수 있는 온 디맨드 분석을 지원하여 인사이트를 찾아낼 수 있는 솔루션 #\rAzure HDInsight 오픈소스 기반의 Hadoop을 관리되는 형태의 서비스를 제공, 쉽고 빠르고 비용 효율적으로 데이터 처리가 가능 #\r#\r인공지능 (Artificial Intelligence\r#\r#\rAzure Machin Learning service SDK 기반으로 손쉽게 code를 작성하고 train, test, deploy, manage 및 track 할 수 있는 플랫폼을 제공 #\rAzure Machine Learning Studio GUI 기반으로 코드 없이도 손쉽게 ML model을 만들고 테스트를 배퐇라 수 있는 플랫폼을 제공 #\r#\r서버리스 (Serveless computing)\r#\r#\rAzure Functions 서비스를 위한 코드에 집중 (인프라 및 플랫폼으로 부터의 자유도 확보) #\rAzure Logic Apps 작업 및 비즈니스 프로세스를 자동화하고 오케스트레이션 할 수 있도록 서비스 제공 엔터프라이즈 환경에서 앱, 데이터 긜고 시스템의 통합을 지원 #\rAzure Event Grid 배포와 구독형태의 이벤트 소비를 위한 관리형 엔진 기반의 이벤트 라우팅 서비스 #\r#\rDevOps\r#\r#\rAzure DevOps services 클라우드 기반의 통합 개발 협업 서비스 (CI/CD) 제공 파이프라인, Git 저장소, 오픈 소스 연계 등 #\rAzure DevTest Labs 쉽고 빠르게 재사용 가능한 템플릿을 통해 배포하여 최신 개발 코드를 배포 및 테스트 가능 #\r#\rAzure 관리 도구\r#\r#\rAzure Advisor 배포된 Azure 리소스를 분석하고 가용성, 보안, 성능, 비용측면을 개선하는 방법을 제공 #\rAzure quick start templates 사전에 code로 설정이 되어 있는 탬플릿을 토대로 리소스를 배포할 수 있게 도와주는 도구 JSON 형태를 가지고 있다. #\rPowerShell Window 사용자를 위한 Shell로 Azure 서비스를 관리할 수 있다. #\rAzure CLI BASH Shell을 사용하여 Azure 서비스를 관리할 수 있다. #\r#\r네트워크 연결 보호\r#\r#\r심층보호 (Denfense in depth)\n컴퓨터 시스템의 안전한 보호를 위한 대한 단계적 접근 방식을 구현\n여러 수준의 보호를 제공\n한 레이어에 대한 공격은 후속 레이어에서 격리\n#\r공동 책임 (Shared security)\n고객이 제저아흔 데이터센터에서 클라우드 기반 데이터 센터로 마이그레이션하면 보안에 대한 책임 변경이 발생\n보안은 클라우드 공급자와 고객 간의 공통 관심사가 됨\n#\r방화벽 (Azure Firewall)\n네트워크 리소스를 보호하기 위해 IP주소를 기반으로 서버 엑세스를 허용/ 거부하도록 하는 PaaS 형태의 방화벽 서비스\n인 바운드 및 아웃바운드 트래픽 필터링 규칙 적용\n고 가용성이 내장\n아웃바운드에서만 애플리케이션 레이어서의 프로텍션을 제공\n무제한 클라우드 확정성\nAzure 모니터 로깅을 사용\n#\rAzure Distributed Denial of Service (DDoS)\nDDoS는 지속적인 공격으로 피해자의 리소스를 소모시켜 마비시키는 공격\n서비스 가용성에 영향을 미치기전에 원치 않는 네트워크 트래픽을 제공\n베이직은 기본적으로 제공\n스탠다드는 보다 나은 완화기능 (머신러닝 기반의 어댑티브 튜닝 등)\n#\r네트워크 보안 그룹 (Network Security Groups : NSGs)\nAzure 가상 네트워크에서 Azure 리소스로의 네트어크 트래픽을 필터링\n소스 및 대상 IPㅈ소, 포트 및 프로토콜로 필터링하도록 인 바운드 및 아웃바운드 규칙의 설정이 가능\n필요에 따라 구독 한도 내에서 여러 규칙을 추가가능\nAzure는 세 NSG에 기본적인 기준, 보안 규칙을 적용\n우선 순위가 높은 규칙으로 기본 규칙 재정의 가능\n#\r#\rAzure 네트워크 보안 솔루션 선택\r#\r#\r경계 레이어 (Perimeter layer) Azure DDoS 보호 및 Azure 방화벽을 통해 네트워크 경계를 보호 #\r네트워크 레이어 (Networking layer) NSG(네트워크 보안 그룹) 인 바운드 및 아웃바운드 규칙을 사용하여 네트워크 리소스 간에 허용된 트래픽만 하용 #\r#\r핵심 Azure Identity 서비스\r#\r#\r인증 및 권한 (Azure Active Deirctory : AAD)\nMicrosoft Azure의 클라우드 기반 신원 확인 및 접근 관리 서비스\n단일인증 (SSO)\n응용 프로그램 관리\nB2B (Federation)\nB2C (Consumer) ID 서비스\n디바이스 관리\n인증 (Authentication)\n리소스에 대한 엑세스를 원하는 사람 또는 서비스를 식별 권한부야 (Authoizotion)\n리소스에 대한 사용권한을 원하는 사람 또는 서비스에게 제공 #\r다단계인증 (Azure Multi-Factor Authentication) 전체 인증을 위해 두 개 이상의 요소를 요구하여 신원 확인에 대한 추가 보안을 제공 보통 세가지 범류로 분류 당신이 알고 있는 것 당신이 가지고 있는 것 당신 임을 증명할 수 있는 것 #\r#\r보안 도구\r#\r#\r보안센터 (Azure Security Center)\nAzure 온-프레미스 서비스에 대한 위협 보호 기능을 제공하는 모니터링 서비스\n구성된 설정, 리소스 및 네트워크에 따라 보안 권장사항을 제공\n#\r보안 센터 시용 시나리오\n장애 시, 감지, 평가 및 진단 단계에서 보안 세터를 사용\n감지, 평가, 진단만 모니터링 나머지는 자기자신이 해결\n#\r키 자격증명 (Azure Key Vault) 응용 프로그램 보안을 중앙 집중식 클라우드에 저장하여 액세스 권한을 안전하게 제어 (접근 등에 대한 로깅 및 관리) 비밀번호 관리 키 관리 인증서 관리 하드웨어 보안 모듈 (HSM)을 지원하는 장비에 저장된 비밀번호 정보 가져오기 지원 #\r정보보호 (Azure Information Protecton : AIP)\n레이블을 적용하여 문서 및 전자 메일을 분류하고 보호\n관리자가 정의한 규칙 및 조건을 자동으로 사용 가능\n사용자가 수동으로 적용, 활용지원\n권장 사항에 따라 자동 및 수동 방법을 결합할 수 있음\n#\r고급위협보호 (Azure Advanced Threat Protection : ATP)\n지능형 위협, 손상된 ID 및 악의적인 내부자 작업을 식별, 탐지 및 조사하기 위한 클라우드 기반 보안 솔루션\nPortal : 의심스러운 활동을 모니터링하고 대응하기 위한 전용 포털\nSensorts : 도메인 컨트롤러에 직접 설치\nCloud Service : Azure 인프라에서 실행\n#\r#\rAzure 커버넌스 방법론\r#\r#\r정책 (Azure Policy)\nAzure 리소스에 대한 규칙을 적용하기 위해 정책을 사용하여 회사 표준 및 서비스 수준 계약(SLA)을 준수할 수 있음\n정책을 준수하지 않는 Azure 리소스를 평가하고 식별\n스토리지, 네트워킹, 컴퓨팅, 보안 센터 및 모니터링과 같은 범주에서 기본 제공 정책 및 이니셔티브 정의를 제공\n정챍 정의 \u0026ndash;\u0026gt; 리소스 정책 할당 \u0026ndash;\u0026gt; 평가 검토\n#\r정책 이니셔티브 (Policy Initiatives) 이니셔티브는 Azure 정책과 함께 작동 #\r역할 기반 액세스 제어 (RBAC)\nAzure 리소스에 대한 세분화된 엑세스 관리 제어 기능\n팀 내에 책임을 분리하여 그 작업을 수행하는 데 필요한 사용자에게만 적당한 권한을 부여\nAzure 포털 및 리스스의 접근을 허용 및 거부하도록 설정 지원\n잠금 (Resource locks)\n실수로 삭제하거나 수정하지 않도록 Azure 리소스를 보호\nAzure Portal 에서 구독, 리소스 구룹 또는 개별 리소스 수준에서 잠금을 관리 (상속 지원)\n#\rAzure Blueprints\nAzure 리소스 및 정책들을 즉시 재생성 할 수 있도록 재사용 가능한 환경 정의를 만들 수 있다\n기본 제공 도구 및 아티팩트를 사용하여 배포를 감사하고 추적하고 규정 준수를 유지\nBlueprint를 특정 Azure DevOps 빌드 아디펙트 및 릴리스 파이프라인과 연결하여 엄격한 추적을 수행\n#\r#\r모니터링 및 리포트\r#\r#\r태그 (Tags)\nAzure 리소스에 대한 메타 데이타 지원\n{키-값} 쌍으로 구성\n논리적으로 리소스를 분류하기 위해 활용\n청구 혹은 관리용 데이터 분석에 용이\n#\r모니터 (Azure Monitor) 클라우드 및 온-프레미스 환경에서 원격 데이터를 수집, 분석 및 사용하여 애플리케이션의 가용성과 성능을 극대화 #\r서비스건강 (Azure Service Health) #\r#\r규정 준수 약관 및 요구사항\r#\r#\rMicrosoft는 다른 클라우드 서비스 공급자보다 가장 포괄적인 compliance offerings (인증 및 증명)을 제공 #\r#\rAzure 가격 책정 및 지원\r#\r#\rAzure 구매 및 관리\r#\rhttps://azure.microsoft.com/ko-kr/support/plans/ https://azure.microsoft.com/ko-kr/resources/knowledge-center\n"},{"id":56,"href":"/cloud/docs/Azure/MicrosoftAzure/Azure04/","title":"Azure Web","section":"Azure docs","content":"\rAzure Web\r#\r#\rAzure Web 에는 웹앱 및 HTTP 기반 웹 서비스의 빌드 및 호스트에 대한 최고 수준의 지원이 포함되어 있습니다. #\r#\rAzure App Service\r#\r#\r강력한 클라우드 웹 기반 앱을 신속하게 만들기 #\r#\rAzure Notification Hubs\r#\r#\r원하는 백 엔드에서 원하는 플랫폼으로 푸시 알림을 전송할 수 있습니다. Azure API Management\r#\r#\r개발자, 파트너 및 직원에게 API를 안전하게 대규모로 게시할 수 있습니다. #\r#\rAzure Cognitive Search\r#\r#\r완전 관리형 SaaS(Search-as-a-Service)입니다.\nAzure App Service의 Web Apps 기능 중요 업무용 웹앱을 대규모로 만들고 배포할 수 있습니다.\n#\r#\rAzure SignalR Service\r#\r#\r실시간 웹 기능을 쉽게 추가할 수 있습니다. #\r"},{"id":57,"href":"/cloud/docs/AWS/AWSSAA/SAA-15/","title":"15장 기출문제 정리","section":"AWS SAA 시험정리","content":"\r15장 기출문제 정리\r#\r#\r답들은 정확하지 않습니다. 공부하시면서 찾아보셔야 합니다.\r#\r#\rQUESTION 1-100\r#\r#\rQUESTION\r#\rA company has a web application with sporadic usage patterns. There is heavy usage at the beginning of each month, moderate usage at the start of each week, and unpredictable usage during the week. The application consists of a web server and a MySQL database server running inside the data center. The company would like to move the application to the AWS Cloud, and needs to select a cost-effective database platform that will not require database modifications. Which solution will meet these requirements?\nA. Amazon DynamoDB\nB. Amazon RDS for MySQL C. MySQL-compatible Amazon Aurora Serverless D. MySQL deployed on Amazon EC2 in an Auto Scaling group\n문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA start-up company has a web application based in the us-east-1 Region with multiple Amazon EC2 instances running behind an Application Load Balancer across multiple Availability Zones. As the company\u0026rsquo;s user base grows in the us-west-1 Region, it needs a solution with low latency and high availability. What should a solutions architect do to accomplish this?\nA. Provision EC2 instances in us-west-1. Switch the Application Load Balancer to a Network Load Balancer to achieve cross-Region load balancing. B. Provision EC2 instances and an Application Load Balancer in us-west-1. Make the load balancer distribute the traffic based on the location of the request. C. Provision EC2 instances and configure an Application Load Balancer in us-west-1. Create an accelerator in AWS Global Accelerator that uses an endpoint group that includes the load balancer endpoints in both Regions. D. Provision EC2 instances and configure an Application Load Balancer in us-west-1. Configure Amazon Route 53 with a weighted routing policy. Create alias records in Route 53 that point to the Application Load Balancer. 문제 풀이\r...\rAnswer: C\r#\rExplanation https://aws.amazon.com/global-accelerator/faqs/ Register endpoints for endpoint groups: You register one or more regional resources, such as Application Load Balancers, Network Load Balancers, EC2 Instances, or Elastic IP addresses, in each endpoint group. Then you can set weights to choose how much traffic is routed to each endpoint. Endpoints in AWS Global Accelerator Endpoints in AWS Global Accelerator can be Network Load Balancers, Application Load Balancers, Amazon EC2 instances, or Elastic IP addresses. A static IP address serves as a single point of contact for clients, and Global Accelerator then distributes incoming traffic across healthy endpoints. Global Accelerator directs traffic to endpoints by using the port (or port range) that you specify for the listener that the endpoint group for the endpoint belongs to. Each endpoint group can have multiple endpoints. You can add each endpoint to multiple endpoint groups, but the endpoint groups must be associated with different listeners. Global Accelerator continually monitors the health of all endpoints that are included in an endpoint group. It routes traffic only to the active endpoints that are healthy. If Global Accelerator doesn\u0026rsquo;t have any healthy endpoints to route traffic to, it routes traffic to all endpoints. https://docs.aws.amazon.com/global-accelerator/latest/dg/about-endpoints.html\n#\r#\rQUESTION\r#\rA solutions architect is designing an application for a two-step order process The first step is synchronous and must return to the user with little latency The second step takes longer, so it will be implemented in a separate component Orders must be processed exactly once and in the order in which they are received How should the solutions architect integrate these components?\nA. Use an Amazon SQS FIFO queues B. Use an AWS Lambda function along with Amazon SQS standard queues C. Create an SNS topic and subscribe an Amazon SQS FIFO queue to that topic D. Create an SNS topic and subscribe an Amazon SQS Standard queue to that topic. 문제 풀이\r...\rAnswer: A\r#\rC가 불가능한 이유는 SQS FIFO와 SNS는 함께 사용이 불가능합니다.\n#\r#\rQUESTION\r#\rA leasing company generates and emails PDF statements every month for all its customers. Each statement is about 400 KB in size. Customers can download their statements from the website for up to 30 days from when the statements were generated. At the end of their 3-year lease, thecustomers are emailed a ZIP file that contains all the statements. What is the MOST cost-effective storage solution for this situation?\nA. Store the statements using the Amazon S3 Standard storage class. Create a lifecycle policy tomove the statements to Amazon S3 Glacier storage after 1 day. B. Store the statements using the Amazon S3 Glacier storage class. Create a lifecycle policy to movethe statements to Amazon S3 Glacier Deep Archive storage after 30 days. C. Store the statements using the Amazon S3 Standard storage class. Create a lifecycle policy to move the statements to Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) storage after 30 days. D. Store the statements using the Amazon S3 Standard-Infrequent Access (S3 Standard-IA) storage class. Create a lifecycle policy to move the statements to Amazon S3 Glacier storage after 30 days. 문제 풀이\r...\rAnswer: D\r#\rS3-IA는 파일 크기 당 최소 128kb, 최소 30일의 저장기간을 가지고 있습니다. Deep 아카이브는 가장 저렴하지만 속도가 느리고 3년 후의 파일이 검색되므로 불가능합니다.\n#\r#\rQUESTION\r#\rA company is designing a message-driven order processing application on AWS. The application consists of many services and needs to communicate the results of its processing to multiple consuming services. Each of the consuming services may take up to 5 days to receive the messages Which process will meet these requirements?\nA. The application sends the results of its processing to an Amazon Simple Notification Service (Amazon SNS) topic Each consuming service subscribes to this SNS topic and consumes the results B. The application sends the results of its processing to an Amazon Simple Notification Service (Amazon SNS) topic Each consuming service consumes the messages directly from its corresponding SNS topic. C. The application sends the results of its processing to an Amazon Simple Queue Service (Amazon SQS) queue Each consuming service runs as an AWS Lambda function that consumes this single SQS queue. D. The application sends the results of its processing to an Amazon Simple Notification Service (Amazon SNS) topic. An Amazon Simple Queue Service (Amazon SQS) queue is created for each service and each queue is configured to be a subscriber of the SNS topic. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company delivers files in Amazon S3 to certain users who do not have AWS credentials. These users must be given access for a limited lime. What should a solutions architect do to securely meet these requirements?\nA. Enable public access on an Amazon S3 bucket. B. Generate a presigned URL to share with the users. C. Encrypt files using AWS KMS and provide keys to the users. D. Create and assign IAM roles that will grant GetObject permissions to the users. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company has an application that runs on Amazon EC2 instances within a private subnet in a VPC The instances access data in an Amazon S3 bucket in the same AWS Region. The VPC contains a NAT gateway in a public subnet to access the S3 bucket The company wants to reduce costs by replacing the NAT gateway without compromising security or redundancy Which solution meets these requirements?\nA. Replace the NAT gateway with a NAT instance B. Replace the NAT gateway with an internet gateway. C. Replace the NAT gateway with a gateway VPC endpoint D. Replace the NAT gateway with an AWS Direct Connect connection 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company has a two-tier application architecture that runs in public and private subnets Amazon EC2 instances running the web application are in the public subnet and a database runs on the private subnet The web application instances and the database are running in a single Availability Zone (AZ). Which combination of steps should a solutions architect take to provide high availability for this architecture? (Select TWO.)\nA. Create new public and private subnets in the same AZ for high availability B. Create an Amazon EC2 Auto Scaling group and Application Load Balancer spanning multiple AZs C. Add the existing web application instances to an Auto Scaling group behind an Application Load Balancer D. Create new public and private subnets in a new AZ Create a database using Amazon EC2 in one AZ E. Create new public and private subnets in the same VPC each in a new AZ Migrate the database to an Amazon RDS multi-AZ deployment 문제 풀이\r...\rAnswer: B E\r#\rExplanation You can take advantage of the safety and reliability of geographic redundancy by spanning your Auto Scaling group across multiple Availability Zones within a Region and then attaching a load balancer to distribute incoming traffic across those zones. Incoming traffic is distributed equally across all Availability Zones enabled for your load balancer. Note An Auto Scaling group can contain Amazon EC2 instances from multiple Availability Zones within the\n81 same Region. However, an Auto Scaling group can\u0026rsquo;t contain instances from multiple Regions. When one Availability Zone becomes unhealthy or unavailable, Amazon EC2 Auto Scaling launches new instances in an unaffected zone. When the unhealthy Availability Zone returns to a healthy state, Amazon EC2 Auto Scaling automatically redistributes the application instances evenly across all of the zones for your Auto Scaling group. Amazon EC2 Auto Scaling does this by attempting to launch new instances in the Availability Zone with the fewest instances. If the attempt fails, however, Amazon EC2 Auto Scaling attempts to launch in other Availability Zones until it succeeds. You can expand the availability of your scaled and load-balanced application by adding an Availability Zone to your Auto Scaling group and then enabling that zone for your load balancer. After you\u0026rsquo;ve enabled the new Availability Zone, the load balancer begins to route traffic equally among all the enabled zones. High Availability (Multi-AZ) for Amazon RDS Amazon RDS provides high availability and failover support for DB instances using Multi-AZ deployments. Amazon RDS uses several different technologies to provide failover support. Multi-AZ deployments for MariaDB, MySQL, Oracle, and PostgreSQL DB instances use Amazon\u0026rsquo;s failover technology. SQL Server DB instances use SQL Server Database Mirroring (DBM) or Always On Availability Groups (AGs). In a Multi-AZ deployment, Amazon RDS automatically provisions and maintains a synchronous standby replica in a different Availability Zone. The primary DB instance is synchronously replicated across Availability Zones to a standby replica to provide data redundancy, eliminate I/O freezes, and minimize latency spikes during system backups. Running a DB instance with high availability can enhance availability during planned system maintenance, and help protect your databases against DB instance failure and Availability Zone disruption. For more information on Availability Zones, see Regions, Availability Zones, and Local Zones https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html\n#\r#\rQUESTION\r#\rA company is developing a new machine learning model solution in AWS. The models are developed as independent microservices that fetch about 1 GB of model data from Amazon S3 at startup and load the data into memory. Users access the models through an asynchronous API. Users can send a request or a batch of requests and specify where the results should be sent. The company provides models to hundreds of users. The usage patterns for the models are irregular Some models could be unused for days or weeks Other models could receive batches of thousands of requests at a time Which solution meets these requirements?\nA. The requests from the API are sent to an Application Load Balancer (ALB) Models are deployed as AWS Lambda functions invoked by the ALB. B. The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SQS) queue.\nModels are deployed as AWS Lambda functions triggered by SQS events AWS Auto Scaling is enabled on Lambda to increase the number of vCPUs based on the SQS queue size C. The requests from the API are sent to the model\u0026rsquo;s Amazon Simple Queue Service (Amazon SQS) queue. Models are deployed as Amazon Elastic Container Service (Amazon ECS) services reading from the queue AWS App Mesh scales the instances of the ECS cluster based on the SQS queue size. D. The requests from the API are sent to the models Amazon Simple Queue Service (Amazon SQS) queueModels are deployed as Amazon Elastic Container Service (Amazon ECS) services reading from the queue AWS Auto Scaling .s enabled on Amazon ECS for both the cluster and copies of the service based on the queue size. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company has several business systems that require access to data stored in a file share.\nthe business systems will access the file share using the Server Message Block (SMB) protocol. The file share solution should be accessible from both of the company\u0026rsquo;s legacy on-premises environment and with AWS. Which services mod the business requirements? (Select TWO.)\nA. Amazon EBS B. Amazon EFS C. Amazon FSx for Windows D. Amazon S3 E. AWS Storage Gateway file gateway 문제 풀이\r...\rAnswer: C E\r#\rAmazon FSx 파일 스토리지는 Windows, Linux 및 MacOS 컴퓨팅 인스턴스 및 AWS 또는 온 프레미스에서 실행되는 디바이스에서 액세스 할 수 있습니다.\nAWS Storage Gateway는 사실상 무제한 클라우드 스토리지에 대한 온 프레미스 액세스를 제공하는 하이브리드 클라우드 스토리지 서비스입니다. Storage Gateway는 기존 애플리케이션을 다시 작성하지 않고도 AWS 스토리지를 사용할 수 있도록 iSCSI, SMB 및 NFS와 같은 표준 스토리지 프로토콜 세트를 제공합니다.\n#\r#\rQUESTION\r#\rA company recently deployed a two-tier application in two Availability Zones in the us-east1 Region. The databases are deployed in a private subnet while the web servers are deployed in a public subnet. An internet gateway is attached to the VPC. The application and database run on Amazon EC2 instances. The database servers are unable to access patches on the internet. A solutions architect needs to design a solution that maintains database security with the least operational overhead.\nWhich solution meets these requirements?\nA. Deploy a NAT gateway inside the public subnet for each Availability Zone and associate it with an Elastic IP address. Update the routing table of the private subnet to use it as the default route. B. Deploy a NAT gateway inside the private subnet for each Availability Zone and associate it with an Elastic IP address. Update the routing table of the private subnet to use it as the default route. C. Deploy two NAT instances inside the public subnet for each Availability Zone and associate them with Elastic IP addresses. Update the routing table of the private subnet to use it as the default route. D. Deploy two NAT instances inside the private subnet for each Availability Zone and associate them with Elastic IP addresses. Update the routing table of the private subnet to use it as the default route. 문제 풀이\r...\rAnswer: A\r#\rNAT 인스턴스는 퍼블릭 서브넷에 이치해야합니다.\n#\r#\rQUESTION\r#\rA solutions architect observes that a nightly batch processing job is automatically scaled up for 1 hour before the desired Amazon EC2 capacity is reached. The peak capacity is the same every night and the batch jobs always start at 1 AM. The solutions architect needs to find a cost-effective solution that will allow for the desired EC2 capacity to be reached quickly and allow the Auto Scaling group to scale down after the batch jobs are complete. What should the solutions architect do to meet these requirements?\nA. Increase the minimum capacity for the Auto Scaling group.\nB. Increase the maximum capacity for the Auto Scaling group.\nC. Configure scheduled scaling to scale up to the desired compute level.\nD. Change the scaling policy to add more EC2 instances during each scaling operation. 문제 풀이\r...\rAnswer: C\r#\r정기적인 배치 작업이 필요하다면, 예약 구매를 통해 비용을 줄일 수 있습니다.\n#\r#\rQUESTION\r#\rA solutions architect is implementing a document review application using an Amazon S3 bucket for storage The solution must prevent accidental deletion of the documents and ensure that all versions of the documents are available Users must be able to download, modify, and upload documents Which combination of actions should be taken to meet these requirements? (Select TWO)\nA. Enable a read-only bucket ACL B. Enable versioning on the bucket C. Attach an IAM policy to the bucket D. Enable MFA Delete on the bucket E. Encrypt the bucket using AWS KMS 문제 풀이\r...\rAnswer: B D\r#\rExplanation Object Versioning Use Amazon S3 Versioning to keep multiple versions of an object in one bucket. For example, you could store my-image.jpg (version 111111) and my-image.jpg (version 222222) in a single bucket. S3 Versioning protects you from the consequences of unintended overwrites and deletions. You can also use it to archive objects so that you have access to previous versions. To customize your data retention approach and control storage costs, use object versioning with Object lifecycle management. For information about creating S3 Lifecycle policies using the AWS Management Console, see How Do I Create a Lifecycle Policy for an S3 Bucket?\nin the Amazon Simple Storage Service Console User Guide. If you have an object expiration lifecycle policy in your non-versioned bucket and you want to maintain the same permanent delete behavior when you enable versioning, you must add a noncurrent expiration policy. The noncurrent expiration lifecycle policy will manage the deletes of the noncurrent object versions\nin the version-enabled bucket. (A version-enabled bucket maintains one current and zero or more noncurrent object versions.) You must explicitly enable S3 Versioning on your bucket. By default, S3 Versioning is disabled. Regardless of whether you have enabled Versioning, each object in your bucket has a version ID. If you have not enabled Versioning, Amazon S3 sets the value of the version ID to null. If S3 Versioning is enabled, Amazon S3 assigns a version ID value for the object. This value distinguishes it from other versions of the same key. Enabling and suspending versioning is done at the bucket level. When you enable versioning on an existing bucket, objects that are already stored in the bucket are unchanged. The version IDs (null), contents, and permissions remain the same. After you enable S3 Versioning for a bucket, each object that is added to the bucket gets a version ID, which distinguishes it from other versions of the same key. Only Amazon S3 generates version IDs, and they can\u0026rsquo;t be edited. Version IDs are Unicode, UTF-8 encoded, URL-ready, opaque strings that are no more than 1,024 bytes long. The following is an example: 3/L4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo. Using MFA delete If a bucket\u0026rsquo;s versioning configuration is MFA Delete-enabled, the bucket owner must include the xamz-mfa request header in requests to permanently delete an object version or change the versioning state of the bucket. Requests that include x-amz-mfa must use HTTPS. The header\u0026rsquo;s value is the concatenation of your authentication device\u0026rsquo;s serial number, a space, and the authentication code displayed on it. If you do not include this request header, the request fails. https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMFADelete.html\n#\r#\rQUESTION\r#\rA company wants to migrate a high performance computing (HPC) application and data from on-premises to the AWS Cloud The company uses tiered storage on premises with hot highperformance parallel storage to support the application during periodic runs of the application and more economical cold storage to hold the data when the application is not actively running Which combination of solutions should a solutions architect recommend to support the storage needs of the application? (Select TWO )\nA. Amazon S3 for cold data storage B. Amazon EFS for cold data storage C. Amazon S3 for high-performance parallel storage D. Amazon FSx for Lustre for high-performance parallel storage E. Amazon FSx for Windows for high-performance parallel storage 문제 풀이\r...\rAnswer: A D\r#\r#\r#\rQUESTION\r#\rA company is planning to deploy an Amazon RDS DB instance running Amazon Aurora The company has a backup retention policy requirement of 90 days Which solution should a solutions architect recommend?\nA. Set the backup retention period to 90 days when creating the RDS DB instance\nB. Configure RDS to copy automated snapshots to a user-managed Amazon S3 bucket with a lifecycle policy set to delete after 90 days.\nC. Create an AWS Backup plan to perform a daily snapshot of the RDS database with the retention set to 90 days Create an AWS Backup job to schedule the execution of the backup plan daily\nD. Use a daily scheduled event with Amazon CloudWatch Events to execute a custom AWS Lambda function that makes a copy of the RDS automated snapshot Purge snapshots older than 90 days 문제 풀이\r...\rAnswer: C\r#\r백업 보존 기간은 0- 35일 입니다. 사용자 정의 S3 버킷에서 RDS 백업이 발생하지 않습니다. #\r#\rQUESTION\r#\rA company that hosts its web application on AWS wants to ensure all Amazon EC2 instances. Amazon RDS DB instances and Amazon Redshift clusters are configured with tags. The company wants to minimize the effort of configuring and operating this check.\nWhat should a solutions architect do to accomplish this?\nA. Use AWS Config rules to define and detect resources that are not property tagged\nB. Use Cost Explorer to display resources that are not properly tagged Tag those resources manually.\nC. Write API calls to check all resources for proper tag allocation. Periodically run the code on an EC2 instance.\nD. Write API calls to check all resources for proper tag allocation. Schedule an AWS Lambda function through Amazon CloudWatch to periodically run the code 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company runs multiple Amazon EC2 Linux instances in a VPC with applications that use a hierarchical directory structure. The applications need to rapidly and concurrently read and write to shared storage How can this be achieved?\nA. Create an Amazon EFS file system and mount it from each EC2 instance. B. Create an Amazon S3 bucket and permit access from all the EC2 instances in the VPC. C. Create a file system on an Amazon EBS Provisioned IOPS SSD (io1) volume. Attach the volume to all the EC2 instances. D. Create file systems on Amazon EBS volumes attached to each EC2 instance. Synchronize the Amazon EBS volumes across the different EC2 instances. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company is creating an architecture for a mobile app that requires minimal latency for its users The company\u0026rsquo;s architecture consists of Amazon EC2 instances behind an Application Load Balancer running in an Auto Scaling group The EC2 instances connect to Amazon RDS. Application beta testing showed there was a slowdown when reading the data However the metrics indicate that the EC2 instances do not cross any CPU utilization thresholds How can this issue be addressed?\nA. Reduce the threshold for CPU utilization in the Auto Scaling group B. Replace the Application Load Balancer with a Network Load Balancer. C. Add read replicas for the RDS instances and direct read traffic to the replica. D. Add Multi-AZ support to the RDS instances and direct read traffic to the new EC2 instance. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company has an application hosted on Amazon EC2 instances in two VPCs across different AWS Regions To communicate with each other, the instances use the internet for connectivity. The security team wants to ensure that no communication between the instances happens over the internet What should a solutions architect do to accomplish this?\nA. Create a NAT gateway and update the route table of the EC2 instances\u0026rsquo; subnet\nB. Create a VPC endpoint and update the route table of the EC2 instances\u0026rsquo; subnet\nC. Create a VPN connection and update the route table of the EC2 instances\u0026rsquo; subnet\nD. Create a VPC peering connection and update the route table of the EC2 instances\u0026rsquo; subnet 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company has an on-premises MySQL database used by the global sales team with infrequent access patterns. The sales team requires the database to have minimal downtime. A database administrator wants to migrate this database to AWS without selecting a particular instance type in anticipation of more users in the future. Which service should a solution architect recommend?\nA. Amazon Aurora MySQL B. Amazon Aurora Serverless for MySQL C. Amazon Redshift Spectrum D. Amazon RDS for MySQL 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company has migrated an on-premises Oracle database to an Amazon RDS (or Oracle Multi-AZ DB instance In the us-east-l Region. A solutions architect is designing a disaster recovery strategy to have the database provisioned In the us-west-2 Region In case the database becomes unavailable in the us-east-1 Region. The design must ensure the database is provisioned in the uswest-2 Region in a maximum of 2 hours, with a data loss window of no more than 3 hours. How can these requirements be met?\nA. Edit the DB instance and create a read replica in us-west-2. Promote the read replica to master In us-west-2 in case the disaster recovery environment needs to be activated. B. Select the multi-Region option to provision a standby instance in us-west-2. The standby Instance will be automatically promoted to master In us-west-2 in case the disaster recovery environment needs to be created. C. Take automated snapshots of the database instance and copy them to us-west-2 every 3 hours. Restore the latest snapshot to provision another database instance in us-west-2 in case the disaster recovery environment needs to be activated. D. Create a multimaster read/write instances across multiple AWS Regions Select VPCs in us-east-1 and us-west-2 lo make that deployment. Keep the master read/write instance in us-west-2 available to avoid having to activate a disaster recovery environment. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company must generate sales reports at the beginning of every month. The reporting process launches 20 Amazon EC2 instances on the first of the month. The process runs for 7 days and cannot be interrupted. The company wants to minimize costs. Which pricing model should the company choose?\nA. Reserved Instances\nB. Spot Block Instances\nC. On-Demand Instances\nD. Scheduled Reserved Instances 문제 풀이\r...\rAnswer: D\r#\rExplanation Scheduled Reserved Instances Scheduled Reserved Instances (Scheduled Instances) enable you to purchase capacity reservations that recur on a daily, weekly, or monthly basis, with a specified start time and duration, for a oneyear term. You reserve the capacity in advance, so that you know it is available when you need it. You pay for the time that the instances are scheduled, even if you do not use them. Scheduled Instances are a good choice for workloads that do not run continuously, but do run on a regular schedule. For example, you can use Scheduled Instances for an application that runs during business hours or for batch processing that runs at the end of the week. If you require a capacity reservation on a continuous basis, Reserved Instances might meet your needs and decrease costs. How Scheduled Instances Work Amazon EC2 sets aside pools of EC2 instances in each Availability Zone for use as Scheduled Instances. Each pool supports a specific combination of instance type, operating system, and network. To get started, you must search for an available schedule. You can search across multiple pools or a single pool. After you locate a suitable schedule, purchase it. You must launch your Scheduled Instances during their scheduled time periods, using a launch configuration that matches the following attributes of the schedule that you purchased: instance type, Availability Zone, network, and platform. When you do so, Amazon EC2 launches EC2 instances on your behalf, based on the specified launch specification. Amazon EC2 must ensure that the EC2 instances have terminated by the end of the current scheduled time period so that the capacity is available for any other Scheduled Instances it is reserved for. Therefore, Amazon EC2 terminates the EC2 instances three minutes before the end of the current scheduled time period. You can\u0026rsquo;t stop or reboot Scheduled Instances, but you can terminate them manually as needed. If you terminate a Scheduled Instance before its current scheduled time period ends, you can launch it again after a few minutes. Otherwise, you must wait until the next scheduled time period. The following diagram illustrates the lifecycle of a Scheduled Instance. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-scheduled-instances.html\n#\r#\rQUESTION\r#\rA company is looking for a solution that can store video archives in AWS from old news footage. The company needs to minimize costs and will rarely need to restore these files. When the files are needed, they must be available in a maximum of five minutes. What is the MOST cost-effective solution?\nA. Store the video archives in Amazon S3 Glacier and use Expedited retrievals.\nB. Store the video archives in Amazon S3 Glacier and use Standard retrievals.\nC. Store the video archives in Amazon S3 Standard-Infrequent Access (S3 Standard-IA).\nD. Store the video archives in Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA). 문제 풀이\r...\rAnswer: A\r#\r신속 검색을 사용해야 5분 이내에 검색이 가능합니다. #\r#\rQUESTION\r#\rA company is designing a new service that will run on Amazon EC2 instance behind an Elastic Load Balancer. However, many of the web service clients can only reach IP addresses whitelisted on their firewalls. What should a solution architect recommend to meet the clients\u0026rsquo; needs?\nA. A Network Load Balancer with an associated Elastic IP address.\nB. An Application Load Balancer with an a associated Elastic IP address\nC. An A record in an Amazon Route 53 hosted zone pointing to an Elastic IP address\nD. An EC2 instance with a public IP address running as a proxy in front of the load balancer 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has a custom application with embedded credentials that retrieves information from an Amazon RDS MySQL DB instance. Management says the application must be made more secure with the least amount of programming effort. What should a solutions architect do to meet these requirements?\nA. Use AWS Key Management Service (AWS KMS) customer master keys (CMKs) to create keys. Configure the application to load the database credentials from AWS KMS Enable automatic key rotation. B. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Create an AWS Lambda function that rotates the credentials in Secret Manager. C. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Secrets Manager. Configure the application to load the database credentials from Secrets Manager. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Secrets Manager. D. Create credentials on the RDS for MySQL database for the application user and store the credentials in AWS Systems Manager Parameter Store. Configure the application to load the database credentials from Parameter Store. Set up a credentials rotation schedule for the application user in the RDS for MySQL database using Parameter Store. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rAn ecommerce company has noticed performance degradation of its Amazon RDS based web application. The performance degradation is attribute to an increase in the number of read-only SQL queries triggered by business analysts. A solution architect needs to solve the problem with minimal changes to the existing web application. What should the solution architect recommend?\nA. Export the data to Amazon DynamoDB and have the business analysts run their queries. B. Load the data into Amazon ElasticCache and have the business analysts run their queries. C. Create a read replica of the primary database and have the business analysts run their queries. D. Copy the data into an Amazon Redshift cluster and have the business analysts run their queries. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company is running a media store across multiple Amazon EC2 instances distributed across multiple Availability Zones in a single VPC. The company wants a high-performing solution to share data between all the EC2 Instances, and prefers to keep the data within the VPC only. What should a solutions architect recommend?\nA. Create an Amazon S3 bucket and call the service APIs from each instance\u0026rsquo;s application. B. Create an Amazon S3 bucket and configure all instances to access it as a mounted volume. C. Configure an Amazon Elastic Block Store (Amazon EBS) volume and mount it across all instances. D. Configure an Amazon Elastic File System (Amazon EFS) file system and mount it across all instances 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company is running a multi-tier web application on premises. The web application is containerized and runs on a number of Linux hosts connected to a PostgreSQL database that contains user records. The operational overhead of maintaining the infrastructure and capacity planning is limiting the company\u0026rsquo;s growth A solutions architect must improve the application\u0026rsquo;s infrastructure. Which combination of actions should the solutions architect take to accomplish this? (Select TWO.)\nA. Migrate the PostgreSQL database to Amazon Aurora\nB. Migrate the web application to be hosted on Amazon EC2 instances.\nC. Set up an Amazon CloudFront distribution for the web application content.\nD. Set up Amazon ElastiCache between the web application and the PostgreSQL database\nE. Migrate the web application to be hosted on AWS Fargate with Amazon Elastic Container Service (Amazon ECS) 문제 풀이\r...\rAnswer: C D\r#\r#\r#\rQUESTION\r#\rA company has copied 1 PB of data from a colocation facility to an Amazon S3 bucket in the us-east-1 Region using an AWS Direct Connect link. The company now wants to copy the data to another S3 bucket in the us-west-2 Region. The colocation facility does not allow the use AWS Snowball. What should a solutions architect recommend to accomplish this?\nA. Order a Snowball Edge device to copy the data from one Region to another Region.\nB. Transfer contents from the source S3 bucket to a target S3 bucket using the S3 console.\nC. Use the aws S3 sync command to copy data from the source bucket to the destination bucket.\nD. Add a cross-Region replication configuration to copy objects across S3 buckets in different Reg. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing an architecture for a new application that requires low network latency and high network throughput between Amazon EC2 instances. Which component should be included in the architectural design?\nA. An Auto Scaling group with Spot Instance types.\nB. A placement group using a cluster placement strategy.\nC. A placement group using a partition placement strategy.\nD. An Auto Scaling group with On-Demand instance types. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company has a dynamic web application hosted on two Amazon EC2 instances. The company has its own SSL certificate, which is on each instance to perform SSL termination. There has been an increase in traffic recently, and the operations team determined that SSL encryption and decryption is causing the compute capacity of the web servers to reach their maximum limit. What should a solutions architect do to increase the application\u0026rsquo;s performance?\nA. Create a new SSL certificate using AWS Certificate Manager (ACM). Install the ACM certificate on each instance.\nB. Create an Amazon S3 bucket. Migrate the SSL certificate to the S3 bucket. Configure the EC2 instances to reference the bucket for SSL termination.\nC. Create another EC2 instance as a proxy server. Migrate the SSL certificate to the new instance and configure it to direct connections to the existing EC2 instances.\nD. Import the SSL certificate into AWS Certificate Manager (ACM). Create an Application Load Balancer with an HTTPS listener that uses the SSL certificate from ACM. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has on-premises servers running a relational database The current database serves high read traffic for users in different locations The company wants to migrate to AWS with the least amount of effort The database solution should support disaster recovery and not affect the company\u0026rsquo;s current traffic flow. Which solution meets these requirements?\nA. Use a database in Amazon RDS with Multi-AZ and at least one read replica\nB. Use a database in Amazon RDS with Multi-AZ and at least one standby replica\nC. Use databases hosted on multiple Amazon EC2 instances in different AWS Regions\nD. Use databases hosted on Amazon EC2 instances behind an Application Load Balancer in different Availability Zones 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company\u0026rsquo;s production application runs online transaction processing (OLTP) transactions on an Amazon RDS MySQL DB instance The company is launching a new reporting tool that will access the same data The reporting tool must be highly available and not impact the performance of the production application. How can this be achieved?\nA. Create hourly snapshots of the production RDS DB instance\nB. Create a Multi-AZ RDS Read Replica of the production RDS DB instance\nC. Create multiple RDS Read Replicas of the production RDS DB instance Place the Read Replicas in an Auto Scaling group\nD. Create a Single-AZ RDS Read Replica of the production RDS DB instance Create a second Single-AZ RDS Read Replica from the replica 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company hosts its static website content from an Amazon S3 bucket in the us-east-1 Region. Content is made available through an Amazon CloudFront origin pointing to that bucket Cross-Region replication is set up to create a second copy of the bucket in the ap-southeast-1 Region. Management wants a solution that provides greater availability for the website. Which combination of actions should a solutions architect take to increase availability? (Select TWO.)\nA. Add both buckets to the CloudFront origin\nB. Configure failover routing in Amazon Route 53\nC. Create a record in Amazon Route 53 pointing to the replica bucket\nD. Create an additional CloudFront origin pointing to the ap-southeast-1 bucket\nE. Set up a CloudFront origin group with the us-east-1 bucket as the primary and the ap-southeast-1 bucket as the secondary 문제 풀이\r...\rAnswer: D E\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing a web application that will run on Amazon EC2 instances behind an Application Load Balancer (ALB) The company strictly requires that the application be resilient against malicious internet activity and attacks, and protect against new common vulnerabilities and exposures What should the solutions architect recommend?\nA. Leverage Amazon CloudFront with the ALB endpoint as the origin\nB. Deploy an appropriate managed rule for AWS WAF and associate it with the ALB\nC. Subscribe to AWS Shield Advanced and ensure common vulnerabilities and exposures are blocked\nD. Configure network ACLs and security groups to allow only ports 80 and 443 to access the EC2 instances 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company captures clickstream data from multiple websites and analyzes it using batch processing. The data is loaded nightly into Amazon Redshift and is consumed by business analysts. The company wants to move towards near-real-time data processing for timely insights. The solution should process the streaming data with minimal effort and operational overhead. Which combination of AWS services are MOST cost-effective for this solution? (Choose two.)\nA. Amazon EC2\nB. AWS Lambda\nC. Amazon Kinesis Data Streams\nD. Amazon Kinesis Data Firehose\nE. Amazon Kinesis Data Analytics 문제 풀이\r...\rAnswer: D E\r#\rExplanation Kinesis Data Streams and Kinesis Client Library (KCL) - Data from the data source can be continuously captured and streamed in near real-time using Kinesis Data Streams. With the Kinesis Client Library (KCL), you can build your own application that can preprocess the streaming data as they arrive and emit the data for generating incremental views and downstream analysis. Kinesis Data Analytics - This service provides the easiest way to process the data that is streaming through Kinesis Data Stream or Kinesis Data Firehose using SQL. This enables customers to gain actionable insight in near real-time from the incremental stream before storing it in Amazon S3.\nhttps://d1.awsstatic.com/whitepapers/lambda-architecure-on-for-batch-aws.pdf\n#\r#\rQUESTION\r#\rA company has media and application files that need to be shared internally. Users currently are authenticated using Active Directory and access files from a Microsoft Windows platform. The chief execute officer wants to keep the same user permissions, but wants the company to improve the process as the company is reaching its storage capacity limit. What should a solutions architect recommend?\nA. Set up a corporate Amazon S3 bucket and move and media and application files.\nB. Configure Amazon FSx for Windows File Server and move all the media and application files.\nC. Configure Amazon Elastic File System (Amazon EFS) and move all media and application files.\nD. Set up Amazon EC2 on Windows, attach multiple Amazon Elastic Block Store (Amazon EBS) volumes and, and move all media and application files. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company\u0026rsquo;s packaged application dynamically creates and returns single-use text files in response to user requests. The company is using Amazon CloudFront for distribution, but wants to future reduce data transfer costs. The company modify the application\u0026rsquo;s source code. What should a solution architect do to reduce costs?\nA. Use Lambda adage to compress the files as they are sent to users.\nB. Enable Amazon S3 Transfer Acceleration to reduce the response times.\nC. Enable caching on the CloudFront distribution to store generated files at the edge.\nD. Use Amazon S3 multipart uploads to move the files to Amazon S3 before returning them to users. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has 150 TB of archived image data stored on-premises that needs to be mowed to the AWS Cloud within the next month. The company\u0026rsquo;s current network connection allows up to 100 Mbps uploads for this purpose during the night only. What is the MOST cost-effective mechanism to move this data and meet the migration deadline?\nA. Use AWS Snowmobile to ship the data to AWS.\nB. Order multiple AWS Snowball devices to ship the data to AWS.\nC. Enable Amazon S3 Transfer Acceleration and securely upload the data.\nD. Create an Amazon S3 VPC endpoint and establish a VPN to upload the data. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company is migrating to the AWS Cloud. A file server is the first workload to migrate. Users must be able to access the file share using the Server Message Block (SMB) protocol. Which AWS managed service meets these requirements?\nA. Amazon EBS\nB. Amazon EC2\nC. Amazon FSx\nD. Amazon S3 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA solutions architect is using Amazon S3 to design the storage architecture of a new digital media application. The media files must be resilient to the loss of an Availability Zone Some files are accessed frequently while other files are rarely accessed in an unpredictable pattern. The solutions architect must minimize the costs of storing and retrieving the media files. Which storage option meets these requirements?\nA. S3 Standard\nB. S3 Intelligent-Tiering\nC. S3 Standard-Infrequent Access {S3 Standard-IA)\nD. S3 One Zone-Infrequent Access (S3 One Zone-IA) 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company has application running on Amazon EC2 instances in a VPC. One of the applications needs to call an Amazon S3 API to store and read objects. The company\u0026rsquo;s security policies restrict any internet-bound traffic from the applications. Which action will fulfill these requirements and maintain security?\nA. Configure an S3 interface endpoint.\nB. Configure an S3 gateway endpoint.\nC. Create an S3 bucket in a private subnet.\nD. Create an S3 bucket in the same Region as the EC2 instance. 문제 풀이\r...\rAnswer: B\r#\rExplanation VPC endpoints A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by AWS PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC do not require public IP addresses to communicate with resources in the service. Traffic between your VPC and the other service does not leave the Amazon network. An interface endpoint is an elastic network interface with a private IP address from the IP address range of your subnet that serves as an entry point for traffic destined to a supported service. Interface endpoints are powered by AWS PrivateLink, a technology that enables you to privately access services by using private IP addresses. AWS PrivateLink restricts all network traffic between your VPC and services to the Amazon network. You do not need an internet gateway, a NAT device, or a virtual private gateway. https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html\n#\r#\rQUESTION\r#\rA company is planning to build a new web application on AWS. The company expects predictable traffic most of the year and very high traffic on occasion. The web application needs to be highly available and fault tolerant with minimal latency. What should a solutions architect recommend to meet these requirements?\nA. Use an Amazon Route 53 routing policy to distribute requests to two AWS Regions, each with one Amazon EC2 instance.\nB. Use Amazon EC2 instances in an Auto Scaling group with an Application Load Balancer across multiple Availability Zones.\nC. Use Amazon EC2 instances in a cluster placement group with an Application Load Balancer across multiple Availability Zones.\nD. Use Amazon EC2 instances in a cluster placement group and include the cluster placement group within a new Auto Scaling group. 문제 풀이\r...\rAnswer: B\r#\r클러스터는 다중 AZ를 지원하지 않습니다. #\r#\rQUESTION\r#\rA company has created an isolated backup of its environment in another Region. The application is running in warm standby mode and is fronted by an Application Load Balancer (ALB). The current failover process is manual and requires updating a DNS alias record to point to the secondary ALB in another Region. What should a solution architect do to automate the failover process?\nA. Enable an ALB health check\nB. Enable an Amazon Route 53 health check.\nC. Crate an CNAME record on Amazon Route 53 pointing to the ALB endpoint.\nD. Create conditional forwarding rules on Amazon Route 53 pointing to an internal BIND DNS server. 문제 풀이\r...\rAnswer: B\r#\rALB는 다른 지역에서 확장 할 수 없습니다. #\r#\rQUESTION\r#\rA solutions architect is deploying a distributed database on multiple Amazon EC2 instances The database stores all data on multiple instances so it can withstand the loss of an instance The database requires block storage with latency and throughput to support several million transactions per second per server Which storage solution should the solutions architect use?\nA. Amazon EBS\nB. Amazon EC2 instance store\nC. Amazon EFS\nD. Amazon S3 문제 풀이\r...\rAnswer: B\r#\rExplanation https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html\n#\r#\rQUESTION\r#\rA solutions architect is designing a VPC with public and private subnets. The VPC and subnets use IPv4 CIDR blocks. There is one public subnet and one private subnet in each of three Availability Zones (AZs) for high availability. An interne! gateway is used to provide internet access for the public subnets. The private subnets require access to the internet to allow Amazon EC2 instances to download software updates. What should the solutions architect do to enable internet access for the private subnets?\nA. Create three NAT gateways, one for each public subnet in each AZ. Create a private route table for each AZ that forwards non-VPC traffic to the NAT gateway in its AZ B. Create three NAT instances, one for each private subnet in each AZ. Create a private route table for each AZ that forwards non-VPC traffic to the NAT instance in its AZ C. Create a second internet gateway on one of the private subnets. Update the route table for the private subnets that forward non-VPC traffic to the private internet gateway D. Create an egress only internet gateway on one of the public subnets. Update the route table for the private subnets that forward non-VPC traffic to the egress only internet gateway 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing a new service behind Amazon API Gateway The request patterns for the service will be unpredictable and can change suddenly from 0 requests to over 500 per second The total size of the data that needs to be persisted in a backend database is currently less than 1 GB with unpredictable future growth Data can be queried using simple key-value requests Which combination of AWS services would meet these requirements? (Select TWO )\nA. AWS Fargate B. AWS Lambda C. Amazon DynamoDB D. Amazon EC2 Auto Scaling E. MySQL-compatible Amazon Aurora 문제 풀이\r...\rAnswer: B C\r#\rExplanation https://aws.amazon.com/about-aws/whats-new/2017/11/amazon-api-gateway-supports-endpointintegrations-wit\n#\r#\rQUESTION\r#\rAn ecommerce company is running a multi-tier application on AWS. The front-end and backend tiers both run on Amazon EC2. and the database runs on Amazon RDS for MySQL. The backend tier communicates with the RDS instance. There are frequent calls to return identical datasets from the database that are causing performance slowdowns. Which action should be taken to improve the performance of the backend?\nA. Implement Amazon SNS to store the database calls. B. Implement Amazon ElastiCache to cache the large datasets. C. Implement an RDS for MySQL read replica to cache database calls. D. Implement Amazon Kinesis Data Firehose to stream the calls to the database. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA solutions architect has created a new AWS account and must secure AWS account root user access Which combination of actions will accomplish this? (Select TWO.)\nA. Ensure the root user uses a strong password\nB. Enable multi-factor authentication to the root user\nC. Store root user access keys in an encrypted Amazon S3 bucket\nD. Add the root user to a group containing administrative permissions.\nE. Apply the required permissions to the root user with an inline policy document 문제 풀이\r...\rAnswer: A B\r#\r#\r#\rQUESTION\r#\rAn ecommerce website is deploying its web application as Amazon Elastic Container Service (Amazon ECS) container instances behind an Application Load Balancer (ALB). During periods of high activity, the website slows down and availability is reduced. A solutions architect uses Amazon CloudWatch alarms to receive notifications whenever there is an availability issue so they can scale out resources. Company management wants a solution that automatically responds to such events. Which solution meets these requirements?\nA. Set up AWS Auto Scaling to scale out the ECS service when there are timeouts on the ALB Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.\nB. Set up AWS Auto Scaling to scale out the ECS service when the ALB CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.\nC. Sot up AWS Auto Scaling to scale out the ECS service when the service\u0026rsquo;s CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high.\nD. Set up AWS Auto Scaling to scale out the ECS service when the ALB target group CPU utilization is too high. Set up AWS Auto Scaling to scale out the ECS cluster when the CPU or memory reservation is too high. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has a Microsoft Windows-based application that must be migrated to AWS. This application requires the use of a shared Windows file system attached to multiple Amazon EC2 Windows instances. What should a solution architect do to accomplish this?\nA. Configure a volume using Amazon EFS Mount the EPS volume to each Windows Instance\nB. Configure AWS Storage Gateway in Volume Gateway mode Mount the volume to each Windows instance\nC. Configure Amazon FSx for Windows File Server Mount the Amazon FSx volume to each Windows Instance\nD. Configure an Amazon EBS volume with the required size Attach each EC2 instance to the volume Mount the file system within the volume to each Windows instance 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA recently created startup built a three-tier web application. The front end has static content. The application layer is based on microservices. User data is stored as JSON documents that need to be accessed with low latency. The company expects regular traffic to be low during the first year, with peaks in traffic when it publicizes new features every month. The startup team needs to minimize operational overhead costs. What should a solutions architect recommend to accomplish this?\nA. Use Amazon S3 static website hosting to store and serve the front end Use AWS Elastic Beanstalk for the application layer. Use Amazon DynamoDB to store user data. B. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon Elastic Kubernetes Service (Amazon EKS) for the application layer. Use Amazon DynamoDB to store user data. C. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon API Gateway and AWS Lambda functions for the application layer Use Amazon DynamoDB to store user data. D. Use Amazon S3 static website hosting to store and serve the front end. Use Amazon API Gateway and AWS Lambda functions for the application layer. Use Amazon RDS with read replicas to store user data. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company must migrate 20 TB of data from a data center to the AWS Cloud within 30 days. The company\u0026rsquo;s network bandwidth is limited to 15 Mbps and cannot exceed 70% utilization. What should a solutions architect do to meet these requirements?\nA. Use AWS Snowball.\nB. Use AWS DataSync.\nC. Use a secure VPN connection.\nD. Use Amazon S3 Transfer Acceleration. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company is managing health records on-premises. The company must keep these records indefinitely, disable any modifications to the records once they are stored, and granularly audit access at all levels. The chief technology officer (CTO) is concerned because there are already millions of records not being used by any application, and the current infrastructure is running out of space The CTO has requested a solutions architect design a solution to move existing data and support future records Which services can the solutions architect recommend to meet these requirements'?\nA. Use AWS DataSync to move existing data to AWS. Use Amazon S3 to store existing and new data Enable Amazon S3 object lock and enable AWS CloudTrail with data events.\nB. Use AWS Storage Gateway to move existing data to AWS Use Amazon S3 to store existing and new data. Enable Amazon S3 object lock and enable AWS CloudTrail with management events.\nC. Use AWS DataSync to move existing data to AWS Use Amazon S3 to store existing and new data Enable Amazon S3 object lock and enable AWS CloudTrail with management events.\nD. Use AWS Storage Gateway to move existing data to AWS Use Amazon Elastic Block Store (Amazon EBS) to store existing and new data Enable Amazon S3 object lock and enable Amazon S3 server access logging 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing a mission-critical web application. It will consist of Amazon EC2 instances behind an Application Load Balancer and a relational database. The database should be highly available and fault tolerant. Which database implementations will meet these requirements? (Select TWO.)\nA. Amazon Redshift B. Amazon DynamoDB C. Amazon RDS for MySQL D. MySQL-compatible Amazon Aurora Multi-AZ E. Amazon RDS for SQL Server Standard Edition Mufti-AZ 문제 풀이\r...\rAnswer: D E\r#\r#\r#\rQUESTION\r#\rA company is reviewing a recent migration of a three-tier application to a VPC. The security team discovers thai the principle of least privilege is not being applied to Amazon EC2 security group ingress and egress rules between the application tiers. What should a solutions architect do to correct this issue?\nA. Create security group rules using the instance ID as the source or destination.\nB. Create security group rules using the security group ID as the source or destination.\nC. Create security group rules using the VPC CIDR blocks as the source or destination.\nD. Create security group rules using the subnet CIDR blocks as the source or destination. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company is running an ecommerce application on Amazon EC2 The application consists of a stateless web tier that requires a minimum of 10 instances, and a peak of 250 instances to support the application\u0026rsquo;s usage The application requires 50 instances 80% of the time Which solution should be used to minimize costs?\nA. Purchase Reserved Instances to cover 250 instances\nB. Purchase Reserved Instances to cover 80 instances Use Spot Instances to cover the remaining instances\nC. Purchase On-Demand Instances to cover 40 instances Use Spot Instances to cover the remaining instances\nD. Purchase Reserved Instances to cover 50 instances Use On-Demand and Spot Instances to cover the remaining instances 문제 풀이\r...\rAnswer: D\r#\rExplanation Reserved Instances Having 50 EC2 RIs provide a discounted hourly rate and an optional capacity reservation for EC2 instances. AWS Billing automatically applies your RI\u0026rsquo;s discounted rate when attributes of EC2 instance usage match attributes of an active RI. If an Availability Zone is specified, EC2 reserves capacity matching the attributes of the RI. The capacity reservation of an RI is automatically utilized by running instances matching these attributes. You can also choose to forego the capacity reservation and purchase an RI that is scoped to a region. RIs that are scoped to a region automatically apply the RI\u0026rsquo;s discount to instance usage across AZs and instance sizes in a region, making it easier for you to take advantage of the RI\u0026rsquo;s discounted rate. On-Demand Instance On-Demand instances let you pay for compute capacity by the hour or second (minimum of 60 seconds) with no long-term commitments. This frees you from the costs and complexities of planning, purchasing, and maintaining hardware and transforms what are commonly large fixed costs into much smaller variable costs. The pricing below includes the cost to run private and public AMIs on the specified operating system\n100 (\u0026ldquo;Windows Usage\u0026rdquo; prices apply to Windows Server 2003 R2, 2008, 2008 R2, 2012, 2012 R2, 2016, and 2019). Amazon also provides you with additional instances for Amazon EC2 running Microsoft Windows with SQL Server, Amazon EC2 running SUSE Linux Enterprise Server, Amazon EC2 running Red Hat Enterprise Linux and Amazon EC2 running IBM that are priced differently. Spot Instances A Spot Instance is an unused EC2 instance that is available for less than the On-Demand price. Because Spot Instances enable you to request unused EC2 instances at steep discounts, you can lower your Amazon EC2 costs significantly. The hourly price for a Spot Instance is called a Spot price. The Spot price of each instance type in each Availability Zone is set by Amazon EC2, and adjusted gradually based on the long-term supply of and demand for Spot Instances. Your Spot Instance runs whenever capacity is available and the maximum price per hour for your request exceeds the Spot price. https://aws.amazon.com/ec2/pricing/reserved-instances/ https://aws.amazon.com/ec2/pricing/on-demand/ https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html\n#\r#\rQUESTION\r#\rA solutions architect is optimizing a website for an upcoming musical event Videos of the performances will be streamed in real time and then will be available on demand The event is expected to attract a global online audience Which service will improve the performance of both the real-time and on-demand streaming?\nA. Amazon CloudFront\nB. AWS Global Accelerator\nC. Amazon Route 53\nD. Amazon S3 Transfer Acceleration 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company runs an internal browser-based application The application runs on Amazon EC2 instances behind an Application Load Balancer The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones The Auto Scaling group scales up to 20 instances during work hours, but scales down to 2 instances overnight Staff are complaining that the application is very slow when the day begins, although it runs well by mid-morning. How should the scaling be changed to address the staff complaints and keep costs to a minimum?\nA. Implement a scheduled action that sets the desired capacity to 20 shortly before the office opens\nB. Implement a step scaling action triggered at a lower CPU threshold, and decrease the cooldown period.\nC. Implement a target tracking action triggered at a lower CPU threshold and decrease the cooldown period\nD. Implement a scheduled action that sets the minimum and maximum capacity to 20 shortly before the office opens 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company wants to build a scalable key management infrastructure to support developers who need to encrypt data in their applications. What should a solutions architect do to reduce the operational burden?\nA. Use multi-factor authentication (MFA) to protect the encryption keys B. Use AWS Key Management Service (AWS KMS) to protect the encryption keys C. Use AWS Certificate Manager (ACM) to create, store and assign the encryption keys D. Use an IAM policy to limit the scope of users who have access permissions to protect the encryption keys 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company runs a production application on a fleet of Amazon EC2 instances The application reads the data from an Amazon SQS queue and processes the messages in parallel. The message volume is unpredictable and often has intermittent traffic. This application should continually process messages without any downtime Which solution meets these requirements MOST cost-effectively?\nA. Use Spot Instances exclusively to handle the maximum capacity required B. Use Reserved Instances exclusively to handle the maximum capacity required C. Use Reserved Instances for the baseline capacity and use Spot InstaKes to handle additional capacity D. Use Reserved instances for the baseline capacity and use On-Demand Instances to handle additional capacity 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA solutions architect must create a highly available bastion host architecture. The solution needs to be resilient within a single AWS Region and should require only minimal effort to maintain. What should the solutions architect do to meet these requirements?\nA. Create a Network Load Balancer backed by an Auto Scaling group with a UDP listener. B. Create a Network Load Balancer backed by a Spot Fleet with instances in a group with instances in a partition placement group. C. Create a Network Load Balancer backed by the existing serves in different Availability Zones as the target. D. Create a Network Load Balancer backed by an Auto Scaling with instances in multiple Availability zones as the target 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA development team needs to host a website that will be accessed by other teams. The website contents.consist of HTML, CSS, client side JavaScript, and images. Which method is the MOST cost-effective for hosting the website?\nA. Containerize the website and host it in AWS Fargate\nB. Create an Amazon S3 bucket and host the website there.\nC. Deploy a web server on an Amazon EC2 instance to host the website.\nD. Configure an Application Load Balancer with an AWS Lambda target that uses the Express is framework 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\ra website on Amazon S3. The website serves petabytes of outbound traffic monthly, which accounts for most of the company\u0026rsquo;s AWS costs. What should a solutions architect do to reduce costs?\nA. Configure Amazon CloudFront with the existing website as the origin.\nB. Move the website to Amazon EC2 with Amazon EBS volumes for storage.\nC. Use AWS Global Accelerator and specify the existing website as the endpoint.\nD. Rearchitect the website to run on a combination of Amazon API Gateway and AWS Lambda. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA public-facing web application queries a database hosted on a Amazon EC2 instance in a private subnet. A large number of queries involve multiple table joins, and the application performance has been degrading due to an increase in complex queries. The application team will be performing updates to improve performance. What should a solutions architect recommend to the application team? (Select TWO.)\nA. Cache query data in Amazon SQS B. Create a read replica to offload queries C. Migrate the database to Amazon Athena D. Implement Amazon DynamoDB Accelerator to cache data. E. Migrate the database to Amazon RDS 문제 풀이\r...\rAnswer: B E\r#\rB E\n#\r#\rQUESTION\r#\rA solutions architect needs to ensure that API calls to Amazon DynamoDB from Amazon EC2 instances in a VPC do not traverse the internet What should the solutions architect do to accomplish this? (Select TWO )\nA. Create a route table entry for the endpoint B. Create a gateway endpoint for DynamoDB C. Create a new DynamoDB table that uses the endpoint D. Create an ENI for the endpoint in each of the subnets of the VPC E. Create a security group entry in the default security group to provide access 문제 풀이\r...\rAnswer: A B\r#\rExplanation A VPC endpoint enables you to privately connect your VPC to supported AWS services and VPC endpoint services powered by AWS PrivateLink without requiring an internet gateway, NAT device, VPN connection, or AWS Direct Connect connection. Instances in your VPC do not require public IP addresses to communicate with resources in the service. Traffic between your VPC and the other service does not leave the Amazon network. Gateway endpoints A gateway endpoint is a gateway that you specify as a target for a route in your route table for traffic destined to a supported AWS service. The following AWS services are supported: Amazon S3 DynamoDB https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html\n#\r#\rQUESTION\r#\rA company has a large Microsoft SharePoint deployment running on-premises that requires Microsoft Windows shared file storage. The company wants to migrate this workload to the AWS Cloud and is considering various storage options. The storage solution must be highly available and integrated with Active Directory for access control. Which solution will satisfy these requirements?\nA. Configure Amazon EFS storage and set the Active Directory domain for authentication. B. Create an SMB file share on an AWS Storage Gateway file gateway in two Availability Zones. C. Create an Amazon S3 bucket and configure Microsoft Windows Server to mount it as a volume. D. Create an Amazon FSx for Windows File Server file system on AWS and set the Active Directory domain for authentication. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company is running an online transaction processing (OLTP) workload on AWS. This workload uses an unencrypted Amazon RDS DB instance in a Multi-AZ deployment. Daily database snapshots are taken from this instance. What should a solutions architect do to ensure the database and snapshots are always encrypted moving forward?\nA. Encrypt a copy of the latest DB snapshot. Replace existing DB instance by restoring the encrypted snapshot. B. Create a new encrypted Amazon Elastic Block Store (Amazon EBS) volume and copy the snapshots lo it. Enable encryption on the DB instance. C. Copy the snapshots and enable encryption using AWS Key Management Service (AWS KMS). Restore encrypted snapshot to an existing DB instance. D. Copy the snapshots to an Amazon S3 bucket that is encrypted using server-side encryption with AWS Key Management Service (AWS KMS) managed keys (SSE-KMS). 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company wants to host its web application on AWS using multiple Amazon EC2 instances across different AWS Regions Since the application content will be specific to each geographic region, the client requests need to be routed to the server that hosts the content for that clients Region. What should a solutions architect do to accomplish this?\nA. Configure Amazon Route 53 with a latency routing policy. B. Configure Amazon Route 53 with a weighted routing policy. C. Configure Amazon Route 53 with a geolocation routing policy D. Configure Amazon Route 53 with a multivalue answer routing policy 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA mobile gaming company runs application servers on Amazon EC2 instances. The servers receive updates from players every 15 minutes. The mobile game creates a JSON object of the progress made in the game since the last update, and sends the JSON object to an Application Load Balancer. As the mobile game is played, game updates are being lost. The company wants to create a durable way to get the updates in older. What should a solutions architect recommend to decouple the system?\nA. Use Amazon Kinesis Data Streams to capture the data and store the JSON object in Amazon S3. B. Use Amazon Kinesis Data Firehose to capture the data and store the JSON object in Amazon S3. C. Use Amazon Simple Queue Service (Amazon SQS) FIFO queues to capture the data and EC2 instances to process the messages in the queue. D. Use Amazon Simple Notification Service (Amazon SNS) to capture the data and EC2 instances to process the messages sent to the Application Load Balancer. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company is planning to migrate a legacy application to AWS. The application currently uses NFS to communicate to an on-premises storage solution to store application data. The application cannot be modified to use any other communication protocols other than NFS for this purpose. Which storage solution should a solutions architect recommend for use after the migration?\nA. AWS DataSync B. Amazon Elastic Block Store (Amazon EBS) C. Amazon Elastic File System (Amazon EFS) D. Amazon EMR File System (Amazon EMRFS) 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA solutions architect is moving the static content from a public website hosted on Amazon EC2 instances to an Amazon S3 bucket. An Amazon CloudFront distribution will be used to deliver the static assets. The security group used by the EC2 instances restricts access to a limited set of IP ranges. Access to the static content should be similarly restricted. Which combination of steps will meet these requirements? (Select TWO.)\nA. Create an origin access identity (OAI) and associate it with the distribution. Change the permissions in the bucket policy so that only the OAI can read the objects. B. Create an AWS WAF web ACL that includes the same IP restrictions that exist in the EC2 security group. Associate this new web ACL with the CloudFront distribution. C. Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the CloudFront distribution. D. Create a new security group that includes the same IP restrictions that exist in the current EC2 security group. Associate this new security group with the S3 bucket hosting the static content. E. Create a new IAM role and associate the role with the distribution. Change the permissions either on the S3 bucket or on the files within the S3 bucket so that only the newly created IAM role has read and download permissions. 문제 풀이\r...\rAnswer: A B\r#\r#\r#\rQUESTION\r#\rA company wants to deploy a shared file system for its .NET application servers and Microsoft SQL Server database running on Amazon EC2 instance with Windows Server 2016. The solution must be able to be integrated in to the corporate Active Directory domain, be highly durable, be managed by AWS, and provided levels of throuput and IOPS. Which solution meets these requirements?\nA. Use Amazon FSx for Windows File Server B. Use Amazon Elastic File System (Amazon EFS) C. Use AWS Storage Gateway in file gateway mode. D. Deploy a Windows file server on two On Demand instances across two Availability Zones. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company that develops web applications has launched hundreds of Application Load Balancers (ALBs) in multiple Regions. The company wants to create an allow list (or the IPs of all the load balancers on its firewall device. A solutions architect is looking for a one-time, highly available solution to address this request, which will also help reduce the number of IPs that need to be allowed by the firewall. What should the solutions architect recommend to meet these requirements?\nA. Create a AWS Lambda function to keep track of the IPs for all the ALBs in different Regions Keep refreshing this list. B. Set up a Network Load Balancer (NLB) with Elastic IPs. Register the private IPs of all the ALBs as targets to this NLB. C. Launch AWS Global Accelerator and create endpoints for all the Regions. Register all the ALBs in different Regions to the corresponding endpoints D. Set up an Amazon EC2 instance, assign an Elastic IP to this EC2 instance, and configure the instance as a proxy to forward traffic to all the ALBs. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA recent analysis of a company\u0026rsquo;s IT expenses highlights the need to reduce backup costs. The company\u0026rsquo;s chief information officer wants to simplify the on-premises backup infrastructure and reduce costs by eliminating the use of physical backup tapes. The company must preserve the existing investment in the on-premises backup applications and workflows. What should a solutions architect recommend?\nA. Set up AWS Storage Gateway to connect with the backup applications using the NFS interface. B. Set up an Amazon EFS file system that connects with the backup applications using the NFS interface C. Set up an Amazon EFS file system that connects with the backup applications using the iSCSI interface D. Set up AWS Storage Gateway to connect with the backup applications using the iSCSI-virtual tape library (VTL) interface. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company wants to share forensic accounting data is stored in an Amazon RDS DB instance with an external auditor. The Auditor has its own AWS account and requires its own copy of the database. How should the company securely share the database with the auditor?\nA. Create a read replica of the database and configure IAM standard database authentication to grant the auditor access. B. Copy a snapshot of the database to Amazon S3 and assign an IAM role to the auditor to grant access to the object in that bucket. C. Export the database contents to text files, store the files in Amazon S3, and create a new IAM user for the auditor with access to that bucket. D. Make an encrypted snapshot of the database, share the snapshot, and allow access to the AWS Key Management Service (AWS KMS) encryption key. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company has a 10 Gbps AWS Direct Connect connection from its on-premises servers to AWS. The workloads using the connection are critical. The company requires a disaster recovery strategy with maximum resiliency that maintains the current connection bandwidth at a minimum. What should a solutions architect recommend?\nA. Set up a new Direct Connect connection in another AWS Region. B. Set up a new AWS managed VPN connection in another AWS Region. C. Set up two new Direct Connect connections: one in the current AWS Region and one in another Region. D. Set up two new AWS managed VPN connections: one in the current AWS Region and one in another Region. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has created a VPC with multiple private subnets in multiple Availability Zones (AZs) and one public subnet in one of the AZs. The public subnet is used to launch a NAT gateway. There are instance in the private subnet that use a NAT gateway to connect to the internet. In case is used of an AZ failure, the company wants to ensure that the instance are not all experiencing internet connectivity issues and that there is a backup plan ready. Which solution should a solutions architect recommend that is MOST highly available?\nA. Create a new public subnet with a NAT gateway in the same AZ Distribute the traffic between the two NAT gateways B. Create an Amazon EC2 NAT instance in a now public subnet Distribute the traffic between the NAT gateway and the NAT instance C. Create public subnets In each AZ and launch a NAT gateway in each subnet Configure the traffic from the private subnets In each A2 to the respective NAT gateway D. Create an Amazon EC2 NAT instance in the same public subnet Replace the NAT gateway with the NAT instance and associate the instance with an Auto Scaling group with an appropriate scaling policy. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA solutions architect is tasked with transferring 750 TB of data from a network-attached file system located at a branch office to Amazon S3 Glacier The solution must avoid saturating the branch office\u0026rsquo;s low-bandwidth internet connection What is the MOST cost-effective solution1?\nA. Create a site-to-site VPN tunnel to an Amazon S3 bucket and transfer the files directly Create a bucket policy to enforce a VPC endpoint B. Order 10 AWS Snowball appliances and select an S3 Glacier vault as the destination Create a bucket policy to enforce a VPC endpoint C. Mount the network-attached file system to Amazon S3 and copy the files directly. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier D. Order 10 AWS Snowball appliances and select an Amazon S3 bucket as the destination. Create a lifecycle policy to transition the S3 objects to Amazon S3 Glacier 문제 풀이\r...\rAnswer: D\r#\rExplanation Regional Limitations for AWS Snowball The AWS Snowball service has two device types, the standard Snowball and the Snowball Edge. The following table highlights which of these devices are available in which regions. Limitations on Jobs in AWS Snowball The following limitations exist for creating jobs in AWS Snowball: For security purposes, data transfers must be completed within 90 days of the Snowball being prepared. Currently, AWS Snowball Edge device doesn\u0026rsquo;t support server-side encryption with customer-provided keys (SSE-C). AWS Snowball Edge device does support server-side encryption with Amazon S3- managed encryption keys (SSE-S3) and server-side encryption with AWS Key Management Servicemanaged keys (SSE-KMS). For more information, see Protecting Data Using Server-Side Encryption in the Amazon Simple Storage Service Developer Guide. In the US regions, Snowballs come in two sizes: 50 TB and 80 TB. All other regions have the 80 TB Snowballs only. If you\u0026rsquo;re using Snowball to import data, and you need to transfer more data than will fit on a single Snowball, create additional jobs. Each export job can use multiple Snowballs. The default service limit for the number of Snowballs you can have at one time is 1. If you want to increase your service limit, contact AWS Support. All objects transferred to the Snowball have their metadata changed. The only metadata that remains the same is filename and filesize. All other metadata is set as in the following example: -rw-rw-r\u0026ndash; 1 root root [filesize] Dec 31 1969 [path/filename] Object lifecycle management To manage your objects so that they are stored cost effectively throughout their lifecycle, configure their Amazon S3 Lifecycle. An S3 Lifecycle configuration is a set of rules that define actions that Amazon S3 applies to a group of objects. There are two types of actions: Transition actions-Define when objects transition to another storage class. For example, you might choose to transition objects to the S3 Standard-IA storage class 30 days after you created them, or archive objects to the S3 Glacier storage class one year after creating them. Expiration actions-Define when objects expire. Amazon S3 deletes expired objects on your behalf. The lifecycle expiration costs depend on when you choose to expire objects. https://docs.aws.amazon.com/snowball/latest/ug/limits.html https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html\n#\r#\rQUESTION\r#\rA solution architect is designing a hybrid application using the AWS cloud. The network between the on-premises data center and AWS will use an AWS Direct Connect (DX) connection. The application connectivity between AWS and the on-premises data center must be highly resilient. Which DX configuration should be implemented to meet these requirements?\nA. Configure a DX connection with a VPN on top of it. B. Configure DX connections at multiple DX locations. C. Configure a DX connection using the most reliable DX partner. D. Configure multiple virtual interfaces on top of a DX connection. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company has implemented one of its microservices on AWS Lambda that accesses an Amazon DynamoDB table named Books. A solutions architect is design an IAM policy to be attached to the Lambda function\u0026rsquo;s IAM role, giving it access to put, update, and delete items in the Books table. the IAM policy must prevent function from performing any other actions on the Books table or any other. Which IAM policy would fulfill these needs and provide the LEAST privileged access?\nA. Option A\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PutUpdateDeleteOnBooks\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb: PutItem\u0026#34;, \u0026#34;dynamodb: UpdateItem\u0026#34;, \u0026#34;dynamodb: DeleteItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/Books\u0026#34; } ] } #\rB. Option B\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PutUpdateDeleteOnBooks\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb: PutItem\u0026#34;, \u0026#34;dynamodb: UpdateItem\u0026#34;, \u0026#34;dynamodb: DeleteItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/*\u0026#34; } ] } #\rC. Option C\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PutUpdateDeleteOnBooks\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb: *\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/Books\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;PutUpdateDeleteOnBooks\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb: *\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/Books\u0026#34; }, ] } #\rD. Option D\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PutUpdateDeleteOnBooks\u0026#34;, \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;dynamodb: PutItem\u0026#34;, \u0026#34;dynamodb: UpdateItem\u0026#34;, \u0026#34;dynamodb: DeleteItem\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/Books\u0026#34; } ] } 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has applications hosted on Amazon EC2 instances with IPv6 addresses. The applications must initiate communications with other external applications using the internet. However, the company\u0026rsquo;s security policy states that any external service cannot initiate a connection to the EC2 instances. What should a solutions architect recommend to resolve this issue?\nA. Create a NAT gateway and make it the destination of the subnet\u0026rsquo;s route table B. Create an internet gateway and make it the destination of the subnet\u0026rsquo;s route table C. Create a virtual private gateway and make it the destination of the subnet\u0026rsquo;s route table D. Create an egress-only internet gateway and make it the destination of the subnet\u0026rsquo;s route table 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company has an application that generates a large number of files, each approximately 5 MB in size. The files are stored in Amazon S3. Company policy requires the files to be stored for 4 years before they can be deleted. Immediate accessibility is always required as the files contain critical business data that is not easy to reproduce. The files are frequently accessed in the first 30 days of the object creation but are rarely accessed after the first 30 days. Which storage solution is MOST cost-effective?\nA. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Glacier 30 days from object creation. Delete the files 4 years after object creation. B. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 One Zone-Infrequent Access (S3 One Zone-IA) 30 days from object creation. Delete the files 4 years after object creation. C. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Delete the files 4 years after object creation. D. Create an S3 bucket lifecycle policy to move files from S3 Standard to S3 Standard-Infrequent Access (S3 Standard-IA) 30 days from object creation. Move the files to S3 Glacier 4 years after object creation. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing a new API using Amazon API Gateway that will receive requests from users The volume of requests is highly variable, several hours can pass without receiving a single request The data processing will take place asynchronously but should be completed within a few seconds after a request is made Which compute service should the solutions architect have the API invoke to deliver the requirements at the lowest cost?\nA. An AWS Glue job B. An AWS Lambda function C. A containerized service hosted in Amazon Elastic Kubernetes Service (Amazon EKS) D. A containerized service hosted in Amazon ECS with Amazon EC2 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company has a three-tier image-sharing application it uses an Amazon EC2 instance for the front-end layer, another for the backend tier, and a third for the MySQL database A solutions architect has been tasked with designing a solution that is highly available, and requires the least amount of changes to the application.\nWhich solution meets these requirements?\nA. Use Amazon S3 to host the front-end layer and AWS Lambda functions for the backend layer Move the database to an Amazon DynamoDB table and use Amazon S3 to store and serve users\u0026rsquo; images B. Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end and backend layers Move the database to an Amazon RDS instance with multiple read replicas to store and serve users\u0026rsquo; images. C. Use Amazon S3 to host the front-end layer and a fleet of Amazon EC2 instances in an Auto Scaling group for the backend layer Move the database to a memory optimized instance type to store and serve users\u0026rsquo; images D. Use load-balanced Multi-AZ AWS Elastic Beanstalk environments for the front-end and backend layers Move the database to an Amazon RDS instance with a Multi-AZ deployment Use Amazon S3 to store and serve users\u0026rsquo; images 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company has data stored in an on-premises data center that is used by several onpremises applications. The company wants to maintain its existing application environment and be able to use AWS services for data analytics and future visualizations. Which storage service should a solutions architect recommend?\nA. Amazon Redshift B. AWS Storage Gateway for files C. Amazon Elastic Block Store (Amazon EBS) D. Amazon Elastic File System (Amazon EFS) 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing a two-tier web application The application consists of a public-facing web tier hosted on Amazon EC2 in public subnets The database tier consists of Microsoft SQL Server running on Amazon EC2 in a private subnet Security is a high priority for the company How should security groups be configured in this situation? (Select TWO )\nA. Configure the security group for the web tier to allow inbound traffic on port 443 from 0 0 0 0/0 B. Configure the security group for the web tier to allow outbound traffic on port 443 from 0 0 0 0/0 C. Configure the security group for the database tier to allow inbound traffic on port 1433 from the security group for the web tier D. Configure the security group for the database tier to allow outbound traffic on ports 443 and 1433 to the security group for the web tier E. Configure the security group for the database tier to allow inbound traffic on ports 443 and 1433 from the security group for the web tier 문제 풀이\r...\rAnswer: A C\r#\r#\r#\rQUESTION\r#\rA company recently launched its website to serve content to its global user base. The company wants to store and accelerate the delivery of static content to its users by leveraging Amazon CloudFront with an Amazon EC2 instance attached as its origin. How should a solutions architect optimize high availability for the application?\nA. Use Lambda@Edge for CloudFront. B. Use Amazon S3 Transfer Acceleration for CloudFront. C. Configure another EC2 instance in a different Availability Zone as part of the origin group. D. Configure another EC2 instance as part of the origin server cluster in the same Availability Zone. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company has two AWS accounts Production and Development There are code changes ready in the Development account to push to the Production account In the alpha phase, only two senior developers on the development team need access to the Production account in the beta phase, more developers might need access to perform testing as well. What should a solutions architect recommend?\nA. Create two policy documents using the AWS Management Console in each account Assign the policy to developers who need access B. Create an IAM role in the Development account Give one IAM role access to the Production account Allow developers to assume the role C. Create an IAM role in the Production account with the trust policy that specifies the Development account. Allow developers to assume the role. D. Create an IAM group in the Production account and add it as a principal in the trust policy that specifies the Production account Add developers to the group 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company\u0026rsquo;s dynamic website is hosted using on-premises servers in the United States. The company is launching its product in Europe and it wants to optimize site loading times for new European users. The site\u0026rsquo;s backend must remain in the United States. The product is being launched in a few days, and an immediate solution is needed What should the solutions architect recommend?\nA. Launch an Amazon EC2 instance in us-east-1 and migrate the site to it B. Move the website to Amazon S3 Use cross-Region replication between Regions. C. Use Amazon CloudFront with a custom origin pointing to the on-premises servers D. Use an Amazon Route 53 geoproximity routing policy pointing to on-premises servers 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA recently acquired company is required to build its own infrastructure on AWS and migrate multiple applications to the cloud within a month Each application has approximately 50 TB of data to be transferred After the migration is complete this company and its parent company will both require secure network connectivity with consistent throughput from their data centers to the applications A solutions architect must ensure one-time data migration and ongoing network connectivity Which solution will meet these requirements?\nA. AWS Direct Connect for both the initial transfer and ongoing connectivity B. AWS Site-to-Site VPN for both the initial transfer and ongoing connectivity C. AWS Snowball for the initial transfer and AWS Direct Connect for ongoing connectivity D. AWS Snowball for the initial transfer and AWS Site-to-Site VPN for ongoing connectivity 문제 풀이\r...\rAnswer: C\r#\rExplanation https://aws.amazon.com/directconnect/\n#\r#\rQUESTION\r#\rA company currently has 250 TB of backup files stored in Amazon S3 in a vendor\u0026rsquo;s proprietary format. Using a Linux-based software application provided by the vendor, the company wants to retrieve files from Amazon S3, transform the files to an industry-standard format, and reupload them to Amazon S3. The company wants to minimize the data transfer charges associated with this conversation. What should a solution architect do to accomplish this?\nA. Install the conversion software as an Amazon S3 batch operation so the data is transformed without leaving Amazon S3. B. Install the conversion software onto an on-premises virtual machines. Perform the transformation and re-upload the files to Amazon S3 from the virtual machine. C. Use AWS Snowball Edge device to expert the data and install the conversion software onto the devices. Perform the data transformation and re-upload the files to Amazon S3 from the Snowball devices. D. Launch an Amazon EC2 instance in the same Region as Amazon S3 and install the conversion software onto the instance. Perform the transformation and re-upload the files to Amazon S3 from the EC2 instance. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company uses Amazon Redshift for its data warehouse. The company wants to ensure high durability for its data in case of any component failure. What should a solutions architect recommend?\nA. Enable concurrency seating. B. Enable cross-Region snapshots. C. Increase the data retention period. D. Deploy Amazon Redshift in Multi-AZ. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company is hosting a web application on AWS using a single Amazon EC2 instance that stores user-uploaded documents in an Amazon EBS volume For better scalability and availability the company duplicated the architecture and created a second EC2 instance and EBS volume in another Availability Zone: placing both behind an Application Load Balancer After completing this change users reported that each time they refreshed the website they could see one subset of their documents or the other but never all of the documents at the same time What should a solutions architect propose to ensure users see all of their documents at once?\nA. Copy the data so both EBS volumes contain all the documents B. Configure the Application Load Balancer to direct a user to the server with the documents C. Copy the data from both EBS volumes to Amazon EFS Modify the application to save new documents to Amazon EFS D. Configure the Application Load Balancer to send the request to both servers Return each document from the correct server 문제 풀이\r...\rAnswer: C\r#\rExplanation https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html#how-it-works-ec2 Amazon EFS provides file storage in the AWS Cloud. With Amazon EFS, you can create a file system, mount the file system on an Amazon EC2 instance, and then read and write data to and from your file system. You can mount an Amazon EFS file system in your VPC, through the Network File System versions 4.0 and 4.1 (NFSv4) protocol. We recommend using a current generation Linux NFSv4.1 client, such as those found in the latest Amazon Linux, Redhat, and Ubuntu AMIs, in conjunction with the Amazon EFS Mount Helper. For instructions, see Using the amazon-efs-utils Tools. For a list of Amazon EC2 Linux Amazon Machine Images (AMIs) that support this protocol, see NFS Support. For some AMIs, you\u0026rsquo;ll need to install an NFS client to mount your file system on your Amazon EC2 instance. For instructions, see Installing the NFS Client. You can access your Amazon EFS file system concurrently from multiple NFS clients, so applications that scale beyond a single connection can access a file system. Amazon EC2 instances running in multiple Availability Zones within the same AWS Region can access the file system, so that many users can access and share a common data source. How Amazon EFS Works with Amazon EC2 https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html#how-it-works-ec2\n#\r#\rQUESTION\r#\rA company\u0026rsquo;s legacy application is currently relying on a single-instance Amazon RDS MySQL database without encryption Due to new compliance requirements, all existing and new data in this database must be encrypted How should this be accomplished?\nA. Create an Amazon S3 bucket with server-side encryption enabled Move all the data to Amazon S3 Delete the RDS instance B. Enable RDS Multi-AZ mode with encryption at rest enabled Perform a failover to the standby instance to delete the original instance C. Take a snapshot of the RDS instance Create an encrypted copy of the snapshot Restore the RDS instance from the encrypted snapshot D. Create an RDS read replica with encryption at rest enabled Promote the read replica to master and switch the application over to the new master Delete the old RDS instance. 문제 풀이\r...\rAnswer: C\r#\rExplanation How do I encrypt Amazon RDS snapshots?\nThe following steps are applicable to Amazon RDS for MySQL, Oracle, SQL Server, PostgreSQL, or MariaDB. Important: If you use Amazon Aurora, you can restore an unencrypted Aurora DB cluster snapshot to an encrypted Aurora DB cluster if you specify an AWS Key Management Service (AWS KMS)\n115 encryption key when you restore from the unencrypted DB cluster snapshot. For more information, see Limitations of Amazon RDS Encrypted DB Instances. Open the Amazon RDS console, and then choose Snapshots from the navigation pane. Select the snapshot that you want to encrypt. Under Snapshot Actions, choose Copy Snapshot. Choose your Destination Region, and then enter your New DB Snapshot Identifier. Change Enable Encryption to Yes. Select your Master Key from the list, and then choose Copy Snapshot. After the snapshot status is available, the Encrypted field will be True to indicate that the snapshot is encrypted. You now have an encrypted snapshot of your DB. You can use this encrypted DB snapshot to restore the DB instance from the DB snapshot. https://aws.amazon.com/premiumsupport/knowledge-center/encrypt-rds-snapshots/\n#\r#\rQUESTION\r#\rA company needs a secure connection between its on-premises environment and AWS. This connection does not need high bandwidth and will handle a small amount of traffic. The connection should be set up quickly. What is the MOST cost-effective method to establish this type of connection?\nA. Implement a client VPN B. Implement AWS Direct Connect C. Implement a bastion host on Amazon EC2 53D. D. Implement an AWS Site-to-Site VPN connection. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company is running a two-tier ecommerce website using services. The current architect uses a publish-facing Elastic Load Balancer that sends traffic to Amazon EC2 instances in a private subnet. The static content is hosted on EC2 instances, and the dynamic content is retrieved from a MYSQL database. The application is running in the United States. The company recently started selling to users in Europe and Australia. A solution architect needs to design solution so their international users have an improved browsing experience. Which solution is MOST cost-effective?\nA. Host the entire website on Amazon S3. B. Use Amazon CloudFront and Amazon S3 to host static images. C. Increase the number of public load balancers and EC2 instances D. Deploy the two-tier website in AWS Regions in Europe and Austraila. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company has two applications it wants to migrate to AWS. Both applications process a large set of files by accessing the same files at the same time. Both applications need to read the files with low latency. Which architecture should a solutions architect recommend for this situation?\nA. Configure two AWS Lambda functions to run the applications. Create an Amazon EC2 instance with an instance store volume to store the data. B. Configure two AWS Lambda functions to run the applications. Create an Amazon EC2 instance with an Amazon Elastic Block Store (Amazon EBS) volume to store the data. C. Configure one memory optimized Amazon EC2 instance to run both applications simultaneously. Create an Amazon Elastic Block Store (Amazon EBS) volume with Provisioned IOPS to store the data. D. Configure two Amazon EC2 instances to run both applications. Configure Amazon Elastic File System (Amazon EFS) with General Purpose performance mode and Bursting Throughput mode to store the data. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA media streaming company collects real-time data and stores it in a disk-optimized database system The company is not getting the expected throughput and wants an in-memory database storage solution that performs faster and provides high availability using data replication. Which database should a solutions architect recommend'?\nA. Amazon RDS for MySQL B. Amazon RDS for PostgreSQL C. Amazon ElastiCache for Redis D. Amazon ElastiCache for Memcached 문제 풀이\r...\rAnswer: C\r#\rExplanation https://aws.amazon.com/elasticache/redis-vs-memcached/ In-memory databases on AWS Amazon Elasticache for Redis Amazon ElastiCache for Redis is a blazing fast in-memory data store that provides submillisecond latency to power internet-scale, real-time applications. Developers can use ElastiCache for Redis as an in-memory nonrelational database. The ElastiCache for Redis cluster configuration supports up to 15 shards and enables customers to run Redis workloads with up to 6.1 TB of in-memory capacity in a single cluster. ElastiCache for Redis also provides the ability to add and remove shards from a running cluster. You can dynamically scale out and even scale in your Redis cluster workloads to adapt to changes in demand https://aws.amazon.com/nosql/in-memory/\n#\r#\rQUESTION\r#\rA company has a custom application running on an Amazon EC2 instance that:\nReads a large amount of data from Amazon S3 Performs a multi stage analysis Writes the results to Amazon DynamoDB The application writes a significant number of large temporary files during the multi stage analysis The process performance depends on the temporary storage performance. What would be the fastest storage option for holding the temporary files? A. Multiple Amazon S3 buckets with Transfer Acceleration for storage B. Multiple Amazon EBS drives with Provisioned IOPS and EBS optimization C. Multiple Amazon EFS volumes using the Network I lie System version 4.1 (NFSv4.1) protocol. D. Multiple instance store volumes with software RAID 0. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company is designing a web application using AWS that processes insurance quotes Users will request quotes from the application Quotes must be separated by quote type must be responded to within 24 hours, and must not be lost The solution should be simple to set up and maintain. Which solution meets these requirements?\nA. Create multiple Amazon Kinesis data streams based on the quote type Configure the web application to send messages to the proper data stream Configure each backend group of application servers to pool messages from its own data stream using the Kinesis Client Library (KCL) B. Create multiple Amazon Simple Notification Service {Amazon SNS) topics and register Amazon SQS queues to their own SNS topic based on the quote type. Configure the web application to publish messages to the SNS topic queue Configure each backend application server to work its own SQS queue C. Create a single Amazon Simple Notification Service {Amazon SNS) topic and subscribe the Amazon SQS queues to the SNS topic Configure SNS message filtering to publish messages to the proper SQS queue based on the quote type. Configure each backend application server to work its own SQS queue. D. Create multiple Amazon Kinesis Data Firehose delivery streams based on the quote type to deliver data streams to an Amazon Elasticsearch Service {Amazon ES) cluster. Configure the web application to send messages to the proper delivery stream Configure each backend group of application servers to search for the messages from Amazon ES and process them accordingly 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION 101-200\r#\r#\r#\r#\rQUESTION\r#\rA company has an API-based inventory reporting application running on Amazon EC2 instances The application stores information in an Amazon DynamoDB table The company\u0026rsquo;s distribution centers have an on-premises shipping application that calls an API to update the inventory before printing shipping labels The company has been experiencing application interruptions several times each day, resulting in lost transactions What should a solutions architect recommend to improve application resiliency?\nA. Modify the shipping application to write to a local database B. Modify the application APIs to run serverless using AWS Lambda C. Configure Amazon API Gateway to call the EC2 inventory application APIs. D. Modify the application to send inventory updates using Amazon Simple Queue Service (Amazon SQS) 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rCompany is designing a website that uses an Amazon S3 bucket to store static images. The company wants ail future requests have taster response times while reducing both latency and cost. Which service configuration should a solutions architect recommend?\nA. Deploy a NAT server in front of Amazon S3. B. Deploy Amazon CloudFront in front of Amazon S3. C. Deploy a Network Load Balancer in front of Amazon S3. D. Configure Auto Scaling to automatically adjust the capacity of the website. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA web application runs on Amazon EC2 instances behind an Application Load Balancer. The application allows users to create custom reports of historical weather data. Generating a report can take up to 5 minutes. These long-running requests use many of the available incoming connections, making the system unresponsive to other users. How can a solutions architect make the system more responsive?\nA. Use Amazon SQS with AWS Lambda to generate reports. B. Increase the idle timeout on the Application Load Balancer to 5 minutes. C. Update the client-side application code to increase its request timeout to 5 minutes. D. Publish the reports to Amazon S3 and use Amazon CloudFront for downloading to the user. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA monolithic application was recently migrated to AWS and is now running on a single Amazon EC2 instance. Due to application limitations, it is not possible to use automatic scaling to scale out the application. The chief technology officer (CTO) wants an automated solution to restore the EC2 instance in the unlikely event the underlying hardware fails. What would allow for automatic recovery of the EC2 instance as quickly as possible?\nA. Configure an Amazon CloudWatch alarm that triggers the recovery of the EC2 instance if it becomes impaired. B. Configure an Amazon CloudWatch alarm to trigger an SNS message that alerts the CTO when the EC2 instance is impaired. C. Configure AWS CloudTrail to monitor the health of the EC2 instance, and if it becomes impaired, triggered instance recovery. D. Configure an Amazon EventBridge event to trigger an AWS Lambda function once an hour that checks the health of the EC2 instance and triggers instance recovery if the EC2 instance is unhealthy. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA website runs a web application that receives a burst of traffic each day at noon. The users upload new pictures and content daily, but have been complaining of timeouts. The architecture uses Amazon EC2 Auto Scaling groups, and the custom application consistently takes 1 minute to initiate upon boot up before responding to user requests. How should a solutions architect redesign the architecture to better respond to changing traffic?\nA. Configure a Network Load Balancer with a slow start configuration. B. Configure AWS ElastiCache for Redis to offload direct requests to the servers. C. Configure an Auto Scaling step scaling policy with an instance warmup condition. D. Configure Amazon CloudFront to use an Application Load Balancer as the origin. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company has three VPCs named Development, Testing and Production in the us-east-1 Region. The three VPCs need to be connected to an on-premises data center and are designed to be separate to maintain security and prevent any resource sharing A solutions architect needs to find a scalable and secure solution What should the solutions architect recommend?\nA. Create an AWS Direct Connect connection and a VPN connection for each VPC to connect back to the data center. B. Create VPC peers from all the VPCs to the Production VPC Use an AWS Direct Connect connection from the Production VPC back to the data center C. Connect VPN connections from all the VPCs to a VPN in the Production VPC. Use a VPN connection from the Production VPC back to the data center D. Create a new VPC called Network Within the Network VPC create an AWS Transit Gateway with an AWS Direct Connect connection back to the data center Attach all the other VPCs to the Network VPC. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing the cloud architecture for a new application being deployed on AWS The process should run in parallel while adding and removing application nodes as needed based on the number of jobs to be processed The processor application is stateless The solutions architect must ensure that the application is loosely coupled and the job items are durably stored Which design should the solutions architect use?\nA. Create an Amazon SNS topic to send the jobs that need to be processed Create an Amazon Machine Image (AMI) that consists of the processor application Create a launch configuration that uses the AMI Create an Auto Scaling group using the launch configuration Set the scaling policy for the Auto Scaling group to add and remove nodes based on CPU usage B. Create an Amazon SQS queue to hold the jobs that need to be processed Create an Amazon Machine Image (AMI) that consists of the processor application Create a launch configuration that uses the AMI Create an Auto Scaling group using the launch configuration Set the scaling policy for the Auto Scaling group to add and remove nodes based on network usage C. Create an Amazon SQS queue to hold the jobs that needs to be processed Create an Amazon Machine Image (AMI) that consists of the processor application Create a launch template that uses the AMI Create an Auto Scaling group using the launch template Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of items in the SQS queue D. Create an Amazon SNS topic to send the jobs that need to be processed Create an Amazon Machine Image (AMI) that consists of the processor application Create a launch template that uses the AMI Create an Auto Scaling group using the launch template Set the scaling policy for the Auto Scaling group to add and remove nodes based on the number of messages published to the SNS topic. 문제 풀이\r...\rAnswer: C\r#\rExplanation Amazon Simple Queue Service Amazon Simple Queue Service (SQS) is a fully managed message queuing service that enables you to decouple and scale microservices, distributed systems, and serverless applications. SQS eliminates the complexity and overhead associated with managing and operating message oriented middleware, and empowers developers to focus on differentiating work. Using SQS, you can send, store, and receive messages between software components at any volume, without losing messages or requiring other services to be available. Get started with SQS in minutes using the AWS console, Command Line Interface or SDK of your choice, and three simple commands. SQS offers two types of message queues. Standard queues offer maximum throughput, best-effort ordering, and at-least-once delivery. SQS FIFO queues are designed to guarantee that messages are processed exactly once, in the exact order that they are sent. Scaling Based on Amazon SQS There are some scenarios where you might think about scaling in response to activity in an Amazon SQS queue. For example, suppose that you have a web app that lets users upload images and use them online. In this scenario, each image requires resizing and encoding before it can be published. The app runs on EC2 instances in an Auto Scaling group, and it\u0026rsquo;s configured to handle your typical upload rates. Unhealthy instances are terminated and replaced to maintain current instance levels at all times. The app places the raw bitmap data of the images in an SQS queue for processing. It processes the images and then publishes the processed images where they can be viewed by users. The architecture for this scenario works well if the number of image uploads doesn\u0026rsquo;t vary over time. But if the number of uploads changes over time, you might consider using dynamic scaling to scale the capacity of your Auto Scaling group. https://aws.amazon.com/sqs/#:~:text=Amazon%20SQS%20leverages%20the%20AWS,queues%20pro vide%20n https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html\n#\r#\rQUESTION\r#\rA company allows its developers to attach existing IAM policies to existing IAM roles to enable (aster experimentation and agility However the security operations team is concerned that the developers could attach the existing administrator policy, which would allow the developers to circumvent any other security policies How should a solutions architect address this issue?\nA. Create an Amazon SNS topic to send an alert every time a developer creates a new policy B. Use service control policies to disable IAM activity across all accounts in the organizational unit C. Prevent the developers from attaching any policies and assign all IAM duties to the security operations team D. Set an IAM permissions boundary on the developer IAM role that explicitly denies attaching the administrator policy 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company hosts a static website on-premises and wants to migrate the website to AWS The website should load as quickly as possible for users around the world The company also wants the most cost-effective solution What should a solutions architect do to accomplish this?\nA. Copy the website content to an Amazon S3 bucket Configure the bucket to serve static webpage content Replicate the S3 bucket to multiple AWS Regions B. Copy the website content to an Amazon S3 bucket Configure the bucket to serve static webpage content Configure Amazon CloudFront with the S3 bucket as the origin C. Copy the website content to an Amazon EBS-backed Amazon EC2 instance running Apache HTTP Server Configure Amazon Route 53 geolocation routing policies to select the closest origin D. Copy the website content to multiple Amazon EBS-backed Amazon EC2 instances running Apache HTTP Server in multiple AWS Regions Configure Amazon CloudFront geolocation routing policies to select the closest origin 문제 풀이\r...\rAnswer: B\r#\rExplanation What Is Amazon CloudFront?\nAmazon CloudFront is a web service that speeds up distribution of your static and dynamic web content, such as .html, .css, .js, and image files, to your users. CloudFront delivers your content through a worldwide network of data centers called edge locations. When a user requests content that you\u0026rsquo;re serving with CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance Using Amazon S3 Buckets for Your Origin When you use Amazon S3 as an origin for your distribution, you place any objects that you want CloudFront to deliver in an Amazon S3 bucket. You can use any method that is supported by Amazon S3 to get your objects into Amazon S3, for example, the Amazon S3 console or API, or a third-party tool. You can create a hierarchy in your bucket to store the objects, just as you would with any other Amazon S3 bucket. Using an existing Amazon S3 bucket as your CloudFront origin server doesn\u0026rsquo;t change the bucket in any way; you can still use it as you normally would to store and access Amazon S3 objects at the standard Amazon S3 price. You incur regular Amazon S3 charges for storing the objects in the bucket. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/DownloadDistS3AndCusto mOrigins.h\n#\r#\rQUESTION\r#\rA company is developing a mobile game that streams score updates to a backend processor and then posts results on a leaderboard. A solutions architect needs to design a solution that can handle large traffic spikes, process the mobile game updates in order of receipt, and store the processed updates in a highly available database. The company also wants to minimize the management overhead required to maintain the solution. What should the solutions architect do to meet these requirements?\nA. Push score updates to Amazon Kinesis Data Streams. Process the updates in Kinesis Data Streams with AWS Lambda. Store the processed updates in Amazon DynamoDB. B. Push score updates to Amazon Kinesis Data Streams. Process the updates with a fleet of Amazon EC2 instances set up for Auto Scaling. Store the processed updates in Amazon Redshifl. C. Push score updates to an Amazon Simple Notification Service (Amazon SNS) topic. Subscribe an AWS Lambda function to the SNS topic to process the updates. Store the processed updates in a SOL database running on Amazon EC2. D. Push score updates to an Amazon Simple Queue Service (Amazon SQS) queue. Use a fleet of Amazon EC2 instances with Auto Scaling to process the updates in the SQS queue. Store the processed updates in an Amazon RDS Multi-AZ DB instance. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA solutions architect has configured the following IAM policy. Which action will be allowed by the policy?\nA. An AWS Lambda function can be deleted from any network. B. An AWS Lambda function can be created from any network. C. An AWS Lambda function can be deleted from the 100.220.0.0/20 network D. An AWS Lambda function can be deleted from the 220 100.16 0 20 network 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company needs to implement a relational database with a multi-Region disaster recovery Recovery Point Objective (RPO) of 1 second and an Recovery Time Objective (RTO) of 1 minute. Which AWS solution can achieve this?\nA. Amazon Aurora Global Database B. Amazon DynamoDB global tables. C. Amazon RDS for MySQL with Multi-AZ enabled. D. Amazon RDS for MySQL with a cross-Region snapshot copy. 문제 풀이\r...\rAnswer: A\r#\rRPO 1초, RTO 1분의 특징을 가지는 데이터베이스 유형은 Aurora입니다. #\r#\rQUESTION\r#\rA company is building a document storage application on AWS. The Application runs on Amazon EC2 instances in multiple Availability Zones. The company requires the document store to be highly available. The documents need to be returned immediately when requested. The lead engineer has configured the application to use Amazon Elastic Block Store (Amazon EBS) to store the documents, but is willing to consider other options to meet the availability requirement. What should a solution architect recommend?\nA. Snapshot the EBS volumes regularly and build new volumes using those snapshots in additional Availability Zones. B. Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3. C. Use Amazon EBS for the EC2 instance root volumes. Configure the application to build the document store on Amazon S3 Glacier. D. Use at least three Provisioned IOPS EBS volumes for EC2 instances. Mount the volumes to the EC2 instances in RAID 5 configuration. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing a high performance computing (HPC) workload on Amazon EC2 The EC2 instances need to communicate to each other frequently and require network performance with low latency and high throughput Which EC2 configuration meets these requirements'?\nA. Launch the EC2 instances in a cluster placement group in one Availability Zone B. Launch the EC2 instances in a spread placement group in one Availability Zone C. Launch the EC2 instances in an Auto Scaling group in two Regions and peer the VPCs D. Launch the EC2 instances in an Auto Scaling group spanning multiple Availability Zones 문제 풀이\r...\rAnswer: A\r#\rExplanation Placement groups When you launch a new EC2 instance, the EC2 service attempts to place the instance in such a way that all of your instances are spread out across underlying hardware to minimize correlated failures. You can use placement groups to influence the placement of a group of interdependent instances to meet the needs of your workload. Depending on the type of workload. Cluster - packs instances close together inside an Availability Zone. This strategy enables workloads to achieve the low-latency network performance necessary for tightly-coupled node-to-node communication that is typical of HPC applications. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html\n#\r#\rQUESTION\r#\rA company is using a VPC peering strategy to connect its VPCs in a single Region to allow for cross-communication. A recent increase in account creations and VPCs has made it difficult to maintain the VPC peering strategy, and the company expects to grow to hundreds of VPCs. There are also new requests to create site-to-site VPNs with some of the VPCs. A solutions architect has been tasked with creating a centrally networking setup for multiple accounts, VPNS, and VPNs. Which networking solution meets these requirements?\nA. Configure shared VPCs and VPNs and share to each other B. Configure a hub-and-spoke and route all traffic through VPC peering. C. Configure an AWS Direct Connect between all VPCs and VPNs. D. Configure a transit gateway with AWS Transit Gateway and connected all VPCs and VPNs. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company\u0026rsquo;s website is used to sell products to the public The site runs on Amazon EC2 instances in an Auto Scaling group behind an Application Load Balancer (ALB) There is also an Amazon CloudFront distribution and AWS WAF is being used to protect against SQL injection attacks The ALB is the origin for the CloudFront distribution A recent review of security logs revealed an external malicious IP that needs to be blocked from accessing the website What should a solutions architect do to protect the application?\nA. Modify the network ACL on the CloudFront distribution to add a deny rule for the malicious IP address B. Modify the configuration of AWS WAF to add an IP match condition to block the malicious IP address C. Modify the network ACL for the EC2 instances in the target groups behind the ALB to deny the malicious IP address D. Modify the security groups for the EC2 instances in the target groups behind the ALB to deny the malicious IP address 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company currently stores symmetric encryption keys in a hardware security module (HSM). A solution architect must design a solution to migrate key management to AWS. The solution should allow for key rotation and support the use of customer provided keys. Where should the key material be stored to meet these requirements?\nA. Amazon S3 B. AWS Secrets Manager C. AWS Systems Manager Parameter store D. AWS Key Management Service (AWS KMS) 문제 풀이\r...\rAnswer: D\r#\rHSM이 가능한 서비스는 Key Management Service 입니다. #\r#\rQUESTION\r#\rA company is investigating potential solutions that would collect, process, and store users\u0026rsquo; service usage data. The business objective is to create an analytics capability that will enable the company to gather operational insights quickly using standard SQL queries. The solution should be highly available and ensure Atomicity, Consistency, Isolation, and Durability (ACID) compliance in the data tier. Which solution should a solutions architect recommend?\nA. Use Amazon DynamoDB transactions B. Create an Amazon Neptune database in a Multi AZ design C. Use a fully managed Amazon RDS for MySQL database in a Multi-AZ design D. Deploy PostgreSQL on an Amazon EC2 instance that uses Amazon EBS Throughput Optimized HDD (st1) storage. 문제 풀이\r...\rAnswer: C\r#\r설명은 MySQL의 대한 특징들입니다. #\r#\rQUESTION\r#\rA company serves content to its subscribers across the world using an application running on AWS The application has several Amazon EC2 instances in a private subnet behind an Application Load Balancer (ALB) Due to a recent change in copyright restrictions the chief information officer (CIO) wants to block access for certain countries Which action will meet these requirements?\nA. Modify the ALB security group to deny incoming traffic from blocked countries. B. Modify the security group for EC2 instances to deny incoming traffic from blocked countries. C. Use Amazon CloudFront to serve the application and deny access to blocked countries. D. Use ALB listener rules to return access denied responses to incoming traffic from blocked countries. 문제 풀이\r...\rAnswer: C\r#\rExplanation https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/georestrictions.html \u0026ldquo;block access for certain countries.\u0026rdquo; You can use geo restriction, also known as geo blocking, to prevent users in specific geographic locations from accessing content that you\u0026rsquo;re distributing through a CloudFront web distribution.\n#\r#\rQUESTION\r#\rA company has a web server running on an Amazon EC2 instance in a public subnet with an Elastic IP address The default security group is assigned to the EC2 instance. The default network ACL has been modified to block all traffic. A solutions architect needs to make the web server accessible from everywhere on port 443 Which combination of steps will accomplish this task? (Select TWO.)\nA. Create a security group with a rule to allow TCP port 443 from source 0.0.0.0/0. B. Create a security group with a rule to allow TCP port 443 to destination 0 0 0 0/0. C. Update the network ACL to allow TCP port 443 from source 0.0 0 0/0. D. Update the network ACL to allow inbound/outbound TCP port 443 from source 0.0.0.0/0 and to destination 0.0.0.0/0. E. Update the network ACL to allow inbound TCP port 443 from source 0.0.0 0/0 and outbound TCP port 32768-65535 to destination 0 0 0.0/0 문제 풀이\r...\rAnswer: A E\r#\r#\r#\rQUESTION\r#\rA company is deploying a web portal. The company wants to ensure that only the web portion of the application is publicly accessible. To accomplish this, the VPC was designed with two public subnets and two private subnets. The application will run on several Amazon EC2 instances in an Auto Scaling group. SSL termination must be offloaded from the EC2 instances. What should a solutions architect do to ensure these requirements are met?\nA. Configure the Network Load Balancer in the public subnets. Configure the Auto Scaling group in the private subnets and associate it with the Application Load Balancer B. Configure the Network Load Balancer in the public subnets. Configure the Auto Scaling group in the public subnets and associate it with the Application Load Balancer C. Configure the Application Load Balancer in the public subnets. Configure the Auto Scaling group in the private subnets and associate it with the Application Load Balancer D. Configure the Application Load Balancer in the private subnets. Configure the Auto Scaling group in the private subnets and associate it with the Application Load Balancer 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company runs an application on a group of Amazon Linux EC2 instances The application writes log files using standard API calls For compliance reasons, all log files must be retained indefinitely and will be analyzed by a reporting tool that must access all files concurrently Which storage service should a solutions architect use to provide the MOST cost-effective solution?\nA. Amazon EBS B. Amazon EFS C. Amazon EC2 instance store D. Amazon S3 문제 풀이\r...\rAnswer: D\r#\rExplanation Amazon S3 Requests to Amazon S3 can be authenticated or anonymous. Authenticated access requires credentials that AWS can use to authenticate your requests. When making REST API calls directly from your code, you create a signature using valid credentials and include the signature in your request. Amazon Simple Storage Service (Amazon S3) is an object storage service that offers industryleading scalability, data availability, security, and performance. This means customers of all sizes and industries can use it to store and protect any amount of data for a range of use cases, such as websites, mobile applications, backup and restore, archive, enterprise applications, IoT devices, and big data analytics. Amazon S3 provides easy-to-use management features so you can organize your data and configure finely-tuned access controls to meet your specific business, organizational, and compliance requirements. Amazon S3 is designed for 99.999999999% (11 9\u0026rsquo;s) of durability, and stores data for millions of applications for companies all around the world. https://aws.amazon.com/s3/\n#\r#\rQUESTION\r#\rA financial services company has a web application that serves users in the United States and Europe The application consists of a database tier and a web server tier The database tier consists of a MySQL database hosted in us-east-1 Amazon Route 53 geoproximity routing is used to direct traffic to instances in the closest Region A performance review of the system reveals that European users are not receiving the same level of query performance as those in the United States Which changes should be made to the database tier to improve performance?\nA. Migrate the database to Amazon RDS for MySQL Configure Multi-AZ in one of the European Regions B. Migrate the database to Amazon DynamoDB Use DynamoDB global tables to enable replication to additional Regions C. Deploy MySQL instances in each Region Deploy an Application Load Balancer in front of MySQL to reduce the load on the primary instance D. Migrate the database to an Amazon Aurora global database in MySQL compatibility mode Configure read replicas in one of the European Regions 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company is migrating a three-tier application to AWS. The application requires a MySQL database. In the past, the application users reported poor application performance when creating new entries. These performance issues were caused by users generating different real-time reports from the application duringworking hours. Which solution will improve the performance of the application when it is moved to AWS?\nA. Import the data into an Amazon DynamoDB table with provisioned capacity. Refactor the application to use DynamoDB for reports. B. Create the database on a compute optimized Amazon EC2 instance. Ensure compute resources exceed the on-premises database. C. Create an Amazon Aurora MySQL Multi-AZ DB cluster with multiple read replicas. Configure the application reader endpoint for reports. D. Create an Amazon Aurora MySQL Multi-AZ DB cluster. Configure the application to use the backup instance of the cluster as an endpoint for the reports. 문제 풀이\r...\rAnswer: C\r#\rExplanation Amazon RDS Read Replicas Now Support Multi-AZ Deployments Starting today, Amazon RDS Read Replicas for MySQL and MariaDB now support Multi-AZ deployments. Combining Read Replicas with Multi-AZ enables you to build a resilient disaster recovery strategy and simplify your database engine upgrade process. Amazon RDS Read Replicas enable you to create one or more read-only copies of your database instance within the same AWS Region or in a different AWS Region. Updates made to the source database are then asynchronously copied to your Read Replicas. In addition to providing scalability for read-heavy workloads, Read Replicas can be promoted to become a standalone database instance when needed. Amazon RDS Multi-AZ deployments provide enhanced availability for database instances within a single AWS Region. With Multi-AZ, your data is synchronously replicated to a standby in a different Availability Zone (AZ). In the event of an infrastructure failure, Amazon RDS performs an automatic failover to the standby, minimizing disruption to your applications. You can now use Read Replicas with Multi-AZ as part of a disaster recovery (DR) strategy for your production databases. A well-designed and tested DR plan is critical for maintaining business continuity after a disaster. A Read Replica in a different region than the source database can be used as a standby database and promoted to become the new production database in case of a regional disruption. You can also combine Read Replicas with Multi-AZ for your database engine upgrade process. You can create a Read Replica of your production database instance and upgrade it to a new database engine version. When the upgrade is complete, you can stop applications, promote the Read Replica to a standalone database instance, and switch over your applications. Since the database instance is already a Multi-AZ deployment, no additional steps are needed. Overview of Amazon RDS Read Replicas Deploying one or more read replicas for a given source DB instance might make sense in a variety of scenarios, including the following: Scaling beyond the compute or I/O capacity of a single DB instance for read-heavy database workloads. You can direct this excess read traffic to one or more read replicas. Serving read traffic while the source DB instance is unavailable. In some cases, your source DB instance might not be able to take I/O requests, for example due to I/O suspension for backups or scheduled maintenance. In these cases, you can direct read traffic to your read replicas. For this use case, keep in mind that the data on the read replica might be \u0026ldquo;stale\u0026rdquo; because the source DB instance is unavailable. Business reporting or data warehousing scenarios where you might want business reporting queries to run against a read replica, rather than your primary, production DB instance. Implementing disaster recovery. You can promote a read replica to a standalone instance as a disaster recovery solution if the source DB instance fails. https://aws.amazon.com/about-aws/whats-new/2018/01/amazon-rds-read-replicas-now-supportmulti-az-deploym https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html\n#\r#\rQUESTION\r#\rAn application running on an Amazon EC2 instance in VPC-A needs to access files in another EC2 instance in VPC-B. Both are in separate. AWS accounts. The network administrator needs to design a solution to enable secure access to EC2 instance in VPC-B from VPC-A. The connectivity should not have a single point of failure or bandwidth concerns. Which solution will meet these requirements?\nA. Set up a VPC peering connection between VPC-A and VPC-B. B. Set up VPC gateway endpoints for the EC2 instance running in VPC-B. C. Attach a virtual private gateway to VPC-B and enable routing from VPC-A. D. Create a private virtual interface (VIF) for the EC2 instance running in VPC-B and add appropriate routes from VPC-B. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company wants to replicate its data to AWS to recover in the event of a disaster. Today, a system administrator has scripts that copy data to a NFS share Individual backup files need to be accessed with low latency by application administrators to deal with errors in processing. What should a solutions architect recommend to meet these requirements?\nA. Modify the script to copy data to an Amazon S3 bucket instead of the on-premises NFS share B. Modify the script to copy data to an Amazon S3 Glacier Archive instead of the on-premises NFS share C. Modify the script to copy data to an Amazon Elastic File System (Amazon EFS) volume instead of the on-premises NFS share. D. Modify the script to copy data to an AWS Storage Gateway for File Gateway virtual appliance instead of the on-premises NFS share. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company is building a payment application that must be highly available even during regional service disruptions A solutions architect must design a data storage solution that can be easily replicated and used in other AWS Regions. The application also requires low-latency atomicity, consistency, isolation, and durability (ACID) transactions that need to be immediately available to generate reports The development team also needs to use SQL. Which data storage solution meets these requirements'?\nA. Amazon Aurora Global Database B. Amazon DynamoDB global tables C. Amazon S3 with cross-Region replication and Amazon Athena D. MySQL on Amazon EC2 instances with Amazon Elastic Block Store Amazon EBS) snapshot replication 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company is deploying a multi-instance application within AWS that requires minimal latency between the instances. What should a solutions architect recommend?\nA. Use an Auto Scaling group with a cluster placement group. B. Use an Auto Scaling group with single Availability Zone in the same AWS Region. C. Use an Auto Scaling group with multiple Availability Zones in the same AWS Region. D. Use a Network Load Balancer with multiple Amazon EC2 Dedicated Hosts as the targets 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company is hosting a website behind multiple Application Load Balancers. The company has different distribution rights for its content around the world. A solutions architect needs to ensure that users are served the correct content without violating distribution rights. Which configuration should the solutions architect choose to meet these requirements?\nA. Configure Amazon CloudFront with AWS WAF. B. Configure Application Load Balancers with AWS WAF. C. Configure Amazon Route 53 with a geolocation policy. D. Configure Amazon Route 53 with a geoproximity routing policy. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company runs a static website through its on-premises data center. The company has multiple servers mat handle all of its traffic, but on busy days, services are interrupted and the website becomes unavailable. The company wants to expand its presence globally and plans to triple its website traffic. What should a solutions architect recommend to meet these requirements?\nA. Migrate the website content to Amazon S3 and host the website on Amazon CloudFront. B. Migrate the website content to Amazon EC2 instances with public Elastic IP addresses in multiple AWS Regions. C. Migrate the website content to Amazon EC2 instances and vertically scale as the load increases. D. Use Amazon Route 53 to distribute the loads across multiple Amazon CloudFront distributions for each AWS Region that exists globally. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA solution architect has created two IAM policies: Policy1 and Policy2. Both policies are attached to an IAM group.\nPolicy1 { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;iam:Get*\u0026#34;, \u0026#34;iam:List*\u0026#34;, \u0026#34;kms:List*\u0026#34;, \u0026#34;ec2:*\u0026#34;, \u0026#34;ds:*\u0026#34;, \u0026#34;logs:Get*\u0026#34;, \u0026#34;logs:Describe*\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } #\rPolicy1 { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;ds:Delete\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; } ] } A cloud engineer is added as an IAM user to the IAM group. Which action will the cloud engineer be able to perform?\nA. Deleting IAM users B. Deleting directories C. Deleting Amazon EC2 instances D. Deleting logs from Amazon CloudWatch Logs 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company wants to optimize the cost of its data storage for data that is accessed quarterly. The company requires high throughput, low latency, and rapid access, when needed Which Amazon S3 storage class should a solutions architect recommend?\nA. Amazon S3 Standard-Infrequent Access (S3 Standard-IA)\nB. Amazon S3 Glacier (S3 Glacier)\nC. Amazon S3 Intelligent-Tiering (S3 Intelligent-Tiering)\nD. Amazon S3 Standard (S3 Standard) 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company has a mobile game that reads most of its metadata from an Amazon RDS DB instance As the game increased in popularity developers noticed slowdowns related to the game\u0026rsquo;s metadata load times Performance metrics indicate that simply scaling the database will not help A solutions architect must explore all options that include capabilities for snapshots replication and sub-millisecond response times What should the solutions architect recommend to solve these issues?\nA. Migrate the database to Amazon Aurora with Aurora Replicas\nB. Migrate the database to Amazon DyramoDB with global tables\nC. Add an Amazon ElastiCache for Redis layer in front of the database.\nD. Add an Amazon ElastiCache for Memcached layer in front of the database 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company\u0026rsquo;s website provides users with downloadable historical performance reports. The website needs a solution that will scale to meet the company\u0026rsquo;s website demands globally. The solution should be cost effective, limit the? provisioning of Into and provide the fastest possible response time. Which combination should a solutions architect recommend to meet these requirements?\nA. Amazon CloudFront and Amazon S3\nB. AWS Lambda and Amazon Dynamo\nC. Application Load Balancer with Amazon EC2 Auto Scaling\nD. Amazon Route 53 with internal Application Load Balances 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has enabled AWS CloudTrail logs to deliver log files to an Amazon S3 bucket for each of its developer accounts. The company has created a central AWS account for streamlining management and audit reviews. An internal auditor needs to access the CloudTrail logs, yet access needs to be restricted for all developer account users. The solution must be secure and optimized. How should a solutions architect meet these requirements?\nA. Configure an AWS Lambda function in each developer account to copy the log files to the central account. Create an IAM role in the central account for the auditor. Attach an IAM policy providing read-only permissions to the bucket. B. Configure CloudTrail from each developer account to deliver the log files to an S3 bucket in the central account. Create an IAM user in the central account for the auditor. Attach an IAM policy providing full permissions to the bucket. C. Configure CloudTrail from each developer account to deliver the log files to an S3 bucket in the central account. Create an IAM role in the central account for the auditor. Attach an IAM policy providing read-only permissions to the bucket. D. Configure an AWS Lambda function in the central account to copy the log files from the S3 bucket in each developer account. Create an IAM user in the central account for the auditor. Attach an IAM policy providing full permissions to the bucket. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company has several Amazon EC2 instances set up in a private subnet for security reasons These instances host applications that read and write large amounts of data to and from Amazon S3 regularly. Currently, subnet routing directs all the traffic destined for the internet through a NAT gateway The company wants to optimize the overall cost without impacting the ability of the application to communicate with Amazon S3 or the outside internet What should a solutions architect do to optimize costs?\nA. Create an additional NAT gateway Update the route table to route to the NAT gateway Update the network ACL to allow S3 traffic B. Create an internet gateway Update the route table to route traffic to the internet gateway Update the network ACL to allow S3 traffic. C. Create a VPC endpoint for Amazon S3 Attach an endpoint policy to the endpoint Update the route table to direct traffic to the VPC endpoint D. Create an AWS Lambda function outside of the VPC to handle S3 requests Attach an IAM policy to the EC2 instances, allowing them to invoke the Lambda function. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA web application is deployed in the AWS Cloud It consists of a two-tier architecture that includes a web layer and a database layer The web server is vulnerable to cross-site scripting (XSS) attacks What should a solutions architect do to remediate the vulnerability?\nA. Create a Classic Load Balancer Put the web layer behind the load balancer and enable AWS WAF B. Create a Network Load Balancer Put the web layer behind the load balancer and enable AWS WAF C. Create an Application Load Balancer Put the web layer behind the load balancer and enable AWS WAF D. Create an Application Load Balancer Put the web layer behind the load balancer and use AWS Shield Standard 문제 풀이\r...\rAnswer: C\r#\rExplanation Working with cross-site scripting match conditions Attackers sometimes insert scripts into web requests in an effort to exploit vulnerabilities in web applications. You can create one or more cross-site scripting match conditions to identify the parts of web requests, such as the URI or the query string, that you want AWS WAF Classic to inspect for possible malicious scripts. Later in the process, when you create a web ACL, you specify whether to allow or block requests that appear to contain malicious scripts. Web Application Firewall You can now use AWS WAF to protect your web applications on your Application Load Balancers. AWS WAF is a web application firewall that helps protect your web applications from common web exploits that could affect application availability, compromise security, or consume excessive resources. https://docs.aws.amazon.com/waf/latest/developerguide/classic-web-acl-xss-conditions.html https://aws.amazon.com/elasticloadbalancing/features/\n#\r#\rQUESTION\r#\rA company has an on-premises application that generates a large amount of time-sensitive data that is backed up to Amazon S3. The application has grown and there are user complaints about internet bandwidth limitations. A solutions architect needs to design a long term solution that allows for both timely backups to Amazon S3 and with minimal impact on internet connectivity tor internal users. Which solution meets these requirements?\nA. Establish AWS VPN connections and proxy all traffic through a VPC gateway endpoint B. Establish a new AWS Direct Connect connection and direct backup traffic through this new connection C. Order daily AWS Snowball devices Load the data onto the Snowball devices and return the devices to AWS each day D. Submit a support ticket through the AWS Management Console Request the removal of S3 service limits from the account. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rAn application running on an Amazon EC2 instance needs to securely access tiles on an Amazon Elastic File System (Amazon I tile system. The EFS tiles are stored using encryption at rest. Which solution for accessing the tiles is MOST secure?\nA. Enable TLS when mounting Amazon EFS\nB. Store the encryption key in the code of the application\nC. Enable AWS Key Management Service (AWS KMS) when mounting Amazon EFS\nD. Store the encryption key in an Amazon S3 bucket and use IAM roles to grant the EC2 instance access permission 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing a customer-facing application. The application is expected to have a variable amount of reads and writes depending on the time of year and clearly defined access patterns throughout the year. Management requires that database auditing and scaling be managed in the AWS Cloud. The Recovery Point Objective (RPO) must be less than 5 hours. Which solutions can accomplish this? (Select TWO.)\nA. Use Amazon DynamoDB with auto scaling. Use on-demand backups and AWS CloudTrail. B. Use Amazon DynamoDB with auto scaling. Use on-demand backups and Amazon DynamoDB Streams. C. Use Amazon Redshift Configure concurrency scaling. Enable audit logging. Perform database snapshots every 4 hours. D. Use Amazon RDS with Provisioned IOPS. Enable the database auditing parameter. Perform database snapshots every 5 hours. E. Use Amazon RDS with auto scaling. Enable the database auditing parameter. Configure the backup retention period to at least 1 day. 문제 풀이\r...\rAnswer: A B\r#\r#\r#\rQUESTION\r#\rManagement has decided to deploy all AWS VPCs with IPv6 enabled After some time a solutions architect tries to launch a new instance and receives an error stating that there is not enough IP address space available in the subnet What should the solutions architect do to fix this?\nA. Check to make sure that only IPv6 was used during the VPC creation. B. Create a new IPv4 subnet with a larger range, and then launch the instance C. Create a new IPv6-only subnet with a larger range, and then launch the instance D. Disable the IPv4 subnet and migrate all instances to IPv6 only Once that is complete launch the instance 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing the storage architecture for a new web application used for stonng and viewing engineering drawings. All application components will be deployed on the AWS infrastructure. The application design must support caching to minimize the amount of time that users wait for the engineering drawings to load. The application must be able to store petabytes of data. Which combination of storage and caching should the solutions architect use?\nA. Amazon S3 with Amazon CloudFront\nB. Amazon S3 Glacier with Amazon ElastiCache\nC. Amazon Elastic Block Store (Amazon EBS) volumes with Amazon CloudFront\nD. AWS Storage Gateway with Amazon ElastiCache 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company is hosting its static website in an Amazon S3 bucket, which is the origin for Amazon CioudFront. The company has users in the United States. Canada, and Europe and wants to reduce costs. What should a solutions architect recommend?\nA. Adjust the CloudFront caching time to live (TTL) from the default to a longer timeframe. B. Implement CloudFront events with Lambda@Edge to run the website\u0026rsquo;s data processing. C. Modify the CloudFront price class to include only the locations of the countries that are served. D. Implement a CloudFront Secure Sockets Layer (SSL) certificate to push security closer to the locations of the countries that are served. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company hosts a training site on a fleet of Amazon EC2 instances. The company anticipates that its new course, which consists of dozens of training videos on the site, will be extremely popular when it is released in 1 week. What should a solutions architect do to minimize the anticipated server load?\nA. Store the videos in Amazon ElastiCache for Redis Update the web servers to serve the videos using the Elastic ache API B. Store the videos in Amazon Elastic File System (Amazon EFS) Create a user data script for the web servers to mount the EFS volume. C. Store the videos in an Amazon S3 bucket Create an Amazon CloudFlight distribution with an origin access identity (OAI) of that S3 bucket Restrict Amazon S3 access to the OAI. D. Store the videos in an Amazon S3 bucket. Create an AWS Storage Gateway file gateway to access the S3 bucket Create a user data script for the web servers to mount the file gateway 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company needs to comply with a regulatory requirement that states all emails must Pestored and archived externally for 7 years. An administrator has created compressed email files on premises and wants a managed service to transfer the files to AWS storage. Which managed service should a solutions architect recommend?\nA. Amazon Elastic File System (Amazon EPS) B. Amazon S3 Glacier C. AWS Backup D. AWS Storage Gateway 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA solutions architect is developing a multiple-subnet VPC architecture. The solution will consist of six subnets in two Availability Zones. The subnets are defined as public, private and dedicated for databases Only the Amazon EC2 instances running in the private subnets should be able to access a database. Which solution meets these requirements?\nA. Create a now route table that excludes the route to the public subnets\u0026rsquo; CIDR blocks Associate the route table lo the database subnets. B. Create a security group that denies ingress from the security group used by instances in the public subnets Attach the security group to an Amazon RDS DB instance C. Create a security group that allows ingress from the security group used by instances in the private subnets. Attach the security group to an Amazon RDS DB instance. D. Create a new peering connection between the public subnets and the private subnets. Create a different peering connection between the private subnets and the database subnets. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company is performing an AWS Well-Architected Framework review of an existing workload deployed on AWS. The review identified a public-facing website running on the same Amazon EC2 instance as a Microsoft Active Directory domain controller that was install recently to support other AWS services. A solutions architect needs to recommend a new design that would improve the security of the architecture and minimize the administrative demand on IT staff. What should the solutions architect recommend?\nA. Use AWS Directory Service to create a managed Active Directory. Uninstall Active Directory on the current EC2 instance.\nB. Create another EC2 instance in the same subnet and reinstall Active Directory on it. Uninstall Active Directory.\nC. Use AWS Directory Service to create an Active Directory connector. Proxy Active Directory requests to the Active domain controller running on the current EC2 instance.\nD. Enable AWS Single Sign-On (AWS SSO) with Security Assertion Markup Language (SAML) 2.0 federation with the current Active Directory controller. Modify the EC2 instance\u0026rsquo;s security group to deny public access to Active Directory. 문제 풀이\r...\rAnswer: A\r#\rExplanation AWS Managed Microsoft AD AWS Directory Service lets you run Microsoft Active Directory (AD) as a managed service. AWS Directory Service for Microsoft Active Directory, also referred to as AWS Managed Microsoft AD, is powered by Windows Server 2012 R2. When you select and launch this directory type, it is created as a highly available pair of domain controllers connected to your virtual private cloud (VPC). The domain controllers run in different Availability Zones in a region of your choice. Host monitoring and recovery, data replication, snapshots, and software updates are automatically configured and managed for you. https://docs.aws.amazon.com/directoryservice/latest/admin-guide/directory_microsoft_ad.html\n#\r#\rQUESTION\r#\rA company wants to host a scalable web application on AWS. The application will be accessed by users from different geographic regions of the world. Application users will be able to download and upload unique data up to gigabytes in size. The development team wants a cost-effective solution to minimize upload and download latency and maximize performance. What should a solutions architect do to accomplish this?\nA. Use Amazon S3 with Transfer Acceleration to host the application. B. Use Amazon S3 with CacheControl headers to host the application. C. Amazon EC2 with Auto Scaling and Amazon CloudFront to host the application. D. Use Amazon EC2 with Auto Scaling and Amazon ElastiCache to host the application. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rAs part of budget planning, management wants a report of AWS billed items listed by user. The data will be used to create department budgets. A solutions architect needs to determine the most efficient way to obtain this report information. Which solution meets these requirements?\nA. Run a query with Amazon Athena to generate the report. B. Create a report in Cost Explorer and download the report. C. Access the bill details from the billing dashboard and download the bill. D. Modify a cost budget in AWS Budgets to alert with Amazon Simple Email Service (Amazon SES). 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rWhich solution will improve the performance of the application when it is moved to AWS?\nA. Import the data into an Amazon DynamoDB table with provisioned capacity. Refactor the application to use DynamoDB for reports. B. Create the database on a compute optimized Amazon EC2 instance Ensure compute resources exceed the on-premises database C. Create an Amazon Aurora MySQL Multi-AZ DB cluster with multiple read replicas. Configure the application to use the reader endpoint tor reports. D. Create an Amazon Aurora MySQL Multi-AZ DB cluster Configure The application to use the backup instance of the cluster as an endpoint for the reports. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company is using a tape backup solution to store its key application data offsite The daily data volume is around 50 TB The company needs to retain the backups for 7 years for regulatory purposes The backups are rarely accessed and a week\u0026rsquo;s notice is typically given if a backup needs to be restored The company is now considering a cloud-based option to reduce the storage costs and operational burden of managing tapes The company also wants to make sure that the transition (rom tape backups to the cloud minimizes disruptions Which storage solution is MOST cost-effective'?\nA. Use Amazon Storage Gateway to back up to Amazon Glacier Deep Archive B. Use AWS Snowball Edge to directly integrate the backups with Amazon S3 Glacier. C. Copy the backup data to Amazon S3 and create a lifecycle policy to move the data to Amazon S3 Glacier D. Use Amazon Storage Gateway to back up to Amazon S3 and create a lifecycle policy to move the backup to Amazon S3 Glacier 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has a multi-tier application that runs six front-end web servers in an Amazon EC2 Auto Scaling group in a single Availability Zone behind an Application Load Balancer (ALB) A solutions architect needs to modify the infrastructure to be highly available without modifying the application Which architecture should the solutions architect choose that provides high availability?\nA. Create an Auto Scaling group that uses three instances across each of two Regions B. Modify the Auto Scaling group to use three instances across each of two Availability Zones C. Create an Auto Scaling template that can be used to quickly create more instances in another Region D. Change the ALB in front of the Amazon EC2 instances in a round-robin configuration to balance traffic to the web tier 문제 풀이\r...\rAnswer: B\r#\rExplanation https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html Expanding Your Scaled and Load-Balanced Application to an Additional Availability Zone When one Availability Zone becomes unhealthy or unavailable, Amazon EC2 Auto Scaling launches new instances in an unaffected zone. When the unhealthy Availability Zone returns to a healthy state, Amazon EC2 Auto Scaling automatically redistributes the application instances evenly across all of the zones for your Auto Scaling group. Amazon EC2 Auto Scaling does this by attempting to launch new instances in the Availability Zone with the fewest instances. If the attempt fails, however, Amazon EC2 Auto Scaling attempts to launch in other Availability Zones until it succeeds. You can expand the availability of your scaled and load-balanced application by adding an Availability Zone to your Auto Scaling group and then enabling that zone for your load balancer. After you\u0026rsquo;ve enabled the new Availability Zone, the load balancer begins to route traffic equally among all the enabled zones. https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html\n#\r#\rQUESTION\r#\rA company is running a highly sensitive application on Amazon EC2 backed by an Amazon RDS database Compliance regulations mandate that all personally identifiable information (Pll) be encrypted at rest Which solution should a solutions architect recommend to meet this requirement with the LEAST amount of changes to the infrastructure??\nA. Deploy AWS Certificate Manager to generate certificates Use the certificates to encrypt the database volume B. Deploy AWS CloudHSM. generate encryption keys, and use the customer master key (CMK) to encrypt database volumes. C. Configure SSL encryption using AWS Key Management Service customer master keys (AWS KMS CMKs) to encrypt database volumes D. Configure Amazon Elastic Block Store {Amazon EBS) encryption and Amazon RDS encryption with AWS Key Management Service (AWS KMS) keys to encrypt instance and database volumes. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company has 700 TB of backup data stored in network attached storage (NAS) in its data center This backup data need to be accessible for infrequent regulatory requests and must be retained 7 years. The company has decided to migrate this backup data from its data center to AWS. The migration must be complete within 1 month The company has 500 Mbps of dedicated bandwidth on its public internet connection available for data transfer. What should a solutions architect do to migrate and store the data at the LOWEST cost?\nA. Order AWS Snowball devices to transfer the data Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive B. Deploy a VPN connection between the data center and Amazon VPC Us the AWS CLI to copy the data from on premises to Amazon S3 Glacier. C. Provision a 500 Mbps AWS Direct Connect connection and transfer the data to Amazon S3. Use a lifecycle policy to transition the files to Amazon S3 Glacier Deep Archive. D. Use AWS DataSync to transfer the data and deploy a DataSync agent on premises Use the DataSync task to copy files from the on-premises NAS storage lo Amazon S3 Glacier 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rAn application requires a development environment (DEV) and production environment (PROD) for several years. The DEV instances will run for 10 hours each day during normal business hours, while the PROD instances will run 24 hours each day. A solutions architect needs to determine a compute instance purchase strategy to minimize costs. Which solution is the MOST cost-effective?\nA. DEV with Spot Instances and PROD with On-Demand Instances B. DEV with On-Demand Instances and PROD with Spot Instances C. DEV with Scheduled Reserved Instances and PROD with Reserved Instances D. DEV with On-Demand Instances and PROD with Scheduled Reserved Instances 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company has established a new AWS account. The account is newly provisioned and no changed have been made to the default settings. The company is concerned about the security of the AWS account root user. What should be done to secure the root user?\nA. Create IAM users for daily administrative tasks Disable the root user. B. Create IAM users for daily administrative tasks Enable multi-factor authentication on the root user. C. Generate an access key for the root user. Use the access key for daily administration tasks instead of the AWS Management Console. D. Provide the root user credentials to the most senior solution architect. Have the solution architect use the root user for daily administration tasks. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company recently expanded globally and wants to make its application accessible to users in those geographic locations. The application is deploying on Amazon EC2 instances behind an Application Load balancer in an Auto Scaling group. The company needs the ability shift traffic from resources in one region to another. What should a solutions architect recommend?\nA. Configure an Amazon Route 53 latency routing policy B. Configure an Amazon Route 53 geolocation routing policy C. Configure an Amazon Route 53 geoproximity fouling policy. D. Configure an Amazon Route 53 multivalue answer routing policy 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company hosts a static website within an Amazon S3 bucket. A solutions architect needs to ensure that data can be recovered in case of accidental deletion. Which action will accomplish this?\nA. Enable Amazon S3 versioning B. Enable Amazon S3 Intelligent-Tiering. C. Enable an Amazon S3 lifecycle policy D. Enable Amazon S3 cross-Region replication. 문제 풀이\r...\rAnswer: A\r#\rExplanation Data can be recover if versioning enable, also it provide a extra protection like file delete,MFA delete. MFA Delete only works for CLI or API interaction, not in the AWS Management Console. Also, you cannot make version DELETE actions with MFA using IAM user credentials. You must use your root AWS account. https://aws.amazon.com/blogs/security/securing-access-to-aws-using-mfa-part-3/ Object Versioning Use Amazon S3 Versioning to keep multiple versions of an object in one bucket. For example, you could store my-image.jpg (version 111111) and my-image.jpg (version 222222) in a single bucket. S3 Versioning protects you from the consequences of unintended overwrites and deletions. You can also use it to archive objects so that you have access to previous versions. You must explicitly enable S3 Versioning on your bucket. By default, S3 Versioning is disabled. Regardless of whether you have enabled Versioning, each object in your bucket has a version ID. If you have not enabled Versioning, Amazon S3 sets the value of the version ID to null. If S3 Versioning is enabled, Amazon S3 assigns a version ID value for the object. This value distinguishes it from other versions of the same key. https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html\n#\r#\rQUESTION\r#\rA company decides to migrate its three-tier web application from on premises to the AWS Cloud. The new database must be capable of dynamically scaling storage capacity and performing table joins. Which AWS service meets these requirements?\nA. Amazon Aurora B. Amazon RDS for SqlServer C. Amazon DynamoDB Streams D. Amazon DynamoDB on-demand 문제 풀이\r...\rAnswer: A\r#\rDynamoDB는 조인이 가능하지 않습니다. (NoSQL) #\r#\rQUESTION\r#\rA web application must persist order data to Amazon S3 to support neat-real time processing. A solutions architect needs create an architecture that is both scalable and fault tolerant. Which solutions meet these requirements? (Select TWO )\nA. Write the order event to an Amazon DynamoDB table. Use DynamoDB Streams to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3. B. Write the order event to an Amazon Simple Queue Service (Amazon SQS) queue. Use the queue to trigger an AWS Lambda function that parsers the payload and writes the data to Amazon S3. C. Write the order event to an Amazon Simple Notification Service (Amazon SNS) topic. Use the SNS topic to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3 D. Write the order event to an Amazon Simple Queue Service (Amazon SQS) queue. Use an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3 E. Write the order event to an Amazon Simple Notification Service (Amazon SNS) topic Use an Amazon EventBridge (Amazon CloudWatch Events) rule to trigger an AWS Lambda function that parses the payload and writes the data to Amazon S3 문제 풀이\r...\rAnswer: B E\r#\r#\r#\rQUESTION\r#\rA company operates a website on Amazon EC2 Linux instances. Some of the instances are faring Troubleshooting points to insufficient swap space on the failed instances. The operations team lead needs a solution to monitor this. What should a solutions architect recommend?\nA. Configure an Amazon CloudWatch SwapUsage metric dimension. Monitor the SwapUsage dimension in the EC2 metrics in CloudWatch.\nB. Use EC2 metadata to collect information, then publish it to Amazon CloudWatch custom metrics. Monitor SwapUsage metrics in CloudWatch.\nC. Install an Amazon CloudWatch agent on the instances. Run an appropriate script on a set schedule. Monitor SwapUtilizalion metrics in CloudWatch.\nD. Enable detailed monitoring in the EC2 console. Create an Amazon CloudWatch SwapUtilizalion custom metric. Monitor SwapUtilization metrics in CloudWatch. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rAn application is running on Amazon EC2 instances Sensitive information required for the application is stored in an Amazon S3 bucket The bucket needs to be protected from internet access while only allowing services within the VPC access to the bucket. Which combination of actions should a solutions archived take to accomplish this\u0026rsquo;\u0026rsquo; (Select TWO.)\nA. Create a VPC endpoint for Amazon S3. B. Enable server access logging on the bucket C. Apply a bucket policy to restrict access to the S3 endpoint. D. Add an S3 ACL to the bucket that has sensitive information E. Restrict users using the IAM policy to use the specific bucket 문제 풀이\r...\rAnswer: A C\r#\r#\r#\rQUESTION\r#\rApplication developers have noticed that a production application is very slow when business reporting users run large production reports against the Amazon RDS instance backing the application. the CPU and memory utilization metrics for the RDS instance-d not exceed 60% while the reporting queries are running. The business reporting users must be able to generate reports without affecting the applications performance. Which action will accomplish this?\nA. Increase the size of the RDS instance B. Create a read replica and connect the application to it. C. Enable multiple Availability Zones on the RDS instance D. Create a read replication and connect the business reports to it. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company recently implemented hybrid cloud connectivity using AWS Direct Connect and is migrating data to Amazon S3. The company is looking for a fully managed solution that will automate and accelerate the replication of data between the on-premises storage systems and AWS storage services. Which solution should a solutions architect recommend to keep the data private?\nA. Deploy an AWS DataSync agent tor the on-premises environment Configure a sync job to replicate the data and connect it with an AWS service endpoint. B. Deploy an AWS DataSync agent for the on-premises environment. Schedule a batch job to replicate point-ln-time snapshots to AWS. C. Deploy an AWS Storage Gateway volume gateway for the on-premises environment Configure it to store data locally, and asynchronously back up point-in-time snapshots to AWS. D. Deploy an AWS Storage Gateway file gateway for the on-premises environment. Configure it to store data locally, and asynchronously back up point-in-lime snapshots to AWS. 문제 풀이\r...\rAnswer: A\r#\rDataSync는 온 프레미스에서 AWS로 실제 데이터를 전송하는 반면 Storage Gateway는 AWS로 전송되는 데이터에 대한 액세스를 유지합니다. #\r#\rQUESTION\r#\rA company is preparing to deploy a data lake on AWS A solutions architect must define the encryption strategy tor data at rest m Amazon S3 The company\u0026rsquo;s security policy states\nKeys must be rotated every 90 days Strict separation of duties between key users and key administrators must be implemented Auditing key usage must be possible What should the solutions architect recommend? A. Server-side encryption with AWS KMS managed keys (SSE-KMS) with customer managed customer master keys (CMKs) B. Server-side encryption with AWS KMS managed keys (SSE-KMS) with AWS managed customer master keys (CMKs) C. Server-side encryption with Amazon S3 managed keys (SSE-S3) with customer managed customer master keys (CMKs) D. Server-side encryption with Amazon S3 managed keys (SSE-S3) with AWS managed customer master keys (CMKs) 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA media company is evaluating the possibility of moving its systems to the AWS Cloud. The company needs at least 10 TB of storage with the maximum possible I/O performance for video processing. 300 TB of very durable storage for storing media content, and 900 TB of storage to meet requirements for archival media that is not in use anymore. Which set of services should a solutions architect recommend to meet these requirements?\nA. Amazon EBS for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage B. Amazon EBS for maximum performance. Amazon EFS for durable data storage, and Amazon S3 Glacier for archival storage C. Amazon EC2 instance store for maximum performance, Amazon EFS for durable data storage, and Amazon S3 for archival storage D. Amazon EC2 instance store for maximum performance, Amazon S3 for durable data storage, and Amazon S3 Glacier for archival storage 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA security team wants to limit access to specific services or actions in all of the team\u0026rsquo;s AWS accounts. All accounts belong to a large organization in AWS Organizations The solution must be scalable and there must be a single point where permissions can be maintained. What should a solutions architect do to accomplish this?\nA. Create an ACL to provide access to the services or actions. B. Create a security group to allow accounts and attach it to user groups C. Create cross-account roles in each account to deny access to the services or actions. D. Create a service control policy in the root organizational unit to deny access to the services or actions 문제 풀이\r...\rAnswer: D\r#\rExplanation https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.html. Service Control Policy concepts SCPs offer central access controls for all IAM entities in your accounts. You can use them to enforce the permissions you want everyone in your business to follow. Using SCPs, you can give your developers more freedom to manage their own permissions because you know they can only operate within the boundaries you define. You create and apply SCPs through AWS Organizations. When you create an organization, AWS Organizations automatically creates a root, which forms the parent container for all the accounts in your organization. Inside the root, you can group accounts in your organization into organizational units (OUs) to simplify management of these accounts. You can create multiple OUs within a single organization, and you can create OUs within other OUs to form a hierarchical structure. You can attach SCPs to the organization root, OUs, and individual accounts. SCPs attached to the root and OUs apply to all OUs and accounts inside of them. SCPs use the AWS Identity and Access Management (IAM) policy language; however, they do not grant permissions. SCPs enable you set permission guardrails by defining the maximum available permissions for IAM entities in an account. If a SCP denies an action for an account, none of the entities in the account can take that action, even if their IAM permissions allow them to do so. The guardrails set in SCPs apply to all IAM entities in the account, which include all users, roles, and the account root user. https://aws.amazon.com/blogs/security/how-to-use-service-control-policies-to-set-permissionguardrails-across-a\n#\r#\rQUESTION\r#\rA manufacturing company wants to implement predictive maintenance on its machinery equipment The company will install thousands of loT sensors that will send data to AWS in real time A solutions architect is tasked with implementing a solution that will receive events in an ordered manner for each machinery asset and ensure that data is saved for further processing at a later time Which solution would be MOST efficient?\nA. Use Amazon Kinesis Data Streams for real-time events with a artition for each equipment asset Use Amazon Kinesis Data Firehose to save data to Amazon S3 B. Use Amazon Kinesis Data Streams for real-time events with a shard for each equipment asset Use Amazon Kinesis Data Firehose to save data to Amazon EBS C. Use an Amazon SQS FIFO queue for real-time events with one queue for each equipment asset Trigger an AWS Lambda function for the SQS queue to save data to Amazon EFS D. Use an Amazon SQS standard queue for real-time events with one queue for each equipment asset Trigger an AWS Lambda function from the SQS queue to save data to Amazon S3 문제 풀이\r...\rAnswer: C\r#\rKinesis Firehose는 현재 s3 및 redshift 만 지원합니다. Explanation Amazon SQS Introduces FIFO Queues with Exactly-Once Processing and Lower Prices for Standard Queues You can now use Amazon Simple Queue Service (SQS) for applications that require messages to be processed in a strict sequence and exactly once using First-in, First-out (FIFO) queues. FIFO queues are designed to ensure that the order in which messages are sent and received is strictly preserved and that each message is processed exactly once. Amazon SQS is a reliable and highly-scalable managed message queue service for storing messages in transit between application components. FIFO queues complement the existing Amazon SQS standard queues, which offer high throughput, best-effort ordering, and at-least-once delivery. FIFO queues have essentially the same features as standard queues, but provide the added benefits of supporting ordering and exactly-once processing. FIFO queues provide additional features that help prevent unintentional duplicates from being sent by message producers or from being received by message consumers. Additionally, message groups allow multiple separate ordered message streams within the same queue. https://aws.amazon.com/about-aws/whats-new/2016/11/amazon-sqs-introduces-fifo-queues-withexactly-once-pr #\r#\rQUESTION\r#\rA company has a hybrid application hosted on multiple on-premises servers with static IP addresses. There is already a VPN that provides connectivity between the VPC and the on-premises network. The company wants to distribute TCP traffic across the on-premises servers for internet users. What should a solutions architect recommend to provide a highly available and scalable solution?\nA. Launch an internet-facing Network Load Balancer (NLB) and register on-premises IP addresses with the NLB. B. Launch an internet-facing Application Load Balancer (ALB) and register on-premises IP addresses with the ALB. C. Launch an Amazon EC2 instance, attach an Elastic IP address, and distribute traffic to the onpremises servers. D. Launch an Amazon EC2 instance with public IP addresses in an Auto Scaling group and distribute traffic to the on-premises servers. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company is migrating from an on-premises infrastructure to the AWS Cloud One of the company\u0026rsquo;s applications stores files on a Windows file server farm that uses Distributed File System Replication (DFSR) to keep data in sync A solutions architect needs to replace the file server farm Which service should the solutions architect use?\nA. Amazon EFS B. Amazon FSx C. Amazon S3 D. AWS Storage Gateway 문제 풀이\r...\rAnswer: B\r#\rAmazon FSx는 회사의 애플리케이션은 Windows 파일 서버 팜에 파일을 저장합니다. Amazon FSx는 비즈니스 애플리케이션 용 Windows 파일 서버용 Amazon FSx와 고성능 워크로드 용 Luster 용 Amazon FSx 중에서 선택할 수있는 두 가지 파일 시스템을 제공합니다. Explanation Migrating Existing Files to Amazon FSx for Windows File Server Using AWS DataSync We recommend using AWS DataSync to transfer data between Amazon FSx for Windows File Server file systems. DataSync is a data transfer service that simplifies, automates, and accelerates moving and replicating data between on-premises storage systems and other AWS storage services over the internet or AWS Direct Connect. DataSync can transfer your file system data and metadata, such as ownership, time stamps, and access permissions. #\r#\rQUESTION\r#\rA company that operates a web application on premises is preparing to launch a newer version of the application on AWS. The company needs to route requests to either the AWS-hosted or the on-premises-hosted application based on the URL query string. The on-premises application is not available from the internet, and a VPN connection is established between Amazon VPC and the company\u0026rsquo;s data center. The company wants to use an Application Load Balancer (ALB) for this launch. Which solution meets these requirements?\nA. Use two ALBs: one for on premises and one for the AWS resource. Add hosts to each target group of each ALB. Route with Amazon Route 53 based on the URL query string. B. Use two ALBs: one for on premises and one for the AWS resource. Add hosts to the target group of each ALB. Create a software router on an EC2 instance based on the URL query string. C. Use one ALB with two target groups: one for the AWS resource and one for on premises. Add hosts to each target group of the ALB. Configure listener rules based on the URL query string. D. Use one ALB with two AWS Auto Scaling groups: one for the AWS resource and one for on premises. Add hosts to each Auto Scaling group. Route with Amazon Route 53 based on the URL query string. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company built an application that lets users check in to places they visit, rank the places, and add reviews about their experiences The application is successful with a rapid increase in the number of users every month The chief technology officer fears the database supporting the current Infrastructure may not handle the new load the following month because the single Amazon RDS for MySQL instance has triggered alarms related lo resource exhaustion due to read requests. What can a solutions architect recommend to prevent service Interruptions at the database layer with minimal changes to code?\nA. Create an Amazon EMR cluster and migrate the data to a Hadoop Distributed File System (HDFS) with a replication factor of 3. B. Create RDS read replicas and redirect read-only traffic to the read replica endpoints Enable a Multi-AZ deployment. C. Create an Amazon ElastiCache cluster and redirect all read-only traffic to the cluster. Set up the cluster to be deployed m three Availability Zones. D. Create an Amazon DynamoDB table to replace the RDS instance and redirect all read-only traffic to the DynamoDB table Enable DynamoDB Accelerator to offload traffic from the main table. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company wants to use Amazon S3 for the secondary copy of its on-premises dataset. The company would rarely need to access this copy. The storage solution\u0026rsquo;s cost should be minimal. Which storage solution meets these requirements?\nA. S3 Standard B. S3 Intelligent-Tiering C. S3 Standard-Infrequent Access (S3 Standard-IA) D. S3 One Zone-Infrequent Access (S3 One Zone-IA) 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company is using Amazon DynamoDB with provisioned throughput for the database tier of its ecommerce website. During flash sales, customers experience periods of time when the database cannot handle the high number of transactions taking place. This causes the company to lose transactions During normal periods, the database performs appropriately. Which solution solves the performance problem the company faces?\nA. Switch DynamoDB to on-demand mode during flash sales B. Implement DynamoDB Accelerator for fast in memory performance C. Use Amazon Kinesis to queue transactions for processing to DynamoDB D. Use Amazon Simple Queue Service (Amazon SQS) to queue transactions to DynamoDB 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has a mobile chat application with a data store based in Amazon DynamoDB. Users would like new messages to be read with as little latency as possible. A solutions architect needs to design an optimal solution that requires minimal application changes. Which method should the solutions architect select?\nA. Configure Amazon DynamoDB Accelerator (DAX) for the new messages table. Update the code to use the DAX endpoint. B. Add DynamoDB read replicas to handle the increased read load. Update the application to point to the read endpoint for the read replicas. C. Double the number of read capacity units for the new messages table in DynamoDB. Continue to use the existing DynamoDB endpoint. D. Add an Amazon ElastiCache for Redis cache to the application stack. Update the application to point to the Redis cache endpoint instead of DynamoDB. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has a website deployed on AWS. The database backend is hosted on Amazon RDS for MySQL with a primary instance and five read replicas to support scaling needs. The read replicas should lag no more than 1 second behind the primary instance to support the user experience As traffic on the website continues to increase, the replicas are falling further behind during periods of peak load, resulting in complaints from users when searches yield inconsistent results A solutions architect needs to reduce the replication lag as much as possible, with minimal changes to the application code or operational requirements Which solution meets these requirements?\nA. Migrate the database to Amazon Aurora MySQL Replace the MySQL read replicas with Aurora Replicas and enable Aurora Auto Scaling B. Deploy an Amazon ElastiCache for Redis cluster in front of the database Modify the website to check the cache before querying the database read endpoints C. Migrate the database from Amazon RDS to MySQL running on Amazon EC2 compute instances. Choose very large compute optimized instances for all replica nodes. D. Migrate the database to Amazon DynamoDB Initially provision a large number of read capacity units (RCUs) to support the required throughput with on-demand capacity scaling enabled 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA solution architect must design a solution that uses Amazon CloudFront with an Amazon S3 to store a static website. The company security policy requires that all websites traffic be inspected by AWS WAF. How should the solution architect company with these requirements?\nA. Configure an S3 bucket policy to accept requests coming from the AWS WAF Amazon Resource Name (ARN) only B. Configure Amazon CloudFront to forward all incoming requests to AWS WAF before requesting content from the S3 origin, C. Configure a security group that allows Amazon CloudFront IP addresses to access Amazon S3 only Associate AWS WAF to CloudFront. D. Configure Amazon CloudFront and Amazon S3 to use an origin access identity (OAI) to restrict access to the S3 bucket. Enable AWS WAF on the distribution. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA disaster response team is using drones to collect images ot recent storm damage. The response team\u0026rsquo;s laptops lack the storage and compute capacity to transfer the images and process the data. While the team has Amazon EC2 instances for processing and Amazon S3 buckets for storage, network connectivity is intermittent and unreliable. The images need to be processed to evaluate the damage. What should a solutions architect recommend?\nA. Use AWS Snowball Edge devices to process and store the images. B. Upload the images to Amazon Simple Queue Service (Amazon SOS) during intermittent connectivity to EC2 instances. C. Configure Amazon Kinesis Data Firehose to create multiple delivery streams aimed separately at the S3 buckets for storage and the EC2 instances for processing the images. D. Use AWS Storage Gateway pre-installed on a hardware appliance to cache the images locally for Amazon S3 to process the images when connectivity becomes available. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA group requires permissions to list an Amazon S3 bucket and delete objects from that bucket. An administrator has created the following IAM policy to provide access to the bucket and applied that policy to the group. The group is not able to delete objects in the bucket. The company follows least-privilege access rules.\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::bucket-name\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34; } ] } #\rA. Option A\n\u0026#34;Action\u0026#34;: [ \u0026#34;s3:*Object\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::bucket-name/*\u0026#34; ], \u0026#34;Effect\u0026#34; \u0026#34;Allow\u0026#34; #\rB. Option B\n\u0026#34;Action\u0026#34;: [ \u0026#34;s3:*\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::bucket-name/*\u0026#34; ], \u0026#34;Effect\u0026#34; \u0026#34;Allow\u0026#34; #\rC. Option C\n\u0026#34;Action\u0026#34;: [ \u0026#34;s3:*DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::bucket-name*\u0026#34; ], \u0026#34;Effect\u0026#34; \u0026#34;Allow\u0026#34; #\rD. Option D\n\u0026#34;Action\u0026#34;: [ \u0026#34;s3:*DeleteObject\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::bucket-name/*\u0026#34; ], \u0026#34;Effect\u0026#34; \u0026#34;Allow\u0026#34; 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company\u0026rsquo;s application hosted on Amazon EC2 instances needs to access an Amazon S3 bucket. Due to data sensitivity, traffic cannot traverse the internet How should a solutions architect configure access?\nA. Create a private hosted zone using Amazon Route 53.\nB. Configure a VPC gateway endpoint for Amazon S3 in the VPC.\nC. Configure AWS PrivateLink between the EC2 instance and the S3 bucket.\nD. Set up a site-to-site VPN connection between the VPC and the S3 bucket. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company is preparing to store confidential data in Amazon S3. For compliance reasons, the data must be encrypted at rest. Encryption key usage must be logged for auditing purposes. Keys must be rotated every year. Which solution meets these requirements and is the MOST operationally efficient?\nA. Server-side encryption with customer-provided keys (SSE-C) B. Server-side encryption with Amazon S3 managed keys (SSE-S3) C. Server-side encryption with AWS KMS (SSE-KMS) customer master keys (CMKs) with manual rotation D. Server-side encryption with AWS KMS (SSE-KMS) customer master keys (CMKs) with automatic rotation 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company built an application that lets users check in to places they visit, rank the places, and add reviews about their experiences The application is successful with a rapid increase in the number of users every month The chief technology officer fears the database supporting the current Infrastructure may not handle the new load the following month because the single Amazon RDS for MySQL instance has triggered alarms related lo resource exhaustion due to read requests. What can a solutions architect recommend to prevent service Interruptions at the database layer with minimal changes to code?\nA. Create RDS read replicas and redirect read-only traffic to the read replica endpoints Enable a Multi-AZ deployment. B. Create an Amazon EMR cluster and migrate the data to a Hadoop Distributed File System (HDFS) with a replication factor of 3. C. Create an Amazon ElastiCache cluster and redirect all read-only traffic to the cluster. Set up the cluster to be deployed m three Availability Zones. D. Create an Amazon DynamoDB table to replace the RDS instance and redirect all read-only traffic to the DynamoDB table Enable DynamoDB Accelerator to offload traffic from the main table. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company is planning to migrate its virtual server-based workloads to AWS The company has internet-facing load balancers backed by application servers. The application servers rely on patches from an internet-hosted repository Which services should a solutions architect recommend be hosted on the public subnet? (Select TWO.)\nA. NAT gateway B. Amazon RDS DB instances C. Application Load Balancers D. Amazon EC2 application servers E. Amazon Elastic File System (Amazon EFS) volumes 문제 풀이\r...\rAnswer: A C\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing a solution to access a catalog of images and provide users with the ability to submit requests to customize images Image customization parameters will be in any request sent to an AWS API Gateway API The customized image will be generated on demand, and users will receive a link they can click to view or download their customized image The solution must be highly available for viewing and customizing images What is the MOST cost-effective solution to meet these requirements?\nA. Use Amazon EC2 instances to manipulate the original image into the requested customization Store the original and manipulated images in Amazon S3 Configure an Elastic Load Balancer in front of the EC2 instances B. Use AWS Lambda to manipulate the original image to the requested customization Store the original and manipulated images in Amazon S3 Configure an Amazon CloudFront distribution with the S3 bucket as the origin C. Use AWS Lambda to manipulate the original image to the requested customization Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB Configure an Elastic Load Balancer in front of the Amazon EC2 instances D. Use Amazon EC2 instances to manipulate the original image into the requested customization Store the original images in Amazon S3 and the manipulated images in Amazon DynamoDB Configure an Amazon CloudFront distribution with the S3 bucket as the origin 문제 풀이\r...\rAnswer: B\r#\rExplanation AWS Lambda is a compute service that lets you run code without provisioning or managing servers. AWS Lambda executes your code only when needed and scales automatically, from a few requests per day to thousands per second. You pay only for the compute time you consume - there is no charge when your code is not running. With AWS Lambda, you can run code for virtually any type of application or backend service - all with zero administration. AWS Lambda runs your code on a high -availability compute infrastructure and performs all of the administration of the compute resources, including server and operating system maintenance, capacity provisioning and automatic scaling, code monitoring and logging. All you need to do is supply your code in one of the languages that AWS Lambda supports. Storing your static content with S3 provides a lot of advantages. But to help optimize your application\u0026rsquo;s performance and security while effectively managing cost, we recommend that you also set up Amazon CloudFront to work with your S3 bucket to serve and protect the content. CloudFront is a content delivery network (CDN) service that delivers static and dynamic web content, video streams, and APIs around the world, securely and at scale. By design, delivering data out of CloudFront can be more cost effective than delivering it from S3 directly to your users. CloudFront serves content through a worldwide network of data centers called Edge Locations. Using edge servers to cache and serve content improves performance by providing content closer to where viewers are located. CloudFront has edge servers in locations all around the world https://docs.aws.amazon.com/lambda/latest/dg/welcome.html https://aws.amazon.com/blogs/networking-and-content-delivery/amazon-s3-amazon-cloudfront-amatch-made-in\n#\r#\rQUESTION\r#\rA company has an application that posts messages to Amazon SQS Another application polls the queue and processes the messages in an l/O-intensive operation The company has a service level agreement (SLA) that specifies the maximum amount of time that can elapse between receiving the messages and responding to the users Due to an increase in the number of messages the company has difficulty meeting its SLA consistently. What should a solutions architect do to help improve the application\u0026rsquo;s processing time and ensure it can handle the load at any level?\nA. Create an Amazon Machine Image (AMI) from the instance used for processing Terminate the instance and replace it with a larger size. B. Create an Amazon Machine Image (AMI) from the instance used for processing Terminate the instance and replace it with an Amazon EC2 Dedicated Instance C. Create an Amazon Machine image (AMI) from the instance used for processing Create an Auto Scaling group using this image in its launch configuration Configure the group with a target tracking policy to keep us aggregate CPU utilization below 70% D. Create an Amazon Machine Image (AMI) from the instance used for processing Create an Auto Scaling group using this image in its launch configuration Configure the group with a target tracking policy based on the age of the oldest message in the SQS queue 문제 풀이\r...\rAnswer: D\r#\rSLA는 메시지의 기간을 기반으로 합니다. #\r#\rQUESTION\r#\rA company hosts its web application on AWS using seven Amazon EC2 instances The company requires that the IP addresses of all healthy EC2 instances be returned in response to DNS queries. Which policy should be used to meet this requirement?\nA. Simple routing policy B. Latency routing policy C. Multivalue routing policy D. Geolocation routing policy 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company relies on an application that needs at least 4 Amazon EC2 instances during regular traffic and must scale up to 12 EC2 instances during peak loads. The application is critical to the business and must be highly available Which solution will meet these requirements?\nA. Deploy the EC2 instances in an Auto Scaling group Set the minimum to 4 and the maximum to M, with 2 in Availability Zone A and 2 in Availability Zone B B. Deploy the EC2 instances in an Auto Scaling group Set the minimum to 4 and the maximum to 12, with all 4 in Availability Zone A C. Deploy the EC2 instances in an Auto Scaling group Set the minimum to 8 and the maximum to 12, with 4 in Availability Zone A and 4 in Availability Zone B D. Deploy the EC2 instances in an Auto Scaling group Set the minimum to 8 and the maximum to 12 with all 8 in Availability Zone A 문제 풀이\r...\rAnswer: C\r#\r최소 4개라는 것에 유의해야합니다. #\r#\rQUESTION\r#\rA company has recently updated its internal security standards. The company must now ensure all Amazon S3 buckets and Amazon Elastic Block Store (Amazon EBS) volumes are encrypted with keys created and periodically rotated by internal security specialists. The company is looking for a native, software-based AWS service to accomplish this goal. What should a solutions architect recommend as a solution?\nA. Use AWS Secrets Manager with customer master keys (CMKs) to store master key material and apply a routine to create a new CMK periodically and replace it in AWS Secrets Manager. B. Use AWS Key Management Service (AWS KMS) with customer master keys (CMKs) to store master key material and apply a routing to re-create a new key periodically and replace it in AWS KMS. C. Use an AWS CloudHSM cluster with customer master keys (CMKs) to store master key material and apply a routine a re-create a new key periodically and replace it in the CloudHSM cluster nodes. D. Use AWS Systems Manager Parameter Store with customer master keys (CMKs) keys to store master key material and apply a routine to re-create a new periodically and replace it in the Parameter Store. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rAn engineering team is developing and deploying AWS Lambda functions. The team needs to create roles and manage policies in AWS IAM to configure the permissions of the Lambda functions. How should the permissions for the team be configured so they also adhere to the concept of least privilege?\nA. Create an IAM role with a managed policy attached Allow the engineering team and the Lambda functions to assume this role B. Create an IAM group for the engineering team with an lAMFullAccess policy attached Add all the users from the team to this IAM group C. Create an execution role for the Lambda functions. Attach a managed policy that has permission boundaries specific to these Lambda functions D. Create an IAM role with a managed policy attached that has permission boundaries specific to the Lambda functions Allow the engineering team to assume this role. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company wants to migrate its MySQL database from on premises to AWS. The company recently experienced a database outage that significantly impacted the business. To ensure this does not happen again, the company wants a reliable database solution on AWS that minimizes data loss and stores every transaction on at least two nodes. Which solution meets these requirements?\nA. Create an Amazon RDS DB instance with synchronous replication to three nodes in three Availability Zones. B. Create an Amazon RDS MySQL DB instance with Multi-AZ functionality enabled to synchronously replicate the data C. Create an Amazon RDS MySQL DB instance and then create a read replica in a separate AWS Region that synchronously replicates the data. D. Create an Amazon EC2 instance with a MySQL engine installed that triggers an AWS Lambda function to synchronously replicate the data to an Amazon RDS MySQL DB instance. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company built a food ordering application that captures user data and stores it for future analysis The application\u0026rsquo;s static front end is deployed on an Amazon EC2 instance The front-end application sends the requests to the backend application running on separate EC2 instance The backend application then stores the data in Amazon RDS What should a solutions architect do to decouple the architecture and make it scalable?\nA. Use Amazon S3 to serve the front-end application which sends requests to Amazon EC2 to execute the backend application The backend application will process and store the data in Amazon RDS B. Use Amazon S3 to serve the front-end application and write requests to an Amazon Simple Notification Service (Amazon SNS) topic Subscribe Amazon EC2 instances to the HTTP/HTTPS endpoint of the topic and process and store the data in Amazon RDS C. Use an EC2 instance to serve the front end and write requests to an Amazon SQS queue Place the backend instance in an Auto Scaling group and scale based on the queue depth to process and store the data in Amazon RDS D. Use Amazon S3 to serve the static front-end application and send requests to Amazon API Gateway which writes the requests to an Amazon SQS queue Place the backend instances in an Auto Scaling group and scale based on the queue depth to process and store the data in Amazon RDS 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company is concerned that two NAT instances in use will no longer be able to support the traffic needed for the company\u0026rsquo;s application. A solutions architect wants to implement a solution that is highly available fault tolerant, and automatically scalable What should the solutions architect recommend?\nA. Remove the two NAT instances and replace them with two NAT gateways in the same Availability Zone. B. Use Auto Scaling groups with Network Load Balancers for the NAT instances in different Availability Zones. C. Remove the two NAT instances and replace them with two NAT gateways in different Availability Zones. D. Replace the two NAT instances with Spot Instances in different Availability Zones and deploy a Network Load Balancer. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA solutions architect needs to design a low-latency solution for a static single-page application accessed by users utilizing a custom domain name. The solution must be serverless, encrypted in transit, and cost-effective. Which combination of AWS services and features should the solutions architect use? (Select TWO.)\nA. Amazon S3 B. Amazon EC2 C. AWS Fargate D. Amazon CloudFront E. Elastic Load Balancer 문제 풀이\r...\rAnswer: A D\r#\r#\r#\rQUESTION\r#\rA company is processing data on a daily basis The results of the operations are stored in an Amazon S3 bucket, analyzed daily for one week, and then must remain immediately accessible for occasional analysis What is the MOST cost-effective storage solution alternative to the current configuration?\nA. Configure a lifecycle policy to delete the objects after 30 days B. Configure a lifecycle policy to transition the objects to Amazon S3 Glacier after 30 days. C. Configure a lifecycle policy to transition the objects to Amazon S3 Standard-Infrequent Access (S3 Standard-IA) after 30 days D. Configure a lifecycle policy to transition the objects to Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has a highly dynamic batch processing job that uses many Amazon EC2 instances to complete it. The job is stateless in nature, can be started and stopped at any given time with no negative impact, and typically takes upwards of 60 minutes total to complete The company has asked a solutions architect to design a scalable and cost-effective solution that meets the requirements of the job. What should the solutions architect recommend?\nA. Implement EC2 Spot Instances B. Purchase EC2 Reserved Instances C. Implement EC2 On-Demand Instances D. Implement the processing on AWS Lambda 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company has a live chat application running on list on-premises servers that use WebSockets. The company wants to migrate the application to AWS Application traffic is inconsistent, and the company expects there to be more traffic with sharp spikes in the future. The company wants a highly scalable solution with no server maintenance nor advanced capacity planning Which solution meets these requirements?\nA. Use Amazon API Gateway and AWS Lambda with an Amazon DynamoDB table as the data store Configure the DynamoDB table for provisioned capacity B. Use Amazon API Gateway and AWS Lambda with an Amazon DynamoDB table as the data store Configure the DynaiWDB table for on-demand capacity C. Run Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group with an Amazon DynamoDB table as the data store Configure the DynamoDB table for on-demand capacity D. Run Amazon EC2 instances behind a Network Load Balancer in an Auto Scaling group with an Amazon DynamoDB table as the data store Configure the DynamoDB table for provisioned capacity 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company hosts its core network services, including directory services and DNS. in its onpremises data center. The data center is connected to the AWS Cloud using AWS Direct Connect (DX) Additional AWS accounts are planned that will require quick, cost-effective, and consistent access to these network services What should a solutions architect implement to meet these requirements with the LEAST amount of operational overhead?\nA. Create a DX connection in each new account Route the network traffic to the on-premises servers B. Configure VPC endpoints in the DX VPC for all required services Route the network traffic to the on-premises servers. C. Create a VPN connection between each new account and the DX VPp, Route the network traffic to the on-premises servers D. Configure AWS Transit Gateway between the accounts Assign DX to the transit gateway and route network traffic to the on-premises servers 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company is experiencing growth as demand for its product has increased The company\u0026rsquo;s existing purchasing application is slow when traffic spikes The application is a monolithic three tier application that uses synchronous transactions and sometimes sees bottlenecks in the application tier A solutions architect needs to design a solution that can meet required application response times while accounting for traffic volume spikes. Which solution will meet these requirements?\nA. Vertically scale the application instance using a larger Amazon EC2 instance size. B. Scale the application\u0026rsquo;s persistence layer horizontally by introducing Oracle RAC on AWS C. Scale the web and application tiers horizontally using Auto Scaling groups and an Application Load Balancer D. Decouple the application and data tiers using Amazon Simple Queue Service (Amazon SQS) with asynchronous AWS Lambda calls. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company has a 143 TB MySQL database that it wants to migrate to AWS. The plan is to use Amazon Aurora MySQL as the platform going forward. The company has a 100 Mbps AWS Direct Connect connection to Amazon VPC. Which solution meets the company\u0026rsquo;s needs and takes the LEAST amount of time?\nA. Use a gateway endpoint for Amazon S3 Migrate the data to Amazon S3 Import the data into Aurora B. Upgrade the Direct Connect link to 500 Mbps. Copy the data to Amazon S3 Import the data into Aurora C. Order an AWS Snowmobile and copy the database backup to it. Have AWS import the data into Amazon S3 Import the backup into Aurora D. Order four 50-TB AWS Snowball devices and copy the database backup onto them. Have AWS import the data into Amazon S3 Import the data into Aurora 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company has an application workflow that uses an AWS Lambda function to download and decrypt files from Amazon S3 These files are encrypted using AWS Key Management Service Customer Master Keys (AWS KMS CMKs) A solutions architect needs to design a solution that will ensure the required permissions are set correctly. Which combination of actions accomplish this? (Select TWO.)\nA. Attach the kms.decrypt permission to the Lambda function\u0026rsquo;s resource policy. B. Grant the decrypt permission for the Lambda IAM role in the KMS key\u0026rsquo;s policy C. Grant the decrypt permission for the Lambda resource policy in the KMS key\u0026rsquo;s policy. D. Create a new IAM policy with the kms:decrypt permission and attach the policy to the Lambda function E. Create a new IAM role with the kms decrypt permission and attach the execution role to the Lambda function. 문제 풀이\r...\rAnswer: B E\r#\r#\r#\rQUESTION 201-300\r#\r#\r#\rQUESTION\r#\rA company\u0026rsquo;s application runs on Amazon EC2 instances behind an Application Load Balancer (ALB) The instances run in an Amazon EC2 Auto Scaling group across multiple Availability Zones On the first day of every month at midnight the application becomes much slower when the month-end financial calculation batch executes This causes the CPU utilization of the EC2 instances to immediately peak to 100%. which disrupts the application What should a solutions architect recommend to ensure the application is able to handle the workload and avoid downtime?\nA. Configure an Amazon CloudFront distribution in front of the ALB B. Configure an EC2 Auto Scaling simple scaling policy based on CPU utilization C. Configure an EC2 Auto Scaling scheduled scaling policy based on the monthly schedule. D. Configure Amazon ElastiCache to remove some of the workload from the EC2 instances\n문제 풀이\r...\rAnswer: C\r#\rExplanation Scheduled Scaling for Amazon EC2 Auto Scaling Scheduled scaling allows you to set your own scaling schedule. For example, let\u0026rsquo;s say that every week the traffic to your web application starts to increase on Wednesday, remains high on Thursday, and starts to decrease on Friday. You can plan your scaling actions based on the predictable traffic patterns of your web application. Scaling actions are performed automatically as a function of time and date. https://docs.aws.amazon.com/autoscaling/ec2/userguide/schedule_time.html\n#\r#\rQUESTION\r#\rA company had a build server that is in an Auto Scaling group and often has multiple Linux instances running. The build server requires consistent and mountable shared NFS storage for jobs and configurations. Which storage option should a solutions architect recommend?\nA. Amazon S3 B. Amazon FSx C. Amazon Elastic Block Store (Amazon EBS) D. Amazon Elastic File System (Amazon EFS) 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company\u0026rsquo;s website runs on Amazon EC2 instances behind an Application Load Balancer (ALB) The website has a mix of dynamic and static content Users around the globe are reporting that the website is slow Which set of actions will improve website performance for users worldwide?\nA. Create an Amazon CloudFront distribution and configure the ALB as an origin Then update the Amazon Route 53 record to point to the CloudFront distribution B. Create a latency-based Amazon Route 53 record for the ALB Then launch new EC2 instances with larger instance sizes and register the instances with the ALB C. Launch nev. EC2 instances hosting the same web application in different Regions closer to the users. Then register the instances with the same ALB using cross-Region VPC peering D. Host the website in an Amazon S3 bucket in the Regions closest to the users and delete the ALB and EC2 instances Then update an Amazon Route 53 record to point to the S3 buckets 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company is building a media-sharing application and decides to use Amazon S3 for storage. When a media file is uploaded the company starts a multi-step process to create thumbnails, identify objects in the images, transcode videos into standard formats and resolutions and extract and store the metadata to an Amazon DynamoDB table. The metadata is used for searching and navigation. The amount of traffic is variable The solution must be able to scale to handle spikes in load without unnecessary expenses. What should a solutions architect recommend to support this workload?\nA. Build the processing into the website or mobile app used to upload the content to Amazon S3 Save the required data to the DynamoDB table when the objects are uploaded B. Trigger AWS Step Functions when an object is stored in the S3 bucket Have the Step Functions perform the steps needed to process the object and then write the metadata to the DynamoDB table C. Trigger an AWS Lambda function when an object is stored in the S3 bucket Have the Lambda function start AWS Batch to perform the steps to process the object Place the object data in the DynamoDB table when complete D. Trigger an AWS Lambda function to store an initial entry in the DynamoDB table when an object is uploaded to Amazon S3. Use a program running on an Amazon EC2 instance in an Auto Scaling group to poll the index for unprocess use the program to perform the processing 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA solutions architect at an ecommerce company wants to back up application log data to Amazon S3 The solutions architect is unsure how frequently the logs will be accessed or which logs will be accessed the most The company wants to keep costs as low as possible by using the appropriate S3 storage class. Which S3 storage class should be implemented to meet these requirements?\nA. S3 Glacier B. S3 Intelligent-Tiering C. S3 Standard-Infrequent Access (S3 Standard-IA) D. S3 One Zone-Infrequent Access (S3 One Zone-IA) 문제 풀이\r...\rAnswer: B\r#\rExplanation S3 Intelligent-Tiering S3 Intelligent-Tiering is a new Amazon S3 storage class designed for customers who want to optimize storage costs automatically when data access patterns change, without performance impact or operational overhead. S3 Intelligent-Tiering is the first cloud object storage class that delivers automatic cost savings by moving data between two access tiers - frequent access and infrequent access - when access patterns change, and is ideal for data with unknown or changing access patterns . S3 Intelligent-Tiering stores objects in two access tiers: one tier that is optimized for frequent access and another lower-cost tier that is optimized for infrequent access. For a small monthly monitoring and automation fee per object, S3 Intelligent-Tiering monitors access patterns and moves objects that have not been accessed for 30 consecutive days to the infrequent access tier. There are no retrieval fees in S3 Intelligent-Tiering. If an object in the infrequent access tier is accessed later, it is automatically moved back to the frequent access tier. No additional tiering fees apply when objects are moved between access tiers within the S3 Intelligent-Tiering storage class. S3 Intelligent-Tiering is designed for 99.9% availability and 99.999999999% durability, and offers the same low latency and high throughput performance of S3 Standard. https://aws.amazon.com/about-aws/whats-new/2018/11/s3-intelligent-tiering/\n#\r#\rQUESTION\r#\rAn online shopping application accesses an Amazon RDS Multi-AZ DB instance. Database performance is slowing down the application. After upgrading to the next-generation instance type, there was no significant performance improvement. Analysis shows approximately 700 IOPS are sustained, common queries run for long durations and memory utilization is high. Which application change should a solutions architect recommend to resolve these issues?\nA. Migrate the RDS instance to an Amazon Redshift cluster and enable weekly garbage collection B. Separate the long-running queries into a new Multi AZ RDS database and modify the application to query whichever database is needed C. Deploy a two-node Amazon ElastiCache cluster and modify the application to query the cluster first and query the database only if needed D. Create an Amazon Simple Queue Service (Amazon SQS) FIFO queue for common queries and query it first and query the database only if needed\n문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rWhat should a solutions architect do to ensure that all objects uploaded to an Amazon S3 bucket are encrypted?\nA. Update the bucket policy to deny if the PutObject does not have an s3 x-amz-acl header set B. Update the bucket policy to deny if the PutObject does not have an s3 x-amz-acl header set to private C. Update the bucket policy to deny if the PutObject does not have an aws SecureTransport header set to true D. Update the bucket policy to deny if the PutObject does not have an x-amz-server-side-encryption header set 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company has been storing analytics data in an Amazon RDS instance for the past few years. The company asked a solutions architect to find a solution that allows users to access this data using an API The expectation is that the application will experience periods of inactivity but could receive bursts of traffic within seconds Which solution should the solutions architect suggest?\nA. Set up an Amazon API Gateway and use Amazon ECS. B. Set up an Amazon API Gateway and use AWS Elastic Beanstalk. C. Set up an Amazon API Gateway and use AWS Lambda functions D. Set up an Amazon API Gateway and use Amazon EC2 with Auto Scaling 문제 풀이\r...\rAnswer: C\r#\rExplanation AWS Lambda With Lambda, you can run code for virtually any type of application or backend service - all with zero administration. Just upload your code and Lambda takes care of everything required to run and scale your code with high availability. You can set up your code to automatically trigger from other AWS services or call it directly from any web or mobile app. Amazon API Gateway Amazon API Gateway is a fully managed service that makes it easy for developers to create, publish, maintain, monitor, and secure APIs at any scale. APIs act as the \u0026ldquo;front door\u0026rdquo; for applications to access data, business logic, or functionality from your backend services. Using API Gateway, you can create RESTful APIs and WebSocket APIs that enable real-time two-way communication applications. API Gateway supports containerized and serverless workloads, as well as web applications. API Gateway handles all the tasks involved in accepting and processing up to hundreds of thousands of concurrent API calls, including traffic management, CORS support, authorization and access control, throttling, monitoring, and API version management. API Gateway has no minimum fees or startup costs. You pay for the API calls you receive and the amount of data transferred out and, with the API Gateway tiered pricing model, you can reduce your cost as your API usage scales. https://aws.amazon.com/lambda/ https://aws.amazon.com/api-gateway/\n#\r#\rQUESTION\r#\rA company\u0026rsquo;s application is running on Amazon EC2 instances m a single Region in the event of a disaster a solutions architect needs to ensure that the resources can also be deployed to a second Region Which combination of actions should the solutions architect take to accomplish this? (Select TWO)\nA. Detach a volume on an EC2 instance and copy it to Amazon S3 B. Launch a new EC2 instance from an Amazon Machine image (AMI) in a new Region C. Launch a new EC2 instance in a new Region and copy a volume from Amazon S3 to the new instance D. Copy an Amazon Machine Image (AMI) of an EC2 instance and specify a different Region for the destination E. Copy an Amazon Elastic Block Store (Amazon EBS) volume from Amazon S3 and launch an EC2 instance in the destination Region using that EBS volume 문제 풀이\r...\rAnswer: B D\r#\rExplanation Cross Region EC2 AMI Copy We know that you want to build applications that span AWS Regions and we\u0026rsquo;re working to provide you with the services and features needed to do so. We started out by launching the EBS Snapshot Copy feature late last year. This feature gave you the ability to copy a snapshot from Region to Region with just a couple of clicks. In addition, last month we made a significant reduction (26% to 83%) in the cost of transferring data between AWS Regions, making it less expensive to operate in more than one AWS region. Today we are introducing a new feature: Amazon Machine Image (AMI) Copy. AMI Copy enables you to easily copy your Amazon Machine Images between AWS Regions. AMI Copy helps enable several key scenarios including: Simple and Consistent Multi-Region Deployment - You can copy an AMI from one region to another, enabling you to easily launch consistent instances based on the same AMI into different regions. Scalability - You can more easily design and build world-scale applications that meet the needs of your users, regardless of their location. Performance - You can increase performance by distributing your application and locating critical components of your application in closer proximity to your users. You can also take advantage of region-specific features such as instance types or other AWS services. Even Higher Availability - You can design and deploy applications across AWS regions, to increase availability. Once the new AMI is in an Available state the copy is complete. https://aws.amazon.com/blogs/aws/ec2-ami-copy-between-regions/\n#\r#\rQUESTION\r#\rA company runs a web service on Amazon EC2 instances behind an Application Load Balancer The instances run in an Amazon EC2 Auto Scaling group across two Availability ones I he company needs a minimum of tour instances at all limes to meet the required service level agreement (SLA) while keeping costs low If an Availability Zone tails, how can the company remain compliant with the SLA?\nA. Add a target tracking scaling policy with a short cooldown period B. Change the Auto Scaling group launch configuration to use a larger instance type C. Change the Auto Scaling group to use six servers across three Availability Zones D. Change the Auto Scaling group to use eight servers across two Availability Zones 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rAn operations team has a standard that states IAM policies should not be applied directly to users. Some new members have not been following this standard. The operation manager needs a way to easily identify the users with attached policies. What should a solutions architect do to accomplish this?\nA. Monitor using AWS CloudTrail B. Create an AWS Config rule to run daily C. Publish IAM user changes lo Amazon SNS D. Run AWS Lambda when a user is modified 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA solutions architect needs to design a managed storage solution for a company\u0026rsquo;s application that includes high-performance machine learning This application runs on AWS Fargate and the connected storage needs to have concurrent access to files and deliver high performance. Which storage option should the solutions architect recommend?\nA. Create an Amazon S3 bucket for the application and establish an IAM role for Fargate to communicate with Amazon S3 B. Create an Amazon FSx for Lustre file share and establish an IAM role that allows Fargate to communicate with FSx for Lustre. C. Create an Amazon Elastic File System (Amazon EFS) file share and establish an IAM role that allows Fargate to communicate with Amazon EFS. D. Create an Amazon Elastic Block Store (Amazon EBS) volume for the application and establish an IAM role that allows Fargate to communicate with Amazon EBS 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company is using Amazon EC2 to run its big data analytics workloads. These variable workloads run each night, and it is critical they finish by the start of business the following day. A solutions architect has been tasked with designing the MOST cost-effective solution. Which solution will accomplish this?\nA. Spot Fleet B. Spot Instances C. Reserved Instances D. On-Demand Instances 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company runs an application on Amazon EC2 Instances. The application is deployed in private subnets in three Availability Zones of the us-east-1 Region. The instances must be able to connect to the internet to download files The company wants a design that Is highly available across the Region. Which solution should be implemented to ensure that there are no disruptions to Internet connectivity?\nA. Deploy a NAT Instance In a private subnet of each Availability Zone. B. Deploy a NAT gateway in a public subnet of each Availability Zone. C. Deploy a transit gateway in a private subnet of each Availability Zone. D. Deploy an internet gateway in a public subnet of each Availability Zone. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company has an application that calls AWS Lambda functions A recent code review found database credentials stored in the source code The database credentials need to be removed from the Lambda source code The credentials must then be securely stored and rotated on an ongoing basis to meet security policy requirements What should a solutions architect recommend to meet these requirements?\nA. Store the password in AWS CloudHSM Associate the Lambda function with a role that can retrieve the password from CloudHSM given its key ID B. Store the password in AWS Secrets Manager Associate the Lambda function with a role that can retrieve the password from Secrets Manager given its secret ID C. Move the database password to an environment variable associated with the Lambda function Retrieve the password from the environment variable upon execution D. Store the password in AWS Key Management Service (AWS KMS) Associate the Lambda function with a role that can retrieve the password from AWS KMS given its key ID 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA development team is collaborating with another company to create an integrated product. The other company needs to access an Amazon Simple Queue Service (Amazon SQS) queue that is contained in the development team\u0026rsquo;s account. The other company wants to poll the queue without giving up its own account permissions to do so. How should a solutions architect provide access to the SQS queue?\nA. Create an instance profile that provides the other company access to the SQS queue. B. Create an IAM policy that provides the other company access to the SQS queue. C. Create an SQS access policy that provides the other company access to the SQS queue. D. Create an Amazon Simple Notification Service (Amazon SNS) access policy that provides the other company access to the SQS queue. 문제 풀이\r...\rAnswer: C\r#\rSQS에도 엑세스 정책을 설정할 수 있습니다. #\r#\rQUESTION\r#\rA company wants to run a hybrid workload for data processing. The data needs to be accessed by on-premises applications for local data processing using an NFS protocol, and must also be accessible from the AWS Cloud for further analytics and batch processing. Which solution will meet these requirements?\nA. Use an AWS Storage Gateway file gateway to provide file storage to AWS, then perform analytics on this data in the AWS Cloud. B. Use an AWS storage Gateway tape gateway to copy the backup of the local data to AWS, then perform analytics on this data in the AWS cloud. C. Use an AWS Storage Gateway volume gateway in a stored volume configuration to regularly take snapshots of the local data, then copy the data to AWS. D. Use an AWS Storage Gateway volume gateway in a cached volume configuration to back up all the local storage in the AWS cloud, then perform analytics on this data in the cloud. 문제 풀이\r...\rAnswer: A\r#\rNFS는 파일 게이트웨이를 통해 전송되어야 합니다. #\r#\rQUESTION\r#\rA company has a multi-tier application deployed on several Amazon EC2 instances in an Auto Scaling group. An Amazon RDS for Oracle instance is the application\u0026rsquo;\u0026rsquo;, data layer that uses Oracle-specific PUSQL functions. Traffic to the application has been steadily increasing This is causing the EC2 instances to become overloaded an i RDS instance to run out of storage. The Auto Scaling group does not have any scaling metrics and defines the minimum healthy instance count only. The company predicts that traffic will continue to increase at a steady but unpredictable rate before leveling off. What should a solutions architect do to ensure the system can automatically scale for the increased traffic? (Select TWO)\nA. Configure storage Auto Scaling on the RDS for Oracle instance. B. Migrate the database to Amazon Aurora to use Auto Scaling storage C. Configure an alarm on the RDS for Oracle instance for low free storage space. D. Configure the Auto Scaling group to use the average CPU as the scaling metric. E. Configure the Auto Scaling group to use the average free memory as the scaling metric. 문제 풀이\r...\rAnswer: A C\r#\r#\r#\rQUESTION\r#\rA company uses Amazon S3 as its object storage solution. The company has thousands of S3 it uses to store data. Some of the S3 bucket have data that is accessed less frequently than others. A solutions architect found that lifecycle policies are not consistently implemented or are implemented partially. resulting in data being stored in high-cost storage. Which solution will lower costs without compromising the availability of objects?\nA. Use S3 ACLs B. Use Amazon Elastic Block Store EBS) automated snapshots C. Use S3 inteligent-Tiering storage D. Use S3 One Zone-infrequent Access (S3 One Zone-IA). 문제 풀이\r...\rAnswer: C\r#\rB\n#\r#\rQUESTION\r#\rA company recently deployed a new auditing system to centralize information about operating system versions, patching, and installed software for Amazon EC2 instances. A solutions architect must ensure all instances provisioned through EC2 Auto Scaling groups successfully send reports to the auditing system as soon as they are launched and terminated. Which solution achieves these goals MOST efficiently?\nA. Use a scheduled AWS Lambda function and execute a script remotely on all EC2 instances to send data to the audit system. B. Use EC2 Auto Scaling lifecycle hooks to execute a custom script to send data to the audit system when instances are launched and terminated. C. Use an EC2 Auto Scaling launch configuration to execute a custom script through user data to send data to the audit system when instances are launched and terminated. D. Execute a custom script on the instance operating system to send data to the audit system. Configure the script to be executed by the EC2 Auto Scaling group when the instance starts and is terminated. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing a system to analyze the performance of financial markets while the markets are closed The system will run a series of compute-intensive jobs for 4 hours every night The time to complete the compute jobs is expected to remain constant, and jobs cannot be interrupted once started Once completed, the system is expected to run for a minimum of 1 year Which type of Amazon EC2 instances should be used to reduce the cost of the system?\nA. Spot Instances B. On-Demand Instances C. Standard Reserved Instances D. Scheduled Reserved Instances 문제 풀이\r...\rAnswer: D\r#\r정기 예약은 사용시간까지도 설정이 되어 표준예약에 비해 가격이 더 저렴합니다. #\r#\rQUESTION\r#\rA company maintains a searchable repository of items on its website Tie data is stored in an Amazon RDS for MySQL database table that contains over 10 million rows The database has 2 TB of General Purpose SSD (gp2) storage. There are millions of updates against this data every day through the company\u0026rsquo;s website The company has noticed some operations are taking 10 seconds or longer and has determined that the database storage performance is the bottleneck Which solution addresses the performance issue?\nA. Change the storage type to Provisioned IOPS SSD (io1) B. Change the instance to a memory-optimized instance class C. Change the instance to a burstable performance DB instance class D. Enable Multi-AZ RDS read replicas with MySQL native asynchronous replication 문제 풀이\r...\rAnswer: B\r#\r병목현상인 경우 메모리 리소스를 최적화시킵니다. #\r#\rQUESTION\r#\rAn application hosted on AWS is experiencing performance problems, and the application vendor wants to perform an analysis of the log file to troubleshoot further. The log file is stored on Amazon S3 and is 10 GB in size. The application owner will make the log file available to the vendor for a limited time. What is the MOST secure way to do this?\nA. Enable public read on the S3 object and provide the link to the vendor. B. Upload the file to Amazon WorkDocs and share the public link with the vendor. C. Generate a presigned URL and have the vendor download the log file before it expires. D. Create an IAM user for the vendor to provide access to the S3 bucket and the application. Enforce multifactor authentication. 문제 풀이\r...\rAnswer: C\r#\rExplanation Share an object with others All objects by default are private. Only the object owner has permission to access these objects. However, the object owner can optionally share objects with others by creating a presigned URL, using their own security credentials, to grant time-limited permission to download the objects. When you create a presigned URL for your object, you must provide your security credentials, specify a bucket name, an object key, specify the HTTP method (GET to download the object) and expiration date and time. The presigned URLs are valid only for the specified duration. Anyone who receives the presigned URL can then access the object. For example, if you have a video in your bucket and both the bucket and the object are private, you can share the video with others by generating a presigned URL. https://docs.aws.amazon.com/AmazonS3/latest/dev/ShareObjectPreSignedURL.html\n#\r#\rQUESTION\r#\rA company runs a website on Amazon EC2 instances behind an ELB Application Load Balancer. Amazon Route 53 is used for the DNS. The company wants to set up a backup website with a message including a phone number and email address that users can reach if the primary website is down. How should the company deploy this solution?\nA. Use Amazon S3 website hosting for the backup website and Route 53 failover routing policy. B. Use Amazon S3 website hosting for the backup website and Route 53 latency routing policy. C. Deploy the application in another AWS Region and use ELB health checks for failover routing. D. Deploy the application in another AWS Region and use server-side redirection on the primary website. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company hosts its product information webpages on AWS. The existing solution uses multiple Amazon C2 instances behind an Application Load Balancer in an Auto Scaling group. The website also uses a custom DNS name and communicates with HTTPS only using a dedicated SSL certificate. The company is planning a new product launch and wants to be sure that users from around the world have the best possible experience on the new website. What should a solutions architect do to meet these requirements?\nA. Redesign the application to use Amazon CloudFront. B. Redesign the application to use AWS Elastic Beanstalk. C. Redesign the application to use a Network Load Balancer. D. Redesign the application to use Amazon S3 static website hosting. 문제 풀이\r...\rAnswer: A\r#\rExplanation What Is Amazon CloudFront?\nAmazon CloudFront is a web service that speeds up distribution of your static and dynamic web content, such as .html, .css, .js, and image files, to your users. CloudFront delivers your content through a worldwide network of data centers called edge locations. When a user requests content that you\u0026rsquo;re serving with CloudFront, the user is routed to the edge location that provides the lowest latency (time delay), so that content is delivered with the best possible performance. If the content is already in the edge location with the lowest latency, CloudFront delivers it immediately. If the content is not in that edge location, CloudFront retrieves it from an origin that you\u0026rsquo;ve definedsuch as an Amazon S3 bucket, a MediaPackage channel, or an HTTP server (for example, a web server) that you have identified as the source for the definitive version of your content. As an example, suppose that you\u0026rsquo;re serving an image from a traditional web server, not from CloudFront. For example, you might serve an image, sunsetphoto.png, using the URL http://example.com/sunsetphoto.png. Your users can easily navigate to this URL and see the image. But they probably don\u0026rsquo;t know that their request was routed from one network to another-through the complex collection of interconnected networks that comprise the internet-until the image was found. CloudFront speeds up the distribution of your content by routing each user request through the AWS backbone network to the edge location that can best serve your content. Typically, this is a CloudFront edge server that provides the fastest delivery to the viewer. Using the AWS network dramatically reduces the number of networks that your users\u0026rsquo; requests must pass through, which improves performance. Users get lower latency-the time it takes to load the first byte of the file-and higher data transfer rates. You also get increased reliability and availability because copies of your files (also known as objects) are now held (or cached) in multiple edge locations around the world. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html\n#\r#\rQUESTION\r#\rA solutions architect is working on optimizing a legacy document management application running on Microsoft Windows Server in an on-premises data center. The application stores a large number of files on a network file share The chief information officer wants to reduce the on-premises data center footprint and minimize storage costs by moving on-premises storage to AWS What should the solutions architect do to meet these requirements?\nA. Set up an AWS Storage Gateway file gateway. B. Set up Amazon Elastic File System (Amazon EFS) C. Set up AWS Storage Gateway as a volume gateway D. Set up an Amazon Elastic Block Store (Amazon EBS) volume. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company requires a durable backup storage solution for its on-premises database servers while ensuring on-premises applications maintain access to these backups for quick recovery. The company will use AWS storage services as the destination for these backups A solutions architect is designing a solution with minimal operational overhead Which solution should the solutions architect implement?\nA. Deploy an AWS Storage Gateway file gateway on-premises and associate it with an Amazon S3 bucket B. Back up the databases to an AWS Storage Gateway volume gateway and access it using the Amazon S3 API. C. Transfer the database backup files to an Amazon Elastic Block Store (Amazon EBS) volume attached to an Amazon EC2 instance. D. Back up the database directly to an AWS Snowball device and uss lifecycle rules to move the data to Amazon S3 Glacier Deep Archive. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company runs an application that uses multiple Amazon EC2 instances to gather data from its users The data is then processed and transferred to Amazon S3 for long-term storage A review of the application shows that there were long penods of time when the EC2 instances were not being used A solutions architect needs to design a solution that optimizes utilization and reduces costs. Which solution meets these requirements?\nA. Use Amazon EC2 in an Auto Scaling group with On-Demand instances. B. Build the application to use Amazon Lightsail with On-Demand Instances C. Create an Amazon CloudWatch cron job to automatically stop the EC2 instances when there is no activity D. Redesign the application to use an event-driven design with Amazon Simple Queue Service (Amazon SQS) and AWS Lambda. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA solutions architect is helping a developer design a new ecommerce shopping cart application using AWS services. The developer is unsure of the current database schema and expects to make changes as the ecommerce site grows. The solution needs to be highly resilient and capable of automatically scaling read and write capacity. Which database solution meets these requirements?\nA. Amazon Aurora PostgreSQL B. Amazon DynamoDB with on-demand enabled C. Amazon DynamoDB with DynamoDB Streams enabled D. Amazon SQS and Amazon Aurora PostgreSQL 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA three-tier web application processes orders from customers. The web tier consists of Amazon EC2 instances behind an Application Load Balancer, a middle tier of three EC2 instances decoupled from the web tier using Amazon SQS. and an Amazon DynamoDB backend. At peak times, customers who submit orders using the site have to wait much longer than normal to receive confirmations due to lengthy processing times. A solutions architect needs to reduce these processing times.\nWhich action will be MOST effective in accomplishing this?\nA. Replace the SQS queue with Amazon Kinesis Data Firehose. B. Use Amazon ElastiCache for Redis in front of the DynamoDB backend tier. C. Add an Amazon CloudFront distribution to cache the responses for the web tier. D. Use Amazon EC2 Auto Scaling to scale out the middle tier instances based on the SOS queue depth. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company built a food ordering application that captures user data and stores it for future analysis The application\u0026rsquo;s static front end is deployed on an Amazon EC2 instance The front-end application sends the requests to the backend application running on separate EC2 instance The backend application then stores the data in Amazon RDS What should a solutions architect do to decouple the architecture and make it scalable?\nA. Use Amazon S3 to serve the front-end application and write requests to an Amazon Simple Notification Service (Amazon SNS) topic Subscribe Amazon EC2 instances to the HTTP/HTTPS endpoint of the topic and process and store the data in Amazon RDS B. Use Amazon S3 to serve the front-end application which sends requests to Amazon EC2 to execute the backend application The backend application will process and store the data in Amazon RDS C. Use an EC2 instance to serve the front end and write requests to an Amazon SQS queue Place the backend instance in an Auto Scaling group and scale based on the queue depth to process and store the data in Amazon RDS D. Use Amazon S3 to serve the static front-end application and send requests to Amazon API Gateway which writes the requests to an Amazon SQS queue Place the backend instances in an Auto Scaling group and scale based on the queue depth to process and store the data in Amazon RDS 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA solutions architect must design a solution for a persistent database that is being migrated from on-premises to AWS. The database requires 64,000 IOPS according to the database administrator. If possible, the database administrator wants to use a single Amazon Elastic Block Store (Amazon EBS) volume to host the database instance. Which solution effectively meets the database administrator\u0026rsquo;s criteria?\nA. Use an instance from the 13 I/O optimized family and leverage local ephemeral storage to achieve the IOPS requirement. B. Create an Nitro-based Amazon EC2 instance with an Amazon EBS Provisioned IOPS SSD (io1) volume attached. Configure the volume to have 64,000 IOPS. C. Create and map an Amazon Elastic File System (Amazon EFS) volume to the database instance and use the volume to achieve the required IOPS for the database. D. Provision two volumes and assign 32,000 IOPS to each. Create a logical volume at the operating system level that aggregates both volumes to achieve the IOPS requirements. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing storage for a high performance computing (HPC) environment based on Amazon Linux. The workload stores and processes a large amount of engineering drawings that require shared storage and heavy computing. Which storage option would be the optimal solution?\nA. Amazon Elastic File System (Amazon EFS) B. Amazon FSx for Lustre C. Amazon EC2 instance store D. Amazon EBS Provisioned IOPS SSD (io1) 문제 풀이\r...\rAnswer: B\r#\rExplanation Amazon FSx for Lustre Amazon FSx for Lustre is a new, fully managed service provided by AWS based on the Lustre file system. Amazon FSx for Lustre provides a high-performance file system optimized for fast processing of workloads such as machine learning, high performance computing (HPC), video processing, financial modeling, and electronic design automation (EDA). FSx for Lustre allows customers to create a Lustre filesystem on demand and associate it to an Amazon S3 bucket. As part of the filesystem creation, Lustre reads the objects in the buckets and adds that to the file system metadata. Any Lustre client in your VPC is then able to access the data, which gets cached on the high-speed Lustre filesystem. This is ideal for HPC workloads, because you can get the speed of an optimized Lustre file system without having to manage the complexity of deploying, optimizing, and managing the Lustre cluster. Additionally, having the filesystem work natively with Amazon S3 means you can shut down the Lustre filesystem when you don\u0026rsquo;t need it but still access objects in Amazon S3 via other AWS Services. FSx for Lustre also allows you to also write the output of your HPC job back to Amazon S3.\n#\r#\rQUESTION\r#\rA company\u0026rsquo;s operations teams has an existing Amazon S3 bucket configured to notify an Amazon SQS queue when new object are created within the bucket. The development team also wants to receive events when new objects are created. The existing operations team workflow must remain intact. Which solution would satisfy these requirements?\nA. Create another SQS queue Update the S3 events in bucket to also update the new queue when a new object is created. B. Create a new SQS queue that only allows Amazon S3 to access the queue, Update Amazon S3 update this queue when a new object is created C. Create an Amazon SNS topic and SQS queue for the Update. Update the bucket to send events to the new topic. Updates both queues to poll Amazon SNS. D. Create an Amazon SNS topic and SQS queue for the bucket updates. Update the bucket to send events to the new topic Add subscription for both queue in the topic. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA marketing company is storing CSV files in an Amazon S3 bucket for statistical analysis An application on an Amazon EC2 instance needs permission to efficiently process the CSV data stored in the S3 bucket. Which action will MOST securely grant the EC2 instance access to the S3 bucket?\nA. Attach a resource-based policy to the S3 bucket B. Create an IAM user for the application with specific permissions to the S3 bucket C. Associate an IAM role with least privilege permissions to the EC2 instance profile D. Store AWS credentials directly on the EC2 instance for applications on the instance to use for API calls 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company stores call recordings on a monthly basis Statistically, the recorded data may be referenced randomly within a year but accessed rarely after 1 year Files that are newer than 1 year old must be queried and retrieved as quickly as possible. A delay in retrieving older files is acceptable A solutions architect needs to store the recorded data at a minimal cost Which solution is MOST costeffective?\nA. Store individual files in Amazon S3 Glacier and store search metadata in object tags created in S3 Glacier Query S3 Glacier tags and retrieve the files from S3 Glacier B. Store individual files in Amazon S3 Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year. Query and retrieve the files from Amazon S3 or S3 Glacier. C. Archive individual files and store search metadata for each archive in Amazon S3 Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year Query and retrieve the files by searching for metadata from Amazon S3 D. Archive individual files in Amazon S3 Use lifecycle policies to move the files to Amazon S3 Glacier after 1 year Store search metadata in Amazon DynamoDB Query the files from DynamoDB and retrieve them from Amazon S3 or S3 Glacier 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company\u0026rsquo;s web application is using multiple Linux Amazon EC2 instances and storing data on Amazon EBS volumes. The company is looking for a solution to increase the resiliency of the application in case of a failure and to provide storage that complies with atomicity, consistency, isolation, and durability (ACID). What should a solutions architect do to meet these requirements?\nA. Launch the application on EC2 instances in each Availability Zone. Attach EBS volumes to each EC2 instance. B. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones Mount an instance store on each EC2 instance C. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones. Store data on Amazon EFS and mount a target on each instance. D. Create an Application Load Balancer with Auto Scaling groups across multiple Availability Zones Store data using Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) 문제 풀이\r...\rAnswer: C\r#\rExplanation How Amazon EFS Works with Amazon EC2 The following illustration shows an example VPC accessing an Amazon EFS file system. Here, EC2 instances in the VPC have file systems mounted. In this illustration, the VPC has three Availability Zones, and each has one mount target created in it. We recommend that you access the file system from a mount target within the same Availability Zone. One of the Availability Zones has two subnets. However, a mount target is created in only one of the subnets. Benefits of Auto Scaling Better fault tolerance. Amazon EC2 Auto Scaling can detect when an instance is unhealthy, terminate it, and launch an instance to replace it. You can also configure Amazon EC2 Auto Scaling to use multiple Availability Zones. If one Availability Zone becomes unavailable, Amazon EC2 Auto Scaling can launch instances in another one to compensate. Better availability. Amazon EC2 Auto Scaling helps ensure that your application always has the right amount of capacity to handle the current traffic demand. Better cost management. Amazon EC2 Auto Scaling can dynamically increase and decrease capacity as needed. Because you pay for the EC2 instances you use, you save money by launching instances when they are needed and terminating them when they aren\u0026rsquo;t. https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html#how-it-works-ec2 https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-benefits.html\n#\r#\rQUESTION\r#\rA company with facilities in North America. Europe, and Asia is designing new distributed application to optimize its global supply chain and manufacturing process. The orders booked on one continent should be visible to all Regions in a second or less. The database should be able to support failover with a short Recovery Time Objective (RTO) The uptime of the application is important to ensure that manufacturing is not impacted What should a solutions architect recommend?\nA. Use Amazon DynamoDB global tables B. Use Amazon Aurora Global Database C. Use Amazon RDS for MySQL with a cross-Region read replica D. Use Amazon RDS for PostgreSQL with a cross-Region read replica 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company collects temperature, humidity, and atmospheric pressure data in cities across multiple continents. The average volume of data collected per site each day is 500 GB. Each site has a high-speed internet connection. The company\u0026rsquo;s weather forecasting applications are based in a single Region and analyze the data daily. What is the FASTEST way to aggregate data for all of these global sites?\nA. Enable Amazon S3 Transfer Acceleration on the destination bucket. Use multipart uploads to directly upload site data to the destination bucket. B. Upload site data to an Amazon S3 bucket in the closest AWS Region. Use S3 cross-Region replication to copy objects to the destination bucket. C. Upload site data to an Amazon S3 bucket in the closest AWS Region. Use S3 cross-Region replication to copy objects to the destination bucket. D. Upload the data to an Amazon EC2 instance in the closes Region. Store the data in an Amazon EBS volume. One a day take an EBS snapshot and copy it to the centralize Region. Restore the EBS volume in the centralized Region and run an analysis on the data daily. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA healthcare company stores highly sensitive patient records. Compliance requires that multiple copies be stored in different locations Each record must be stored for 7 years. The company has a service level agreement (SLA) to provide records to government agencies immediately for the first 30 days and then within 4 hours of a request thereafter. What should a solutions architect recommend?\nA. Use Amazon S3 with cross-Region replication enabled After 30 days, transition the data to Amazon S3 Glacier using lifecycle policy B. Use Amazon S3 with cross-origin resource sharing (CORS) enabled. After 30 days, transition the data to Amazon S3 Glacier using a lifecycle policy. C. Use Amazon S3 with cross-Region replication enabled After 30 days, transition the data to Amazon S3 Glacier Deep Achieve using a lifecycle policy D. Use Amazon S3 with cross-origin resource sharing (GORS) enabled After 30 days, transition the data to Amazon S3 Glacier Deep Archive using a lifecycle policy 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company running an on-premises application is migrating the application to AWS to increase its elasticity and availability. The current architecture uses a Microsoft SQL Server database with heavy read activity. The company wants to explore alternate database options and migrate database engines, if needed. Every 4 hours, the development team does a full copy of the production database to populate a test database. During this period, users experience latency. What should a solution architect recommend as replacement database?\nA. Use Amazon Aurora with Multi-AZ Aurora Replicas and restore from mysqldump for the test database. B. Use Amazon Aurora with Multi-AZ Aurora Replicas and restore snapshots from Amazon RDS for the test database. C. Use Amazon RDS for MySQL with a Multi-AZ deployment and read replicas, and use the standby instance for the test database. D. Use Amazon RDS for SQL Server with a Multi-AZ deployment and read replicas, and restore snapshots from RDS for the test database. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing a security solution for a company that wants to provide developers with individual AWS accounts through AWS Organizations, while also maintaining standard security controls. Because the individual developers will have AWS account root user-level access to their own accounts, the solutions architect wants to ensure that the mandatory AWS CloudTrail configuration that is applied to new developer accounts is not modified. Which action meets these requirements?\nA. Create an IAM policy that prohibits changes to CloudTrail, and attach it to the root user. B. Create a new trail in CloudTrail from within the developer accounts with the organization trails option enabled. C. Create a service control policy (SCP) the prohibits changes to CloudTrail, and attach it the developer accounts. D. Create a service-linked role for CloudTrail with a policy condition that allows changes only from an Amazon Resource Name (ARN) in the master account. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company has a website running on Amazon EC2 instances across two Availability Zones. The company is expecting spikes in traffic on specific holidays, and wants to provide a consistent user experience. How can a solutions architect meet this requirement?\nA. Use step scaling. B. Use simple scaling. C. Use lifecycle hooks. D. Use scheduled scaling. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing a multi-Region disaster recovery solution for an application that will provide public API access. The application will use Amazon EC2 instances with a userdata script to load application code and an Amazon RDS for MySQL database The Recovery Time Objective (RTO) is 3 hours and the Recovery Point Objective (RPO) is 24 hours. Which architecture would meet these requirements at the LOWEST cost?\nA. Use an Application Load Balancer for Region failover. Deploy new EC2 instances with the userdata script. Deploy separate RDS instances in each Region B. Use Amazon Route 53 for Region failover Deploy new EC2 instances with the userdata script Create a read replica of the RDS instance in a backup Region C. Use Amazon API Gateway for the public APIs and Region failover Deploy new EC2 instances with the userdata script Create a MySQL read replica of the RDS instance in a backup Region D. Use Amazon Route 53 for Region failover Deploy new EC2 instances with the userdata scnpt for APIs, and create a snapshot of the RDS instance daily for a backup Replicate the snapshot to a backup Region 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rAn application runs on Amazon EC2 instances in private subnets. The application needs to access an Amazon DynamoDB table. What is the MOST secure way to access the table while ensuring that the traffic does not leave the AWS network?\nA. Use a VPC endpoint for DynamoDB. B. Use a NAT gateway in a public subnet. C. Use a NAT instance in a private subnet. D. Use the internet gateway attached to the VPC. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has two VPCs named Management and Production. The Management VPC uses VPNs through a customer gateway to connect to a single device in the data center The Production VPC uses a virtual private gateway with two attached AWS Direct Connect connections. The Management and Production VPCs both use a single VPC peering connection to allow communication between the applications. What should a solutions architect do to mitigate any single point of failure in this architecture?\nA. Add a set of VPNs between the Management and Production VPCs. B. Add a second virtual private gateway and attach it to the Management VPC C. Add a second set of VPNs to the Management VPC from a second customer gateway device D. Add a second VPC peering connection between the Management VPC and the Production VPC. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company receives inconsistent service from its data center provider because the company is headquartered in an area affected by natural disasters. The company is not ready to fully migrate to the AWS Cloud, but it wants a failure environment on AWS in case the on-premises data center fails. The company runs web servers that connect to external vendors. The data available on AWS and on premises must be uniform. Which solution should a solutions architect recommend that has the LEAST amount of downtime?\nA. Configure an Amazon Route 53 failover record. Run application servers on Amazon EC2 instances behind an Application Load Balancer in an Auto Scaling group. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3. B. Configure an Amazon Route 53 failover record. Execute an AWS CloudFormation template from a script to create Amazon EC2 instances behind an Application Load Balancer. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3. C. Configure an Amazon Route 53 failover record. Set up an AWS Direct Connect connection between a VPC and the data center. Run application servers on Amazon EC2 in an Auto Scaling group. Run an AWS Lambda function to execute an AWS CloudFormation template to create an Application Load Balancer. D. Configure an Amazon Route 53 failover record. Run an AWS Lambda function to execute an AWS CloudFormation template to launch two Amazon EC2 instances. Set up AWS Storage Gateway with stored volumes to back up data to Amazon S3. Set up an AWS Direct Connect connection between a VPC and the data center. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company mandates that an Amazon S3 gateway endpoint must allow traffic to trusted buckets only Which method should a solutions architect implement to meet this requirement?\nA. Create a bucket policy for each of the company\u0026rsquo;s trusted S3 buckets that allows traffic only from the company\u0026rsquo;s trusted VPCs B. Create a bucket policy for each of the company\u0026rsquo;s trusted S3 buckets that allows traffic only from the company\u0026rsquo;s S3 gateway endpoint IDs C. Create an S3 endpoint policy for each of the company\u0026rsquo;s S3 gateway endpoints that blocks access from any VPC other than the company\u0026rsquo;s trusted VPCs D. Create an S3 endpoint policy for each of the company\u0026rsquo;s S3 gateway endpoints that provides access to the Amazon Resource Name (ARN) of the trusted S3 buckets 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA Solutions Architect must design a web application that will be hosted on AWS, allowing users to purchase access to premium, shared content that is stored in an S3 bucket. Upon payment, content will be available for download for 14 days before the user is denied access Which of the following would be the LEAST complicated implementation?\nA. Use an Amazon CloudFront distribution with an origin access identity (OAI) Configure the distribution with an Amazon S3 origin to provide access to the file through signed URL\u0026rsquo;s Design a Lambda function to remove data that is older than 14 days. B. Use an S3 bucket and provide direct access to the tile Design the application to track purchases in a DynamoDH table Configure a Lambda function to remove data that is older than 14 days based on a query to Amazon DynamoDB C. Use an Amazon CloudFront distribution with an OAI Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs Design the application to sot an expiration of 14 days for the URL D. Use an Amazon CloudFront distribution with an OAI Configure the distribution with an Amazon S3 origin to provide access to the file through signed URLs Design the application to set an expiration of 60 minutes for the URL and recreate the URL as necessary 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company provides an API to its users that automates inquiries for tax computations based on item prices. The company experiences a larger number of inquiries during the holiday season only that cause slower response times. A solutions architect needs to design a solution that is scalable and elastic What should the solutions architect do to accomplish this?\nA. Provide an API hosted on an Amazon EC2 instance. The EC2 instance performs the required computations when the API request is made. B. Design a REST API using Amazon API Gateway that accepts the item names API Gateway passes item names to AWS Lambda for tax computations C. Create an Application Load Balancer that has two Amazon EC2 instances behind it. The EC2 instances will compute the tax on the received item names. D. Design a REST API using Amazon API Gateway that connects with an API hosted on an Amazon EC2 instance API Gateway accepts and passes the item names to the EC2 instance for tax computations 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company uses Application Load Balancers (ALBs) in different AWS Regions. The ALBs receive inconsistent traffic that can spike and drop throughout the year The company\u0026rsquo;s networking team needs to allow the IP addresses of the ALBs in the on-premises firewall to enable connectivity. Which solution is the MOST scalable with minimal configuration changes?\nA. Write an AWS Lambda script to get the IP addresses of the ALBs in different Regions Update the on-premises firewall\u0026rsquo;s rule to allow the IP addresses of the ALBs. B. Migrate all ALBs in different Regions to the Network Load Balancers (NLBs) Update the onpremises firewall\u0026rsquo;s rule to allow the Elastic IP addresses of all the NLBs. C. Launch AWS Global Accelerator Register the ALBs in different Regions to the accelerator. Update the on-premises firewall\u0026rsquo;s rule to allow static IP addresses associated with the accelerator. D. Launch a Network Load Balancer (NLB) in one Region Register the private IP addresses of the ALBs m different Regions with the NLB Update the on-premises firewall\u0026rsquo;s rule to allow the Elastic IP address attached to the NLB. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA solution architect must migrate a Windows internet information Services (IIS) web application to AWS. The application currently relies on a file share hosted in the user\u0026rsquo;s on-premises network-attached storage (NAS). The solution architected has proposed migrating the IIS web servers Which replacement to the on-promises filo share is MOST resilient and durable?\nA. Migrate the file Share to Amazon RDS. B. Migrate the tile Share to AWS Storage Gateway C. Migrate the file Share to Amazon FSx dor Windows File Server. D. Migrate the tile share to Amazon Elastic File System (Amazon EFS) 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company is building applications in containers. The company wants to migrate its onpremises development and operations services from its on-premises data center to AWS. Management states that production system must be cloud agnostic and use the same configuration and administrator tools across production systems. A solutions architect needs to design a managed solution that will align open-source software. Which solution meets these requirements?\nA. Launch the containers on Amazon EC2 with EC2 instance worker nodes. B. Launch the containers on Amazon Elastic Kubernetes Service (Amazon EKS) and EKS workers nodes. C. Launch the containers on Amazon Elastic Containers service (Amazon ECS) with AWS Fargate instances. D. Launch the containers on Amazon Elastic Container Service (Amazon EC) with Amazon EC2 instance worker nodes. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company currently operates a web application backed by an Amazon RDS MySQL database It has automated backups that are run daily and are not encrypted A security audit requires future backups to be encrypted and the unencrypted backups to be destroyed The company will make at least one encrypted backup before destroying the old backups What should be done to enable encryption for future backups?\nA. Enable default encryption for the Amazon S3 bucket where backups are stored B. Modify the backup section of the database configuration to toggle the Enable encryption check box C. Create a snapshot of the database Copy it to an encrypted snapshot Restore the database from the encrypted snapshot D. Enable an encrypted read replica on RDS for MySQL Promote the encrypted read replica to primary Remove the original database instance 문제 풀이\r...\rAnswer: C\r#\rExplanation However, because you can encrypt a copy of an unencrypted DB snapshot, you can effectively add encryption to an unencrypted DB instance. That is, you can create a snapshot of your DB instance, and then create an encrypted copy of that snapshot. You can then restore a DB instance from the encrypted snapshot, and thus you have an encrypted copy of your original DB instance DB instances that are encrypted can\u0026rsquo;t be modified to disable encryption. You can\u0026rsquo;t have an encrypted read replica of an unencrypted DB instance or an unencrypted read replica of an encrypted DB instance. Encrypted read replicas must be encrypted with the same key as the source DB instance when both are in the same AWS Region. You can\u0026rsquo;t restore an unencrypted backup or snapshot to an encrypted DB instance. To copy an encrypted snapshot from one AWS Region to another, you must specify the KMS key identifier of the destination AWS Region. This is because KMS encryption keys are specific to the AWS Region that they are created in. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html\n#\r#\rQUESTION\r#\rA company hosts its website on AWS. To address the highly variable demand, the company has implemented Amazon EC2 Auto Scaling. Management is concerned that the company is overprovisioning its infrastructure, especially at the front end of the three-tier application. A solutions architect needs to ensure costs are optimized without impacting performance. What should the solutions architect do to accomplish this?\nA. Use Auto Scaling with Reserved Instances. B. Use Auto Scaling with a scheduled scaling policy. C. Use Auto Scaling with the suspend-resume feature D. Use Auto Scaling with a target tracking scaling policy. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company uses a legacy on-premises analytics application that operates on gigabytes of csv files and represents months of data The legacy application cannot handle the growing size of csv files New csv files are added daily from various data sources to a central on-premises storage location The company wants to continue to support the legacy application while users learn AWS analytics services To achieve this, a solutions architect wants to maintain two synchronized copies of all the csv files on-premises and in Amazon S3 Which solution should the solutions architect recommend?\nA. Deploy AWS DataSync on-premises. Configure DataSync to continuously replicate the csv files between the company\u0026rsquo;s on-premises storage and the company\u0026rsquo;s S3 bucket B. Deploy an on-premises file gateway Configure data sources to write the csv files to the file gateway Point the legacy analytics application to the file gateway The file gateway should replicate the csv files to Amazon S3 C. Deploy an on-premises volume gateway. Configure data sources to write the csv files to the volume gateway. Point the legacy analytics application to the volume gateway. The volume gateway should replicate data to Amazon S3. D. Deploy AWS DataSync on-premises Configure DataSync to continuously replicate the csv files between on-premises and Amazon Elastic File System (Amazon EFS) Enable replication from Amazon EFS to the company\u0026rsquo;s S3 bucket. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA solutions architect is designing a solution where users will De directed to a backup static error page it the primary website is unavailable The primary website\u0026rsquo;s DNS records are hosted in Amazon Route 53 where their domain is pointing to an Application Load Balancer (ALB) Which configuration should the solutions architect use to meet the company\u0026rsquo;s needs while minimizing changes and infrastructure overhead?\nA. Point a Route 53 alias record to an Amazon CloudFront distribution with the ALB as one of its origins Then, create custom error pages for the distribution B. Set up a Route 53 active-passive failover configuration Direct traffic to a static error page hosted within an Amazon S3 bucket when Route 53 health checks determine that the ALB endpoint is unhealthy C. Update the Route 53 record to use a latency-based routing policy Add the backup static error page hosted within an Amazon S3 bucket to the record so the traffic is sent to the most responsive endpoints D. Set up a Route 53 active-active configuration with the ALB and an Amazon EC2 instance hosting a static error page as endpoints Route 53 will only send requests to the instance if the health checks fail for the ALB 문제 풀이\r...\rAnswer: B\r#\rExplanation Active-passive failover Use an active-passive failover configuration when you want a primary resource or group of resources to be available the majority of the time and you want a secondary resource or group of resources to be on standby in case all the primary resources become unavailable. When responding to queries, Route 53 includes only the healthy primary resources. If all the primary resources are unhealthy, Route 53 begins to include only the healthy secondary resources in response to DNS queries. To create an active-passive failover configuration with one primary record and one secondary record, you just create the records and specify Failover for the routing policy. When the primary resource is healthy, Route 53 responds to DNS queries using the primary record. When the primary resource is unhealthy, Route 53 responds to DNS queries using the secondary record. How Amazon Route 53 averts cascading failures As a first defense against cascading failures, each request routing algorithm (such as weighted and failover) has a mode of last resort. In this special mode, when all records are considered unhealthy, the Route 53 algorithm reverts to considering all records healthy. For example, if all instances of an application, on several hosts, are rejecting health check requests, Route 53 DNS servers will choose an answer anyway and return it rather than returning no DNS answer or returning an NXDOMAIN (non-existent domain) response. An application can respond to users but still fail health checks, so this provides some protection against misconfiguration. Similarly, if an application is overloaded, and one out of three endpoints fails its health checks, so that it\u0026rsquo;s excluded from Route 53 DNS responses, Route 53 distributes responses between the two remaining endpoints. If the remaining endpoints are unable to handle the additional load and they fail, Route 53 reverts to distributing requests to all three endpoints. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-problems.html\n#\r#\rQUESTION\r#\rA company has a legacy application that processes data in two parts The second part of the process takes longer than the first, so the company has decided to rewrite the application as two microservices running on Amazon ECS that can scale independently. How should a solutions architect integrate the microservices?\nA. Implement code in microservice 1 to send data to an Amazon S3 bucket. Use S3 event notifications to invoke microservice 2. B. Implement code in microservice 1 to publish data to an Amazon SNS topic Implement code in microservice 2 to subscribe to this topic C. Implement code in microservice 1 to send data to Amazon Kinesis Data Firehose. Implement code in microservice 2 to read from Kinesis Data Firehose. D. Implement code in microservice 1 to send data to an Amazon SQS queue Implement code in microservice 2 to process messages from the queue 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company runs a multi-tier web application that hosts news content The application runs on Amazon EC2 instances behind an Application Load Balancer. The instances run in an EC2 Auto Scaling group across multiple Availability Zones and use an Amazon Aurora database. A solutions architect needs to make the application more resilient to periodic increases in request rates. Which architecture should the solutions architect implement? (Select TWO )\nA. Add AWS Shield. B. Add Aurora Replicas C. Add AWS Direct Connect D. Add AWS Global Accelerator. E. Add an Amazon CloudFront distribution in front of the Application Load Balancer 문제 풀이\r...\rAnswer: D E\r#\rExplanation AWS Global Accelerator Acceleration for latency-sensitive applications Many applications, especially in areas such as gaming, media, mobile apps, and financials, require very low latency for a great user experience. To improve the user experience, Global Accelerator directs user traffic to the application endpoint that is nearest to the client, which reduces internet latency and jitter. Global Accelerator routes traffic to the closest edge location by using Anycast, and then routes it to the closest regional endpoint over the AWS global network. Global Accelerator quickly reacts to changes in network performance to improve your users\u0026rsquo; application performance. Amazon CloudFront Amazon CloudFront is a fast content delivery network (CDN) service that securely delivers data, videos, applications, and APIs to customers globally with low latency, high transfer speeds, all within a developer-friendly environment. https://docs.aws.amazon.com/global-accelerator/latest/dg/introduction-benefits-of-migrating.html\n#\r#\rQUESTION\r#\rA company\u0026rsquo;s application is running on Amazon EC2 instances within an Auto Scaling group behind an Elastic Load Balancer Based on the application\u0026rsquo;s history, the company anticipates a spike in traffic during a holiday each year A solutions architect must design a strategy to ensure that the Auto Scaling group proactively increases capacity to minimize any performance impact on application users Which solution will meet these requirements?\nA. Create an Amazon CloudWatch alarm to scale up the EC2 instances when CPU utilization exceeds 90% B. Create a recurring scheduled action to scale up the Auto Scaling group before the expected period of peak demand C. Increase the minimum and maximum number of EC2 instances in the Auto Scaling group during the peak demand period D. Configure an Amazon Simple Notification Service (Amazon SNS) notification to send alerts when there are auto scaling EC2_INSTANCE_LAUNCH events 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company is migrating a Linux-based web server group to AWS The web servers must access files in a shared file store for some content To meet the migration date, minimal changes can be made What should a solutions architect do to meet these requirements?\nA. Create an Amazon S3 Standard bucket with access to the web server. B. Configure an Amazon CloudFront distribution with an Amazon S3 bucket as the origin C. Create an Amazon Elastic File System (Amazon EFS) volume and mount it on all web servers D. Configure Amazon Elastic Block Store (Amazon EBS) Provisioned IOPS SSD (io1) volumes and mount them on all web servers. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company wants to host a web application on AWS that will communicate to a database within a VPC. The application should be highly available. What should a solutions architect recommend?\nA. Create two Amazon EC2 instances to host the web servers behind a load balancer, and then deploy the database on a large instance. B. Deploy a load balancer in multiple Availability Zones with an Auto Scaling group for the web servers, and then deploy Amazon RDS in multiple Availability Zones. C. Deploy a load balancer in the public subnet with an Auto Scaling group for the web servers, and then deploy the database on an Amazon EC2 instance in the private subnet. D. Deploy two web servers with an Auto Scaling group, configure a domain that points to the two web servers, and then deploy a database architecture in multiple Availability Zones. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company receives structured and semi-structured data from various sources once every day. A solutions architect needs to design a solution that leverages big data processing frameworks. The data should be accessible using SQL queries and business intelligence tools. What should the solutions architect recommend to build the MOST high-performing solution?\nA. Use AWS Glue to process data and Amazon S3 to store data B. Use Amazon EMR to process data and Amazon Redshift to store data C. Use Amazon EC2 to process data and Amazon Elastic Block Store (Amazon EBS) to store data D. Use Amazon Kinesis Data Analytics to process data and Amazon Elastic File System (Amazon EFS) to store data 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company\u0026rsquo;s web application is running on Amazon EC2 instances behind an Application Load Balancer. The company recently changed its policy, which now requires the application to be accessed from one specific country only. Which configuration will meet this requirement?\nA. Configure the security group for the EC2 instances. B. Configure the security group on the Application Load Balancer. C. Configure AWS WAF on the Application Load Balancer in a VPC. D. Configure the network ACL for the subnet that contains the EC2 instances. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company wants to migrate a workload to AWS. The chief information security officer requires that all data be encrypted at rest when stored in the cloud. The company wants complete control of encryption key lifecycle management. The company must be able to immediately remove the key material and audit key usage independently of AWS CloudTrail. The chosen services should integrate with other storage services that will be used on AWS. Which services satisfies these security requirements?\nA. AWS CloudHSM with the CloudHSM client B. AWS Key Management Service (AWS KMS) with AWS CloudHSM C. AWS Key Management Service (AWS KMS) with an external key material origin D. AWS Key Management Service (AWS KMS) with AWS managed customer master keys (CMKs) 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company hosts an application used to upload files to an Amazon S3 bucket Once uploaded, the files are processed to extract metadata, which takes less than 5 seconds. The volume and frequency of the uploads vanes from a few files each hour to hundreds of concurrent uploads. The company has asked a solutions architect to design a cost effective architecture that will meet these requirements. What should the solutions architect recommend?\nA. Configure AWS CloudTrail trails to log S3 API calls Use AWS AppSync to process the files B. Configure an object-created event notification within the S3 bucket to invoke an AWS Lambda function to process the files. C. Configure Amazon Kinesis Data Streams to process and send data to Amazon S3 Invoke an AWS Lambda function to process the files D. Configure an Amazon Simple Notification Service (Amazon SNS) topic to process the files uploaded to Amazon S3. Invoke an AWS Lambda function to process the files. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company hosts an online shopping application that stores all orders in an Amazon RDS for PostgreSQL Single-AZ DB instance Management wants to eliminate single points of failure and has asked a solutions architect to recommend an approach to minimize database downtime without requiring any changes to the application code.\nWhich solution meets these requirements?\nA. Convert the existing database instance to a Multi-AZ deployment by modifying the database instance and specifying the Multi-AZ option. B. Create a new RDS Multi-AZ deployment Take a snapshot of the current RDS instance and restore the new Multi-AZ deployment with the snapshot C. Create a read-only replica of the PostgreSQL database in another Availability Zone Use Amazon Route 53 weighted record sets to distribute requests across the databases. D. Place the RDS for PostgreSQL database in an Amazon EC2 Auto Scaling group with a minimum group size of two Use Amazon Route 53 weighted record sets to distribute requests across instances. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company\u0026rsquo;s web application uses an Amazon RDS PostgreSQL DB instance to store its application data. During the financial closing period at the start of every month. Accountants run large queries that impact the database\u0026rsquo;s performance due to high usage. The company wants to minimize the impact that the reporting activity has on the web application. What should a solutions architect do to reduce the impact on the database with the LEAST amount of effort?\nA. Create a read replica and direct reporting traffic to the replica. B. Create a Multi-AZ database and direct reporting traffic to the standby. C. Create a cross-Region read replica and direct reporting traffic to the replica. D. Create an Amazon Redshift database and direct reporting traffic to the Amazon Redshift database. 문제 풀이\r...\rAnswer: A\r#\rExplanation https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html Amazon RDS uses the MariaDB, MySQL, Oracle, PostgreSQL, and Microsoft SQL Server DB engines\u0026rsquo; built-in replication functionality to create a special type of DB instance called a read replica from a source DB instance. Updates made to the source DB instance are asynchronously copied to the read replica. You can reduce the load on your source DB instance by routing read queries from your applications to the read replica. When you create a read replica, you first specify an existing DB instance as the source. Then Amazon RDS takes a snapshot of the source instance and creates a read-only instance from the snapshot. Amazon RDS then uses the asynchronous replication method for the DB engine to update the read replica whenever there is a change to the source DB instance. The read replica operates as a DB instance that allows only read-only connections. Applications connect to a read replica the same way they do to any DB instance. Amazon RDS replicates all databases in the source DB instance. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html\n#\r#\rQUESTION\r#\rA company runs a high performance computing (HPC) workload on AWS. The workload required low-latency network performance and high network throughput with tightly coupled nodeto-node communication. The Amazon EC2 instances are properly sized for compute and storage capacity, and are launched using default options. What should a solutions architect propose to improve the performance of the workload?\nA. Choose a cluster placement group while launching Amazon EC2 instances B. Choose dedicated instance tenancy while launching Amazon EC2 instances C. Choose an Elastic Inference accelerator while launching Amazon EC2 instances D. Choose the required capacity reservation while launching Amazon EC2 instances. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has an application with a REST-based Interface that allows data to be received in near-real time from a third-party vendor Once received, the application processes and stores the data for further analysis. The application Is running on Amazon EC2 instances. The third-party vendor has received many 503 Service Unavailable Errors when sending data to the application. When the data volume spikes, the compute capacity reaches its maximum limit and the application is unable to process all requests. Which design should a solutions architect recommend to provide a more scalable solution?\nA. Use Amazon Kinesis Data Streams to ingest the data Process the data using AWS Lambda functions. B. Use Amazon API Gateway on top of the existing application. Create a usage plan with a quota Iimit for the third-party vendor. C. Use Amazon Simple Notification Service (Amazon SNS) to ingest the data Put the EC2 instances in an Auto Scaling group behind an Application Load Balancer. D. Repackage the application as a container. Deploy the application using Amazon Elastic Container Service (Amazon ECS) using the EC2 launch type with an Auto Scaling group. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA solutions architect needs to ensure that all Amazon Elastic Block Store (Amazon EBS) volumes restored from unencrypted EBS snapshots are encrypted What should the solutions architect do to accomplish this?\nA. Enable EBS encryption by default for the AWS Region B. Enable EBS encryption by default for the specific volumes C. Create a new volume and specify the symmetric customer master key (CMK) to use for encryption D. Create a new volume and specify the asymmetric customer master key (CMK) to use for encryption. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has an on-premises data center that is running out of storage capacity. The company wants to migrate its storage infrastructure to AWS while minimizing bandwidth costs The solution must allow for immediate retrieval of data at no additional cost. How can these requirements be met?\nA. Deploy Amazon S3 Glacier Vault and enable expedited retrieval. Enable provisioned retrieval capacity for the workload B. Deploy AWS Storage Gateway using cached volumes. Use Storage Gateway to store data in Amazon S3 while retaining copies of frequently accessed data subsets locally. C. Deploy AWS Storage Gateway using stored volumes to store data locally. Use Storage Gateway to asynchronously back up point-in-time snapshots of the data to Amazon S3 D. Deploy AWS Direct Connect to connect with the on-premises data center. Configure AWS Storage Gateway to store data locally. Use Storage Gateway to asynchronously bacK up potnt-tn-time snapshots of the data to Amazon S3. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company stores user data in AWS. The data is used continuously with peak usage during business hours. Access patterns vary, with some data not being used tor months at a time. A solution architect must choose a cost that maintains the highest level ot durability while maintaining high availability. Which storage solution meets these requirements?\nA. Amazon S3 Standard B. Amazon S3 intelligent Tiering C. Amazon S3 Glacier Deep Archive D. Amazon S3 One Zone-Infrequent Access (S3 One Zone-IA) 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rAn online photo application lets users upload photos and perform image editing operations The application offers two classes of service free and paid Photos submitted by paid users are processed before those submitted by free users Photos are uploaded to Amazon S3 and the job information is sent to Amazon SQS. Which configuration should a solutions architect recommend?\nA. Use one SQS FIFO queue Assign a higher priority to the paid photos so they are processed first B. Use two SQS FIFO queues: one for paid and one for free Set the free queue to use short polling and the paid queue to use long polling C. Use two SQS standard queues one for paid and one for free Configure Amazon EC2 instances to prioritize polling for the paid queue over the free queue. D. Use one SQS standard queue. Set the visibility timeout of the paid photos to zero Configure Amazon EC2 instances to prioritize visibility settings so paid photos are processed first 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company plans to store sensitive user data on Amazon S3. Internal security compliance requirement mandata encryption of data before sending it to Amazon S3. What should a solution architect recommend to satisfy these requirements?\nA. Server-side encryption with customer-provided encryption keys B. Client-side encryption with Amazon S3 managed encryption keys C. Server-side encryption with keys stored in AWS key Management Service (AWS KMS) D. Client-side encryption with a master key stored in AWS Key Management Service (AWS KMS) 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company requires that all versions of objects in its Amazon S3 bucket be retained Current object versions will be frequently accessed during the first 30 days, after which they will be rarely accessed and must be retrievable within 5 minutes Previous object versions need to be kept forever, will be rarely accessed, and can be retrieved within 1 week. All storage solutions must be highly available and highly durable What should a solutions architect recommend to meet these requirements in the MOST cost-effective manner?\nA. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Glacier after 30 days and moves previous object versions to S3 Glacier after 1 day. B. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Glacier after 30 days and moves previous object versions to S3 Glacier Deep Archive after 1 day C. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 Standard-infrequent Access (S3 Standard-IA) after 30 days and moves previous object versions to S3 Glacier Deep Archive after 1 day D. Create an S3 lifecycle policy for the bucket that moves current object versions from S3 Standard storage to S3 One Zone-Infrequent Access (S3 One Zone-IA) after 30 days and moves previous object versions to S3 Glacier Deep Archive after 1 day 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company runs an application in a branch office within a small data closet with no virtualized compute resources. The application data is stored on an NFS volume. Compliance standards require a daily offsite backup of the NFS volume. Which solution meet these requirements?\nA. Install an AWS Storage Gateway file gateway on premises to replicate the data to Amazon S3. B. Install an AWS Storage Gateway file gateway hardware appliance on premises to replicate the data to Amazon S3. C. Install an AWS Storage Gateway volume gateway with stored volumes on premises to replicate the data to Amazon S3. D. Install an AWS Storage Gateway volume gateway with cached volumes on premises to replicate the data to Amazon S3. 문제 풀이\r...\rAnswer: B\r#\rExplanation https://aws.amazon.com/storagegateway/file/ AWS Storage Gateway Hardware Appliance\nHardware Appliance Storage Gateway is available as a hardware appliance, adding to the existing support for VMware ESXi, Microsoft Hyper-V, and Amazon EC2. This means that you can now make use of Storage Gateway in situations where you do not have a virtualized environment, server-class hardware or IT staff with the specialized skills that are needed to manage them. You can order appliances from Amazon.com for delivery to branch offices, warehouses, and \u0026ldquo;outpost\u0026rdquo; offices that lack dedicated IT resources. Setup (as you will see in a minute) is quick and easy, and gives you access to three storage solutions: File Gateway - A file interface to Amazon S3, accessible via NFS or SMB. The files are stored as S3 objects, allowing you to make use of specialized S3 features such as lifecycle management and crossregion replication. You can trigger AWS Lambda functions, run Amazon Athena queries, and use Amazon Macie to discover and classify sensitive data. https://aws.amazon.com/blogs/aws/new-aws-storage-gateway-hardware-appliance/\n#\r#\rQUESTION\r#\rOrganizers for a global event want to put daily reports online as static HTML pages The pages are expected to generate millions of views from users around the world The files are stored in an Amazon S3 bucket A solutions architect has been asked to design an efficient and effective solution Which action should the solutions architect take to accomplish this?\nA. Generate presigned URLs for the files B. Use cross-Region replication to all Regions C. Use the geoproximity feature of Amazon Route 53 D. Use Amazon CloudFront with the S3 bucket as its origin 문제 풀이\r...\rAnswer: D\r#\rExplanation Using Amazon S3 Origins, MediaPackage Channels, and Custom Origins for Web Distributions Using Amazon S3 Buckets for Your Origin When you use Amazon S3 as an origin for your distribution, you place any objects that you want CloudFront to deliver in an Amazon S3 bucket. You can use any method that is supported by Amazon S3 to get your objects into Amazon S3, for example, the Amazon S3 console or API, or a third-party tool. You can create a hierarchy in your bucket to store the objects, just as you would with any other Amazon S3 bucket. Using an existing Amazon S3 bucket as your CloudFront origin server doesn\u0026rsquo;t change the bucket in any way; you can still use it as you normally would to store and access Amazon S3 objects at the standard Amazon S3 price. You incur regular Amazon S3 charges for storing the objects in the bucket. Using Amazon S3 Buckets Configured as Website Endpoints for Your Origin You can set up an Amazon S3 bucket that is configured as a website endpoint as custom origin with CloudFront. When you configure your CloudFront distribution, for the origin, enter the Amazon S3 static website hosting endpoint for your bucket. This value appears in the Amazon S3 console, on the Properties tab, in the Static website hosting pane. For example: http://bucket-name.s3-website-region.amazonaws.com For more information about specifying Amazon S3 static website endpoints, see Website endpoints in the Amazon Simple Storage Service Developer Guide. When you specify the bucket name in this format as your origin, you can use Amazon S3 redirects and Amazon S3 custom error documents. For more information about Amazon S3 features, see the Amazon S3 documentation. Using an Amazon S3 bucket as your CloudFront origin server doesn\u0026rsquo;t change it in any way. You can still use it as you normally would and you incur regular Amazon S3 charges.\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/DownloadDistS3AndCusto mOrigins.h\n#\r#\rQUESTION\r#\rA database is on an Amazon RDS MYSQL 5.6 Multi-AZ DB instance that experience highly dynamic reads. Application developers notice a significant slowdown when testing read performance from a secondary AWS Region. The developers want a solution that provides less than 1 second of read replication latency. What should the solutions architect recommend?\nA. Install MySQL on Amazon EC2 in (he secondary Region. B. Migrate the database to Amazon Aurora with cross-Region replicas. C. Create another RDS for MySQL read replica in the secondary. D. Implement Amazon ElastiCache to improve database query performance. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA data science team requires storage for nightly log processing. The size and number of logs is unknown and will persist for 24 hours only What is the MOST cost-effective solution?\nA. Amazon S3 Glacier B. Amazon S3 Standard C. Amazon S3 intelligent-Tiering D. Amazon S3 One Zone-Infrequent Access {S3 One Zone-IA) 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA media company has an application that tracks user clicks on its websites and performs analytics to provide near-real time recommendations. The application has a Heel of Amazon EC2 instances that receive data from the websites and send the data lo an Amazon RDS DB instance Another fleet of EC2 instances hosts the portion of the application that is continuously checking changes in the database and executing SQL queries to provide recommendations. Management has requested a redesign to decouple the infrastructure The solution must ensure that data analysts are writing SQL to analyze the data only No data can the lost during the deployment What should a solutions architect recommend?\nA. Use Amazon Kinesis Data Streams to capture the data from the websites Kinesis Data Firehose to persist the data on Amazon S3, and Amazon Athena to query the data B. Use Amazon Kinesis Data Streams to capture the data from the websites. Kinesis Data Analytics to query the data, and Kinesis Data Firehose to persist the data on Amazon S3 C. Use Amazon Simple Queue Service (Amazon SQS) to capture the data from the websites, keep the fleet of EC2 instances, and change to a bigger instance type in the Auto Scaling group configuration D. Use Amazon Simple Notification Service (Amazon SNS) to receive data from the websites and proxy the messages to AWS Lambda functions that execute the queries and persist the data Change Amazon RDS to Amazon Aurora Serverless to persist the data 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company has deployed an API in a VPC behind an internet-facing Application Load Balancer (ALB) An application that consumes the API as a client is deployed in a second account in private subnets behind a NAT gateway. When requests to the client application increase, the NAT gateway costs are higher than expected. A solutions architect has configured the ALB to be internal. Which combination of architectural changes will reduce the NAT gateway costs?(Select TWO )\nA. Configure a VPC peering connection between the two VPCs. Access the API using the private address B. Configure an AWS Direct Connect connection between the two VPCs. Access the API using the private address. C. Configure a ClassicLink connection for the API into the client VPC Access the API using the ClassicLink address. D. Configure a PrivateLink connection for the API into the client VPC. Access the API using the PrivateLink address. E. Configure an AWS Resource Access Manager connection between the two accounts Access the API using the private address 문제 풀이\r...\rAnswer: A D\r#\r#\r#\rQUESTION\r#\rA product team is creating a new application that will store a large amount of data The data will be analyzed hourly and modified by multiple Amazon EC2 Linux instances The application team believes the amount of space needed will continue to grow for the next 6 months Which set of actions should a solutions architect take to support these needs?\nA. Store the data in an Amazon EBS volume Mount the EBS volume on the application instances B. Store the data in an Amazon EFS file system Mount the file system on the application instances C. Store the data in Amazon S3 Glacier Update the vault policy to allow access to the application instances D. Store the data in Amazon S3 Standard-Infrequent Access (S3 Standard-IA) Update the bucket policy to allow access to the application instances 문제 풀이\r...\rAnswer: B\r#\rExplanation Amazon Elastic File System Amazon Elastic File System (Amazon EFS) provides a simple, scalable, fully managed elastic NFS file system for use with AWS Cloud services and on-premises resources. It is built to scale on demand to petabytes without disrupting applications, growing and shrinking automatically as you add and remove files, eliminating the need to provision and manage capacity to accommodate growth. Amazon EFS is designed to provide massively parallel shared access to thousands of Amazon EC2 instances, enabling your applications to achieve high levels of aggregate throughput and IOPS with consistent low latencies. Amazon EFS is well suited to support a broad spectrum of use cases from home directories to business-critical applications. Customers can use EFS to lift-and-shift existing enterprise applications to the AWS Cloud. Other use cases include: big data analytics, web serving and content management, application development and testing, media and entertainment workflows, database backups, and container storage. Amazon EFS is a regional service storing data within and across multiple Availability Zones (AZs) for high availability and durability. Amazon EC2 instances can access your file system across AZs, regions, and VPCs, while on-premises servers can access using AWS Direct Connect or AWS VPN. https://aws.amazon.com/efs/\n#\r#\rQUESTION\r#\rAn application allows users at a company\u0026rsquo;s headquarters to access product data The product data is stored in an Amazon RDS MySQL DB instance. The operations team has isolated an application performance slowdown and wants to separate read traffic from write traffic. A solutions architect needs to optimize the application\u0026rsquo;s performance quickly. What should the solutions architect recommend?\nA. Change the existing database to a Multi-AZ deployment Serve the read requests from the primary Availability Zone B. Change the existing database to a Multi-AZ deployment Serve the read requests from the secondary Availability Zone C. Create read replicas for the database Configure the read replicas with half of the compute and storage resources as the source database D. Create read replicas for the database Configure the read replicas with the same compute and storage resources as the source database 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rAn application running on AWS uses an Amazon Aurora Multi-AZ deployment for its database When evaluating performance metrics, a solutions architect discovered that the database reads are causing high I/O and adding latency to the write requests against the database What should the solutions architect do to separate the read requests from the write requests?\nA. Enable read-through caching on the Amazon Aurora database B. Update the application to read from the Multi-AZ standby instance C. Create a read replica and modify the application to use the appropriate endpoint D. Create a second Amazon Aurora database and link it to the primary database as a read replica. 문제 풀이\r...\rAnswer: C\r#\rExplanation Amazon RDS Read Replicas Amazon RDS Read Replicas provide enhanced performance and durability for RDS database (DB) instances. They make it easy to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. You can create one or more replicas of a given source DB Instance and serve high-volume application read traffic from multiple copies of your data, thereby increasing aggregate read throughput. Read replicas can also be promoted when needed to become standalone DB instances. Read replicas are available in Amazon RDS for MySQL, MariaDB, PostgreSQL, Oracle, and SQL Server as well as Amazon Aurora. For the MySQL, MariaDB, PostgreSQL, Oracle, and SQL Server database engines, Amazon RDS creates a second DB instance using a snapshot of the source DB instance. It then uses the engines\u0026rsquo; native asynchronous replication to update the read replica whenever there is a change to the source DB instance. The read replica operates as a DB instance that allows only read-only connections; applications can connect to a read replica just as they would to any DB instance. Amazon RDS replicates all databases in the source DB instance. Amazon Aurora futher extends the benefits of read replicas by employing an SSD-backed virtualized storage layer purpose-built for database workloads. Amazon Aurora replicas share the same underlying storage as the source instance, lowering costs and avoiding the need to copy data to the replica nodes. For more information about replication with Amazon Aurora, see the online documentation.\nhttps://aws.amazon.com/rds/features/read-replicas/\n#\r#\rQUESTION\r#\rA company is planning to migrate a business-critical dataset to Amazon S3. The current solution design uses a single S3 bucket in the us-east-1 Region with versioning enabled to store the dataset. The company\u0026rsquo;s disaster recovery policy states that all data multiple AWS Regions. How should a solutions architect design the S3 solution?\nA. Create an additional S3 bucket in another Region and configure cross-Region replication. B. Create an additional S3 bucket in another Region and configure cross-origin resource sharing (CORS). C. Create an additional S3 bucket with versioning in another Region and configure cross-Region replication. D. Create an additional S3 bucket with versioning in another Region and configure cross-origin resource (CORS). 문제 풀이\r...\rAnswer: C\r#\rExplanation Object Versioning Use Amazon S3 Versioning to keep multiple versions of an object in one bucket. For example, you could store my-image.jpg (version 111111) and my-image.jpg (version 222222) in a single bucket. S3 Versioning protects you from the consequences of unintended overwrites and deletions. You can also use it to archive objects so that you have access to previous versions. You must explicitly enable S3 Versioning on your bucket. By default, S3 Versioning is disabled. Regardless of whether you have enabled Versioning, each object in your bucket has a version ID. If you have not enabled Versioning, Amazon S3 sets the value of the version ID to null. If S3 Versioning is enabled, Amazon S3 assigns a version ID value for the object. This value distinguishes it from other versions of the same key. Enabling and suspending versioning is done at the bucket level. When you enable versioning on an existing bucket, objects that are already stored in the bucket are unchanged. The version IDs (null), contents, and permissions remain the same. After you enable S3 Versioning for a bucket, each object that is added to the bucket gets a version ID, which distinguishes it from other versions of the same key. Cross-origin resource sharing (CORS) Cross-origin resource sharing (CORS) defines a way for client web applications that are loaded in one domain to interact with resources in a different domain. With CORS support, you can build rich clientside web applications with Amazon S3 and selectively allow cross-origin access to your Amazon S3 resources. https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html\n#\r#\rQUESTION\r#\rA company has an Amazon EC2 instance running on a private subnet that needs to access a public websites to download patches and updates. The company does not want external websites to see the EC2 instance IP address or initiate connection to it. How can a solution architect achieve this objective?\nA. Create a site-to-site VPN connection between the private subnet and the network in which the public site is deployed B. Create a NAT gateway in a public subnet Route outbound traffic from the private subnet through the NAI gateway C. Create a network ACL for the private subnet where the EC2 instance deployed only allows access from the IP address range of the public website D. Create a security group that only allows connections from the IP address range of the public website. Attach the security group to the EC2 instance. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company is preparing to launch a public-facing web application in the AWS Cloud The architecture consists of Amazon EC2 instances within a VPC behind an Elastic Load Balancer (ELB). A third party service is used for the DNS. The company\u0026rsquo;s solutions architect must recommend a solution to detect and protect against large scale DDoS attacks Which solution meets these requirements?\nA. Enable Amazon GuardDuty on the account B. Enable Amazon Inspector on the EC2 instances C. Enable AWS Shield and assign Amazon Route 53 to it. D. Enable AWS Shield Advanced and assign the ELB to it 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company has global users accessing an application deployed in different AWS Regions, exposing public static IP addresses. The users are experiencing poor performance when accessing the application over the internet. What should a solutions architect recommend to reduce internet latency?\nA. Set up AWS Global Accelerator and add endpoints. B. Set up AWS Direct Connect locations in multiple Regions. C. Set up an Amazon CloudFront distribution to access an application. D. Set up an Amazon Route 53 geoproximity routing policy to route traffic. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA solution architect is performing a security review of a recently migrated workload. The workload is a web application that consists of amazon EC2 instances in an Auto Scaling group behind an Application Load balancer. The solution architect must improve the security posture and minimize the impact of a DDoS attack on resources. Which solution is MOST effective?\nA. Configure an AWS WAF ACL with rate-based rules Create an Amazon CloudFront distribution that points to the Application Load Balancer. Enable the EAF ACL on the CloudFront distribution B. Create a custom AWS Lambda function that adds identified attacks into a common vulnerability pool to capture a potential DDoS attack. use the identified information to modify a network ACL to block access. C. Enable VPC Flow Logs and store then in Amazon S3. Create a custom AWS Lambda functions that parses the logs looking for a DDoS attack. Modify a network ACL to block identified source IP addresses. D. Enable Amazon GuardDuty and , configure findings written 10 Amazon GloudWatch Create an event with Cloud Watch Events for DDoS alerts that triggers Amazon Simple Notification Service (Amazon SNS) Have Amazon SNS invoke a custom AWS lambda function that parses the logs looking for a DDoS attack Modify a network ACL to block identified source IP addresses 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has no existing file share services. A new project requires access to file storage that is mountable as a drive for on-premises desktops. The file server must authenticate users to an Active Directory domain before they are able to access the storage. Which service will allow Active Directory users to mount storage as a drive on their desktops?\nA. Amazon S3 Glacier B. AWS DataSync C. AWS Snowball Edge D. AWS Storage Gateway 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rWhat should the solutions architect recommend?\nA. Install MySQL on Amazon EC2 in the secondary Region B. Migrate the database to Amazon Aurora with cross-Region replicas C. Create another RDS for MySQL read replica in the secondary Region D. Implement Amazon ElastiCache to improve database query performance 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA gaming company has multiple Amazon EC2 instances in a single Availability Zone for its multiplayer game that communicates with users on Layer 4 The chief technology officer (CTO) wants to make the architecture highly available and cost-effective. What should a solutions architect do to meet these requirements? (Select TWO.)\nA. Increase the number of EC2 instances. B. Decrease the number of EC2 instances C. Configure a Network Load Balancer in front of the EC2 instances. D. Configure an Application Load Balancer in front of the EC2 instances E. Configure an Auto Scaling group to add or remove instances in multiple Availability Zones automatically. 문제 풀이\r...\rAnswer: C E\r#\rExplanation Network Load Balancer overview A Network Load Balancer functions at the fourth layer of the Open Systems Interconnection (OSI) model. It can handle millions of requests per second. After the load balancer receives a connection request, it selects a target from the target group for the default rule. It attempts to open a TCP connection to the selected target on the port specified in the listener configuration. When you enable an Availability Zone for the load balancer, Elastic Load Balancing creates a load balancer node in the Availability Zone. By default, each load balancer node distributes traffic across the registered targets in its Availability Zone only. If you enable cross-zone load balancing, each load balancer node distributes traffic across the registered targets in all enabled Availability Zones. For more information, see Availability Zones. If you enable multiple Availability Zones for your load balancer and ensure that each target group has at least one target in each enabled Availability Zone, this increases the fault tolerance of your applications. For example, if one or more target groups does not have a healthy target in an Availability Zone, we remove the IP address for the corresponding subnet from DNS, but the load balancer nodes in the other Availability Zones are still available to route traffic. If a client doesn\u0026rsquo;t honor the time-to-live (TTL) and sends requests to the IP address after it is removed from DNS, the requests fail. For TCP traffic, the load balancer selects a target using a flow hash algorithm based on the protocol, source IP address, source port, destination IP address, destination port, and TCP sequence number. The TCP connections from a client have different source ports and sequence numbers, and can be routed to different targets. Each individual TCP connection is routed to a single target for the life of the connection. For UDP traffic, the load balancer selects a target using a flow hash algorithm based on the protocol, source IP address, source port, destination IP address, and destination port. A UDP flow has the same source and destination, so it is consistently routed to a single target throughout its lifetime. Different UDP flows have different source IP addresses and ports, so they can be routed to different targets. An Auto Scaling group contains a collection of Amazon EC2 instances that are treated as a logical grouping for the purposes of automatic scaling and management. An Auto Scaling group also enables you to use Amazon EC2 Auto Scaling features such as health check replacements and scaling policies. Both maintaining the number of instances in an Auto Scaling group and automatic scaling are the core functionality of the Amazon EC2 Auto Scaling service. The size of an Auto Scaling group depends on the number of instances that you set as the desired capacity. You can adjust its size to meet demand, either manually or by using automatic scaling. An Auto Scaling group starts by launching enough instances to meet its desired capacity. It maintains this number of instances by performing periodic health checks on the instances in the group. The Auto Scaling group continues to maintain a fixed number of instances even if an instance becomes unhealthy. If an instance becomes unhealthy, the group terminates the unhealthy instance and launches another instance to replace it. https://docs.aws.amazon.com/elasticloadbalancing/latest/network/introduction.html https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html\n#\r#\rQUESTION\r#\rA company is moving its legacy workload to the AWS Cloud. The workload files will be shared, appended, and frequently accessed through Amazon EC2 instances when they are first created The files will be accessed occasionally as they age What should a solutions architect recommend?\nA. Store the data using Amazon EC2 instances with attached Amazon Elastic Block Store (Amazon EBS) data volumes B. Store the data using AWS Storage Gateway volume gateway and export rarely accessed data to Amazon S3 storage C. Store the data using Amazon Elastic File System (Amazon EFS) with lifecycle management enabled for rarely accessed data D. Store the data using Amazon S3 with an S3 lifecycle policy enabled to move data to S3 StandardInfrequent Access (S3 Standard-IA) 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company hosts an application on multiple Amazon EC2 instances The application processes messages from an Amazon SQS queue writes to an Amazon RDS table and deletes the message from the queue Occasional duplicate records are found in the RDS table The SQS queue does not contain any duplicate messages What should a solutions archived do to ensure messages are being processed once only?\nA. Use the CreateQueue API call to create a new queue B. Use the AddPermission API call to add appropriate permissions C. Use the ReceiveMessage API call to set an appropriate wait time. D. Use the ChangeMessageVisibility API call to increase the visibility timeout 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA solutions architect is planning the deployment of a new static website. The solution must minimize costs and provide at least 99% availability. Which solution meets these requirements?\nA. Deploy the application to an Amazon S3 bucket in one AWS Region that has versioning disabled. B. Deploy the application to Amazon EC2 instances that run in two AWS Regions and two Availability Zones. C. Deploy the application to an Amazon S3 bucket that has versioning and cross-Region replication enabled. D. Deploy the application to an Amazon EC2 instance that runs in one AWS Region and one Availability Zone. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company is developing a real-time multiplier game that uses UDP for communications between client and servers in an Auto Scaling group Spikes in demand are anticipated during the day, so the game server platform must adapt accordingly. Developers want to store gamer scores and other non-relational data in a database solution that will scale without intervention. Which solution should a solution architect recommend?\nA. Use Amazon Route 53 for traffic distribution and Amazon Aurora Serverless for data storage. B. Use a Network Load Balancer for traffic distribution and Amazon DynamoDB on-demand for data storage. C. Use a Network Load Balancer for traffic distribution and amazon Aura Global for data storage. D. Use an Application Load Balancer for traffic distribution and Amazon DynamoDB global tables for data storage 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company is using a fleet of Amazon EC2 instances to ingest data from on-premises data sources. The data is in JSON format and ingestion rates can be as high as 1 MB/s. When an EC2 instance is rebooted, the data in-flight is lost. The company\u0026rsquo;s data science team wants to query ingested data in near-real time. Which solution provides near-real-time data querying that is scalable with minimal data loss?\nA. Publish data to Amazon Kinesis Data Streams. Use Kinesis Data Analytics to query the data. B. Publish data to Amazon Kinesis Data firehose with Amazon Redshift as the destination. Use Amazon Redshift to query the data. C. Store ingested data in an EC2 instance store Publish data to Amazon Kinesis Data Firehose with Amazon S3 as the destination. Use Amazon Athena to query the data. D. Store ingested data in an Amazon Elastic Block Store (Amazon EBS) volume. Publish data to Amazon ElastiCache for Redis. Subscribe to the Redis channel to query the data. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company previously migrated its data warehouse solution to AWS. The company also has an AWS Direct Connect connection. Corporate office users query the data warehouse using a visualization tool. The average size of a query returned by the data warehouse is 50 MB and each webpage sent by the visualization tool is approximately 500 KB. Result sets returned by the data warehouse are not cached. Which solution provides the LOWEST data transfer egress cost for the company?\nA. Host the visualization tool on premises and query the data warehouse directly over the internet. B. Host the visualization tool in the same AWS Region as the data warehouse. Access it over the internet. C. Host the visualization tool on premises and query the data warehouse directly over a Direct Connect connection at a location in the same AWS Region. D. Host the visualization tool in the same AWS Region as the data warehouse and access it over a Direct Connect connection at a location in the same Region. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company has a web application with sporadic usage patterns. There is heavy usage at the beginning of each month, moderate usage at the start of each week, and unpredictable usage during the week. The application consists of a web server and a MySQL database server running inside the data center. The company would like to move the application to the AWS Cloud, and needs to select a cost-effective database platform that will not require database modifications. Which solution will meet these requirements?\nA. Amazon DynamoDB B. Amazon RDS for MySQL C. MySQL-compatible Amazon Aurora Serverless D. MySQL deployed on Amazon EC2 in an Auto Scaling group 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION 301-\r#\r#\r#\rQUESTION\r#\rA company is using Site-to-Site VPN connections for secure connectivity to its AWS Cloud resources from on premises. Due to an increase in traffic across the VPN connections to the Amazon EC2 instances, users are experiencing slower VPN connectivity Which solution will improve the VPN throughput?\nA. Implement multiple customer gateways for the same network to scale the throughput B. Use a transit gateway with equal cost multipath routing and add additional VPN tunnels C. Configure a virtual private gateway with equal cost multipath routing and multiple channels D. Increase the number of tunnels in the VPN configuration to scale the throughput beyond the default limit 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company runs an application using Amazon ECS. The application creates resized versions of an original image and then makes Amazon S3 API calls to store the resized images in Amazon S3. How can a solutions architect ensure that the application has permission to access Amazon S3?\nA. Update the S3 role in AWS IAM to allow read/write access from Amazon ECS, and then relaunch the container. B. Create an IAM role with S3 permissions, and then specify that role as the taskRoleArn in the task definition. C. Create a security group that allows access from Amazon ECS to Amazon S3, and update the launch configuration used by the ECS cluster. D. Create an IAM user with S3 permissions, and then relaunch the Amazon EC2 instances for the ECS cluster while logged in as this account. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company has a three-tier environment on AWS that ingests sensor data from its users\u0026rsquo; devices. The traffic flows through a Network Load Balancer (NLB) then to Amazon EC2 instances for the web tier, and finally to EC2 instances for the application tier that makes database calls What should a solutions architect do to improve the security of data in transit to the web tier?\nA. Configure a TLS listener and add the server certificate on the NLB. B. Configure AWS Shield Advanced and enable AWS WAF on the NLB C. Change the load balancer to an Application Load Balancer and attach AWS WAF to it. D. Encrypt the Amazon Elastic Block Store (Amazon EBS) volume on the EC2 instances using AWS Key Management Service (AWS KMS) 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company Is reviewing Its AWS Cloud deployment to ensure its data is not accessed by anyone without appropriate authorization. A solutions architect is tasked with identifying all open Amazon S3 buckets and recording any S3 bucket configuration changes. What should the solutions architect do to accomplish this?\nA. Enable AWS Config service with the appropriate rules B. Enable AWS Trusted Advisor with the appropriate checks. C. Write a script using an AWS SDK to generate a bucket report D. Enable Amazon S3 server access logging and configure Amazon CloudWatch Events. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company hosts an application on an Amazon EC2 instance that requires a maximum of 200 GB storage space. The application is used infrequently, with peaks during mornings and evenings. Disk I/O varies, but peaks at 3,000 IOPS. The chief financial officer of the company is concerned about costs and has asked a solutions architect to recommend the most cost-effective storage option that does not sacrifice performance. Which solution should the solutions architect recommend?\nA. Amazon EBS Cold HDD (sc1) B. Amazon EBS General Purpose SSD (gp2) C. Amazon EBS Provisioned IOPS SSD (io1) D. Amazon EBS Throughput Optimized HDD (st1) 문제 풀이\r...\rAnswer: B\r#\r범용 SSD는 최대 3,000 IOPS가 가능합니다. #\r#\rQUESTION\r#\rA company is developing a video conversion application hosted on AWS. The application will be available in two tiers: a free tier and a paid tier. Users in the paid tier will have their videos converted first and then the tree tier users will have their videos converted. Which solution meets these requirements and is MOST cost-effective?\nA. One FIFO queue for the paid tier and one standard queue for the free tier B. A single FIFO Amazon Simple Queue Service (Amazon SQS) queue for all file types C. A single standard Amazon Simple Queue Service (Amazon SQS) queue for all file types D. Two standard Amazon Simple Queue Service (Amazon SQS) queues with one for the paid tier and one for the free tier 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company recently released a new type of internet-connected sensor. The company is expecting lo sell thousands of sensors, which are designed to stream high volumes of data each second to a central location. A solutions architect must design a solution that ingests and stores data so that engineering teams can analyze it in near-real time with millisecond responsiveness. Which solution should the solutions architect recommend?\nA. Use an Amazon SQS queue to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon Redshift. B. Use an Amazon SOS queue to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon DynamoDB. C. Use Amazon Kinesis Data Streams to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon Redshift. D. Use Amazon Kinesis Data Streams to ingest the data. Consume the data with an AWS Lambda function, which then stores the data in Amazon DynamoDB. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company is planning to use Amazon S3 lo store images uploaded by its users The images must be encrypted at rest in Amazon S3 The company does not want to spend time managing and rotating the keys, but it does want to control who can access those keys What should a solutions architect use to accomplish this?\nA. Server-Side Encryption with keys stored in an S3 bucket B. Server-Side Encryption with Customer-Provided Keys (SSE-C) C. Server-Side Encryption with Amazon S3-Managed Keys (SSE-S3) D. Server-Side Encryption with AWS KMS-Managed Keys (SSE-KMS) 문제 풀이\r...\rAnswer: D\r#\rExplanation Link: https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html \u0026ldquo;Server-Side Encryption with Customer Master Keys (CMKs) Stored in AWS Key Management Service (SSE-KMS) is similar to SSE-S3, but with some additional benefits and charges for using this service. There are separate permissions for the use of a CMK that provides added protection against unauthorized access of your objects in Amazon S3. SSE-KMS also provides you with an audit trail that shows when your CMK was used and by whom.\u0026rdquo; Server-Side Encryption: Using SSE-KMS You can protect data at rest in Amazon S3 by using three different modes of server-side encryption: SSE-S3, SSE-C, or SSE-KMS. SSE-S3 requires that Amazon S3 manage the data and master encryption keys. For more information about SSE-S3, see Protecting Data Using Server-Side Encryption with Amazon S3-Managed Encryption Keys (SSE-S3). SSE-C requires that you manage the encryption key. For more information about SSE-C, see Protecting Data Using Server-Side Encryption with Customer-Provided Encryption Keys (SSE-C). SSE-KMS requires that AWS manage the data key but you manage the customer master key (CMK) in AWS KMS. The remainder of this topic discusses how to protect data by using server-side encryption with AWS KMS-managed keys (SSE-KMS). You can request encryption and select a CMK by using the Amazon S3 console or API. In the console, check the appropriate box to perform encryption and select your CMK from the list. For the Amazon S3 API, specify encryption and choose your CMK by setting the appropriate headers in a GET or PUT request. https://docs.aws.amazon.com/kms/latest/developerguide/services-s3.html#sse\n#\r#\rQUESTION\r#\rA company has an application running on Amazon EC2 instances in a private subnet. The application needs to store and retrieve data in Amazon S3 To reduce costs, the company wants to configure its AWS resources in a cost-effective manner How should the company accomplish this?\nA. Deploy a NAT gateway to access the S3 buckets B. Deploy AWS Storage Gateway to access the S3 buckets C. Deploy an S3 gateway endpoint to access the S3 buckets D. Deploy an S3 interface endpoint to access the S3 buckets. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company wants to use an AWS Region as a disaster recovery location for its on-premises infrastructure. The company has 10 TB of existing data, and the on-premise data center has a 1 Gbps internet connection. A solutions architect must find a solution so the company can have its existing data on AWS in 72 hours without transmitting it using an unencrypted channel. Which solution should the solutions architect select?\nA. Send the initial 10 TB of data to AWS using FTP. B. Send the initial 10 TB of data to AWS using AWS Snowball. C. Establish a VPN connection between Amazon VPC and the company\u0026rsquo;s data center. D. Establish an AWS Direct Connect connection between Amazon VPC and the company\u0026rsquo;s data center. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company runs an online marketplace web application on AWS. The application serves hundreds of thousands of users during peak hours. The company needs a scalable, near-real-time solution to share the details of millions of financial transactions with several other internal applications. Transactions also need to be processed to remove sensitive data before being stored in a document database for low-latency retrieval. What should a solutions architect recommend to meet these requirements?\nA. Store the transactions data into Amazon DynamoDB. Set up a rule in DynamoDB to remove sensitive data from every transaction upon write. Use DynamoDB Streams to share the transactions data with other applications. B. Stream the transactions data into Amazon Kinesis Data Firehose to store data in Amazon DynamoDB and Amazon S3. Use AWS Lambda integration with Kinesis Data Firehose to remove sensitive data. Other applications can consume the data stored in Amazon S3. C. Stream the transactions data into Amazon Kinesis Data Streams. Use AWS Lambda integration to remove sensitive data from every transaction and then store the transactions data in Amazon DynamoDB. Other applications can consume the transactions data off the Kinesis data stream. D. Store the batched transactions data in Amazon S3 as files. Use AWS Lambda to process every file and remove sensitive data before updating the files in Amazon S3. The Lambda function then stores the data in Amazon DynamoDB. Other applications can consume transaction files stored in Amazon S3. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company has multiple AWS accounts, for various departments. One of the departments wants to share an Amazon S3 bucket with all other department. Which solution will require the LEAST amount of effort?\nA. Enable cross-account S3 replication for the bucket B. Create a pre signed URL tor the bucket and share it with other departments C. Set the S3 bucket policy to allow cross-account access to other departments D. Create IAM users for each of the departments and configure a read-only IAM policy 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA bicycle sharing company is developing a multi-tier architecture to track the location of its bicycles during peak operating hours The company wants to use these data points in its existing analytics platform A solutions architect must determine the most viable multi-tier option to support this architecture The data points must be accessible from the REST API Which action meets these requirements for storing and retrieving location data?\nA. Use Amazon Athena with Amazon S3 B. Use Amazon API Gateway with AWS Lambda C. Use Amazon QuickSight with Amazon Redshift D. Use Amazon API Gateway with Amazon Kinesis Data Analytics 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company has hired a new cloud engineer who should not have access to an Amazon S3 bucket named Company Confidential. the cloud engineer must be able to read from and write to an S3 bucket called AdminTools. Which IAM policy will meet these requirements?\nA. Option A B. Option B C. Option C D. Option D 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company is hosting multiple websites for several lines of business under its registered parent domain. Users accessing these websites will be routed to appropriate backend Amazon EC2 instances based on the subdomain. The websites host static webpages, images, and server-side scripts like PHP and JavaScript. Some of the websites experience peak access during the first two hours of business with constant usage throughout the rest of the day. A solutions architect needs to design a solution that will automatically adjust capacity to these traffic patterns while keeping costs low. Which combination of AWS services or features will meet these requirements? (Select TWO.)\nA. AWS Batch B. Network Load Balancer C. Application Load Balancer D. Amazon EC2 Auto Scaling E. Amazon S3 website hosting 문제 풀이\r...\rAnswer: D E\r#\r#\r#\rQUESTION\r#\rA company is migrating a NoSQL database cluster to Amazon EC2. The database automatically replicates data to maintain at least three copies of the data. I/O throughput of the servers is the highest priority. Which instance type should a solutions architect recommend for the migration?\nA. Storage optimized instances with instance store B. Burstable general purpose instances with an Amazon Elastic Block Store (Amazon EBS) volume C. Memory optimized instances with Amazon Elastic Block Store (Amazon EBS) optimization enabled D. Compute optimized instances with Amazon Elastic Block Store (Amazon EBS) optimization enabled 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rAn application uses an Amazon RDS MySQL DB instance. The RDS database is becoming low on disk space. A solutions architect wants to increase the disk space without downtime Which solution meets these requirements with the LEAST amount of effort?\nA. Enable storage auto scaling in RDS. B. Increase the RDS database instance size C. Change the RDS database instance storage type to Provisioned IOPS. D. Back up the RDS database, increase the storage capacity, restore the database and stop the previous instance 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rAn application runs on Amazon EC2 instances across multiple Availability Zones The instances run in an Amazon EC2 Auto Scaling group behind an Application Load Balancer The application performs best when the CPU utilization of the EC2 instances is at or near 40% What should a solutions architect do to maintain the desired performance across all instances m the group?\nA. Use a simple scaling policy to dynamically scale the Auto Scaling group B. Use a target tracking policy to dynamically scale the Auto Scaling group C. Use an AWS Lambda function to update the desired Auto Scaling group capacity D. Use scheduled scaling actions to scale up and scale down the Auto Scaling group 문제 풀이\r...\rAnswer:\r#\r#\r#\rQUESTION\r#\rA company is deploying an application in three AWS Regions using an Application Load Balancer Amazon Route 53 will be used to distribute traffic between these Regions. Which Route 53 configuration should a solutions architect use to provide the MOST high-performing experience?\nA. Create an A record with a latency policy. B. Create an A record with a geolocation policy. C. Create a CNAME record with a failover policy. D. Create a CNAME record with a geoproximity policy. 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company needs to share an Amazon S3 bucket with an external vendor. The bucket owner must be able to access all objects. Which action should be taken to share the S3 bucket?\nA. Update the bucket to be a Requester Pays bucket B. Update the bucket to enable cross-origin resource sharing (CPORS) C. Create a bucket policy to require users to grant bucket-owner-full when uploading objects D. Create an IAM policy to require users to grant bucket-owner-full control when uploading objects. 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company\u0026rsquo;s website is using an Amazon RDS MySQL Multi-AZ DB instance for its transactional data storage. There are other internal systems that query this DB instance to fetch data for internal batch processing. The RDS DB instance slows down significantly the internal systems fetch data. This impacts the website\u0026rsquo;s read and write performance, and the users experience slow response times. Which solution will improve the website\u0026rsquo;s performance?\nA. Use an RDS PostgreSQL DB instance instead of a MySQL database. B. Use Amazon ElastiCache to cache the query responses for the website. C. Add an additional Availability Zone to the current RDS MySQL Multi.AZ DB instance. D. Add a read replica to the RDS DB instance and configure the internal systems to query the read replica. 문제 풀이\r...\rAnswer: D\r#\rExplanation Amazon RDS Read Replicas Enhanced performance You can reduce the load on your source DB instance by routing read queries from your applications to the read replica. Read replicas allow you to elastically scale out beyond the capacity constraints of a single DB instance for read-heavy database workloads. Because read replicas can be promoted to master status, they are useful as part of a sharding implementation. To further maximize read performance, Amazon RDS for MySQL allows you to add table indexes directly to Read Replicas, without those indexes being present on the master. https://aws.amazon.com/rds/features/read-replicas/\n#\r#\rQUESTION\r#\rA company wants to optimize the cost of its data storage for data that is accessed quarterly. The company requires high throughput, low latency, and rapid access, when needed Which Amazon S3 storage class should a solutions architect recommend?\nA. Amazon S3 Glacier (S3 Glacier) B. Amazon S3 Standard (S3 Standard) C. Amazon S3 Intelligent-Tiering (S3 Intelligent-Tiering) D. Amazon S3 Standard-Infrequent Access (S3 Standard-IA) 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company runs a web service on Amazon EC2 instances behind an Application Load Balancer The instances run in an Amazon EC2 Auto Scaling group across two Availability Zones The company needs a minimum of four instances at all limes to meet the required service level agreement (SLA) while keeping costs low. If an Availability Zone fails, how can the company remain compliant with the SLA?\nA. Add a target tracking scaling policy with a short cooldown period B. Change the Auto Scaling group launch configuration to use a larger instance type C. Change the Auto Scaling group to use six servers across three Availability Zones D. Change the Auto Scaling group to use eight servers across two Availability Zones 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rAn application running on an Amazon EC2 instance needs to access an Amazon DynamoDB table Both the EC2 instance and the DynamoDB table are in the same AWS account A solutions architect must configure the necessary permissions. Which solution will allow least privilege access to the DynamoDB table from the EC2 instance?\nA. Create an IAM role with the appropriate policy to allow access to the DynamoDB table Create an instance profile to assign this IAM role to the EC2 instance B. Create an IAM role with the appropriate policy to allow access to the DynamoDB table Add the EC2 instance to the trust relationship policy document to allow it to assume the role C. Create an IAM user with the appropriate policy to allow access to the DynamoDB table Store the credentials in an Amazon S3 bucket and read them from within the application code directly. D. Create an IAM user with the appropriate policy to allow access to the DynamoDB table Ensure that the application stores the IAM credentials securely on local storage and uses them to make the DynamoDB calls 문제 풀이\r...\rAnswer: A\r#\r#\r#\rQUESTION\r#\rA company must re-evaluate its need for the Amazon EC2 instances it currently has provisioned in an Auto Scaling group. At present, the Auto Scaling group is configured for minimum of two instances and a maximum of four instances across two Availability zones. A Solutions architect reviewed Amazon CloudWatch metrics and found that CPU utilization is consistently low for the EC2 instances. What should the solutions architect recommend to maximize utilization while ensuring the application remains fault tolerant?\nA. Remove some EC2 instances to increase the utilization of remaining instances. B. Increase the Amazon Elastic Block Store (Amazon EBS) capacity of instances with less CPU utilization. C. Modify the Auto Scaling group scaling policy to scale in and out based on a higher CPU utilization metric. D. Create a new launch configuration that uses smaller instance types. Update the existing Auto Scaling group. 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company is preparing to migrate its on-premises application to AWS The application consists of application servers and a Microsoft SQL Server database The database cannot be migrated to a different engine because SQL Server features are used in the application\u0026rsquo;s NET code. The company wants to attain the greatest availability possible while minimizing operational and management overhead What should a solutions architect do to accomplish this?\nA. Install SQL Server on Amazon EC2 in a Multi-AZ deployment B. Migrate the data to Amazon RDS for SQL Server in a Multi-AZ deployment. C. Deploy the database on Amazon RDS for SQL Server with Multi-AZ Replicas. D. Migrate the data to Amazon RDS for SQL Server in a cross Region Multi-AZ deployment 문제 풀이\r...\rAnswer: B\r#\r#\r#\rQUESTION\r#\rA company is seeing access requests by some suspicious IP addresses. The security team discovers the requests are from different IP addresses under the same CIDR range. What should a solutions architect recommend to the team?\nA. Add a rule in the inbound table of the security to deny the traffic from that CIDR range. B. Add a rule in the outbound table of the security group to deny the traffic from that CIDR range. C. Add a deny rule in the inbound table of the network ACL with a lower number than other rules. D. Add a deny rule in the outbound table of the network ACL with a lower rule number than other rules. 문제 풀이\r...\rAnswer: C\r#\r#\r#\rQUESTION\r#\rA company is planning to transfer multiple terabytes of data to AWS. The data is collected offline from ships. The company want to run complex transformation before transferring the data. Which AWS service should a solutions architect recommend for this migration?\nA. AWS Snowball B. AWS Snowmobile C. AWS Snowball Edge Storage Optimize D. AWS Snowball Edge Compute Optimize 문제 풀이\r...\rAnswer: D\r#\r#\r#\rQUESTION\r#\rA company\u0026rsquo;s near-real-time streaming application is running on AWS As (he data is ingested a job runs on the data and takes 30 minutes to complete The workload frequently experiences high latency due to large amounts of incoming data A solutions architect needs to design a scalable and serverless solution to enhance performance Which combination of steps should the solutions architect take? (Select TWO)\nA. Use Amazon Kinesis Data Firehose to ingest the data B. Use AWS Lambda with AWS Step Functions to process the data C. Use AWS Database Migration Service (AWS DMS) to ingest the data D. Use Amazon EC2 instances in an Auto Scaling group to process the data E. Use AWS Fargate with Amazon Elastic Container Service (Amazon ECS) to process the data. 문제 풀이\r...\rAnswer: A E\r#\r#\r#\rQUESTION\r#\rAn Amazon EC2 administrator created the following policy associated with an IAM group containing several users. What is the effect of this policy?\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;ec2:TerminateInstances\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;IpAddress\u0026#34;: { \u0026#34;aws:SourceIP\u0026#34;: \u0026#34;10.100.100.0/24\u0026#34; } } }, { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;ec2:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringNotEquls\u0026#34;: { \u0026#34;aws:Region\u0026#34;: \u0026#34;us-east-1\u0026#34; } } } ] } A. Users can terminate an EC2 instance in any AWS Region except us-east-1. B. Users can terminate an EC2 instance with the IP address 10.100. 1001 in the us-east-1 Region C. Users can terminate an EC2 instance in the us-east-1 Region when the user\u0026rsquo;s source IP is 10.100.100.254 D. Users cannot terminate an EC2 instance in the us-east-1 Region when the user\u0026rsquo;s source IP is 10.100.100. 254 문제 풀이\r...\rAnswer: C\r#\r"},{"id":58,"href":"/cloud/docs/Azure/AzureTraining/az-900/","title":"Az-900 : 문제풀이","section":"Azure Training","content":"\rAz-900 시험대비 문제풀이\r#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 Yes 거짓이면 No를 선택하십시오. #\r문제 Yes No PaaS는 Azure 서비스에서 모든 시스템의 제공하고 호스트는 웹, 애플리케이션을 모두 컨트롤 한다. PaaS의 웹, 애플리케이션에서 자동으로 Scale ability를 수행한다. PaaS는 솔루션은 사용자 지정 응용 프로그램에 기능을 지속적으로 추가하는 전문 개발 서비스를 제공한다. #\r문제 풀이\r...\r문제 Yes No PaaS는 Azure 서비스에서 모든 시스템의 제공하고 호스트는 웹, 애플리케이션을 모두 컨트롤 한다. ㅇ PaaS의 웹, 애플리케이션에서 자동으로 Scale ability를 수행한다. ㅇ PaaS는 솔루션은 사용자 지정 응용 프로그램에 기능을 지속적으로 추가하는 전문 개발 서비스를 제공한다. ㅇ PaaS는 Platform as a service로 모든 부분을 호스트가 사용하는 것은 IaaS이다.\nScale UP, OUT은 Azure에서 수행한다.\nAzure의 기술지원 솔루션에는 전문 개발 서비스를 제공한다.\n#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 Yes 거짓이면 No를 선택하십시오. #\r문제 Yes No Azure는 CapEx, OpEx 사이의 비용을 유연하게 사용한다. 만약 두 개의 VM을 B2S 크기로 생성하면 다른 VM은 매월 항상 같은 가격이 결제된다. 만약 VM이 정지되어도 스토리지 비용은 지불해야한다. #\r문제 풀이\r...\r문제 Yes No Azure는 CapEx, OpEx 사이의 비용을 유연하게 사용한다. ㅇ 만약 두 개의 VM을 B2S 크기로 생성하면 다른 VM은 매월 항상 같은 가격이 결제된다. ㅇ 만약 VM이 정지되어도 스토리지 비용은 지불해야한다. ㅇ #\r#\rSaaS 솔루션을 구현할 때 고 가용성으로 구성해야 하는 경우 고려해야하는 사항은?\n변경할 필요 없다.\n확장 성 규칙 정의\nSaaS 솔루션 설치\nSaaS 솔루션 구성\n#\r문제 풀이\r...\r4 고 가용성을 구성하기 위해서는 솔루션을 구성해야한다.\n#\r#\r여러 서버가 포함 된 온-프레미스 네트워크가 있습니다. 모든 서버를 Azure로 마이그레이션 할 계획입니다. 단일 Azure 데이터 센터가 장기간 오프라인 상태가 되는 경우 일부 서버를 사용할 수 있도록 솔루션을 권장해야합니다. 다음 중 추천하는 것은? 내결함성\n탄력성\n확장성\n낮은 지연\n#\r문제 풀이\r...\r1\n끊끼지 않는 서비스와 연관된 것은 내결함성입니다.\n#\r#\r사설 클라우드에서 인프라를 호스팅하는 조직은 데이터 센터를 폐기할 수 있습니다. 위의 설명이 정확하면 변경할 필요 없음을 선택하고, 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경할 필요 없습니다.\n하이브리드 클라우드\n공용 클라우드\nHyper-V 호스트\n#\r문제 풀이\r...\r공용 클라우드 프라이빗 클라우드를 폐기하기 위해서는 공용(퍼블릭)클라우드를 100% 사용해야합니다.\n#\r#\r퍼블릭 클라우드의 두 가지 특징은 무엇입니까? 전용 하드웨어\n보안되지 않은 연결\n제한된 저장\n측정 가격\n셀프 서비스 관리\n#\r문제 풀이\r...\r4, 5\n1, 3번은 프라이빗 환경의 특징이며 2번은 초기 퍼블릭 환경의 문제점입니다.\n퍼블릭 클라우드는 사용한 만큼의 가격만 지불하고, 클라이언트가 직접 서비스를 관리할 수 있습니다.\n#\r#\r공용 웹 사이트를 Azure로 마이그레이션하려는 경우 월별 사용 비용을 지불하도록 계획해야합니다. 밑줄이 그어진 텍스트를 검토하십시오. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오 변경이 필요하지 않습니다.\nVPN 배포\n모든 웹 사이트 데이터를 Azure로 전송하기 위한 지불\n웹 사이트 연결 수 줄이기\n#\r문제 풀이\r...\r1\n마이그레이션 시, 추가적인 설정 없이 진행할 수 있습니다.\n#\r#\r회사에서 모든 데이터와 리소스를 Azure로 마이그레이션 할 계획입니다. 회사의 마이그레이션 계획에 따르면 PaaS (Platform as a Service) 솔루션 만 Azure에서 사용해야합니다. 계획된 마이그레이션을 지원하는 Azure 환경을 배포해야합니다.솔루션 : Azure App Service 및 Azure SQL 데이터베이스를 만듭니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r1\nAzure App Service와 Azure SQL은 PaaS입니다.\n#\r#\r회사에서 모든 데이터와 리소스를 Azure로 마이그레이션 할 계획입니다. 회사의 마이그레이션 계획에 따르면 PaaS (Platform as a Service) 솔루션 만 Azure에서 사용해야합니다. 계획된 마이그레이션을 지원하는 Azure 환경을 배포해야합니다. 솔루션 : Microsoft SQL Server가 설치된 Azure App Service 및 Azure 가상 머신을 만듭니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r2\nVM은 IaaS입니다.\n#\r#\r회사에서 모든 데이터와 리소스를 Azure로 마이그레이션 할 계획입니다. 회사의 마이그레이션 계획에 따르면 PaaS (Platform as a Service) 솔루션 만 Azure에서 사용해야합니다. 계획된 마이그레이션을 지원하는 Azure 환경을 배포해야합니다. 솔루션 : Azure App Service 및 Azure Storage 계정을 만듭니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r2\nAzure Storage는 IaaS입니다.\n#\r#\r회사는 회사의 모든 고객이 사용하는 App1이라는 계정을 호스팅합니다. App1은 매월 처음 3 주 동안 사용량이 적고 매월 마지막 주 동안 사용량이 매우 높습니다. 이러한 유형의 사용 패턴에 대한 비용 관리를 지원하는 Azure Cloud Services의 이점은 무엇인가요? 고 가용성\n높은 지연\n탄력성\n부하 분산\n#\r문제 풀이\r...\r3\n자원 리소스를 추가, 제거하는 특징은 탄력성입니다.\n#\r#\r웹 애플리케이션을 Azure로 마이그레이션 할 계획입니다. 웹 애플리케이션은 외부 사용자가 액세스합니다. 웹 애플리케이션을 관리하는 데 사용되는 관리 노력의 양을 최소화하려면 클라우드 배포 솔루션을 권장해야합니다. 추천에 무엇을 포함해야합니까? SaaS\nPaaS\nIaaS\nDaaS\n#\r문제 풀이\r...\r2\n호스트의 입장에서 가장 관리의 양이 적은 것은 SaaS이지만, 웹 애플리케이션이 포함되어 PaaS입니다.\n#\r#\rAzure 가상 머신 및 Azure SQL 데이터베이스에 어떤 클라우드 배포 솔루션이 사용 되나요? 답변하려면 답변 영역에서 적절한 옵션을 선택하십시오. #\r#\r문제 풀이\r...\rVM은 IaaS, SQL은 PaaS입니다.\n#\r#\r100 개의 서버가 포함 된 온-프레미스 네트워크가 있습니다. 사용자에게 추가 리소스를 제공하는 솔루션을 권장해야합니다. 솔루션은 자본 및 운영 비용을 최소화해야합니다. 추천에 무엇을 포함해야합니까? 퍼블릭 클라우드로의 완전한 마이그레이션\n추가 데이터 센터\n사설 클라우드\n하이브리드 클라우드\n#\r문제 풀이\r...\r3\n이미 서버가 있으며, 이에 대한 비용최소화를 위해서는 프라이빗 클라우드를 구성해야합니다.\n#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\r온-프레미스 네트워크에서 Azure로 여러 서버를 마이그레이션 할 계획입니다. 서버에 공용 클라우드 서비스를 사용할 때의 주요 이점을 식별해야합니다. 무엇을 식별해야합니까? 퍼블릭 클라우드는 민간 기업이 아닌 공공 소유입니다.\n퍼블릭 클라우드는 기업에 클라우드를 향상시킬 수 있는 능력을 제공하는 크라우드 소싱 솔루션 입니다.\n모는 고용 클라우드 리소스는 모든 공용 구성원이 자유롭게 액세스 할 수 있습니다.\n퍼블릭 클라우드는 여러 기업이 각각 클라우드에서 리소스의 일부를 사용하는 공유 엔티티입니다.\n#\r문제 풀이\r...\rD\n퍼블릭 클라우드는 여러 기업이 한 기업의 클라우드 리소스를 사용합니다.\n#\r#\r여러 Azure 가상 머신을 배포 할 계획입니다. 단일 데이터 센터가 실패하는 경우 가상 머신에서 실행중인 서비스를 사용할 수 있는지 확인해야합니다. 솔루션 : 가상 머신을 둘 이상의 확장 집합에 배포합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r2\n가용성 집합은 데이터 센터 내에서의 논리적 그룹입니다.\n#\r#\r여러 Azure 가상 머신을 배포 할 계획입니다. 단일 데이터 센터가 실패하는 경우 가상 머신에서 실행중인 서비스를 사용할 수 있는지 확인해야합니다. 솔루션 : 두 개 이상의 가용성 영역에 가상 머신을 배포합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r1 가용성 영역은 각 데이터 센터이므로, 하나의 데이터 센터가 실패해도 정상적으로 작동합니다.\n#\r#\r여러 Azure 가상 머신을 배포 할 계획입니다. 단일 데이터 센터가 실패하는 경우 가상 머신에서 실행중인 서비스를 사용할 수 있는지 확인해야합니다. 솔루션 : 가상 머신을 둘 이상의 지역에 배포합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r2\n지역은 각 지역에 따라 규정과 법이 다를 수 있습니다.\n#\r#\r데이터 센터의 Hyper-V 호스트에서 호스팅되는 가상 머신 1,000 개가 있습니다. 모든 가상 머신을 Azure 종량제 구독으로 마이그레이션 할 계획입니다. 계획된 Azure 솔루션에 사용할 비용 모델을 식별해야합니다. 어떤 지출 모델을 식별해야합니까? 운영\n탄성\n자본\n확장 가능\n#\r문제 풀이\r...\r1\n후불로 지불하는 것을 OpEx 또는 운영 모델이라 합니다.\n#\r#\r답변하려면 왼쪽 열에서 오른쪽 설명으로 적절한 혜택을 드래그하십시오. 각 혜택은 한 번, 두 번 이상 사용하거나 전혀 사용하지 않을 수 있습니다. #\r#\r문제 풀이\r...\r#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\r회사에 여러 서버가 포함 된 온 프레미스 네트워크가 있습니다. 회사는 네트워크 관리자의 다음과 같은 관리 책임을 줄일 계획입니다. ✑ 애플리케이션 데이터 백업\r✑ 실패한 서버 하드웨어 교체\r✑ 물리적 서버 보안 관리\r✑ 서버 운영 체제 업데이트\r✑ 공유 문서에 대한 권한 관리 회사는 여러 서버를 Azure 가상 머신으로 마이그레이션 할 계획입니다. 계획된 마이그레이션 후 감소 할 관리 책임을 식별해야합니다. 어떤 두 가지 책임을 식별해야합니까? 각 정답은 완전한 해결책을 제시합니다.\n실패한 서버 하드웨어 교체\n애플리케이션 데이터 백업\n물리적 서버 보안 관리\n서버 운영 체제 업데이트\n공유 문서에 대한 권한 관리\n#\r문제 풀이\r...\r1, 3\n서버 하드웨어와 물리적 서버 보안은 호스트가 설정할 수 없습니다.\n#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r한 리전의 리소스 구독은 항상 공유되는 것은 아닙니다. 리소스 그룹의 태그를 적용시켰을 때, 모든 리소스 그룹이 태그가 적용되는 것은 아닙니다. 모든 리소스 권한을 주었어도, 비용 등의 몇몇의 권한은 줄 수 없습니다. #\r#\r회사에서 Azure에 AI (인공 지능) 솔루션을 배포 할 계획입니다. 회사는 예측 분석 솔루션을 구축, 테스트 및 배포하기 위해 무엇을 사용해야합니까? Azure Logic Apps\nAzure Machine Learning Studio\nAzure batch\nAzure Cosmos DB\n#\r문제 풀이\r...\r2\n(Azure AI 참조)[https://mung0001.github.io/docs/azure/microsoftazure/azure07/]\n#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. #\r#\r문제 풀이\r...\rAzure Advisor는 보안과는 연관이 있지만, Azure AD(Datalog서비스)와는 연관이 없습니다. Azure Advisor는 가용성, 비용, 보안성 등의 컨설팅을 지원합니다. Azure Advisor은 직접적으로 VM의 네트워크 세팅에는 관여하지 않습니다. #\r#\r여러 지원 엔지니어가 다음 표에 표시된 컴퓨터를 사용하여 Azure를 관리 할 계획입니다. 각 컴퓨터에서 사용할 수있는 Azure 관리 도구를 식별해야합니다. 각 컴퓨터에 대해 무엇을 식별해야합니까? 답변하려면 답변 영역에서 적절한 옵션을 선택하십시오. #\r#\r문제 풀이\r...\r모든 리소스에는 CLI, Portal, PowerShell을 사용할 수 있습니다. #\r#\rAzure 정책은 클라우드 인프라에 개체를 배포하고 Azure 환경에서 일관성을 구현하기위한 공통 플랫폼을 제공합니다. 밑줄이 그어진 텍스트를 검토하십시오. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경이 필요하지 않습니다.\nResource groups provide\nAzure Resource Manager provides\nManagement groups provide\n#\r문제 풀이\r...\r3\nAzure Policies Provide는 Resource Manager와 관련있습니다.\n#\r#\rAzure 서비스를 올바른 설명과 일치시킵니다. 대답하려면 왼쪽 열에서 오른쪽 설명으로 적절한 Azure 서비스를 끕니다. 각 서비스는 한 번, 두 번 이상 또는 전혀 사용하지 않을 수 있습니다 #\r#\r문제 풀이\r...\r#\r#\r회사에는 여러 사업부가 있습니다. 각 사업부에는 일상적인 작업을 위해 20 개의 서로 다른 Azure 리소스가 필요합니다. 모든 사업부에는 동일한 유형의 Azure 리소스가 필요합니다. Azure 리소스 생성을 자동화하는 솔루션을 권장해야합니다. 권장 사항에 무엇을 포함해야합니까? Azure Resource Manager 템플릿\nVirtual Machine scale sets\nthe Azure API Management Service\nmanagement groups\n#\r문제 풀이\r...\r여러 서비스 및 자동화를 위해서는 stack을 생성하기 위한 탬플릿을 사용해야합니다.\n#\r#\rAzure 서비스를 올바른 정의와 일치시킵니다. 대답하려면 왼쪽 열에서 오른쪽 설명으로 적절한 Azure 서비스를 끕니다. 각 서비스는 한 번, 두 번 이상 또는 전혀 사용하지 않을 수 있습니다. #\r#\r문제 풀이\r...\r#\r#\r중요한 LOB (기간 업무) 응용 프로그램을 Azure에 배포 할 계획입니다. 애플리케이션은 Azure 가상 머신에서 실행됩니다. 응용 프로그램에 대한 배포 솔루션을 권장해야합니다. 이 솔루션은 99.99 %의 보장 된 가용성을 제공해야합니다. 배포를 위해 권장해야하는 최소 가상 머신 수와 최소 가용 영역 수는 얼마입니까? 답변하려면 답변 영역에서 적절한 옵션을 선택하십시오. #\r#\r문제 풀이\r...\r99.99%의 가용성을 위해서는 2개의 리전에 VM이 존재해야합니다.\n#\r#\r여러 리소스의 이벤트를 중앙 리포지토리로 연결하려면 어떤 Azure 서비스를 사용해야합니까? Azure Event Hubs\nAzure Analysis Services\nAzure Monitor\nAzure Log Analytics\n#\r문제 풀이\r...\r3\nAzure Monitor을 사용해야합니다.\n#\r#\rAzure 환경이 있습니다. Android 노트북에서 새 Azure 가상 머신을 만들어야합니다. Azure Cloud Shell에서 PowerShell을 사용합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r1\n핸드폰에서도 웹을 통해 Cloud Shell을 사용할 수 있습니다.\n#\r#\rAzure 환경이 있습니다. Android 노트북에서 새 Azure 가상 머신을 만들어야합니다. PowerApps 포털을 사용합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r2\nPowerApps은 웹 페이지 레이아웃을 만드는 도구입니다.\n#\r#\rAzure 환경이 있습니다. Android 노트북에서 새 Azure 가상 머신을 만들어야합니다. Azure Portal을 사용합니다. Yes\nNo\n#\r문제 풀이\r...\rA\n#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r데이터 베이스는 최소 3개의 복제본을 가집니다. 데이터 베이스는 설정시에 백업이 생성됩니다. 스토리지 용량 제한은 2 TB 이상을 가지는 스토리지 서비스도 있습니다 #\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r모든 지역의 가용성영역이 있는 것은 아닙니다. window server는 VM을 통해만 생성가능한 것이 아닙니다. 복제하는 데에 사용하는 것은 맞지만, 주 목적은 보안, 내결함성 등입니다. #\r#\rAzure 지역에는 지연 시간이 짧은 네트워크를 사용하여 연결된 하나 이상의 데이터 센터가 포함됩니다. 변경이 필요하지 않습니다.\nIs found in each country where Microsoft has a subsidiary office\nCan be found in every country in Europe and the Americas only\nContains one or more data centers that are connect by using a high-latency network\n#\r문제 풀이\r...\r1\n#\r#\r20 개의 가상 머신을 Azure 환경에 배포 할 계획입니다. VM1이라는 가상 머신이 다른 가상 머신에 연결할 수 없도록하려면 VM1을 별도의 가상 네트워크에 배포해야합니다. 변경이 필요하지 않습니다.\n다른 가상 머신과 다른 운영 체제 실행\n별도의 리소스 그룹에 배포\n두 개의 네트워크 엔터페이스가 있습니다.\n#\r문제 풀이\r...\r1\n네트워크 설정이 아닌 NIC 등의 설정을 통해 가능합니다.\n#\r#\r여러 Azure 가상 머신에 동시에 권한을 위임해야하는 경우 동일한 Azure 지역에 Azure 가상 머신을 배포해야합니다. 변경이 필요하지 않습니다.\n동일한 Azure Resource Manager 템플릿 사용\n동일한 리소스 그룹\n동일한 리전\n#\r문제 풀이\r...\r3\n동일한 리소스 그룹에 생성하면 권한이 유지됩니다.\n#\r#\r회사의 개발자 팀은 매주 50 개의 사용자 지정 가상 컴퓨터를 배포 한 다음 제거 할 계획입니다. 가상 머신 중 30 개는 Windows Server 2016을 실행하고 가상 머신 중 20 개는 Ubuntu Linux를 실행합니다. 가상 머신을 배포하고 제거하는 데 필요한 관리 노력을 최소화 할 Azure 서비스를 권장해야합니다. 무엇을 추천해야합니까? 1. Azure 예약 Vm 인스턴스\nAzure 가상 머신 확장 집합\nAzure DevTest Labs\nMicrosoft management Desktop\n#\r문제 풀이\r...\r3\n개발자팀은 DevTest Labs를 사용하여 편하게 관리가 가능합니다.\n#\r#\rAzure SQL Data Warehouse의 이점 중 하나는 플랫폼에 고 가용성이 내장되어 있다는 것입니다. 변경이 필요하지 않습니다.\n자동 확장\n데이터 압축\n버전 관리\n#\r문제 풀이\r...\r1\n고 가용성이란 데이터가 손실되지 않는 것을 뜻하므로, 보기에는 존재하지 않습니다.\n#\r#\r지원 엔지니어는 Azure CLI를 사용하여 여러 Azure 관리 작업을 수행 할 계획입니다. 컴퓨터에 CLI를 설치합니다. 지원 엔지니어에게 CLI를 실행하는 데 사용할 도구를 알려야합니다. 지원 엔지니어에게 어떤 도구를 사용하도록 지시해야합니까? 명령 프롬프트\nAzure 리소스 탐색기\nWindows PowerShell\nwindows Defender 방화벽\n네트워크 및 공유 센터\n#\r문제 풀이\r...\rA, 3\nCLI, WindowPowerShell, CloudShell, Web console\n#\r#\rAzure Cloud Shell을 사용하여 Azure를 관리해야합니다. 어떤 Azure Portal 아이콘을 선택해야하나요? 답변하려면 답변 영역에서 적절한 아이콘을 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\rAzure에 20TB의 데이터를 저장할 계획입니다. 데이터는 Microsoft Power BI를 사용하여 가끔 액세스되고 시각화됩니다. 데이터에 대한 스토리지 솔루션을 추천해야합니다. 어떤 두 가지 솔루션을 권장해야합니까? 각 정답은 완전한 해결책을 제시합니다. Azure Data Lake\nAzure Cosmos DB\nAzure SQL Datawarehouse\nAzure SQL 데이터베이스\nPostgreSQL 용 Azure 데이터베이스\n#\r문제 풀이\r...\r1, 3 Cosmos DB (NoSQL), SQL DB(최대 4TB). PostgreSQL DB (최대 16TB)\n#\r#\r10 개의 웹앱 이 포함 된 Azure 환경이 있습니다. 모든 Azure 리소스를 관리하려면 어떤 URL에 연결해야합니까? 답변하려면 답변 영역에서 적절한 옵션을 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\rAzure 서비스에 대한 액세스를 보호하기 위해 Azure 가용성 영역을 사용할 수 있는 오류 유형을 식별해야합니다. 무엇을 식별해야합니까? 물리적 서버 오류\nAzure 지역 오류\n저장 실패\nAzure 데이터 센터 오류\n#\r문제 풀이\r...\r4\n가용성 영역과 연관있는 것은 데이터 센터입니다.\n#\r#\r귀사의 네트워크를 Azure로 확장 할 계획입니다. 네트워크에는 IP 주소 131.107.200.1을 사용하는 VPN 어플라이언스가 포함되어 있습니다. VPN 어플라이언스를 식별하는 Azure 리소스를 만들어야합니다. 어떤 Azure 리소스를 만들어야합니까? 답변하려면 답변 영역에서 적절한 리소스를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\rWindows Server 2016을 실행하는 VM1이라는 가상 머신이 있습니다. VM1은 미국 동부 Azure 지역에 있습니다. VM1의 가용성에 영향을 줄 수있는 서비스 오류 알림을 보려면 Azure Portal에서 어떤 Azure 서비스를 사용해야합니까? Azure 패브릭 서비스\nAzure 모니터\nAzure VM\nAzure Advisor\n#\r문제 풀이\r...\r2\nAzure 모니터를 통해 오류 로그를 확인할 수 있습니다.\n#\r#\rAzure 관리자는 Azure 리소스를 만드는 PowerShell 스크립트를 실행할 계획입니다. 스크립트를 실행하는 데 사용할 컴퓨터 구성을 권장해야합니다. Linux를 실행하고 Azure CLI 도구가 설치된 컴퓨터에서 스크립트를 실행합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r2\nLinux CLI와 PowerShell은 서로 다른 도구입니다.\n#\r#\rAzure 관리자는 Azure 리소스를 만드는 PowerShell 스크립트를 실행할 계획입니다. 스크립트를 실행하는 데 사용할 컴퓨터 구성을 권장해야합니다. Chrome OS를 실행하고 Azure Cloud Shell을 사용하는 컴퓨터에서 스크립트를 실행합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r1 Cloud Shell은 PowerShell을 지원합니다.\n#\r#\rAzure 관리자는 Azure 리소스를 만드는 PowerShell 스크립트를 실행할 계획입니다. 스크립트를 실행하는 데 사용할 컴퓨터 구성을 권장해야합니다. macOS를 실행하고 PowerShell Core 6.0이 설치된 컴퓨터에서 스크립트를 실행합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r1 MacOS에 PowerShell 설치가 가능합니다.\n#\r#\r10 개의 가상 네트워크와 100 개의 가상 머신이 포함 된 Azure 환경이 있습니다. 모든 Azure 가상 네트워크에 대한 인바운드 트래픽 양을 제한해야합니다. 무엇을 만들어야합니까? 하나의 NSG\n10개의 가상 네트워크 게이트웨이\n10 Azure ExpreeRoute 회로\n하나의 Azure 방화벽\n#\r문제 풀이\r...\r4 Azure firewalld은 트래픽을 제한할 수 있습니다.\n#\r#\r여러 Azure 가상 머신이 포함 된 Azure 환경이 있습니다. 온-프레미스 네트워크의 클라이언트 컴퓨터가 Azure 가상 머신과 통신 할 수 있도록하는 솔루션을 구현할 계획입니다. 계획된 솔루션에 대해 만들어야하는 Azure 리소스를 권장해야합니다. 권장 사항에 어떤 Azure 리소스를 포함해야합니까? 각 정답은 솔루션의 일부를 제공합니다. 가상 네트워크 게이트웨이\n로드 밸런서\n애플리케이션 게이트웨이\n가상 네트워크\n게이트웨어 서브넷\n#\r문제 풀이\r...\r1, 5 이미 VM이 있으므로 가상네트워크는 존재합니다. 즉 가상 네트워크와 게이트웨이 와 서브넷을 추가하면 됩니다.\n#\r#\rAzure 서비스를 올바른 설명과 일치시킵니다. 대답하려면 왼쪽 열에서 오른쪽 설명으로 적절한 Azure 서비스를 끕니다. 각 서비스는 한 번, 두 번 이상 또는 전혀 사용하지 않을 수 있습니다. #\r#\r문제 풀이\r...\r3번째는 Data Lake입니다. #\r#\r다음 작업을 수행하는 데 사용해야하는 Azure Portal의 블레이드를 식별해야합니다. ✑ 보안 권장 사항을 봅니다.\r✑ Azure 서비스의 상태를 모니터링합니다.\r✑ 사용 가능한 가상 머신 이미지를 찾습니다. 각 작업에 대해 어떤 블레이드를 식별해야합니까? 답변하려면 답변 영역에서 적절한 옵션을 선택하십시오.\n#\r#\r문제 풀이\r...\r#\r#\rAzure 환경이 있습니다. Android 노트북에서 새 Azure 가상 머신을 만들어야합니다. Azure Cloud Shell에서 Bash를 사용합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r1\nCloud Shell을 통해 생성이 가능합니다.\n#\r#\rAzure 가상 머신을 만들 계획입니다. 가상 머신의 데이터 디스크를 저장하는 데 사용해야하는 스토리지 서비스를 식별해야합니다. 무엇을 식별해야합니까? 응답하려면 응답 영역에서 적절한 서비스를 선택하십시오. #\r#\r문제 풀이\r...\r데이터 디스크를 저장하는 데에는 Blobs가 주로 사용됩니다.\n#\r#\r회사에서 여러 서버를 Azure로 이동할 계획입니다. 회사의 규정 준수 정책에 따르면 FinServer라는 서버는 별도의 네트워크 세그먼트에 있어야합니다. 규정 준수 정책 요구 사항을 충족하는 데 사용할 수있는 Azure 서비스를 평가하고 있습니다. 어떤 Azure 솔루션을 권장해야합니까? FinServer 용 리소스 그룹 및 다른 모든 서버용 다른 리소스 그룹\nFinServer 용 가상 네트워크 및 다른 모든 서버용 다른 가상 네트워크\nFinServer 용 VPN 및 서로 서버용 가상 네트워크 게이트웨이\n모든 서버에 대한 하나의 리소스 그룹 및 FinServer에 대한 리소스 잠금\n#\r문제 풀이\r...\r2\n따로 구성한다는 말에 주의해야합니다.\n#\r#\rWindows 10을 실행하는 여러 컴퓨터의 네트워크 드라이브를 Azure Storage에 매핑 할 계획입니다. 계획된 매핑 된 드라이브에 대해 Azure에서 저장소 솔루션을 만들어야합니다. 무엇을 만들어야합니까? Azure SQL DB\nVM data disk\nFiles service in a storage account\nBloss service in a storage account\n#\r문제 풀이\r...\r3 SMB를 통해 파일 서비스를 적합한 통해 저장소 솔류션을 만들 수 있습니다.\n#\r#\rAzure 데이터베이스 솔루션을 구현할 계획입니다. 다음 요구 사항을 충족하는 데이터베이스 솔루션을 구현해야합니다. ✑ 여러 지역의 데이터를 동시에 추가 할 수 있습니다 . ✑ JSON 문서를 저장할 수 있습니다. 어떤 데이터베이스 서비스를 배포해야합니까?\n#\r문제 풀이\r...\rCosmosDB의 특징입니다.\n#\r#\r회사에서 모든 네트워크 리소스를 Azure로 마이그레이션 할 계획입니다. Azure를 탐색하여 계획 프로세스를 시작해야합니다. 먼저 무엇을 만들어야합니까? 구독\n리소스 그룹\n가상 네트워크\n관리 그룹\n#\r문제 풀이\r...\r1\n모든 권환의 기초는 구독입니다.\n#\r#\r규칙에 따라 자동으로 이메일 알림을 보내는 온-프레미스 애플리케이션이 있습니다. 애플리케이션을 Azure로 마이그레이션 할 계획입니다. 애플리케이션을위한 서버리스 컴퓨팅 솔루션을 권장해야합니다. 추천에 무엇을 포함해야합니까? web app\nAzure Marketplace의 서버 이미지\nlogic app\nAPI app\n#\r문제 풀이\r...\r3\nmail, 문서 등의 작업을 수행할 시에는 logic app을 사용합니다.\n#\r#\rAzure에 웹 사이트를 배포 할 계획입니다. 이 웹 사이트는 전 세계 사용자가 액세스 할 수 있으며 대용량 비디오 파일을 호스팅합니다. 최상의 비디오 재생 환경을 제공하기 위해 사용해야하는 Azure 기능을 권장해야합니다. 무엇을 추천해야합니까? 애플리케이션 게이트웨이\nAzure ExpressRoute circuit\na content delivery network (CDN)\nan Azure Traffic Manager profile\n#\r문제 풀이\r...\r3\nCDN은 전 세계의 호스팅을 위해 사용됩니다.\n#\r#\r귀사는 Azure에 데이터를 업로드 할 수백만 개의 센서를 배포 할 계획입니다. 계획된 솔루션을 지원하기 위해 만들어야하는 Azure 리소스를 식별해야합니다. 어떤 두 Azure 리소스를 식별해야합니까? 각 정답은 솔루션의 일부를 제공합니다. Azure data Lake\nAzure Queue storage\nAzure File Storage\nAzure IoT Hub\nAzure Notification Hubs\n#\r문제 풀이\r...\r2, 4\n센서는 IoT Hub에 관한 설명이고, 식별을 위한 통신은 Queue에 대한 설명입니다.\n#\r#\rAzure 웹앱이 있습니다. iPhone에서 웹 앱의 설정을 관리해야합니다. 사용할 수있는 두 가지 Azure 관리 도구는 무엇인가요? 각 정답은 완전한 해결책을 제시합니다. Azure CLI\nAzure potal\nAzure Cloud Shell\nWindows PowerShell\nAzure 저장소 탐색기\n#\r문제 풀이\r...\r2, 3\n모바일에서 관리할 수 있는 도구들은 모바일 앱, 포탈, 포탈의 클라우드 쉘이 있습니다.\n#\r#\r서비스 수준 계약 (SLA)이 99.95 % 인 Azure 웹앱과 SLA가 99.99 % 인 Azure SQL 데이터베이스로 구성된 애플리케이션이 있습니다. 애플리케이션의 복합 SLA는 99.94 %에 해당하는 두 SLA의 제품입니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경이 필요하지 않습니다.\n애플리케이션과 관련된 최저 SLA (99.95%)\n애플리케이션과 관련된 최고 SLA (99.99%)\n두 SLA의 차이 (0.05%)\n#\r문제 풀이\r...\r1 99.95 x 99.99 = 99.94\n#\r#\rRG1이라는 자원 그룹에 삭제 잠금이있는 경우 글로벌 관리자 그룹의 구성원 만 RG1을 삭제할 수 있습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오 변경이 필요하지 않습니다.\n관리자 전에 삭제 잠금을 제거해야합니다.\n관리자 전에 Azure 정책을 수정해야합니다.\n관리자 전에 Azure 태그를 추가해야합니다.\n#\r문제 풀이\r...\r2\n제거를 위해서는 관리자가 삭제 잠금을 제거해야합니다.\n#\r#\rAzure Germany는 독일의 합법적 인 거주자 만 사용할 수 있습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경이 필요하지 않습니다.\n독일에 등록된 기업만\n독일에 기반을 둔 파트너로부터 Azure 라이선스를 구매한 기업만 해당\n데이터가 독일에 있어야하는 사용자 또는 기업\n#\r문제 풀이\r...\rD\n#\r#\r가상 머신을 생성 한 후에는 TCP 포트 8080에서 가상 머신으로의 연결을 허용하도록 NSG (네트워크 보안 그룹)를 수정해야합니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경이 필요하지 않습니다.\n가상 네트워크 게이트웨이\n가상 네트워크\n라우팅 테이블\n#\r문제 풀이\r...\r1 port로 인바운드, 아웃바운드를 수정하는 서비스는 NSG입니다.\n#\r#\rAzure 환경에는 여러 Azure 가상 머신이 포함되어 있습니다.HTTP를 통해 인터넷에서 VM1이라는 가상 머신에 액세스 할 수 있는지 확인해야합니다. 솔루션 : DDoS 보호 계획을 수정합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r2 방화벽을 수정해야합니다.\n#\r#\rAzure 환경에는 여러 Azure 가상 머신이 포함되어 있습니다. HTTP를 통해 인터넷에서 VM1이라는 가상 머신에 액세스 할 수 있는지 확인해야합니다. 솔루션 : Azure 방화벽을 수정합니다. 이것이 목표를 충족합니까? #\r문제 풀이\r...\r1\n위와 동일\n#\r#\rAzure 환경에는 여러 Azure 가상 머신이 포함되어 있습니다. HTTP를 통해 인터넷에서 VM1이라는 가상 머신에 액세스 할 수 있는지 확인해야합니다. 해결 방법 : Azure Traffic Manager 프로필을 수정합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r2\n방화벽을 수정해야합니다.\n#\r#\rAzure Government를 사용하여 클라우드 솔루션을 개발할 수있는 두 가지 유형의 고객은 무엇입니까? 각 정답은 완전한 해결책을 제시합니다. 캐나다 정부 계약자\n유럽 정부 계약자\n미국 정부 기관\n미국 정부 계약자\n유럽 정부 기관\n#\r문제 풀이\r...\r3, 4 Azure Government는 미국 정부 기관의 준수에 따라 생성되었습니다.\n#\r#\rAzure AD (Azure Active Directory) 사용자가 익명 IP 주소를 사용하여 인터넷에서 Azure AD에 연결할 때 사용자에게 암호를 변경하라는 메시지가 자동으로 표시되는지 확인해야합니다. 어떤 Azure 서비스를 사용해야합니까? Azure AD Connect 상태\nAzure AD ID 관리 권한\nAzrue ATP\nAzure AD ID Protect\n#\r문제 풀이\r...\r4 ID Protect를 통해 계정보안이 관리됩니다.\n#\r#\r회사에서 여러 웹 서버와 여러 데이터베이스 서버를 Azure에 배포 할 계획입니다. 웹 서버에서 데이터베이스 서버로의 연결 유형을 제한하려면 Azure 솔루션을 권장해야합니다. 추천에 무엇을 포함해야합니까? NSG\nAzure Service Bus\nLocal Network Gateway\nroute filter\n#\r문제 풀이\r...\r1\n기본적으로 NSG를 통해 IP, 포트 연결유형을 제한 할 수 있습니다.\n#\r#\r애플리케이션은 보안 토큰을 검색하기 위해 무엇에 연결해야합니까? Azure Storage 계정\nAzure Active Dirctory\n인증서 저장소\nAzure Key Vault\n#\r문제 풀이\r...\r4\nKey Vault는 보안 토큰을 관리합니다.\n#\r#\r리소스 그룹은 여러 구독에서 Azure 리소스의 규정 준수를 관리하는 기능을 조직에 제공합니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경이 필요하지 않습니다.\n관리 그룹\nAzure 정책\nAzure App Service 계획\n#\r문제 풀이\r...\r3\n리소스 그룹을 관리하는 것은 Azure 정책입니다.\n#\r#\r네트워크에 Active Directory 포리스트가 있습니다. 포리스트에는 5,000 개의 사용자 계정이 있습니다. 회사는 모든 네트워크 리소스를 Azure로 마이그레이션하고 온-프레미스 데이터 센터를 폐기 할 계획입니다. 계획된 마이그레이션 후 사용자에게 미치는 영향을 최소화하는 솔루션을 권장해야합니다. 무엇을 추천해야합니까? Azure MFA (Multi-Factor Authentication) 구현\n모든 Active Directory 사용자 계정을 Azure AD (Azure Active Directory)에 동기화\n모든 사용자에게 암호를 변경하도록 지시\n각 사용자에 대해 Azure Active Directory (Azure AD)에서 게스트 사용자 계정 만들기\n#\r문제 풀이\r...\r2 Azure AD가 동일한 역할을 수행합니다.\n#\r#\r인증서를 저장하려면 어떤 Azure 서비스를 사용해야합니까? Azure 보안 센터\nAzure Storage 게정\nAzure Key Vault\nAzure 정보 보호\n#\r문제 풀이\r...\r3\n인증서의 관리는 Azure Key Vault에서 관리됩니다.\n#\r#\rRG1이라는 리소스 그룹이 있습니다. RG1에서 가상 네트워크 및 앱 서비스를 만들 계획입니다. RG1에서만 가상 머신 생성을 방지해야합니다. 무엇을 사용해야합니까? lock\nAzure 역할\ntag\nAzure 정책\n#\r문제 풀이\r...\r4 정책을 통해 삭제를 제한할 수 있습니다.\n#\r#\rAzure Information Protection은 무엇을 암호화 할 수 있나요? 네트워크 트래픽\n문서 및 이메일 메시지\nAzure Storage 계정\nAzure SQL 데이터베이스\n#\r문제 풀이\r...\r2\nAzure Information Protection은 문서 및 이메일 메시지를 관리합니다.\n#\r#\r회사의 Azure 환경이 규정 요구 사항을 충족하는지 평가하려면 무엇을 사용해야합니까? 지식 센터 웹 사이트\nthe Advisor blade from the Azure portal\nCompliance Manager from the Security Trust Portal\nthe Security Center blade from the Azure portal\n#\r문제 풀이\r...\r4\nAzure Portal에 Azure 규정 준수사항이 있습니다.\n#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\r회사는 신용 카드 정보가 포함 된 Microsoft Word 문서에 워터 마크를 자동으로 추가하는 Azure 정책을 구현합니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경할 필요 없습니다.\nDDoS Protection\nAzure Iformation Protection\nAzure AD ID Protection\n#\r문제 풀이\r...\r3\nAzure Information Protection을 통해 워터마크를 자동으로 추가하는 Azure 정책을 구현할 수 있습니다.\n#\r#\rAzure Monitor에서 지난 14 일 동안 특정 가상 머신을 끈 사용자를 볼 수 있습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경이 필요하지 않습니다.\nAzure Event Hubs\nAzure 활동 로그\nAzure 서비스 상태\n#\r문제 풀이\r...\r3\nAzure 활동 로그를 통해 확인이 가능합니다.\n#\r#\rG1이라는 리소스 그룹에 VNET1이라는 Azure 가상 네트워크가 있습니다. 가상 네트워크가 RG1에서 허용되는 리소스 유형이 아님을 지정하는 Azure 정책을 할당합니다. VNET1은 자동으로 삭제됩니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경이 필요하지 않습니다.\n다른 리소스 그룹으로 자동 이동\n계속 정상적으로 작동합니다.\n읽기 전용 개체\n#\r문제 풀이\r...\r1 해당 리소스는 관리가 불가능해집니다.\n#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r3번째 문항은 Yes입니다.\n#\r#\r회사에 여러 지역의 리소스가 포함 된 Azure 환경이 있습니다. 회사 정책에 따르면 관리자는 사무실이 있는 국가의 지역에서만 추가 Azure 리소스를 만들 수 있어야합니다. 정책 요구 사항을 충족하는 데 사용해야하는 Azure 리소스를 만들어야합니다. 무엇을 만들어야합니까? 읽기 전용 잠금\nAzure 정책\n관리 그룹\n예약\n#\r문제 풀이\r...\r2\nAzure 정책을 통해 요구사항을 만족시킬 수 있습니다.\n#\r#\r권한 부여는 사용자의 자격 증명을 확인하는 프로세스입니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경이 필요하지 않습니다.\n인증\n연맹\n발권\n#\r문제 풀이\r...\r2 권한 부여가 아닌 인증을 통해 자격 증명을 받습니다.\n#\r#\r다음 요구 사항을 충족하는 Azure 솔루션을 구성해야합니다. ✑ 공격으로부터 웹 사이트 보호\r✑ 시도 된 공격에 대한 세부 정보가 포함 된 보고서를 생성합니다. 솔루션에 무엇을 포함해야합니까?\nAzure 방화벽\nNSG\nAzure 정보 보호\nDDoS 보호\n#\r문제 풀이\r...\rD 문제는 DDoS 공격에 대한 설명입니다.\n#\r#\rAzure 환경에 대한 여러 보안 서비스를 구현할 계획입니다. 다음 보안 요구 사항을 충족하기 위해 사용해야하는 Azure 서비스를 식별해야합니다. ✑ 센서를 사용하여 위협 모니터링\r✑ 조건에 따라 Azure MFA (Multi-Factor Authentication) 적용 각 요구 사항에 대해 어떤 Azure 서비스를 식별해야합니까? 답변하려면 답변 영역에서 적절한 옵션을 선택하십시오.\n#\r#\r문제 풀이\r...\r#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\r회사는 모든 온-프레미스 데이터를 Azure로 마이그레이션 할 계획입니다. Azure가 회사의 지역 요구 사항을 준수하는지 여부를 식별해야합니다. 무엇을 사용해야합니까? 지식 센터\nAzure Market Place\nAzure Potal\n보안 센터\n#\r문제 풀이\r...\r4 보안센터를 통해 확인할 수 있습니다.\n#\r#\rAzure Key Vault는 Azure AD (Azure Active Directory) 사용자 계정에 대한 비밀을 저장하는 데 사용됩니다. 명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경이 필요하지 않습니다.\nAzure AD 관리 계정\n개인 식별 정보\n서버 애플리케이션\n#\r문제 풀이\r...\r1\nAzure Key Vault에는 Azure AD에 대한 정보를 저장합니다.\n#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\r여러 Azure 가상 머신을 배포 할 계획입니다. 인터넷의 장치가 가상 머신에 액세스하는 데 사용할 수있는 포트를 제어해야합니다. 무엇을 사용해야합니까? NSG\nAzure AD 역할\nAzure AD 그룹\nAzure Key Vault\n#\r문제 풀이\r...\r1\nNSG 에서 Port를 통한 접근을 제어합니다.\n#\r#\rAzure 구독에 여러 가상 머신이 있습니다. 새 구독을 만듭니다. 가상 머신은 새 구독으로 이동할 수 없습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경이 필요하지 않습니다.\n가상 머신을 새 구독으로 이동할 수 있습니다.\n가상 머신은 모두 동일한 리소스 그룹에 있는 경우에만 새 구독으로 이동할 수 있스니다.\n가상 머신은 Windows Server 2016을 실행하는 경우에만 새 구독으로 이동할 수 있습니다.\n#\r문제 풀이\r...\r2\n구독은 수정 및 이전이 가능합니다.\n#\r#\rAzure 환경에서 여러 관리되는 Microsoft SQL Server 인스턴스를 만들려고 시도하고 Azure 구독 제한을 늘려야한다는 메시지를받습니다. 한계를 높이려면 어떻게해야합니까? 서비스 상태 경고 만들기\n지원 계획 업그레이드\nAzure 정책 수정\n새 지원 요청 생성\n#\r문제 풀이\r...\r4\n요청함으로써 사용제한을 풀 수 있습니다.\n#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오 #\r#\r문제 풀이\r...\r#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\r회사에는 10 개의 사무실이 있습니다. Azure Portal에서 여러 청구 보고서를 생성 할 계획입니다. 각 보고서에는 각 사무실의 Azure 리소스 용률이 포함됩니다. 보고서를 생성하기 전에 어떤 Azure Resource Manager 기능을 사용해야합니까? 태그\n탬플릿\nlock\n정책\n#\r문제 풀이\r...\r1\n태그를 통해 분류가 가능합니다.\n#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\rAzure 리소스를 배포합니다. 서비스 중단으로 인해 리소스를 장기간 사용할 수 없게됩니다. Microsoft는 자동으로 귀하의 은행 계좌를 환불 해드립니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경할 필요가 없습니다.\n리소스를 다른 구독으로 자동 마이그레이션\n자동으로 계정에 입금\nAzure 크레딧으로 교환 할 수 있는 쿠폰 코드를 전송\n#\r문제 풀이\r...\r3 자동으로 크레딧으로 변환됩니다.\n#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\r회사에서 Azure로 마이그레이션 할 계획입니다. 회사에는 여러 부서가 있습니다. 각 부서에서 사용하는 모든 Azure 리소스는 부서 관리자가 관리합니다. 부서에 대해 Azure를 분할하는 기능을 제공하는 Azure 배포를 권장해야합니다. 솔루션은 관리 노력을 최소화해야합니다. 추천에 무엇을 포함해야합니까? 여러 구독\n여러 Azure AD 디렉터리\n여러 지역\n여러 리소스 그룹\n#\r문제 풀이\r...\r문제풀이\n#\r#\r회사에 사용되지 않는 다음 리소스가 포함 된 Azure 구독이 있습니다 ✑ Azure Active Directory (Azure AD)의 사용자 계정 20 개 ✑ Azure AD의 그룹 5 개\r✑ 공용 IP 주소 10 개 ✑ 네트워크 인터페이스 10 개 회사의 Azure 비용을 줄여야합니다. 해결 방법 : 사용하지 않는 네트워크 인터페이스를 제거합니다. 이것이 목표를 충족합니까?\nYes\nNo\n#\r문제 풀이\r...\r2\n네트워크 인터페이스는 비용이 지불되지 않습니다.\n#\r#\r회사에 사용되지 않는 다음 리소스가 포함 된 Azure 구독이 있습니다 ✑ Azure Active Directory (Azure AD)의 사용자 계정 20 개 ✑ Azure AD의 그룹 5 개\r✑ 공용 IP 주소 10 개 ✑ 네트워크 인터페이스 10 개 회사의 Azure 비용을 줄여야합니다. 해결 방법 : 사용하지 않는 사용자 계정을 제거합니다. 이것이 목표를 충족합니까?\nYes\nNo\n#\r문제 풀이\r...\r2\n구독은 비용과 연관이 없습니다.\n#\r#\r월간 가동률을 어떻게 계산해야합니까? 답변하려면 답변 영역에서 적절한 옵션을 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\r가능한 가장 낮은 비용으로 모범 사례 정보, 건강 상태 및 알림, 청구 정보에 대한 연중 무휴 액세스를 제공하는 지원 계획 솔루션은 표준 지원 계획입니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경이 필요하지 않습니다.\nDeveloper\nBasic\nPremier\n#\r문제 풀이\r...\r3\n24시간 및 사례 정보 등의 기본 솔루션을 제공하는 것은 Basic입니다.\n#\r#\r여러 Azure 가상 머신을 배포 할 계획입니다. 단일 데이터 센터가 실패하는 경우 가상 머신에서 실행중인 서비스를 사용할 수 있는지 확인해야합니다. 솔루션 : 가상 머신을 둘 이상의 리소스 그룹에 배포합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r2\n리소스 그룹이 아닌 가용영역에 배포해야합니다.\n#\r#\r어떤 Azure 지원 플랜에서 새 지원 요청을 열 수 있나요? Premier 및 Professional Direct 전용\nPremier, Professional Direct 및 Standard 전용\nPremier, Professional Direct, Standard 및 Developer 전용\nPremier, Professional Direct, Standard, Developer 및 Basic\n#\r문제 풀이\r...\r4\n기술지원은 Basic은 지원하지 않지만 지원 요청은 모두 가능합니다.\n#\r#\rsupport.microsoft.com에서 Azure 지원 요청을 만들 수 있습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택하십시오. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경할 필요가 없습니다.\nAuzre Portal\n지식 센터\n보안 및 규정 준수 관리 센터\n#\r문제 풀이\r...\r2 Azure Portal에서 지원 요청이 가능합니다.\n#\r#\rAzure 서비스 수준 계약 (SLA)에서 보장되는 것은 무엇인가요? 가동 시간\n가용성\n대역폭\n성능\n#\r문제 풀이\r...\r2\nSLA에서 보장하는 것은 가용성입니다.\n#\r#\rAzure 서비스는 공개 미리보기 상태 일 때 모든 Azure 고객이 사용할 수 있습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경할 필요 없습니다.\n비공개 미리보기\n개발\nEA (기업 계약) 구독\n#\r문제 풀이\r...\r1 공개 미리보기는 모두 사용하고 있고, 비공개는 특정 고객만 사용이 가능합니다.\n#\r#\r회사의 지원 정책에 따르면 Azure 환경은 전화 또는 이메일로 지원 엔지니어에 액세스 할 수있는 옵션을 제공해야합니다. 지원 정책 요구 사항을 충족하는 지원 계획을 추천해야합니다. 솔루션 : 기본 지원 계획을 권장합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r2\n기본 지원 계획에는 기술지원이 존재하지 않습니다.\n#\r#\r회사에서 Azure를 구매할 계획입니다. 회사의 지원 정책에 따르면 Azure 환경은 전화 또는 이메일로 지원 엔지니어에 액세스 할 수있는 옵션을 제공해야합니다. 지원 정책 요구 사항을 충족하는 지원 계획을 추천해야합니다. 솔루션 : 표준 지원 계획을 권장합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\rA\n#\r#\r회사에서 Azure를 구매할 계획입니다. 회사의 지원 정책에 따르면 Azure 환경은 전화 또는 이메일로 지원 엔지니어에 액세스 할 수있는 옵션을 제공해야합니다. 지원 정책 요구 사항을 충족하는 지원 계획을 추천해야합니다. 솔루션 : 표준 지원 계획을 권장합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\rA\n#\r#\r귀사는 Microsoft에 Azure 환경의 아키텍처 검토를 요청할 계획입니다. 회사는 현재 기본 지원 계획을 가지고 있습니다. 회사에 대한 새로운 지원 계획을 추천해야합니다. 솔루션은 비용을 최소화해야합니다. 어떤 지원 계획을 추천해야합니까? Premier\nDeveloper\nProfessional Direct\nStandard\n#\r문제 풀이\r...\r1\n아키텍처의 검토를 위해서는 프리미어가 지원 플랜이 필요합니다.\n#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오 #\r#\r문제 풀이\r...\r#\r#\rAzure Cost Management를 사용하려면 무엇이 필요합니까? 개발/ 테스트 구독\n소프트웨어 보증\nEA\n종량제 구독\n#\r문제 풀이\r...\r3\nEA를 통해 비용관리가 가능합니다.\n#\r#\rAzure 평가판 계정이 지난주에 만료되었습니다. 이제 추가 Azure AD (Azure Active Directory) 사용자 계정을 만들 수 없습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경이 필요하지 않습니다.\n기존 Azure 가상 머신 시작\nAzure에 저장된 데이터에 엑세스\nAzure Portal 엑세스\n#\r문제 풀이\r...\r3\n가장 맞는 말이 C입니다.\n#\r#\r회사에는 10 개의 부서가 있습니다. 이 회사는 Azure 환경을 구현할 계획입니다. 각 부서가 사용하는 Azure 서비스에 대해 서로 다른 결제 옵션을 사용할 수 있는지 확인해야합니다. 부서별로 무엇을 만들어야합니까? 예약\n구독\n리소스 그룹\n컨테이너 인스턴스\n#\r문제 풀이\r...\r2\n구독을 통해 서로 다른 결제 옵션을 설정할 수 있습니다.\n#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\r다음 각 명령문에 대해 해당 명령문이 참이면 예를 선택하십시오. 그렇지 않으면 아니오를 선택하십시오. #\r#\r문제 풀이\r...\r#\r#\rAzure에서 IaaS (Infrastructure as a Service) 리소스를 프로비저닝 할 계획입니다. IaaS의 예는 어떤 리소스입니까? Azure Web, APP\nAzure VM\nAzure logic APP\nAzure SQL Database\n#\r문제 풀이\r...\r2\nIaaS에 포함되는 서비스는 VM 입니다.\n#\r#\r회사의 개발자 팀은 매주 50 개의 가상 머신을 배포 한 다음 제거 할 계획입니다. 모든 가상 머신은 Azure Resource Manager 템플릿 을 사용하여 구성됩니다. 가상 머신을 배포하고 제거하는 데 필요한 관리 노력을 최소화 할 Azure 서비스를 권장해야합니다. 무엇을 추천해야합니까? Azure VM\nAzure DevTest Labs\nAzure 가상머신 확장 집합\nMicrosoft 관리 데스크톱\n#\r문제 풀이\r...\r2\nDevTest Labs를 사용해야합니다.\n#\r#\rSubscription1이라는 Azure 구독이 있습니다. Azure Portal에 로그인하고 RG1이라는 리소스 그룹을 만듭니다. Azure 설명서에서 VM1이라는 가상 머신을 만드는 다음 명령이 있습니다. az vm create \u0026ndash;resource-group RG1 \u0026ndash;name VM1-이미지 UbuntuLTS \u0026ndash;generate-ssh-keys- 명령을 사용하여 Subscription1에 VM1을 만들어야합니다. 솔루션 : Azure Portal에서 Azure Cloud Shell을 시작하고 PowerShell을 선택합니다. Cloud Shell에서 명령어를 실행합니다. 이것이 목표를 충족합니까? Yes\nNo\n#\r문제 풀이\r...\r1\nPowerShell 에서도 Azure CLI 명령어를 사용할 수 있습니다.\n#\r#\rMicrosoft가 후속 서비스가 없는 Azure 서비스에 대한 지원을 종료 할 계획 인 경우 Microsoft는 최소 12 개월 전에 알림을 제공합니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 1. 변경할 필요가 없습니다. 2. **6 개월**\r3. **90 일**\r4. **30 일**\r#\r문제 풀이\r...\r1\n#\r#\r회사에서 여러 사용자 지정 응용 프로그램을 Azure에 배포 할 계획입니다. 이 응용 프로그램은 회사의 고객에게 송장 서비스를 제공합니다. 각 응용 프로그램에는 몇 가지 필수 응용 프로그램 및 서비스가 설치됩니다. 모든 애플리케이션에 클라우드 배포 솔루션을 권장해야합니다. 무엇을 추천해야합니까? SaaS\nPaaS\nIaaS\n#\r문제 풀이\r...\r3\n#\r#\rAzure에서 서버리스 컴퓨팅을 제공하는 서비스는 무엇입니까? Azure Vm\nAzure Function\nAzure Storage account\nAzure Container Instacne\n#\r문제 풀이\r...\r2\n#\r#\r코드를 관리하기위한 버전 제어 도구 집합을 제공하는 Azure 서비스는 무엇인가요? Azure Repos\nAzure DevTest Labs\nAzure Storage\nAzure Cosmos DB\n#\r문제 풀이\r...\r1\n#\r#\r여러 Azure 구독 및 가상 네트워크에서 네트워크 트래픽 필터링을 제공하는 서비스는 무엇입니까? Azure 방화벽\n애플리케이션 보안 그룹\nAzure DDos 보호\nNSG\n#\r문제 풀이\r...\r1\n#\r#\rAzure Cloud Shell에서 ISO 27001과 같은 회사의 규제 표준 및 규정을 추적 할 수 있습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택하십시오. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경할 필요가 없습니다.\nMicrosoft 클라우드 파트너 포털\n준수 관리자\n보안 센터\n#\r문제 풀이\r...\r문제풀이\n#\r#\rMicrosoft 온라인 서비스 개인 정보 보호 정책은 Microsoft가 처리하는 데이터, Microsoft가 데이터를 처리하는 방법 및 데이터 처리 목적을 설명합니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택하십시오. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경할 필요가 없습니다.\nMicrosoft 온라인 서비스 약관\nMicrosoft 온라인 서비스 수준 계약\nMicrosoft Azure에 대한 온라인 구독 계약\n#\r문제 풀이\r...\r1\n#\r#\r회사에서 Azure로 마이그레이션 할 계획입니다. 회사에는 여러 부서가 있습니다. 각 부서에서 사용하는 모든 Azure 리소스는 부서 관리자가 관리합니다. 부서를 위해 Azure를 분할 할 수있는 두 가지 가능한 기술은 무엇입니까? 각 정답은 완전한 해결책을 제시합니다. 여러 구독\n여러 Azure AD 디렉터리\n여러 지역\n여러 리소스 그룹\n#\r문제 풀이\r...\r1, 4\n#\r#\r다음 중 Azure 서비스에 대한 최신 수명주기 정책을 정확하게 설명하는 문은 무엇입니까? Microsoft는 5년 동안 서비스에 대한 일반 지원을 제공합니다.\nMicrosoft는 서비스 지원을 종료하기 전에 최소 12개월전에 통지합니다.\n서비스가 이반 공급 된 후 Microsoft는 최소 4년 동안 서비스에 대한 지원을 제공합니다.\n서비스가 만료되면 최대 5년까지 서비스에 대한 연장 지원을 구매할 수 있습니다.\n#\r문제 풀이\r...\r2\n#\r#\rAzure 구독에 대한 현재 청구 기간의 비용이 지정된 제한을 초과 할 때 Azure에서 Advisor 권장 사항을 사용하여 이메일 경고를 보낼 수 있습니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택하십시오. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경할 필요가 없습니다.\nIAM\n예산 알림\n규정 준수\n#\r문제 풀이\r...\r3\n#\r#\rAzure Standard 지원 플랜은 전화로 지원 엔지니어에게 연중 무휴 24 시간 액세스 할 수있는 가장 저렴한 옵션입니다. 설명이 정확하면 \u0026ldquo;변경할 필요 없음\u0026quot;을 선택합니다. 설명이 정확하지 않은 경우 해당 설명을 올바르게 만드는 답을 선택하십시오. 변경이 필요하지 않습니다.\n개발자\nBasic\n프로페셔널\n#\r"},{"id":59,"href":"/cloud/docs/Azure/MicrosoftAzure/Azure05/","title":"Azure IoT","section":"Azure docs","content":"\rAzure IoT\r#\r#\rAzure에서 IoT를 위한 엔드투엔드 솔루션을 지원하고 구동할 수 있는 여러 서비스가 있습니다. #\r#\rIoT Central\r#\r#\r대규모 IoT 자산의 연결, 모니터링 및 관리를 도와주는, 완전히 관리되는 글로벌 IoT SaaS(Software-as-a-Service) 솔루션 #\r#\rAzure IoT Hub\r#\r#\r수백만 개의 IoT 디바이스 간의 안전한 통신 및 모니터링을 제공하는 메시징 허브 #\r#\rIoT Edge\r#\r#\r데이터 분석 모델을 IoT 디바이스로 직접 푸시하여 클라우드 기반 AI 모델을 참조할 필요 없이 상태 변경에 신속하게 대응할 수 있습니다. #\r"},{"id":60,"href":"/cloud/docs/AWS/AWSSAA/SAA-16/","title":"16장 기출문제(kr)","section":"AWS SAA 시험정리","content":"\r15장 기출문제\r#\r#\r답들은 정확하지 않습니다. 공부하시면서 찾아보셔야 합니다.\r#\r#\r질문 1-100\r#\r#\r질문\r#\rquestion 회사에 산발적인 사용 패턴이 있는 웹 응용 프로그램이 있습니다. 매월 초에는 사용량이 많고 매주 초에는 사용량이 보통이며 주중에는 사용량이 예측할 수 없습니다. 애플리케이션은 웹 서버와 내부에서 실행되는 MySQL 데이터베이스 서버로 구성됩니다. 데이터 센터. 이 회사는 애플리케이션을 AWS 클라우드로 옮기고자 하며 데이터베이스 수정이 필요하지 않은 비용 효율적인 데이터베이스 플랫폼을 선택해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. Amazon DynamoDB\nB. MySQL용 Amazon RDS C. MySQL 호환 Amazon Aurora Serverless D. Auto Scaling 그룹의 Amazon EC2에 배포된 MySQL\n정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 신생 회사는 여러 가용 영역에 걸쳐 Application Load Balancer 뒤에서 실행되는 여러 Amazon EC2 인스턴스가 있는 us-east-1 리전에 기반을 둔 웹 애플리케이션을 보유하고 있습니다. 회사의 사용자 기반이 us-west-1 리전에서 증가함에 따라 대기 시간이 짧고 가용성이 높은 솔루션이 필요합니다. 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. us-west-1에서 EC2 인스턴스를 프로비저닝합니다. Application Load Balancer를 네트워크 로드로 전환 지역 간 로드 밸런싱을 달성하기 위한 밸런서. B. us-west-1에서 EC2 인스턴스와 Application Load Balancer를 프로비저닝합니다. 로드 밸런서 만들기 요청 위치를 기반으로 트래픽을 분산합니다. C. EC2 인스턴스를 프로비저닝하고 us-west-1에서 Application Load Balancer를 구성합니다. 두 리전의 로드 밸런서 엔드포인트를 포함하는 엔드포인트 그룹을 사용하는 AWS Global Accelerator에서 액셀러레이터를 생성합니다. D. EC2 인스턴스를 프로비저닝하고 us-west-1에서 Application Load Balancer를 구성합니다. 가중치 기반 라우팅 정책으로 Amazon Route 53을 구성합니다. Application Load Balancer를 가리키는 Route 53에서 별칭 레코드를 생성합니다. 정답 풀이\r...\r답: C\r#\r설명 https://aws.amazon.com/global-accelerator/faqs/ 엔드포인트 그룹에 대한 엔드포인트 등록: 다음과 같은 지역 리소스를 하나 이상 등록합니다. 각각의 Application Load Balancer, Network Load Balancer, EC2 인스턴스 또는 탄력적 IP 주소 엔드포인트 그룹. 그런 다음 가중치를 설정하여 각 엔드포인트로 라우팅되는 트래픽의 양을 선택할 수 있습니다. AWS Global Accelerator의 엔드포인트 AWS Global Accelerator의 엔드포인트는 Network Load Balancer, Application Load Balancer, Amazon EC2 인스턴스 또는 탄력적 IP 주소. 고정 IP 주소는 단일 접점 역할을 합니다. 클라이언트의 경우 Global Accelerator가 들어오는 트래픽을 정상 엔드포인트에 분산합니다. 글로벌 Accelerator는 사용자가 지정하는 포트(또는 포트 범위)를 사용하여 엔드포인트로 트래픽을 보냅니다. 엔드포인트의 엔드포인트 그룹이 속한 리스너. 각 엔드포인트 그룹에는 여러 엔드포인트가 있을 수 있습니다. 여러 엔드포인트에 각 엔드포인트를 추가할 수 있습니다. 그룹이지만 엔드포인트 그룹은 다른 리스너와 연결되어야 합니다. Global Accelerator는 엔드포인트에 포함된 모든 엔드포인트의 상태를 지속적으로 모니터링합니다. 그룹. 정상적인 활성 엔드포인트로만 트래픽을 라우팅합니다. Global Accelerator가 작동하지 않는 경우 트래픽을 라우팅할 정상적인 엔드포인트가 있으면 모든 엔드포인트로 트래픽을 라우팅합니다. https://docs.aws.amazon.com/global-accelerator/latest/dg/about-endpoints.html\n#\r#\r질문\r#\rquestion 솔루션 설계자는 2단계 주문 프로세스를 위한 애플리케이션을 설계하고 있습니다. 첫 번째 단계는 동기식이며 대기 시간이 거의 없이 사용자에게 반환되어야 합니다. 두 번째 단계는 더 오래 걸리므로 별도의 구성 요소로 구현됩니다. 주문은 정확히 한 번만 처리되어야 하고 솔루션 설계자는 이러한 구성 요소를 어떻게 통합해야 합니까?\nA. Amazon SQS FIFO 대기열 사용 B. Amazon SQS 표준 대기열과 함께 AWS Lambda 함수 사용 C. SNS 주제 생성 및 해당 주제에 대한 Amazon SQS FIFO 대기열 구독 D. SNS 주제를 생성하고 해당 주제에 대한 Amazon SQS 표준 대기열을 구독합니다. 정답 풀이\r...\r답변: A\r#\rC가 이유는 SQS FIFO와 SNS는 함께 한다고 합니다.\n#\r#\r질문\r#\rquestion 임대 회사는 매월 모든 고객을 위해 PDF 명세서를 생성하여 이메일로 보냅니다. 각 명령문의 크기는 약 400KB입니다. 고객은 명세서가 생성된 날로부터 최대 30일 동안 웹사이트에서 명세서를 다운로드할 수 있습니다. 3년 임대 기간이 끝나면 모든 명세서가 포함된 ZIP 파일이 고객에게 이메일로 전송됩니다. 이 상황에서 가장 비용 효율적인 스토리지 솔루션은 무엇입니까?\nA. Amazon S3 Standard 스토리지 클래스를 사용하여 명령문을 저장합니다. 1일 후에 명령문을 Amazon S3 Glacier 스토리지로 이동하는 수명 주기 정책을 생성합니다. B. Amazon S3 Glacier 스토리지 클래스를 사용하여 명령문을 저장합니다. 30일 후에 Amazon S3 Glacier Deep Archive 스토리지로 명령문을 이동하는 수명 주기 정책을 생성합니다. C. Amazon S3 Standard 스토리지 클래스를 사용하여 명령문을 저장합니다. 30일 후에 명령문을 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA) 스토리지로 이동하는 수명 주기 정책을 생성합니다. D. Amazon S3 Standard-Infrequent Access(S3 Standard-IA) 스토리지 클래스를 사용하여 명령문을 저장합니다. 30일 후에 명령문을 Amazon S3 Glacier 스토리지로 이동하는 수명 주기 정책을 생성합니다. 정답 풀이\r...\r답변: D\r#\rS3-IA는 파일 크기에 대해 최소 128kb, 최소 30일의 저장 기간을 두고 있습니다. 3년 후의 파일고 검색이 가능합니다.\n#\r#\r질문\r#\rquestion 한 회사가 AWS에서 메시지 기반 주문 처리 애플리케이션을 설계하고 있습니다. 애플리케이션은 많은 서비스로 구성되며 처리 결과를 여러 소비 서비스에 전달해야 합니다. 각 소비 서비스는 메시지를 수신하는 데 최대 5일이 소요될 수 있습니다. 이러한 요구 사항을 충족하는 프로세스는 무엇입니까?\nA. 애플리케이션은 처리 결과를 Amazon Simple Notification Service(Amazon SNS) 주제로 전송합니다. 각 소비 서비스는 이 SNS 주제를 구독하고 결과를 소비합니다. B. 애플리케이션은 처리 결과를 Amazon Simple Notification Service(Amazon SNS) 주제로 보냅니다. 각 소비 서비스는 해당 서비스에서 직접 메시지를 소비합니다. SNS 주제. C. 애플리케이션은 처리 결과를 Amazon Simple Queue Service(Amazon SQS) 대기열로 보냅니다. 각 소비 서비스는 이 단일 SQS 대기열을 사용하는 AWS Lambda 함수로 실행됩니다. D. 애플리케이션은 처리 결과를 Amazon Simple Notification Service(Amazon SNS) 주제로 보냅니다. Amazon Simple Queue Service(Amazon SQS) 대기열은 각 서비스에 대해 생성되고 각 대기열은 SNS 주제의 구독자가 되도록 구성됩니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 AWS 자격 증명이 없는 특정 사용자에게 Amazon S3의 파일을 제공합니다. 이러한 사용자에게는 제한된 석회에 대한 액세스 권한이 부여되어야 합니다. 이러한 요구 사항을 안전하게 충족하기 위해 솔루션 설계자는 무엇을 해야 합니까?\nA. Amazon S3 버킷에 대한 공개 액세스를 활성화합니다. B. 사용자와 공유할 미리 서명된 URL을 생성합니다. C. AWS KMS를 사용하여 파일을 암호화하고 사용자에게 키를 제공합니다. D. 사용자에게 GetObject 권한을 부여할 IAM 역할을 생성하고 할당합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사에 VPC의 프라이빗 서브넷 내 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. 인스턴스는 동일한 AWS 리전의 Amazon S3 버킷에 있는 데이터에 액세스합니다. VPC에는 S3 버킷에 액세스하기 위한 퍼블릭 서브넷의 NAT 게이트웨이가 포함되어 있습니다. 회사에서 보안이나 중복성을 손상시키지 않고 NAT 게이트웨이를 교체하여 비용을 절감하고자 합니다. 이 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. NAT 게이트웨이를 NAT 인스턴스로 교체 B. NAT 게이트웨이를 인터넷 게이트웨이로 교체합니다. C. NAT 게이트웨이를 게이트웨이 VPC 엔드포인트로 교체 D. NAT 게이트웨이를 AWS Direct Connect 연결로 교체 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에 퍼블릭 서브넷과 프라이빗 서브넷에서 실행되는 2계층 애플리케이션 아키텍처가 있습니다. 웹 애플리케이션을 실행하는 Amazon EC2 인스턴스는 퍼블릭 서브넷에 있고 데이터베이스는 프라이빗 서브넷에서 실행됩니다. 웹 애플리케이션 인스턴스와 데이터베이스는 단일 가용 영역에서 실행됩니다. (AZ). 솔루션 설계자는 이 아키텍처에 고가용성을 제공하기 위해 어떤 단계 조합을 취해야 합니까? (2개를 선택하십시오.)\nA. 고가용성을 위해 동일한 AZ에 새 퍼블릭 및 프라이빗 서브넷 생성 B. 여러 AZ에 걸쳐 Amazon EC2 Auto Scaling 그룹 및 Application Load Balancer 생성 C. Application Load Balancer 뒤의 Auto Scaling 그룹에 기존 웹 애플리케이션 인스턴스 추가 D. 새 AZ에서 새 퍼블릭 및 프라이빗 서브넷 생성 하나의 AZ에서 Amazon EC2를 사용하여 데이터베이스 생성 E. 새 AZ의 동일한 VPC에 새 퍼블릭 및 프라이빗 서브넷 생성 데이터베이스를 Amazon RDS 다중 AZ 배포로 마이그레이션 정답 풀이\r...\r답: BE\r#\r설명 Auto 리전 내의 여러 가용 영역에 걸쳐 그룹을 확장한 다음 로드 밸런서를 다음에 연결 들어오는 트래픽을 해당 영역에 분산합니다. 들어오는 트래픽은 전체에 균등하게 분배됩니다. 로드 밸런서에 대해 활성화된 가용 영역. 메모 Auto Scaling 그룹에는 여러 가용 영역의 Amazon EC2 인스턴스가 포함될 수 있습니다.\n81 같은 지역. 그러나 Auto Scaling 그룹은 여러 리전의 인스턴스를 포함할 수 없습니다. 하나의 가용 영역이 비정상이거나 사용할 수 없게 되면 Amazon EC2 Auto Scaling이 시작됩니다. 영향을 받지 않는 영역의 새 인스턴스. 비정상 가용 영역이 정상 상태로 돌아오면 Amazon EC2 Auto Scaling은 애플리케이션 인스턴스를 모든 Auto Scaling 그룹의 영역. Amazon EC2 Auto Scaling은 새로운 시작을 시도하여 이를 수행합니다. 가장 적은 수의 인스턴스가 있는 가용 영역의 인스턴스. 그러나 시도가 실패하면 Amazon EC2 Auto Scaling은 성공할 때까지 다른 가용 영역에서 시작을 시도합니다. 가용성을 추가하여 확장되고 로드 밸런싱된 애플리케이션의 가용성을 확장할 수 있습니다. Auto Scaling 그룹으로 영역을 지정한 다음 로드 밸런서에 대해 해당 영역을 활성화합니다. 당신이 새 가용 영역이 활성화되면 로드 밸런서는 모든 활성화된 영역. Amazon RDS용 고가용성(다중 AZ) Amazon RDS는 다중 AZ를 사용하여 DB 인스턴스에 대한 고가용성 및 장애 조치 지원을 제공합니다. 배포. Amazon RDS는 여러 가지 기술을 사용하여 장애 조치 지원을 제공합니다. 다중 AZ 배포 MariaDB의 경우 MySQL, Oracle 및 PostgreSQL DB 인스턴스는 Amazon의 장애 조치 기술을 사용합니다. SQL 서버 DB 인스턴스는 SQL Server 데이터베이스 미러링(DBM) 또는 Always On 가용성 그룹을 사용합니다. (AG). 다중 AZ 배포에서 Amazon RDS는 동기를 자동으로 프로비저닝하고 유지합니다. 다른 가용 영역의 대기 복제본. 기본 DB 인스턴스는 동기식으로 복제됩니다. 가용 영역에서 대기 복제본으로 데이터 중복성을 제공하고 I/O 정지를 제거하며 시스템 백업 중 지연 시간 급증을 최소화합니다. 고가용성으로 DB 인스턴스를 실행하면 계획된 시스템 유지 관리 중 가용성 향상 및 DB로부터 데이터베이스 보호 인스턴스 장애 및 가용 영역 중단. 가용 영역에 대한 자세한 내용은 단원을 참조하십시오. 리전, 가용 영역 및 로컬 영역 https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Concepts.MultiAZ.html\n#\r#\r질문\r#\rquestion 한 회사가 AWS에서 새로운 기계 학습 모델 솔루션을 개발하고 있습니다. 모델은 시작 시 Amazon S3에서 약 1GB의 모델 데이터를 가져와 메모리에 로드하는 독립적인 마이크로서비스로 개발됩니다. 사용자는 비동기 API를 통해 모델에 액세스합니다. 사용자 요청 또는 일괄 요청을 보내고 결과를 보낼 위치를 지정할 수 있습니다. 이 회사는 수백 명의 사용자에게 모델을 제공합니다. 모델의 사용 패턴이 불규칙합니다. 일부 모델은 며칠 또는 몇 주 동안 사용되지 않을 수 있습니다. 다른 모델은 한 번에 수천 개의 요청을 일괄적으로 수신할 수 있습니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. API의 요청은 ALB(Application Load Balancer)로 전송됩니다. 모델은 ALB에서 호출하는 AWS Lambda 함수로 배포됩니다. B. API의 요청은 Amazon Simple Queue Service(Amazon SQS) 대기열 모델로 전송됩니다.\n모델은 SQS 이벤트에 의해 트리거되는 AWS Lambda 함수로 배포됩니다. AWS Auto Scaling은 SQS 대기열 크기에 따라 vCPU 수를 늘리기 위해 Lambda에서 활성화됩니다. C. API의 요청은 모델의 Amazon Simple Queue Service(Amazon SQS) 대기열로 전송됩니다. 모델은 대기열에서 읽는 Amazon Elastic Container Service(Amazon ECS) 서비스로 배포됩니다. AWS App Mesh는 SQS 대기열 크기를 기반으로 ECS 클러스터의 인스턴스를 확장합니다. D. API의 요청이 모델로 전송됩니다. Amazon Simple Queue Service(Amazon SQS) queueModels는 두 클러스터 모두에 대해 Amazon ECS에서 활성화된 AWS Auto Scaling 대기열에서 읽는 Amazon Elastic Container Service(Amazon ECS) 서비스로 배포됩니다. 대기열 크기에 기반한 서비스 사본. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사에는 파일 공유에 저장된 데이터에 액세스해야 하는 여러 비즈니스 시스템이 있습니다.\n비즈니스 시스템은 SMB(서버 메시지 블록) 프로토콜을 사용하여 파일 공유에 액세스합니다. 파일 공유 솔루션은 회사의 레거시 온프레미스 환경 모두에서 액세스할 수 있어야 합니다. 그리고 AWS와 함께. 어떤 서비스가 비즈니스 요구 사항을 수정합니까? (2개를 선택하십시오.)\nA. 아마존 EBS B. 아마존 EFS C. Windows용 Amazon FSx D. 아마존 S3 E. AWS Storage Gateway 파일 게이트웨이 정답 풀이\r...\r답변: CE\r#\rAmazon FSx에서 온 온종일 Windows, Linux 및 MacOS에서 AWS 이상\nAWS Storage Gateway는 동시에 모든 클라우드에 대한 액세스를 제공합니다. Storage Gateway는 지금까지 다양한 기능을 제공하지 않을 예정이며, AWS SMB와 같은 완벽한 세트를 제공합니다.\n#\r#\r질문\r#\rquestion 한 회사는 최근 us-east1 리전의 2개 가용 영역에 2계층 애플리케이션을 배포했습니다. 데이터베이스는 프라이빗 서브넷에 배포되고 웹 서버는 퍼블릭 서브넷에 배포됩니다. 인터넷 게이트웨이가 VPC에 연결됩니다. 애플리케이션과 데이터베이스는 Amazon EC2 인스턴스에서 실행됩니다. 데이터베이스 서버는 인터넷의 패치에 액세스할 수 없습니다. 솔루션 설계자는 최소한의 운영 오버헤드로 데이터베이스 보안을 유지하는 솔루션을 설계해야 합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 각 가용 영역의 퍼블릭 서브넷 내부에 NAT 게이트웨이를 배포하고 이를 탄력적 IP 주소와 연결합니다. 기본 경로로 사용하도록 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다. B. 각 가용 영역의 프라이빗 서브넷 내부에 NAT 게이트웨이를 배포하고 이를 탄력적 IP 주소와 연결합니다. 기본 경로로 사용하도록 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다. C. 각 가용 영역에 대해 퍼블릭 서브넷 내부에 두 개의 NAT 인스턴스를 배포하고 탄력적 IP 주소와 연결합니다. 기본 경로로 사용하도록 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다. D. 각 가용 영역에 대해 프라이빗 서브넷 내부에 두 개의 NAT 인스턴스를 배포하고 탄력적 IP 주소와 연결합니다. 기본 경로로 사용하도록 프라이빗 서브넷의 라우팅 테이블을 업데이트합니다. 정답 풀이\r...\r답변: A\r#\rNAT를 추천합니다.\n#\r#\r질문\r#\rquestion 솔루션 설계자는 원하는 Amazon EC2 용량에 도달하기 전에 야간 배치 처리 작업이 1시간 동안 자동으로 확장되는 것을 관찰합니다. 최대 용량은 매일 밤 동일하며 배치 작업은 항상 오전 1시에 시작합니다. 솔루션 설계자는 원하는 EC2 용량에 빠르게 도달하고 배치 작업이 완료된 후 Auto Scaling 그룹을 축소할 수 있는 비용 효율적인 솔루션을 찾아야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?\nA. Auto Scaling 그룹의 최소 용량을 늘립니다.\nB. Auto Scaling 그룹의 최대 용량을 늘립니다.\nC. 원하는 컴퓨팅 수준으로 확장하도록 예약된 확장을 구성합니다.\nD. 각 조정 작업 동안 더 많은 EC2 인스턴스를 추가하도록 조정 정책을 변경합니다. 정답 풀이\r...\r답: C\r#\r비용은 보험료, 구매 기간 동안 가능합니다.\n#\r#\r질문\r#\rquestion 솔루션 설계자가 Amazon S3를 사용하여 문서 검토 애플리케이션을 구현하고 있습니다. 보관용 버킷 솔루션은 실수로 문서를 삭제하는 것을 방지하고 다음을 보장해야 합니다. 문서의 모든 버전을 사용할 수 있습니다. 사용자는 다운로드, 수정 및 업로드할 수 있어야 합니다. 문서 이러한 요구 사항을 충족하기 위해 취해야 하는 조치의 조합은 무엇입니까? (2개 선택)\nA. 읽기 전용 버킷 ACL 활성화 B. 버킷에서 버전 관리 활성화 C. 버킷에 IAM 정책 연결 D. 버킷에서 MFA 삭제 활성화 E. AWS KMS를 사용하여 버킷 암호화 정답 풀이\r...\r답변: BD\r#\r설명 객체 버전 관리 Amazon S3 버전 관리를 사용하여 하나의 버킷에 여러 버전의 객체를 보관하십시오. 예를 들어, 당신은 my-image.jpg(버전 111111) 및 my-image.jpg(버전 222222)를 단일 버킷에 저장할 수 있습니다. 시즌3 버전 관리는 의도하지 않은 덮어쓰기 및 삭제의 결과로부터 사용자를 보호합니다. 당신은 또한 수 이전 버전에 액세스할 수 있도록 개체를 아카이브하는 데 사용합니다. 데이터 보존 접근 방식을 사용자 정의하고 스토리지 비용을 제어하려면 다음과 함께 객체 버전 관리를 사용하십시오. 개체 수명 주기 관리. AWS를 사용한 S3 수명 주기 정책 생성에 대한 정보 관리 콘솔, S3 버킷에 대한 수명 주기 정책은 어떻게 생성합니까?를 참조하십시오.\n아마존 심플에서 스토리지 서비스 콘솔 사용자 가이드. 버전이 지정되지 않은 버킷에 객체 만료 수명 주기 정책이 있고 다음을 수행하려는 경우 버전 관리를 활성화할 때 동일한 영구 삭제 동작을 유지하려면 현재 만료 정책. 비 최신 만료 수명 주기 정책은 최신이 아닌 객체 버전의 삭제를 관리합니다.\n버전이 활성화된 버킷에서 (버전이 활성화된 버킷은 현재 하나와 0개 이상을 유지합니다. 비 최신 객체 버전.) 버킷에서 S3 버전 관리를 명시적으로 활성화해야 합니다. 기본적으로 S3 버전 관리가 비활성화되었습니다. 버전 관리를 활성화했는지 여부에 관계없이 버킷에는 버전 ID가 있습니다. 버전 관리를 활성화하지 않은 경우 Amazon S3는 버전 값을 설정합니다. ID를 null로 설정합니다. S3 버전 관리가 활성화된 경우 Amazon S3는 객체에 대한 버전 ID 값을 할당합니다. 이 값 동일한 키의 다른 버전과 구별됩니다. 버전 관리 활성화 및 일시 중단은 버킷 수준에서 수행됩니다. 버전 관리를 활성화하면 기존 버킷에서 이미 버킷에 저장된 객체는 변경되지 않습니다. 버전 ID(null), 내용 및 권한은 동일하게 유지됩니다. 버킷에 대해 S3 버전 관리를 활성화한 후 각 객체는 버킷에 추가된 버전은 동일한 버전의 다른 버전과 구별되는 버전 ID를 얻습니다. 열쇠. Amazon S3만 버전 ID를 생성하며 편집할 수 없습니다. 버전 ID는 유니코드, UTF-8입니다. 인코딩된 URL 준비된 불투명 문자열로 길이가 1,024바이트 이하입니다. 다음은 예: 3/L4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo. MFA 삭제 사용 버킷의 버전 관리 구성이 MFA 삭제가 활성화된 경우 버킷 소유자는 객체 버전을 영구적으로 삭제하거나 변경하려는 요청에 xamz-mfa 요청 헤더를 포함해야 합니다. 버킷의 버전 관리 상태. x-amz-mfa를 포함하는 요청은 HTTPS를 사용해야 합니다. 헤더의 값은 인증 장치의 일련 번호, 공백 및 인증 코드가 표시됩니다. 하면 이 요청 헤더를 포함하지 않으면 요청이 실패합니다. https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingMFADelete.html\n#\r#\r질문\r#\rquestion 회사는 고성능 컴퓨팅(HPC) 애플리케이션 및 데이터를 온프레미스에서 AWS 클라우드로 마이그레이션하려고 합니다. 회사는 애플리케이션을 주기적으로 실행하고 애플리케이션을 지원하기 위해 핫 고성능 병렬 스토리지와 함께 온프레미스 계층형 스토리지를 사용합니다. 애플리케이션이 활발히 실행되고 있지 않을 때 데이터를 보관하는 보다 경제적인 콜드 스토리지 애플리케이션의 스토리지 요구 사항을 지원하기 위해 솔루션 설계자가 권장해야 하는 솔루션 조합은 무엇입니까? (2개 선택)\nA. 콜드 데이터 스토리지를 위한 Amazon S3 B. 콜드 데이터 스토리지를 위한 Amazon EFS C. 고성능 병렬 스토리지를 위한 Amazon S3 D. 고성능 병렬 스토리지를 위한 Lustre용 Amazon FSx E. 고성능 병렬 스토리지를 위한 Windows용 Amazon FSx 정답 풀이\r...\r답변: 광고\r#\r#\r#\r질문\r#\rquestion 회사에서 Amazon Aurora를 실행하는 Amazon RDS DB 인스턴스를 배포할 계획입니다. 회사의 백업 보존 정책 요구 사항은 90일입니다. 솔루션 설계자는 어떤 솔루션을 권장해야 합니까?\nA. RDS DB 인스턴스 생성 시 백업 보존 기간을 90일로 설정\nB. 90일 후에 삭제하도록 설정된 수명 주기 정책을 사용하여 자동화된 스냅샷을 사용자 관리형 Amazon S3 버킷에 복사하도록 RDS를 구성합니다.\nC. 보존이 90일로 설정된 RDS 데이터베이스의 일일 스냅샷을 수행하는 AWS Backup 계획을 생성합니다. 매일 백업 계획의 실행을 예약하는 AWS Backup 작업을 생성합니다.\nD. Amazon CloudWatch Events와 함께 매일 예약된 이벤트를 사용하여 RDS 자동 스냅샷의 복사본을 만드는 사용자 지정 AWS Lambda 함수 실행 90일이 지난 스냅샷 제거 정답 풀이\r...\r답: C\r#\r지금은 0-35일입니다. 사용자: S3 APPS에서 감염이 발생했습니다. #\r#\r질문\r#\rquestion AWS에서 웹 애플리케이션을 호스팅하는 회사는 모든 Amazon EC2 인스턴스를 보장하기를 원합니다. Amazon RDS DB 인스턴스 및 Amazon Redshift 클러스터는 태그로 구성됩니다. 회사는 이 검사를 구성하고 운영하는 노력을 최소화하기를 원합니다.\n솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. AWS Config 규칙을 사용하여 속성 태그가 지정되지 않은 리소스 정의 및 감지\nB. 비용 탐색기를 사용하여 태그가 제대로 지정되지 않은 리소스를 표시합니다. 해당 리소스에 수동으로 태그를 지정합니다.\nC. 적절한 태그 할당을 위해 모든 리소스를 확인하는 API 호출을 작성합니다. EC2 인스턴스에서 주기적으로 코드를 실행합니다.\nD. 적절한 태그 할당을 위해 모든 리소스를 확인하는 API 호출을 작성합니다. Amazon CloudWatch를 통해 AWS Lambda 함수를 예약하여 코드를 주기적으로 실행 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 계층적 디렉터리 구조를 사용하는 애플리케이션이 있는 VPC에서 여러 Amazon EC2 Linux 인스턴스를 실행합니다. 애플리케이션은 공유 스토리지를 빠르고 동시에 동시에 읽고 써야 합니다. 이를 어떻게 달성할 수 있습니까?\nA. Amazon EFS 파일 시스템을 생성하고 각 EC2 인스턴스에서 탑재합니다. B. Amazon S3 버킷을 생성하고 VPC의 모든 EC2 인스턴스에서 액세스를 허용합니다. C. Amazon EBS 프로비저닝된 IOPS SSD(io1) 볼륨에 파일 시스템을 생성합니다. 볼륨을 모든 EC2 인스턴스에 연결합니다. D. 각 EC2 인스턴스에 연결된 Amazon EBS 볼륨에 파일 시스템을 생성합니다. 다양한 EC2 인스턴스에서 Amazon EBS 볼륨을 동기화합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 사용자의 지연 시간을 최소화해야 하는 모바일 앱용 아키텍처를 만들고 있습니다. 회사의 아키텍처는 Auto Scaling 그룹에서 실행되는 Application Load Balancer 뒤에 있는 Amazon EC2 인스턴스로 구성됩니다. EC2 인스턴스는 Amazon RDS에 연결됩니다. 애플리케이션 베타 테스트에서는 데이터를 읽을 때 속도가 느려지는 것으로 나타났습니다. 그러나 지표에 따르면 EC2 인스턴스가 CPU 사용률 임계값을 초과하지 않는 것으로 나타났습니다. 이 문제를 해결하려면 어떻게 해야 합니까?\nA. Auto Scaling 그룹에서 CPU 사용률 임계값을 줄입니다. B. Application Load Balancer를 Network Load Balancer로 교체합니다. C. RDS 인스턴스에 대한 읽기 전용 복제본을 추가하고 읽기 트래픽을 복제본으로 보냅니다. D. 다중 AZ 지원을 RDS 인스턴스에 추가하고 읽기 트래픽을 새 EC2 인스턴스로 보냅니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에 서로 다른 두 VPC의 Amazon EC2 인스턴스에서 호스팅되는 애플리케이션이 있습니다. AWS 리전 인스턴스는 서로 통신하기 위해 인터넷을 사용하여 연결합니다. NS 보안 팀은 인스턴스 간에 통신이 인터넷 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. NAT 게이트웨이 생성 및 EC2 인스턴스 서브넷의 라우팅 테이블 업데이트\nB. VPC 엔드포인트 생성 및 EC2 인스턴스 서브넷의 라우팅 테이블 업데이트\nC. VPN 연결 생성 및 EC2 인스턴스 서브넷의 라우팅 테이블 업데이트\nD. VPC 피어링 연결 생성 및 EC2 인스턴스 서브넷의 라우팅 테이블 업데이트 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사에 글로벌 영업 팀에서 사용하는 온프레미스 MySQL 데이터베이스가 있습니다. 드문 액세스 패턴. 영업 팀은 데이터베이스에 다운타임이 최소화되어야 합니다. NS 데이터베이스 관리자가 특정 인스턴스를 선택하지 않고 이 데이터베이스를 AWS로 마이그레이션하려고 합니다. 앞으로 더 많은 사용자를 예상하여 입력하십시오. 솔루션 아키텍트가 추천해야 하는 서비스는?\nA. Amazon Aurora MySQL B. MySQL용 Amazon Aurora 서버리스 C. Amazon Redshift 스펙트럼 D. MySQL용 Amazon RDS 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사에서 온프레미스 Oracle 데이터베이스를 Amazon RDS(또는 Oracle 다중 AZ DB 인스턴스 us-east-l 리전. 솔루션 설계자가 재해 복구를 설계하고 있습니다. us-west-2 지역에서 데이터베이스를 프로비저닝하는 전략 us-east-1 리전에서는 사용할 수 없습니다. 설계는 데이터베이스가 최대 2시간 내에 uswest-2 리전에서 프로비저닝되고 데이터 손실 창은 3시간을 넘지 않도록 해야 합니다. 이러한 요구 사항을 어떻게 충족할 수 있습니까?\nA. DB 인스턴스를 편집하고 us-west-2에서 읽기 전용 복제본을 생성합니다. 읽기 전용 복제본을 마스터 인으로 승격 재해 복구 환경을 활성화해야 하는 경우 us-west-2. B. 멀티 리전 옵션을 선택하여 us-west-2에서 대기 인스턴스를 프로비저닝합니다. 대기 인스턴스 재해 복구 환경의 경우 us-west-2에서 자동으로 마스터로 승격됩니다. 생성할 필요가 있습니다. C. 데이터베이스 인스턴스의 자동 스냅샷을 만들어 3시간마다 us-west-2에 복사합니다. 재해 발생 시 us-west-2의 다른 데이터베이스 인스턴스를 프로비저닝하기 위해 최신 스냅샷을 복원합니다. 복구 환경을 활성화해야 합니다. D. 여러 AWS 리전에서 멀티마스터 읽기/쓰기 인스턴스 생성 us-east-1에서 VPC 선택 그리고 us-west-2 lo는 배포를 합니다. us-west-2의 마스터 읽기/쓰기 인스턴스를 사용 가능한 상태로 유지 재해 복구 환경을 활성화하지 않아도 됩니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 매월 초에 판매 보고서를 생성해야 합니다. 보고 프로세스는 매월 1일에 20개의 Amazon EC2 인스턴스를 시작합니다. 이 과정은 7일 동안 진행되며 중단할 수 없습니다. 회사는 비용을 최소화하기를 원합니다. 회사는 어떤 가격 모델을 선택해야 합니까?\nA. 예약 인스턴스\nB. 스팟 블록 인스턴스\nC. 온디맨드 인스턴스\nD. 정기 예약 인스턴스 정답 풀이\r...\r답변: D\r#\r설명 정기 예약 인스턴스 정기 예약 인스턴스(정기 인스턴스)를 사용하면 용량 예약을 구매할 수 있습니다. 1년 기간 동안 지정된 시작 시간과 기간으로 매일, 매주 또는 매월 반복됩니다. 필요할 때 사용할 수 있도록 미리 용량을 예약합니다. 너 인스턴스를 사용하지 않더라도 인스턴스가 예약된 시간에 대해 비용을 지불합니다. 정기 인스턴스는 지속적으로 실행되지는 않지만 지속적으로 실행되는 워크로드에 적합합니다. 정기 일정. 예를 들어, 다음 기간 동안 실행되는 애플리케이션에 대해 정기 인스턴스를 사용할 수 있습니다. 영업 시간 또는 주말에 실행되는 일괄 처리. 지속적으로 용량 예약이 필요한 경우 예약 인스턴스가 다음을 충족할 수 있습니다. 필요하고 비용을 절감합니다. 정기 인스턴스의 작동 방식 Amazon EC2는 예약된 대로 사용하기 위해 각 가용 영역에 EC2 인스턴스 풀을 따로 설정합니다. 인스턴스. 각 풀은 인스턴스 유형, 운영 체제 및 회로망. 시작하려면 사용 가능한 일정을 검색해야 합니다. 여러 풀 또는 싱글 풀. 적합한 일정을 찾은 후 구입하십시오. 시작을 사용하여 예약된 기간 동안 정기 인스턴스를 시작해야 합니다. 구매한 일정의 다음 속성과 일치하는 구성: 인스턴스 유형, 가용 영역, 네트워크 및 플랫폼. 그렇게 하면 Amazon EC2가 EC2 인스턴스를 시작합니다. 지정된 시작 사양을 기반으로 사용자를 대신합니다. Amazon EC2는 EC2가 현재 예약된 기간이 끝날 때까지 인스턴스가 종료되어 용량이 예약된 다른 모든 정기 인스턴스에 사용할 수 있습니다. 따라서 Amazon EC2는 현재 예약된 기간이 끝나기 3분 전의 EC2 인스턴스. 정기 인스턴스를 중지하거나 재부팅할 수 없지만 필요에 따라 수동으로 종료할 수 있습니다. 만약 너라면 현재 예약된 기간이 끝나기 전에 정기 인스턴스를 종료하면 시작할 수 있습니다. 몇 분 후에 다시. 그렇지 않으면 다음 예약된 시간까지 기다려야 합니다. 다음 다이어그램은 정기 인스턴스의 수명 주기를 보여줍니다. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-scheduled-instances.html\n#\r#\r질문\r#\rquestion 한 회사는 오래된 뉴스의 비디오 아카이브를 AWS에 저장할 수 있는 솔루션을 찾고 있습니다. 피트 길이. 회사는 비용을 최소화해야 하며 이러한 파일을 거의 복원할 필요가 없습니다. 때 파일이 필요한 경우 최대 5분 이내에 사용할 수 있어야 합니다. 가장 비용 효율적인 솔루션은 무엇입니까?\nA. 비디오 아카이브를 Amazon S3 Glacier에 저장하고 신속 검색을 사용합니다.\nB. 비디오 아카이브를 Amazon S3 Glacier에 저장하고 표준 검색을 사용합니다.\nC. 비디오 아카이브를 Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 저장합니다.\nD. 비디오 아카이브를 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)에 저장합니다. 정답 풀이\r...\r답변: A\r#\r의사소통을 어렵게 합니다. #\r#\r질문\r#\rquestion 회사는 뒤에 있는 Amazon EC2 인스턴스에서 실행할 새로운 서비스를 설계하고 있습니다. 엘라스틱 로드 밸런서. 그러나 많은 웹 서비스 클라이언트는 방화벽에 허용된 IP 주소에만 연결할 수 있습니다. 솔루션 설계자는 클라이언트의 요구 사항을 충족하기 위해 무엇을 권장해야 합니까?\nA. 연결된 탄력적 IP 주소가 있는 Network Load Balancer.\nB. 연결된 탄력적 IP 주소가 있는 Application Load Balancer\nC. 탄력적 IP 주소를 가리키는 Amazon Route 53 호스팅 영역의 A 레코드\nD. 로드 밸런서 앞에서 프록시로 실행되는 퍼블릭 IP 주소가 있는 EC2 인스턴스 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에 정보를 검색하는 자격 증명이 내장된 맞춤형 애플리케이션이 있습니다. Amazon RDS MySQL DB 인스턴스에서. 경영진은 응용 프로그램을 더 만들어야 한다고 말합니다. 최소한의 프로그래밍 노력으로 보안을 유지합니다. 솔루션 아키텍트가 충족해야 할 사항 이러한 요구 사항은?\nA. AWS Key Management Service(AWS KMS) 고객 마스터 키(CMK)를 사용하여 키를 생성합니다. AWS KMS에서 데이터베이스 자격 증명을 로드하도록 애플리케이션 구성 자동 키 활성화 회전. B. RDS for MySQL 데이터베이스에서 애플리케이션 사용자에 대한 자격 증명을 생성하고 AWS Secrets Manager의 자격 증명. 데이터베이스 자격 증명을 로드하도록 애플리케이션 구성 비밀 관리자. Secret Manager에서 자격 증명을 교체하는 AWS Lambda 함수를 생성합니다. C. RDS for MySQL 데이터베이스에서 애플리케이션 사용자에 대한 자격 증명을 생성하고 AWS Secrets Manager의 자격 증명. 데이터베이스 자격 증명을 로드하도록 애플리케이션 구성 비밀 관리자. RDS for MySQL에서 애플리케이션 사용자에 대한 자격 증명 교체 일정 설정 Secrets Manager를 사용하여 데이터베이스. D. RDS for MySQL 데이터베이스에서 애플리케이션 사용자에 대한 자격 증명을 생성하고 AWS Systems Manager Parameter Store의 자격 증명. 로드하도록 애플리케이션을 구성합니다. Parameter Store의 데이터베이스 자격 증명. 애플리케이션에 대한 자격 증명 교체 일정 설정 Parameter Store를 사용하는 MySQL용 RDS 데이터베이스의 사용자입니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 전자 상거래 회사는 Amazon RDS 기반의 성능 저하를 발견했습니다. 웹 응용 프로그램. 성능 저하의 원인은 읽기 전용 비즈니스 분석가가 트리거한 SQL 쿼리입니다. 솔루션 아키텍트는 다음과 같은 문제를 해결해야 합니다. 기존 웹 애플리케이션에 대한 최소한의 변경. 솔루션 아키텍트는 무엇을 추천해야 합니까?\nA. 데이터를 Amazon DynamoDB로 내보내고 비즈니스 분석가가 쿼리를 실행하도록 합니다. B. 데이터를 Amazon ElasticCache에 로드하고 비즈니스 분석가가 쿼리를 실행하도록 합니다. C. 기본 데이터베이스의 읽기 전용 복제본을 만들고 비즈니스 분석가가 쿼리를 실행하도록 합니다. D. 데이터를 Amazon Redshift 클러스터에 복사하고 비즈니스 분석가가 쿼리를 실행하도록 합니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사가 분산된 여러 Amazon EC2 인스턴스에서 미디어 스토어를 실행하고 있습니다. 단일 VPC의 여러 가용 영역에 걸쳐 있습니다. 회사는 다음과 같은 고성능 솔루션을 원합니다. 모든 EC2 인스턴스 간에 데이터를 공유하고 VPC 내에서만 데이터를 유지하는 것을 선호합니다. 솔루션 아키텍트는 무엇을 추천해야 합니까?\nA. Amazon S3 버킷을 생성하고 각 인스턴스의 애플리케이션에서 서비스 API를 호출합니다. B. Amazon S3 버킷을 생성하고 모든 인스턴스가 탑재된 볼륨으로 액세스하도록 구성합니다. C. Amazon Elastic Block Store(Amazon EBS) 볼륨을 구성하고 모든 인스턴스에 탑재합니다. D. Amazon Elastic File System(Amazon EFS) 파일 시스템을 구성하고 모든 시스템에 탑재 인스턴스 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에서 온프레미스에서 다중 계층 웹 애플리케이션을 실행하고 있습니다. 웹 애플리케이션은 컨테이너화되고 다음을 포함하는 PostgreSQL 데이터베이스에 연결된 여러 Linux 호스트에서 실행됩니다. 사용자 기록. 인프라 및 용량 계획 유지 관리의 운영 오버헤드는 회사 성장 제한 솔루션 설계자는 애플리케이션의 인프라를 개선해야 합니다. 솔루션 설계자는 이를 달성하기 위해 어떤 조합의 조치를 취해야 합니까? (2개를 선택하십시오.)\nA. PostgreSQL 데이터베이스를 Amazon Aurora로 마이그레이션\nB. Amazon EC2 인스턴스에서 호스팅할 웹 애플리케이션을 마이그레이션합니다.\nC. 웹 애플리케이션 콘텐츠에 대한 Amazon CloudFront 배포를 설정합니다.\nD. 웹 애플리케이션과 PostgreSQL 데이터베이스 간에 Amazon ElastiCache 설정\nE. Amazon Elastic Container Service를 사용하여 AWS Fargate에서 호스팅할 웹 애플리케이션 마이그레이션 (아마존 ECS) 정답 풀이\r...\r답: CD\r#\r#\r#\r질문\r#\rquestion 한 회사가 코로케이션 시설에서 Amazon S3 버킷으로 1PB의 데이터를 복사했습니다. AWS Direct Connect 링크를 사용하는 us-east-1 리전. 회사는 이제 데이터를 다음으로 복사하려고 합니다. us-west-2 리전의 다른 S3 버킷. 코로케이션 시설은 AWS 사용을 허용하지 않습니다. 스노볼. 솔루션 설계자는 이를 달성하기 위해 무엇을 권장해야 합니까?\nA. 한 리전에서 다른 리전으로 데이터를 복사하도록 Snowball Edge 장치를 주문합니다.\nB. S3 콘솔을 사용하여 소스 S3 버킷에서 대상 S3 버킷으로 콘텐츠를 전송합니다.\nC. aws S3 sync 명령을 사용하여 소스 버킷에서 대상 버킷으로 데이터를 복사합니다.\nD. 교차 리전 복제 구성을 추가하여 다른 Reg의 S3 버킷 간에 객체를 복사합니다. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 낮은 요구 사항을 요구하는 새로운 애플리케이션용 아키텍처를 설계하고 있습니다. Amazon EC2 인스턴스 간의 네트워크 지연 및 높은 네트워크 처리량. 어떤 구성 요소 건축 설계에 포함되어야 합니까?\nA. 스팟 인스턴스 유형이 있는 Auto Scaling 그룹.\nB. 클러스터 배치 전략을 사용하는 배치 그룹.\nC. 파티션 배치 전략을 사용하는 배치 그룹.\nD. 온디맨드 인스턴스 유형이 있는 Auto Scaling 그룹. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사에 두 개의 Amazon EC2 인스턴스에서 호스팅되는 동적 웹 애플리케이션이 있습니다. NS 회사에는 SSL 종료를 수행하기 위해 각 인스턴스에 있는 자체 SSL 인증서가 있습니다. 최근 트래픽이 증가했으며 운영 팀은 SSL이 암호화 및 암호 해독으로 인해 웹 서버의 컴퓨팅 용량이 최대 한도. 솔루션 설계자는 애플리케이션의 성능을 향상시키기 위해 무엇을 해야 합니까?\nA. AWS Certificate Manager(ACM)를 사용하여 새 SSL 인증서를 생성합니다. 에 ACM 인증서를 설치합니다. 각 인스턴스.\nB. Amazon S3 버킷을 생성합니다. SSL 인증서를 S3 버킷으로 마이그레이션합니다. EC2 구성 SSL 종료를 위해 버킷을 참조할 인스턴스.\nC. 다른 EC2 인스턴스를 프록시 서버로 생성합니다. SSL 인증서를 새 인스턴스로 마이그레이션하고 기존 EC2 인스턴스에 직접 연결하도록 구성합니다.\nD. SSL 인증서를 AWS Certificate Manager(ACM)로 가져옵니다. 애플리케이션 로드 생성 ACM의 SSL 인증서를 사용하는 HTTPS 리스너가 있는 밸런서. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에 관계형 데이터베이스를 실행하는 온프레미스 서버가 있습니다. 현재 데이터베이스 회사에서 AWS로 마이그레이션하려는 여러 위치의 사용자에게 높은 읽기 트래픽을 제공합니다. 최소한의 노력 데이터베이스 솔루션은 재해 복구를 지원해야 하며 영향을 미치지 않아야 합니다. 회사의 현재 트래픽 흐름. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 다중 AZ와 하나 이상의 읽기 전용 복제본이 있는 Amazon RDS의 데이터베이스 사용\nB. 다중 AZ와 하나 이상의 예비 복제본이 있는 Amazon RDS의 데이터베이스 사용\nC. 서로 다른 AWS 리전의 여러 Amazon EC2 인스턴스에서 호스팅되는 데이터베이스 사용\nD. Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 호스팅되는 데이터베이스를 서로 다른 가용 영역 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사의 프로덕션 애플리케이션이 OLTP(온라인 트랜잭션 처리) 트랜잭션을 실행합니다. Amazon RDS MySQL DB 인스턴스에서 회사는 새로운 보고 도구를 출시합니다. 동일한 데이터에 액세스 보고 도구는 가용성이 높아야 하며 성능에 영향을 미치지 않아야 합니다. 생산 응용 프로그램. 어떻게 달성할 수 있습니까?\nA. 프로덕션 RDS DB 인스턴스의 시간별 스냅샷 생성\nB. 프로덕션 RDS DB 인스턴스의 다중 AZ RDS 읽기 전용 복제본 생성\nC. 프로덕션 RDS DB 인스턴스의 여러 RDS 읽기 전용 복제본 생성 Auto Scaling 그룹\nD. 프로덕션 RDS DB 인스턴스의 단일 AZ RDS 읽기 전용 복제본 생성 두 번째 단일 AZ 생성 복제본의 RDS 읽기 전용 복제본 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 us-east-1의 Amazon S3 버킷에서 정적 웹 사이트 콘텐츠를 호스팅합니다. 지역. 해당 버킷을 가리키는 Amazon CloudFront 오리진을 통해 콘텐츠를 사용할 수 있습니다. 교차 리전 복제는 ap-southeast-1 리전에 버킷의 두 번째 복사본을 생성하도록 설정됩니다. 경영진은 웹사이트에 더 많은 가용성을 제공하는 솔루션을 원합니다. 솔루션 설계자는 가용성을 높이기 위해 어떤 조합의 조치를 취해야 합니까? (2개를 선택하십시오.)\nA. 두 버킷을 CloudFront 오리진에 추가\nB. Amazon Route 53에서 장애 조치 라우팅 구성\nC. 복제본 버킷을 가리키는 Amazon Route 53에 레코드 생성\nD. ap-southeast-1 버킷을 가리키는 추가 CloudFront 오리진 생성\nE. us-east-1 버킷을 기본 버킷으로, ap-southeast-1 버킷을 사용하여 CloudFront 오리진 그룹을 설정합니다. 버킷을 보조로 정답 풀이\r...\r답변: DE\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 Amazon EC2 인스턴스에서 실행될 웹 애플리케이션을 설계하고 있습니다. ALB(Application Load Balancer) 뒤에 있는 회사는 애플리케이션이 악의적인 인터넷 활동 및 공격에 대해 탄력적이며 새로운 공통 취약점 및 노출 솔루션 설계자는 무엇을 권장해야 합니까?\nA. ALB 엔드포인트를 오리진으로 사용하여 Amazon CloudFront 활용\nB. AWS WAF에 적절한 관리형 규칙을 배포하고 ALB와 연결합니다.\nC. AWS Shield Advanced에 가입하고 일반적인 취약점 및 노출을 차단합니다.\nD. 포트 80 및 443만 EC2에 액세스할 수 있도록 네트워크 ACL 및 보안 그룹 구성 인스턴스 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 여러 웹사이트에서 클릭스트림 데이터를 캡처하고 배치를 사용하여 분석합니다. 처리. 데이터는 매일 밤 Amazon Redshift에 로드되며 비즈니스 분석가가 사용합니다. 이 회사는 적시에 통찰력을 얻기 위해 거의 실시간으로 데이터를 처리하기를 원합니다. 해결책 최소한의 노력과 운영 오버헤드로 스트리밍 데이터를 처리해야 합니다. 이 솔루션에 가장 비용 효율적인 AWS 서비스 조합은 무엇입니까? (2개를 선택하세요.)\nA. 아마존 EC2\nB. AWS 람다\nC. Amazon Kinesis 데이터 스트림\nD. Amazon Kinesis Data Firehose\nE. Amazon Kinesis 데이터 분석 정답 풀이\r...\r답변: DE\r#\r설명 Kinesis Data Streams 및 Kinesis Client Library(KCL) - 데이터 소스의 데이터는 지속적으로 Kinesis Data Streams를 사용하여 거의 실시간으로 캡처 및 스트리밍됩니다. Kinesis Client Library(KCL)를 사용하여 사전 처리할 수 있는 자체 애플리케이션을 구축할 수 있습니다. 스트리밍 데이터가 도착하면 증분 보기 및 다운스트림 생성을 위한 데이터 방출 분석. Kinesis Data Analytics - 이 서비스는 스트리밍 중인 데이터를 처리하는 가장 쉬운 방법을 제공합니다. Kinesis Data Stream 또는 SQL을 사용하는 Kinesis Data Firehose를 통해. 이를 통해 고객은 Amazon S3에 저장하기 전에 증분 ​​스트림에서 거의 실시간으로 실행 가능한 통찰력.\nhttps://d1.awsstatic.com/whitepapers/lambda-architecure-on-for-batch-aws.pdf\n#\r#\r질문\r#\rquestion 회사에는 내부적으로 공유해야 하는 미디어 및 응용 프로그램 파일이 있습니다. 현재 사용자 Active Directory를 사용하여 인증되고 Microsoft Windows 플랫폼에서 파일에 액세스합니다. NS 최고 집행 책임자(CEO)는 동일한 사용자 권한을 유지하기를 원하지만 회사가 개선하기를 원합니다. 회사가 스토리지 용량 한계에 도달함에 따라 프로세스. 솔루션 아키텍트는 무엇을 추천해야 합니까?\nA. 기업 Amazon S3 버킷을 설정하고 미디어 및 애플리케이션 파일을 이동합니다.\nB. Windows 파일 서버용 Amazon FSx를 구성하고 모든 미디어 및 애플리케이션 파일을 이동합니다.\nC. Amazon Elastic File System(Amazon EFS)을 구성하고 모든 미디어 및 애플리케이션 파일을 이동합니다.\nD. Windows에서 Amazon EC2 설정, 여러 Amazon Elastic Block Store(Amazon EBS) 연결 볼륨 및 모든 미디어 및 응용 프로그램 파일을 이동합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사의 패키지 응용 프로그램은 일회용 텍스트 파일을 동적으로 생성하고 반환합니다. 사용자 요청에 대한 응답. 회사는 배포를 위해 Amazon CloudFront를 사용하고 있지만 미래에는 데이터 전송 비용을 줄일 수 있습니다. 회사는 응용 프로그램의 소스 코드를 수정합니다. 솔루션 설계자는 비용을 줄이기 위해 무엇을 해야 합니까?\nA. Lambda 격언을 사용하여 사용자에게 전송되는 파일을 압축합니다.\nB. 응답 시간을 줄이려면 Amazon S3 Transfer Acceleration을 활성화합니다.\nC. CloudFront 배포에서 캐싱을 활성화하여 엣지에 생성된 파일을 저장합니다.\nD. Amazon S3 멀티파트 업로드를 사용하여 파일을 사용자에게 반환하기 전에 Amazon S3로 이동합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에 150TB의 보관된 이미지 데이터가 온프레미스에 저장되어 있어 잘라야 합니다. 다음 달 내에 AWS 클라우드로 회사의 현재 네트워크 연결은 최대 이 목적을 위해 밤에만 100Mbps를 업로드합니다. 이 데이터를 이동하고 마이그레이션 기한을 맞추기 위한 가장 비용 효율적인 메커니즘은 무엇입니까?\nA. AWS Snowmobile을 사용하여 데이터를 AWS로 전송합니다.\nB. 여러 AWS Snowball 디바이스를 주문하여 데이터를 AWS로 배송합니다.\nC. Amazon S3 Transfer Acceleration을 활성화하고 데이터를 안전하게 업로드합니다.\nD. Amazon S3 VPC 엔드포인트를 생성하고 VPN을 설정하여 데이터를 업로드합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사가 AWS 클라우드로 마이그레이션하고 있습니다. 파일 서버는 마이그레이션할 첫 번째 워크로드입니다. 사용자는 SMB(서버 메시지 블록) 프로토콜을 사용하여 파일 공유에 액세스할 수 있어야 합니다. 어느 AWS 관리형 서비스가 이러한 요구 사항을 충족합니까?\nA. 아마존 EBS\nB. 아마존 EC2\nC. 아마존 FSx\nD. 아마존 S3 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 Amazon S3를 사용하여 새로운 디지털 스토리지 아키텍처를 설계하고 있습니다. 미디어 응용 프로그램. 미디어 파일은 가용 영역 손실에 대한 복원력이 있어야 합니다. 일부 파일은 자주 액세스됩니다. 반면 다른 파일은 예측할 수 없는 패턴으로 거의 액세스되지 않습니다. 솔루션 아키텍트는 미디어 파일을 저장하고 검색하는 비용을 최소화합니다. 이러한 요구 사항을 충족하는 스토리지 옵션은 무엇입니까?\nA. S3 표준\nB. S3 지능형 계층화\nC. S3 Standard-Infrequent Access {S3 Standard-IA)\nD. S3 One Zone-Infrequent Access(S3 One Zone-IA) 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사에 VPC의 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. 중 하나 애플리케이션은 Amazon S3 API를 호출하여 객체를 저장하고 읽어야 합니다. 회사의 보안 정책은 응용 프로그램의 인터넷 바인딩 트래픽을 제한합니다. 이러한 요구 사항을 충족하고 보안을 유지하는 작업은 무엇입니까?\nA. S3 인터페이스 끝점을 구성합니다.\nB. S3 게이트웨이 엔드포인트를 구성합니다.\nC. 프라이빗 서브넷에 S3 버킷을 생성합니다.\nD. EC2 인스턴스와 동일한 리전에 S3 버킷을 생성합니다. 정답 풀이\r...\r답: B\r#\r설명 VPC 엔드포인트 VPC 엔드포인트를 사용하면 VPC를 지원되는 AWS 서비스 및 VPC에 비공개로 연결할 수 있습니다. 인터넷 게이트웨이, NAT 장치, VPN 연결 또는 AWS Direct Connect 연결. VPC의 인스턴스에는 공개 IP가 필요하지 않습니다. 서비스의 리소스와 통신하기 위한 주소입니다. VPC와 다른 VPC 간의 트래픽 서비스는 Amazon 네트워크를 떠나지 않습니다. 인터페이스 끝점은 IP 주소의 개인 IP 주소가 있는 탄력적 네트워크 인터페이스입니다. 지원되는 서비스로 향하는 트래픽의 진입점 역할을 하는 서브넷 범위. 인터페이스 엔드포인트는 비공개로 사설 IP 주소를 사용하여 서비스에 액세스합니다. AWS PrivateLink는 다음 사이의 모든 네트워크 트래픽을 제한합니다. Amazon 네트워크에 대한 VPC 및 서비스. 인터넷 게이트웨이, NAT 장치가 필요하지 않으며, 또는 가상 프라이빗 게이트웨이. https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html\n#\r#\r질문\r#\rquestion 한 회사가 AWS에서 새로운 웹 애플리케이션을 구축할 계획입니다. 회사는 기대한다 연중 대부분의 예측 가능한 교통량과 때때로 매우 높은 교통량. 웹 애플리케이션은 다음과 같아야 합니다. 최소한의 대기 시간으로 고가용성 및 내결함성. 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?\nA. Amazon Route 53 라우팅 정책을 사용하여 요청을 2개의 AWS 리전으로 분산합니다. Amazon EC2 인스턴스.\nB. Application Load Balancer가 있는 Auto Scaling 그룹의 Amazon EC2 인스턴스 사용 여러 가용 영역.\nC. 클러스터 배치 그룹에서 Application Load Balancer가 있는 Amazon EC2 인스턴스 사용 여러 가용 영역.\nD. 클러스터 배치 그룹에서 Amazon EC2 인스턴스를 사용하고 클러스터 배치 그룹을 포함합니다. 새로운 Auto Scaling 그룹 내에서 정답 풀이\r...\r답: B\r#\r많은 AZ를 지원하지 않습니다. #\r#\r질문\r#\rquestion 회사가 다른 지역에서 해당 환경의 격리된 백업을 생성했습니다. NS 애플리케이션이 웜 대기 모드에서 실행 중이고 ALB(Application Load Balancer)가 앞에 있습니다. 현재 장애 조치 프로세스는 수동이며 다음을 가리키도록 DNS 별칭 레코드를 업데이트해야 합니다. 다른 지역의 보조 ALB. 솔루션 설계자는 장애 조치 프로세스를 자동화하기 위해 무엇을 해야 합니까?\nA. ALB 상태 확인 활성화\nB. Amazon Route 53 상태 확인을 활성화합니다.\nC. ALB 엔드포인트를 가리키는 Amazon Route 53에서 CNAME 레코드를 생성합니다.\nD. 내부 BIND DNS 서버를 가리키는 Amazon Route 53에서 조건부 전달 규칙을 생성합니다. 정답 풀이\r...\r답: B\r#\rALB는 지역에서 확장할 수 있습니다. #\r#\r질문\r#\rquestion 솔루션 설계자가 여러 Amazon EC2 인스턴스에 분산 데이터베이스를 배포하고 있습니다. 데이터베이스는 인스턴스 손실을 견딜 수 있도록 여러 인스턴스에 모든 데이터를 저장합니다. 데이터베이스에는 수백만 개의 트랜잭션을 지원하기 위해 대기 시간과 처리량이 있는 블록 스토리지가 필요합니다. 초당 서버당 솔루션 설계자가 사용해야 하는 스토리지 솔루션은 무엇입니까?\nA. 아마존 EBS\nB. Amazon EC2 인스턴스 스토어\nC. 아마존 EFS\nD. 아마존 S3 정답 풀이\r...\r답: B\r#\r설명 https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/InstanceStorage.html\n#\r#\r질문\r#\rquestion 솔루션 설계자는 퍼블릭 및 프라이빗 서브넷이 있는 VPC를 설계하고 있습니다. VPC와 서브넷은 IPv4 CIDR 블록을 사용합니다. 세 개의 각각에 하나의 퍼블릭 서브넷과 하나의 프라이빗 서브넷이 있습니다. 고가용성을 위한 가용 영역(AZ). 인턴! 게이트웨이는 인터넷 액세스를 제공하는 데 사용됩니다. 공개 서브넷. Amazon EC2 인스턴스를 허용하려면 프라이빗 서브넷이 인터넷에 액세스해야 합니다. 소프트웨어 업데이트를 다운로드합니다. 솔루션 설계자는 인터넷 액세스를 위해 무엇을 해야 합니까? 프라이빗 서브넷?\nA. 각 AZ의 각 퍼블릭 서브넷에 대해 하나씩 3개의 NAT 게이트웨이를 생성합니다. 에 대한 프라이빗 라우팅 테이블 생성 비 VPC 트래픽을 해당 AZ의 NAT 게이트웨이로 전달하는 각 AZ B. 각 AZ의 프라이빗 서브넷마다 하나씩 3개의 NAT 인스턴스를 생성합니다. 프라이빗 라우팅 테이블 생성 비 VPC 트래픽을 해당 AZ의 NAT 인스턴스로 전달하는 각 AZ에 대해 C. 프라이빗 서브넷 중 하나에 두 번째 인터넷 게이트웨이를 생성합니다. 에 대한 라우팅 테이블 업데이트 VPC가 아닌 트래픽을 프라이빗 인터넷 게이트웨이로 전달하는 프라이빗 서브넷 D. 퍼블릭 서브넷 중 하나에 송신 전용 인터넷 게이트웨이를 생성합니다. 에 대한 라우팅 테이블 업데이트 외부 전용 인터넷 게이트웨이로 비 VPC 트래픽을 전달하는 프라이빗 서브넷 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자가 Amazon API Gateway 뒤에 새로운 서비스를 설계하고 있습니다. 서비스 패턴은 예측할 수 없으며 0개 요청에서 500개 이상으로 갑자기 변경될 수 있습니다. 초당 백엔드 데이터베이스에 유지되어야 하는 데이터의 총 크기는 현재 예측할 수 없는 미래 성장으로 1GB 미만 단순한 키-값 요청을 사용하여 데이터를 쿼리할 수 있음 이러한 요구 사항을 충족하는 AWS 서비스 조합은 무엇입니까? (2개 선택)\nA. AWS Fargate B. AWS 람다 C. Amazon DynamoDB D. Amazon EC2 Auto Scaling E. MySQL 호환 Amazon Aurora 정답 풀이\r...\r답변: BC\r#\r설명 https://aws.amazon.com/about-aws/whats-new/2017/11/amazon-api-gateway-supports-endpointintegrations-wit\n#\r#\r질문\r#\rquestion 전자 상거래 회사는 AWS에서 다중 계층 애플리케이션을 실행하고 있습니다. 프론트엔드와 백엔드 계층은 모두 Amazon EC2에서 실행됩니다. 데이터베이스는 MySQL용 Amazon RDS에서 실행됩니다. NS 백엔드 계층은 RDS 인스턴스와 통신합니다. 동일하게 반환하라는 호출이 자주 있습니다. 성능 저하를 일으키는 데이터베이스의 데이터 세트. 백엔드의 성능을 향상시키려면 어떤 조치를 취해야 합니까?\nA. Amazon SNS를 구현하여 데이터베이스 호출을 저장합니다. B. Amazon ElastiCache를 구현하여 대규모 데이터 세트를 캐시합니다. C. RDS for MySQL 읽기 전용 복제본을 구현하여 데이터베이스 호출을 캐시합니다. D. Amazon Kinesis Data Firehose를 구현하여 데이터베이스에 대한 호출을 스트리밍합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자가 새 AWS 계정을 생성했으며 AWS 계정 루트를 보호해야 합니다. 사용자 액세스 이 작업을 수행할 작업 조합은 무엇입니까? (2개를 선택하십시오.)\nA. 루트 사용자가 강력한 암호를 사용하는지 확인하십시오.\nB. 루트 사용자에 대한 다단계 인증 활성화\nC. 암호화된 Amazon S3 버킷에 루트 사용자 액세스 키 저장\nD. 관리 권한이 포함된 그룹에 루트 사용자를 추가합니다.\nE. 인라인 정책 문서를 사용하여 루트 사용자에게 필요한 권한을 적용합니다. 정답 풀이\r...\r답: AB\r#\r#\r#\r질문\r#\rquestion 전자 상거래 웹 사이트는 웹 애플리케이션을 Amazon Elastic Container Service로 배포하고 있습니다. ALB(Application Load Balancer) 뒤에 있는 (Amazon ECS) 컨테이너 인스턴스. 높은 기간 동안 활동이 없으면 웹 사이트가 느려지고 가용성이 감소합니다. Amazon을 사용하는 솔루션 아키텍트 가용성 문제가 있을 때마다 알림을 수신하여 확장할 수 있도록 CloudWatch 경보 리소스를 아웃. 회사 경영진은 이러한 이벤트에 자동으로 대응하는 솔루션을 원합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. ALB 설정에 시간 초과가 있을 때 ECS 서비스를 확장하도록 AWS Auto Scaling을 설정합니다. CPU 또는 메모리 예약이 너무 높을 때 ECS 클러스터를 확장하는 AWS Auto Scaling.\nB. ALB CPU 사용률이 너무 높을 때 ECS 서비스를 확장하도록 AWS Auto Scaling을 설정합니다. 세트 CPU 또는 메모리 예약이 너무 높을 때 AWS Auto Scaling을 확장하여 ECS 클러스터를 확장합니다.\nC. 서비스의 CPU 사용률이 너무 높을 때 ECS 서비스를 확장하도록 AWS Auto Scaling을 설정합니다. CPU 또는 메모리 예약이 너무 많은 경우 ECS 클러스터를 확장하도록 AWS Auto Scaling 설정 높은.\nD. ALB 대상 그룹 CPU 사용률이 다음과 같을 때 ECS 서비스를 확장하도록 AWS Auto Scaling을 설정합니다. 너무 높은. CPU 또는 메모리 예약 시 ECS 클러스터를 확장하도록 AWS Auto Scaling 설정 너무 높습니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에 AWS로 마이그레이션해야 하는 Microsoft Windows 기반 애플리케이션이 있습니다. 이것 애플리케이션은 여러 Amazon EC2에 연결된 공유 Windows 파일 시스템을 사용해야 합니다. Windows 인스턴스. 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. Amazon EFS를 사용하여 볼륨 구성 각 Windows 인스턴스에 EPS 볼륨 탑재\nB. 볼륨 게이트웨이 모드에서 AWS Storage Gateway 구성 각 Windows에 볼륨 마운트 사례\nC. Windows 파일 서버용 Amazon FSx 구성 각 Windows에 Amazon FSx 볼륨 탑재 사례\nD. 필요한 크기로 Amazon EBS 볼륨 구성 각 EC2 인스턴스를 볼륨에 연결 볼륨 내의 파일 시스템을 각 Windows 인스턴스에 마운트 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 최근에 만든 스타트업이 3계층 웹 애플리케이션을 구축했습니다. 프런트 엔드에는 정적 콘텐츠. 애플리케이션 계층은 마이크로서비스를 기반으로 합니다. 사용자 데이터는 다음과 같은 JSON 문서로 저장됩니다. 낮은 대기 시간으로 액세스해야 합니다. 회사는 첫 번째 기간 동안 일반 트래픽이 낮을 것으로 예상합니다. 매달 새로운 기능을 공개할 때 트래픽이 최고조에 달합니다. 스타트업 팀이 필요로 하는 운영 간접비를 최소화합니다. 솔루션 설계자는 이를 달성하기 위해 무엇을 권장해야 합니까?\nA. Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드 저장 및 서비스 AWS Elastic Beanstalk 사용 애플리케이션 레이어용. Amazon DynamoDB를 사용하여 사용자 데이터를 저장합니다. B. Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드를 저장하고 제공합니다. Amazon Elastic 사용 애플리케이션 계층을 위한 Kubernetes Service(Amazon EKS). Amazon DynamoDB를 사용하여 사용자 저장 데이터. C. Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드를 저장하고 제공합니다. Amazon API 게이트웨이 사용 및 애플리케이션 계층을 위한 AWS Lambda 함수 Amazon DynamoDB를 사용하여 사용자 데이터를 저장합니다. D. Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드를 저장하고 제공합니다. Amazon API 게이트웨이 사용 및 애플리케이션 계층을 위한 AWS Lambda 함수. 읽기 전용 복제본과 함께 Amazon RDS를 사용하여 저장 사용자 데이터. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 30일 이내에 데이터 센터에서 AWS 클라우드로 20TB의 데이터를 마이그레이션해야 합니다. 회사의 네트워크 대역폭은 15Mbps로 제한되며 사용률이 70%를 초과할 수 없습니다. 뭐 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 수행해야 합니까?\nA. AWS Snowball을 사용합니다.\nB. AWS DataSync를 사용합니다.\nC. 보안 VPN 연결을 사용합니다.\nD. Amazon S3 Transfer Acceleration을 사용합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 온프레미스에서 건강 기록을 관리하고 있습니다. 회사는 이러한 기록을 보관해야 합니다. 무기한, 레코드가 저장되면 수정 사항을 비활성화하고 세부적으로 감사 모든 수준에서 액세스할 수 있습니다. 최고 기술 책임자(CTO)는 이미 수백만 명의 어떤 애플리케이션에서도 사용되지 않는 레코드의 비율, 현재 인프라에 공간이 부족합니다. CTO는 솔루션 설계자에게 기존 데이터를 이동하고 지원하는 솔루션을 설계하도록 요청했습니다. 향후 기록 이러한 요구 사항을 충족하기 위해 솔루션 설계자가 추천할 수 있는 서비스는 무엇입니까?\nA. AWS DataSync를 사용하여 기존 데이터를 AWS로 이동합니다. Amazon S3를 사용하여 기존 및 새 데이터 저장 Amazon S3 객체 잠금을 활성화하고 데이터 이벤트로 AWS CloudTrail을 활성화합니다.\nB. AWS Storage Gateway를 사용하여 기존 데이터를 AWS로 이동 Amazon S3를 사용하여 기존 및 신규 데이터 저장 데이터. Amazon S3 객체 잠금을 활성화하고 관리 이벤트로 AWS CloudTrail을 활성화합니다.\nC. AWS DataSync를 사용하여 기존 데이터를 AWS로 이동 Amazon S3를 사용하여 기존 및 새 데이터 저장 Amazon S3 객체 잠금을 활성화하고 관리 이벤트로 AWS CloudTrail을 활성화합니다.\nD. AWS Storage Gateway를 사용하여 기존 데이터를 AWS로 이동 Amazon Elastic Block Store(Amazon EBS) 기존 및 새 데이터 저장 Amazon S3 객체 잠금 활성화 및 Amazon S3 서버 활성화 액세스 로깅 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 미션 크리티컬 웹 애플리케이션을 설계하고 있습니다. 아마존으로 구성됩니다. Application Load Balancer 및 관계형 데이터베이스 뒤에 있는 EC2 인스턴스. 데이터베이스는 다음과 같아야 합니다. 고가용성 및 내결함성. 이러한 요구 사항을 충족하는 데이터베이스 구현은 무엇입니까? (2개를 선택하십시오.)\nA. 아마존 레드시프트 B. Amazon DynamoDB C. MySQL용 Amazon RDS D. MySQL 호환 Amazon Aurora 다중 AZ E. SQL Server Standard Edition Mufti-AZ용 Amazon RDS 정답 풀이\r...\r답변: DE\r#\r#\r#\r질문\r#\rquestion 회사는 최근 3계층 애플리케이션을 VPC로 마이그레이션하는 것을 검토하고 있습니다. 보안 팀이 최소 권한 원칙이 Amazon EC2 보안 그룹에 적용되지 않는다는 사실을 발견했습니다. 애플리케이션 계층 간의 수신 및 송신 규칙. 솔루션 설계자는 이 문제를 해결하기 위해 무엇을 해야 합니까?\nA. 인스턴스 ID를 원본 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다.\nB. 보안 그룹 ID를 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다.\nC. VPC CIDR 블록을 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다.\nD. 서브넷 CIDR 블록을 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon EC2에서 전자 상거래 애플리케이션을 실행하고 있습니다. 애플리케이션은 다음으로 구성됩니다. 지원하기 위해 최소 10개의 인스턴스와 최대 250개의 인스턴스가 필요한 상태 비저장 웹 계층 애플리케이션의 사용량 애플리케이션에 50개의 인스턴스가 필요합니다. 시간의 80% 어떤 솔루션이 필요합니까? 비용을 최소화하는 데 사용됩니까?\nA. 250개의 인스턴스를 포함하는 예약 인스턴스 구매\nB. 예약 인스턴스를 구매하여 80개의 인스턴스를 처리합니다. 나머지를 처리하려면 스팟 인스턴스를 사용합니다. 인스턴스\nC. 온디맨드 인스턴스를 구매하여 40개 인스턴스를 처리합니다. 나머지를 처리하려면 스팟 인스턴스를 사용합니다. 인스턴스\nD. 예약 인스턴스를 구매하여 50개의 인스턴스를 커버하기 위해 온디맨드 및 스팟 인스턴스를 사용합니다. 나머지 인스턴스 정답 풀이\r...\r답변: D\r#\r설명 예약 인스턴스 50개의 EC2 RI가 있으면 할인된 시간당 요금과 EC2에 대한 선택적 용량 예약을 제공합니다. 인스턴스. AWS Billing은 EC2 인스턴스 사용의 속성이 다음과 같을 때 RI의 할인 요금을 자동으로 적용합니다. 활성 RI의 속성과 일치합니다. 가용 영역이 지정된 경우 EC2는 RI의 속성과 일치하는 용량을 예약합니다. NS RI의 용량 예약은 이러한 속성과 일치하는 인스턴스를 실행하여 자동으로 활용됩니다. 또한 용량 예약을 포기하고 지역 범위가 지정된 RI를 구매할 수도 있습니다. 리전으로 범위가 지정된 RI는 AZ 및 AZ 전체의 인스턴스 사용량에 RI 할인을 자동으로 적용합니다. 리전의 인스턴스 크기를 조정하여 RI의 할인된 요금을 더 쉽게 활용할 수 있습니다. 온디맨드 인스턴스 온디맨드 인스턴스를 사용하면 컴퓨팅 용량에 대해 시간 또는 초 단위로 비용을 지불할 수 있습니다(최소 60 초) 장기 약정이 없습니다. 이를 통해 비용과 복잡성에서 벗어날 수 있습니다. 하드웨어를 계획, 구매 및 유지 관리하고 일반적으로 큰 고정 비용을 변환합니다. 훨씬 더 작은 가변 비용으로. 아래 가격에는 지정된 운영 체제에서 프라이빗 및 퍼블릭 AMI를 실행하는 비용이 포함됩니다.\n100 (\u0026ldquo;Windows 사용량\u0026rdquo; 가격은 Windows Server 2003 R2, 2008, 2008 R2, 2012, 2012 R2, 2016 및 2019). Amazon은 Microsoft를 실행하는 Amazon EC2용 추가 인스턴스도 제공합니다. SQL Server가 설치된 Windows, SUSE Linux Enterprise Server를 실행하는 Amazon EC2, 실행 중인 Amazon EC2 Red Hat Enterprise Linux 및 IBM을 실행하는 Amazon EC2는 가격이 다릅니다. 스팟 인스턴스 스팟 인스턴스는 온디맨드 가격보다 저렴하게 사용할 수 있는 미사용 EC2 인스턴스입니다. 스팟 인스턴스를 사용하면 사용하지 않은 EC2 인스턴스를 대폭 할인된 가격으로 요청할 수 있으므로 다음을 수행할 수 있습니다. Amazon EC2 비용을 크게 낮출 수 있습니다. 스팟 인스턴스의 시간당 가격을 스팟 가격이라고 합니다. 각 가용 영역에 있는 각 인스턴스 유형의 스팟 가격은 Amazon EC2에서 설정하고 조정됩니다. 스팟 인스턴스에 대한 장기적인 수요와 공급을 기반으로 점차적으로. 스팟 인스턴스 실행 용량이 사용 가능하고 요청에 대한 시간당 최고 가격이 스팟을 초과할 때마다 가격. https://aws.amazon.com/ec2/pricing/reserved-instances/ https://aws.amazon.com/ec2/pricing/on-demand/ https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/using-spot-instances.html\n#\r#\r질문\r#\rquestion 솔루션 아키텍트가 다가오는 뮤지컬 이벤트를 위해 웹사이트를 최적화하고 있습니다. 공연은 실시간으로 스트리밍되며 주문형으로 제공됩니다. 전 세계 온라인 청중을 유치할 것으로 예상되는 서비스 실시간 및 주문형 스트리밍?\nA. 아마존 클라우드프론트\nB. AWS 글로벌 액셀러레이터\nC. 아마존 루트 53\nD. Amazon S3 전송 가속화 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에서 내부 브라우저 기반 애플리케이션을 실행합니다. 애플리케이션이 Amazon EC2에서 실행됩니다. Application Load Balancer 뒤에 있는 인스턴스 Amazon EC2 Auto Scaling에서 실행되는 인스턴스 여러 가용 영역에 걸친 그룹 Auto Scaling 그룹은 작업 중에 최대 20개의 인스턴스를 확장합니다. 몇 시간이지만 밤새 2개의 인스턴스로 축소됩니다. 직원들은 애플리케이션이 매우 느리다고 불평합니다. 하루가 시작되면 오전 중반까지 잘 실행됩니다. 직원 불만을 해결하고 비용을 최소화하려면 규모를 어떻게 변경해야 합니까?\nA. 사무실이 열리기 직전에 원하는 용량을 20으로 설정하는 예약된 작업을 구현합니다.\nB. 더 낮은 CPU 임계값에서 트리거되는 단계 조정 작업을 구현하고 쿨다운을 줄입니다. 기간.\nC. 더 낮은 CPU 임계값에서 트리거된 대상 추적 작업을 구현하고 쿨다운을 줄입니다. 기간\nD. 직전에 최소 및 최대 용량을 20으로 설정하는 예정된 작업을 구현합니다. 사무실이 열립니다 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에서 개발자를 지원하기 위해 확장 가능한 키 관리 인프라를 구축하려고 합니다. 애플리케이션에서 데이터를 암호화해야 하는 사용자 솔루션 아키텍트는 운영 부담?\nA. 다단계 인증(MFA)을 사용하여 암호화 키 보호 B. AWS Key Management Service(AWS KMS)를 사용하여 암호화 키 보호 C. AWS Certificate Manager(ACM)를 사용하여 암호화 키 생성, 저장 및 할당 D. IAM 정책을 사용하여 보호할 액세스 권한이 있는 사용자의 범위를 제한합니다. 암호화 키 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon EC2 인스턴스 집합에서 프로덕션 애플리케이션을 실행합니다. 애플리케이션은 Amazon SQS 대기열에서 데이터를 읽고 메시지를 병렬로 처리합니다. NS 메시지 볼륨은 예측할 수 없으며 종종 간헐적인 트래픽이 발생합니다. 이 응용 프로그램은 다운타임 없이 메시지를 지속적으로 처리 이러한 요구 사항을 충족하는 솔루션 가장 비용 효율적으로?\nA. 스팟 인스턴스를 독점적으로 사용하여 필요한 최대 용량을 처리합니다. B. 예약 인스턴스를 독점적으로 사용하여 필요한 최대 용량 처리 C. 기준 용량에는 예약 인스턴스를 사용하고 추가 처리에는 스팟 인스턴스를 사용합니다. 용량 D. 기준 용량에 대해 예약 인스턴스를 사용하고 온디맨드 인스턴스를 사용하여 처리합니다. 추가 용량 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 고가용성 배스천 호스트 아키텍처를 만들어야 합니다. 해결책 단일 AWS 리전 내에서 복원력이 있어야 하며 유지 관리에 최소한의 노력만 필요합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?\nA. UDP 리스너를 사용하여 Auto Scaling 그룹에서 지원하는 Network Load Balancer를 생성합니다. B. 인스턴스가 있는 그룹의 인스턴스가 있는 스팟 집합에서 지원하는 Network Load Balancer 생성 파티션 배치 그룹. C. 다른 가용 영역의 기존 서비스가 지원하는 네트워크 로드 밸런서를 생성합니다. 표적. D. 여러 가용성의 인스턴스를 사용하여 Auto Scaling에서 지원하는 Network Load Balancer 생성 영역을 대상으로 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 개발 팀은 다른 팀이 액세스할 웹사이트를 호스팅해야 합니다. NS 웹사이트 콘텐츠는 HTML, CSS, 클라이언트 측 JavaScript 및 이미지로 구성됩니다. 웹 사이트 호스팅에 가장 비용 효율적인 방법은 무엇입니까?\nA. 웹 사이트를 컨테이너화하고 AWS Fargate에서 호스팅\nB. Amazon S3 버킷을 생성하고 거기에서 웹 사이트를 호스팅합니다.\nC. Amazon EC2 인스턴스에 웹 서버를 배포하여 웹 사이트를 호스팅합니다.\nD. Express를 사용하는 AWS Lambda 대상으로 Application Load Balancer를 구성하는 것은 다음과 같습니다. 뼈대 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion Amazon S3의 웹사이트. 웹사이트는 매월 페타바이트 규모의 아웃바운드 트래픽을 제공하며, 회사 AWS 비용의 대부분을 차지합니다. 솔루션 설계자는 비용을 줄이기 위해 무엇을 해야 합니까?\nA. 기존 웹 사이트를 오리진으로 사용하여 Amazon CloudFront를 구성합니다.\nB. 웹사이트를 Amazon EBS 볼륨이 있는 Amazon EC2로 이동하여 저장합니다.\nC. AWS Global Accelerator를 사용하고 기존 웹 사이트를 엔드포인트로 지정합니다.\nD. Amazon API Gateway와 AWS Lambda의 조합에서 실행되도록 웹 사이트를 재설계합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 공개 웹 애플리케이션은 Amazon EC2 인스턴스에 호스팅된 데이터베이스를 쿼리합니다. 프라이빗 서브넷. 많은 수의 쿼리에는 여러 테이블 조인이 포함되며 응용 프로그램은 복잡한 쿼리의 증가로 인해 성능이 저하되었습니다. 신청팀은 성능 향상을 위해 업데이트를 수행합니다. 솔루션 설계자는 애플리케이션 팀에 무엇을 권장해야 합니까? (2개를 선택하십시오.)\nA. Amazon SQS의 쿼리 데이터 캐시 B. 쿼리 오프로드를 위한 읽기 전용 복제본 생성 C. 데이터베이스를 Amazon Athena로 마이그레이션 D. 데이터를 캐시하기 위해 Amazon DynamoDB Accelerator를 구현합니다. E. 데이터베이스를 Amazon RDS로 마이그레이션 정답 풀이\r...\r답: BE\r#\rBE\n#\r#\r질문\r#\rquestion 솔루션 설계자는 Amazon EC2에서 Amazon DynamoDB에 대한 API 호출을 확인해야 합니다. VPC의 인스턴스는 인터넷을 통과하지 않습니다. 솔루션 아키텍트가 수행해야 하는 작업 이것? (2개 선택)\nA. 엔드포인트에 대한 라우팅 테이블 항목 생성 B. DynamoDB용 게이트웨이 엔드포인트 생성 C. 엔드포인트를 사용하는 새 DynamoDB 테이블 생성 D. VPC의 각 서브넷에서 엔드포인트에 대한 ENI 생성 E. 기본 보안 그룹에 보안 그룹 항목을 생성하여 액세스 제공 정답 풀이\r...\r답: AB\r#\r설명 VPC 엔드포인트를 사용하면 VPC를 지원되는 AWS 서비스 및 VPC에 비공개로 연결할 수 있습니다. 인터넷 게이트웨이, NAT 장치, VPN 연결 또는 AWS Direct Connect 연결. VPC의 인스턴스에는 공개 IP가 필요하지 않습니다. 서비스의 리소스와 통신하기 위한 주소입니다. VPC와 다른 VPC 간의 트래픽 서비스는 Amazon 네트워크를 떠나지 않습니다. 게이트웨이 엔드포인트 게이트웨이 엔드포인트는 트래픽에 대한 라우팅 테이블에서 경로의 대상으로 지정하는 게이트웨이입니다. 지원되는 AWS 서비스를 대상으로 합니다. 다음 AWS 서비스가 지원됩니다. 아마존 S3 다이나모DB https://docs.aws.amazon.com/vpc/latest/userguide/vpc-endpoints.html\n#\r#\r질문\r#\rquestion 회사에는 다음이 필요한 온프레미스에서 실행되는 대규모 Microsoft SharePoint 배포가 있습니다. Microsoft Windows 공유 파일 저장소. 회사는 이 워크로드를 AWS로 마이그레이션하려고 합니다. 클라우드 및 다양한 스토리지 옵션을 고려하고 있습니다. 스토리지 솔루션은 가용성이 높아야 하며 액세스 제어를 위해 Active Directory와 통합되었습니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. Amazon EFS 스토리지를 구성하고 인증을 위해 Active Directory 도메인을 설정합니다. B. 두 가용 영역의 AWS Storage Gateway 파일 게이트웨이에 SMB 파일 공유를 생성합니다. C. Amazon S3 버킷을 생성하고 볼륨으로 탑재하도록 Microsoft Windows Server를 구성합니다. D. AWS에서 Windows 파일 서버용 Amazon FSx 파일 시스템 생성 및 Active Directory 설정 인증을 위한 도메인. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사는 AWS에서 OLTP(온라인 트랜잭션 처리) 워크로드를 실행하고 있습니다. 이것 워크로드는 다중 AZ 배포에서 암호화되지 않은 Amazon RDS DB 인스턴스를 사용합니다. 일일 데이터베이스 스냅샷은 이 인스턴스에서 가져옵니다. 데이터베이스 및 스냅샷이 항상 암호화되도록 솔루션 설계자가 수행해야 하는 작업 앞으로 나아가 다?\nA. 최신 DB 스냅샷 사본을 암호화합니다. 암호화된 데이터를 복원하여 기존 DB 인스턴스 교체 스냅 사진. B. 암호화된 Amazon Elastic Block Store(Amazon EBS) 볼륨을 새로 생성하고 스냅샷을 복사합니다. 헐. DB 인스턴스에서 암호화를 활성화합니다. C. 스냅샷을 복사하고 AWS Key Management Service(AWS KMS)를 사용하여 암호화를 활성화합니다. 암호화된 스냅샷을 기존 DB 인스턴스로 복원합니다. D. 다음을 사용하여 서버 측 암호화를 사용하여 암호화된 Amazon S3 버킷에 스냅샷을 복사합니다. AWS Key Management Service(AWS KMS) 관리형 키(SSE-KMS). 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 여러 Amazon EC2 인스턴스를 사용하여 AWS에서 웹 애플리케이션을 호스팅하려는 회사 애플리케이션 콘텐츠는 각 지역에 따라 다르기 때문에 다양한 AWS 리전에서 클라이언트 요청은 해당 클라이언트 리전에 대한 콘텐츠를 호스팅하는 서버로 라우팅되어야 합니다. 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. 지연 시간 라우팅 정책으로 Amazon Route 53을 구성합니다. B. 가중치 기반 라우팅 정책으로 Amazon Route 53을 구성합니다. C. 지리적 위치 라우팅 정책으로 Amazon Route 53 구성 D. 다중값 응답 라우팅 정책으로 Amazon Route 53 구성 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 모바일 게임 회사는 Amazon EC2 인스턴스에서 애플리케이션 서버를 실행합니다. 서버 15분마다 플레이어로부터 업데이트를 받습니다. 모바일 게임은 JSON 객체를 생성합니다. 마지막 업데이트 이후 게임의 진행 상황 및 JSON 개체를 Application Load로 보냅니다. 밸런서. 모바일 게임이 진행되면서 게임 업데이트가 손실됩니다. 회사가 만들고자 하는 오래 된 업데이트를 얻을 수있는 내구성 방법. 솔루션 설계자는 시스템을 분리하기 위해 무엇을 권장해야 합니까?\nA. Amazon Kinesis Data Streams를 사용하여 데이터를 캡처하고 Amazon S3에 JSON 객체를 저장합니다. B. Amazon Kinesis Data Firehose를 사용하여 데이터를 캡처하고 Amazon S3에 JSON 객체를 저장합니다. C. Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 사용하여 데이터 및 EC2 캡처 대기열의 메시지를 처리하기 위한 인스턴스. D. Amazon Simple Notification Service(Amazon SNS)를 사용하여 데이터 및 EC2 인스턴스 캡처 Application Load Balancer로 전송된 메시지를 처리합니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에서 레거시 애플리케이션을 AWS로 마이그레이션할 계획입니다. 현재 신청 NFS를 사용하여 온프레미스 스토리지 솔루션과 통신하여 애플리케이션 데이터를 저장합니다. NS 이를 위해 NFS 이외의 다른 통신 프로토콜을 사용하도록 애플리케이션을 수정할 수 없습니다. 목적. 솔루션 설계자가 마이그레이션 후 사용하도록 권장해야 하는 스토리지 솔루션은 무엇입니까?\nA. AWS 데이터싱크 B. Amazon Elastic Block Store(Amazon EBS) C. Amazon Elastic File System(Amazon EFS) D. Amazon EMR 파일 시스템(Amazon EMRFS) 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자가 Amazon에서 호스팅되는 공개 웹 사이트에서 정적 콘텐츠를 이동하고 있습니다. Amazon S3 버킷에 대한 EC2 인스턴스. Amazon CloudFront 배포는 다음을 제공하는 데 사용됩니다. 정적 자산. EC2 인스턴스에서 사용하는 보안 그룹은 제한된 IP 집합에 대한 액세스를 제한합니다. 범위. 정적 콘텐츠에 대한 액세스도 유사하게 제한되어야 합니다. 이러한 요구 사항을 충족하는 단계 조합은 무엇입니까? (2개를 선택하십시오.)\nA. 오리진 액세스 ID(OAI)를 생성하고 이를 배포와 연결합니다. 변경 OAI만 객체를 읽을 수 있도록 버킷 정책의 권한. B. EC2 보안에 존재하는 것과 동일한 IP 제한을 포함하는 AWS WAF 웹 ACL 생성 그룹. 이 새 웹 ACL을 CloudFront 배포와 연결합니다. C. 현재 EC2에 존재하는 것과 동일한 IP 제한을 포함하는 새 보안 그룹 생성 보안 그룹. 이 새 보안 그룹을 CloudFront 배포와 연결합니다. D. 현재 EC2에 존재하는 것과 동일한 IP 제한을 포함하는 새 보안 그룹 생성 보안 그룹. 이 새 보안 그룹을 정적 콘텐츠를 호스팅하는 S3 버킷과 연결합니다. E. 새 IAM 역할을 생성하고 해당 역할을 배포와 연결합니다. 권한을 변경하거나 새로 생성된 IAM 역할만 읽을 수 있도록 S3 버킷 또는 S3 버킷 내의 파일에서 및 다운로드 권한. 정답 풀이\r...\r답: AB\r#\r#\r#\r질문\r#\rquestion 회사는 .NET 응용 프로그램 서버 및 Windows Server 2016이 설치된 Amazon EC2 인스턴스에서 실행되는 Microsoft SQL Server 데이터베이스. 솔루션은 기업 Active Directory 도메인에 통합될 수 있어야 하고 내구성이 높아야 합니다. AWS에서 관리하고 처리량 및 IOPS 수준을 제공합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. Windows 파일 서버용 Amazon FSx 사용 B. Amazon Elastic File System(Amazon EFS) 사용 C. 파일 게이트웨이 모드에서 AWS Storage Gateway를 사용합니다. D. 2개의 가용 영역에 있는 2개의 온디맨드 인스턴스에 Windows 파일 서버를 배포합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 웹 애플리케이션을 개발하는 회사는 수백 개의 애플리케이션 로드를 출시했습니다. 여러 리전의 밸런서(ALB). 회사는 허용 목록(또는 모든 방화벽 장치의 로드 밸런서. 솔루션 아키텍트는 일회성 고가용성을 찾고 있습니다. 필요한 IP 수를 줄이는 데 도움이 되는 이 요청을 해결하기 위한 솔루션 방화벽에서 허용합니다. 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?\nA. 다른 리전의 모든 ALB에 대한 IP를 추적하는 AWS Lambda 함수를 생성하십시오. 이 목록을 새로고침합니다. B. 탄력적 IP로 NLB(Network Load Balancer)를 설정합니다. 모든 ALB의 사설 IP를 다음과 같이 등록하십시오. 이 NLB를 대상으로 합니다. C. AWS Global Accelerator를 시작하고 모든 리전에 대한 엔드포인트를 생성합니다. 모든 ALB를 등록하십시오. 해당 엔드포인트에 대한 다른 리전 D. Amazon EC2 인스턴스를 설정하고 이 EC2 인스턴스에 탄력적 IP를 할당하고 구성 모든 ALB에 트래픽을 전달하기 위한 프록시로 인스턴스. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사의 IT 비용에 대한 최근 분석은 백업 비용을 줄여야 할 필요성을 강조합니다. 회사의 CIO는 온프레미스 백업 인프라를 단순화하고 물리적 백업 테이프를 사용하지 않아 비용을 절감할 수 있습니다. 회사는 보존해야 합니다. 온프레미스 백업 애플리케이션 및 워크플로에 대한 기존 투자 솔루션 아키텍트는 무엇을 추천해야 합니까?\nA. NFS 인터페이스를 사용하여 백업 애플리케이션과 연결하도록 AWS Storage Gateway를 설정합니다. B. NFS를 사용하여 백업 애플리케이션과 연결하는 Amazon EFS 파일 시스템 설정 상호 작용 C. iSCSI를 사용하여 백업 애플리케이션과 연결하는 Amazon EFS 파일 시스템 설정 상호 작용 D. iSCSI 가상 테이프를 사용하여 백업 애플리케이션과 연결하도록 AWS Storage Gateway 설정 라이브러리(VTL) 인터페이스. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion Amazon RDS DB 인스턴스에 저장된 법의학 회계 데이터를 공유하려는 회사 외부 감사관과 함께. 감사자는 자체 AWS 계정을 가지고 있으며 자체 사본이 필요합니다. 데이터 베이스. 회사는 데이터베이스를 감사자와 어떻게 안전하게 공유해야 합니까?\nA. 데이터베이스의 읽기 전용 복제본을 생성하고 IAM 표준 데이터베이스 인증을 다음과 같이 구성합니다. 감사자 액세스 권한을 부여합니다. B. 데이터베이스의 스냅샷을 Amazon S3에 복사하고 감사자에게 IAM 역할을 할당하여 부여 해당 버킷의 객체에 대한 액세스. C. 데이터베이스 콘텐츠를 텍스트 파일로 내보내고 Amazon S3에 파일을 저장하고 새 IAM 사용자 생성 해당 버킷에 대한 액세스 권한이 있는 감사자용입니다. D. 데이터베이스의 암호화된 스냅샷을 만들고, 스냅샷을 공유하고, AWS에 대한 액세스를 허용합니다. 키 관리 서비스(AWS KMS) 암호화 키. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 온프레미스 서버에서 다음으로 10Gbps AWS Direct Connect 연결을 가지고 있습니다. AWS. 연결을 사용하는 워크로드는 중요합니다. 회사에 재해 복구가 필요합니다. 현재 연결 대역폭을 최소로 유지하는 최대 탄력성을 가진 전략입니다. 솔루션 아키텍트는 무엇을 추천해야 합니까?\nA. 다른 AWS 리전에서 새 Direct Connect 연결을 설정합니다. B. 다른 AWS 리전에서 새 AWS 관리형 VPN 연결을 설정합니다. C. 두 개의 새로운 Direct Connect 연결을 설정합니다. 하나는 현재 AWS 리전이고 다른 하나는 다른 리전입니다. 지역. D. 두 개의 새로운 AWS 관리형 VPN 연결을 설정합니다. 하나는 현재 AWS 리전이고 다른 하나는 다른 지역. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 여러 가용 영역(AZ)에 여러 프라이빗 서브넷이 있고 AZ 중 하나에 하나의 퍼블릭 서브넷이 있는 VPC를 생성했습니다. 퍼블릭 서브넷은 NAT 게이트웨이를 시작하는 데 사용됩니다. NAT 게이트웨이를 사용하여 인터넷에 연결하는 프라이빗 서브넷의 인스턴스가 있습니다. 경우에 AZ 오류를 사용하는 경우 회사는 인스턴스가 모두 인터넷을 사용하지 않는지 확인하려고 합니다. 연결 문제 및 준비된 백업 계획이 있는지 확인합니다. 솔루션 설계자가 가장 고가용성인 솔루션을 권장해야 하는 것은 무엇입니까?\nA. 동일한 AZ에 NAT 게이트웨이가 있는 새 퍼블릭 서브넷을 생성합니다. 2개의 NAT 게이트웨이 B. 이제 퍼블릭 서브넷에 Amazon EC2 NAT 인스턴스 생성 NAT 간에 트래픽 분산 게이트웨이 및 NAT 인스턴스 C. 각 AZ에서 퍼블릭 서브넷 생성 및 각 서브넷에서 NAT 게이트웨이 시작 트래픽 구성 각 A2의 프라이빗 서브넷에서 해당 NAT 게이트웨이로 D. 동일한 퍼블릭 서브넷에 Amazon EC2 NAT 인스턴스 생성 NAT 게이트웨이를 다음으로 바꿉니다. NAT 인스턴스 및 인스턴스를 적절한 조정이 있는 Auto Scaling 그룹과 연결 정책. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 네트워크 연결 파일에서 750TB의 데이터를 전송해야 합니다. 지사에 위치한 시스템에서 Amazon S3 Glacier로의 솔루션은 지사를 포화시키지 않아야 합니다. 사무실의 저대역폭 인터넷 연결 가장 비용 효율적인 솔루션1은 무엇입니까?\nA. Amazon S3 버킷에 대한 사이트 간 VPN 터널을 생성하고 파일을 직접 전송합니다. VPC 엔드포인트를 시행하기 위한 버킷 정책 B. AWS Snowball 어플라이언스 10개를 주문하고 S3 Glacier 볼트를 대상으로 선택합니다. VPC 엔드포인트를 시행하기 위한 버킷 정책 C. 네트워크 연결 파일 시스템을 Amazon S3에 탑재하고 파일을 직접 복사합니다. 만들기 S3 객체를 Amazon S3 Glacier로 전환하기 위한 수명 주기 정책 D. AWS Snowball 어플라이언스 10개를 주문하고 Amazon S3 버킷을 대상으로 선택합니다. 만들기 S3 객체를 Amazon S3 Glacier로 전환하기 위한 수명 주기 정책 정답 풀이\r...\r답변: D\r#\r설명 AWS Snowball에 대한 지역 제한 사항 AWS Snowball 서비스에는 표준 Snowball과 Snowball Edge의 두 가지 디바이스 유형이 있습니다. NS 다음 표는 이러한 장치 중 어느 지역에서 사용할 수 있는지 강조합니다. AWS Snowball의 작업 제한 사항 AWS Snowball에서 작업 생성에는 다음과 같은 제한 사항이 있습니다. 보안을 위해 Snowball이 삭제된 후 90일 이내에 데이터 전송을 완료해야 합니다. 준비. 현재 AWS Snowball Edge 디바이스는 고객이 제공한 서버 측 암호화를 지원하지 않습니다. 키(SSE-C). AWS Snowball Edge 디바이스는 Amazon S3를 통한 서버 측 암호화를 지원합니다. 관리형 암호화 키(SSE-S3) 및 AWS Key Management Service 관리형 키(SSE-KMS)를 사용한 서버 측 암호화. 자세한 내용은 서버 측 암호화를 사용하여 데이터 보호를 참조하십시오. Amazon Simple Storage Service 개발자 안내서. 미국 리전에서 Snowball은 50TB와 80TB의 두 가지 크기로 제공됩니다. 다른 모든 지역에는 80TB가 있습니다. 눈덩이만. Snowball을 사용하여 데이터를 가져오는데 필요한 것보다 더 많은 데이터를 전송해야 하는 경우 단일 Snowball에 맞게 추가 작업을 만듭니다. 각 내보내기 작업은 여러 Snowball을 사용할 수 있습니다. 한 번에 가질 수 있는 Snowball 수에 대한 기본 서비스 제한은 1입니다. 서비스 한도를 늘리려면 AWS Support에 문의하십시오. Snowball로 전송된 모든 개체의 메타데이터가 변경되었습니다. 유일하게 남은 메타데이터 파일 이름과 파일 크기도 동일합니다. 다른 모든 메타데이터는 다음 예와 같이 설정됩니다. -rw-rw-r\u0026ndash; 1 루트 루트 [파일 크기] 1969년 12월 31일 [경로/파일 이름] 개체 수명 주기 관리 개체를 관리하려면 수명 주기 동안 비용 효율적으로 저장되도록 Amazon S3 수명 주기를 구성합니다. S3 수명 주기 구성은 Amazon S3가 그룹에 적용하는 작업을 정의하는 규칙 집합입니다. 사물. 두 가지 유형의 작업이 있습니다. 전환 작업 - 객체가 다른 스토리지 클래스로 전환되는 시기를 정의합니다. 예를 들어 다음과 같이 할 수 있습니다. 객체를 생성한 후 30일 후에 객체를 S3 Standard-IA 스토리지 클래스로 전환하도록 선택하거나 객체를 생성한 후 1년이 지나면 객체를 S3 Glacier 스토리지 클래스에 보관합니다. 만료 작업 - 개체가 만료되는 시기를 정의합니다. Amazon S3는 사용자를 대신하여 만료된 객체를 삭제합니다. 수명 주기 만료 비용은 객체 만료를 선택하는 시점에 따라 다릅니다. https://docs.aws.amazon.com/snowball/latest/ug/limits.html https://docs.aws.amazon.com/AmazonS3/latest/dev/object-lifecycle-mgmt.html\n#\r#\r질문\r#\rquestion 솔루션 설계자는 AWS 클라우드를 사용하여 하이브리드 애플리케이션을 설계하고 있습니다. 네트워크 온프레미스 데이터 센터와 AWS 간의 연결은 AWS Direct Connect(DX) 연결을 사용합니다. NS AWS와 온프레미스 데이터 센터 간의 애플리케이션 연결은 복원력이 높아야 합니다. 이러한 요구 사항을 충족하려면 어떤 DX 구성을 구현해야 합니까?\nA. 그 위에 VPN을 사용하여 DX 연결을 구성합니다. B. 여러 DX 위치에서 DX 연결을 구성합니다. C. 가장 신뢰할 수 있는 DX 파트너를 사용하여 DX 연결을 구성합니다. D. DX 연결 위에 여러 가상 인터페이스를 구성합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 AWS Lambda에서 마이크로서비스 중 하나를 구현하여 Books라는 Amazon DynamoDB 테이블. 솔루션 설계자는 연결할 IAM 정책을 설계합니다. Lambda 함수의 IAM 역할에 대한 액세스 권한을 부여하여 Books의 항목을 넣고 업데이트하고 삭제할 수 있습니다. 테이블. IAM 정책은 함수가 Books 테이블 또는 기타. 어떤 IAM 정책이 이러한 요구 사항을 충족하고 최소 권한 액세스를 제공합니까?\nA. 옵션 A\n{ \u0026#34;버전\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;성명\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PutUpdateDeleteOnBooks\u0026#34;, \u0026#34;효과\u0026#34;: \u0026#34;허용\u0026#34;, \u0026#34;행동\u0026#34;: [ \u0026#34;dynamodb: PutItem\u0026#34;, \u0026#34;dynamodb: UpdateItem\u0026#34;, \u0026#34;dynamodb: DeleteItem\u0026#34; ], \u0026#34;리소스\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/Books\u0026#34; } ] } #\rB. 옵션 B\n{ \u0026#34;버전\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;성명\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PutUpdateDeleteOnBooks\u0026#34;, \u0026#34;효과\u0026#34;: \u0026#34;허용\u0026#34;, \u0026#34;행동\u0026#34;: [ \u0026#34;dynamodb: PutItem\u0026#34;, \u0026#34;dynamodb: UpdateItem\u0026#34;, \u0026#34;dynamodb: DeleteItem\u0026#34; ], \u0026#34;리소스\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/*\u0026#34; } ] } #\rC. 옵션 C\n{ \u0026#34;버전\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;성명\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PutUpdateDeleteOnBooks\u0026#34;, \u0026#34;효과\u0026#34;: \u0026#34;허용\u0026#34;, \u0026#34;행동\u0026#34;: [ \u0026#34;다이나모드: *\u0026#34; ], \u0026#34;리소스\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/Books\u0026#34; }, { \u0026#34;Sid\u0026#34;: \u0026#34;PutUpdateDeleteOnBooks\u0026#34;, \u0026#34;효과\u0026#34;: \u0026#34;거부\u0026#34;, \u0026#34;행동\u0026#34;: [ \u0026#34;다이나모드: *\u0026#34; ], \u0026#34;리소스\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/Books\u0026#34; }, ] } #\rD. 옵션 D\n{ \u0026#34;버전\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;성명\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;PutUpdateDeleteOnBooks\u0026#34;, \u0026#34;효과\u0026#34;: \u0026#34;허용\u0026#34;, \u0026#34;행동\u0026#34;: [ \u0026#34;dynamodb: PutItem\u0026#34;, \u0026#34;dynamodb: UpdateItem\u0026#34;, \u0026#34;dynamodb: DeleteItem\u0026#34; ], \u0026#34;리소스\u0026#34;: \u0026#34;arn:aws:dynamodb:us-west-2:123456789012:table/Books\u0026#34; } ] } 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에 IPv6 주소가 있는 Amazon EC2 인스턴스에서 호스팅되는 애플리케이션이 있습니다. NS 응용 프로그램은 인터넷을 사용하여 다른 외부 응용 프로그램과 통신을 시작해야 합니다. 다만, 회사의 보안정책에 따르면 외부 서비스는 접속을 개시할 수 없습니다. EC2 인스턴스에. 솔루션 설계자는 이 문제를 해결하기 위해 무엇을 권장해야 합니까?\nA. NAT 게이트웨이를 생성하고 서브넷의 라우팅 테이블의 대상으로 만듭니다. B. 인터넷 게이트웨이를 생성하고 서브넷의 라우팅 테이블의 대상으로 만듭니다. C. 가상 프라이빗 게이트웨이를 생성하고 서브넷의 라우팅 테이블의 대상으로 만듭니다. D. 이그레스 전용 인터넷 게이트웨이를 만들고 서브넷의 라우팅 테이블의 대상으로 만듭니다. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사에 각각 약 5개의 파일을 생성하는 응용 프로그램이 있습니다. 크기는 MB입니다. 파일은 Amazon S3에 저장됩니다. 회사 정책은 파일을 4 동안 저장하도록 요구합니다. 몇 년 전에 삭제할 수 있습니다. 파일에 재생산하기 쉽지 않은 중요한 비즈니스 데이터. 파일은 처음 30개에서 자주 액세스됩니다. 개체 생성일로부터 시작되지만 처음 30일 후에는 거의 액세스되지 않습니다. 가장 비용 효율적인 스토리지 솔루션은 무엇입니까?\nA. S3 Standard에서 S3 Glacier로 30일 동안 파일을 이동하는 S3 버킷 수명 주기 정책을 생성합니다. 객체 생성. 객체 생성 후 4년이 지나면 파일을 삭제합니다. B. S3 Standard에서 S3 One Zone-Infrequent로 파일을 이동하는 S3 버킷 수명 주기 정책 생성 액세스(S3 One Zone-IA) 객체 생성 후 30일. 객체 생성 후 4년이 지나면 파일을 삭제합니다. C. S3 Standard에서 S3 Standard-Infrequent로 파일을 이동하는 S3 버킷 수명 주기 정책 생성 액세스(S3 Standard-IA) 객체 생성 후 30일. 객체 생성 후 4년이 지나면 파일을 삭제합니다. D. S3 Standard에서 S3 Standard-Infrequent로 파일을 이동하는 S3 버킷 수명 주기 정책 생성 액세스(S3 Standard-IA) 객체 생성 후 30일. 객체 이후 4년 후 파일을 S3 Glacier로 이동 창조. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 Amazon API Gateway를 사용하여 새로운 API를 설계하고 있습니다. 사용자의 요청 요청의 양은 매우 다양하며 없이 몇 시간이 지나갈 수 있습니다. 단일 요청 수신 데이터 처리는 비동기식으로 이루어지지만 다음과 같아야 합니다. 요청 후 몇 초 이내에 완료 설계자는 가장 낮은 비용으로 요구 사항을 제공하기 위해 API를 호출할 수 있습니까?\nA. AWS Glue 작업 B. AWS Lambda 함수 C. Amazon Elastic Kubernetes Service(Amazon EKS)에서 호스팅되는 컨테이너화된 서비스 D. Amazon EC2와 함께 Amazon ECS에서 호스팅되는 컨테이너화된 서비스 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에 Amazon EC2 인스턴스를 사용하는 3계층 이미지 공유 애플리케이션이 있습니다. 프론트 엔드 계층, 백엔드 계층을 위한 또 다른 계층, MySQL 데이터베이스 A 솔루션을 위한 세 번째 계층 건축가는 고가용성 및 최소한의 요구 사항이 있는 솔루션을 설계하는 임무를 받았습니다. 애플리케이션에 대한 변경 사항의 양.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. Amazon S3를 사용하여 프런트 엔드 계층을 호스팅하고 AWS Lambda 함수를 백엔드 계층으로 이동 데이터베이스를 Amazon DynamoDB 테이블에 저장하고 Amazon S3를 사용하여 사용자 이미지 저장 및 제공 B. 프런트 엔드 및 백엔드에 로드 밸런싱된 다중 AZ AWS Elastic Beanstalk 환경 사용 레이어 저장 및 제공할 읽기 전용 복제본이 여러 개 있는 Amazon RDS 인스턴스로 데이터베이스 이동 사용자의 이미지. C. Amazon S3를 사용하여 Auto Scaling에서 프런트 엔드 계층 및 Amazon EC2 인스턴스 집합 호스팅 백엔드 계층에 대한 그룹 데이터베이스를 메모리에 최적화된 인스턴스 유형으로 이동하여 저장하고 사용자의 이미지 제공 D. 프런트 엔드 및 백엔드에 로드 밸런싱된 다중 AZ AWS Elastic Beanstalk 환경 사용 다중 AZ 배포가 있는 Amazon RDS 인스턴스로 데이터베이스 이동 Amazon S3를 사용하여 사용자의 이미지 저장 및 제공 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사에는 여러 온프레미스 애플리케이션에서 사용되는 온프레미스 데이터 센터에 데이터가 저장되어 있습니다. 회사는 기존 응용 프로그램 환경을 유지하고 데이터 분석 및 향후 시각화를 위해 AWS 서비스를 사용할 수 있습니다. 솔루션 설계자가 추천해야 하는 스토리지 서비스는 무엇입니까?\nA. 아마존 레드시프트 B. 파일용 AWS Storage Gateway C. Amazon Elastic Block Store(Amazon EBS) D. Amazon Elastic File System(Amazon EFS) 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 2계층 웹 애플리케이션을 설계하고 있습니다. 애플리케이션은 다음으로 구성됩니다. 퍼블릭 서브넷의 Amazon EC2에서 호스팅되는 공개 웹 계층 데이터베이스 계층은 다음으로 구성됩니다. 프라이빗 서브넷의 Amazon EC2에서 실행되는 Microsoft SQL Server 보안은 company 이 상황에서 보안 그룹을 어떻게 구성해야 합니까? (2개 선택)\nA. 0 0 0 0/0에서 포트 443의 인바운드 트래픽을 허용하도록 웹 계층에 대한 보안 그룹을 구성합니다. B. 0 0 0 0/0에서 포트 443의 아웃바운드 트래픽을 허용하도록 웹 계층에 대한 보안 그룹을 구성합니다. C. 포트 1433에서 인바운드 트래픽을 허용하도록 데이터베이스 계층에 대한 보안 그룹을 구성합니다. 웹 계층에 대한 보안 그룹 D. 포트 443 및 1433에서 아웃바운드 트래픽을 허용하도록 데이터베이스 계층에 대한 보안 그룹 구성 웹 계층에 대한 보안 그룹에 E. 포트 443 및 1433에서 인바운드 트래픽을 허용하도록 데이터베이스 계층에 대한 보안 그룹 구성 웹 계층에 대한 보안 그룹에서 정답 풀이\r...\r답변: AC\r#\r#\r#\r질문\r#\rquestion 한 회사는 최근 글로벌 사용자 기반에 콘텐츠를 제공하기 위해 웹사이트를 시작했습니다. NS 회사는 Amazon EC2 인스턴스가 오리진으로 연결된 Amazon CloudFront. 솔루션 설계자는 애플리케이션의 고가용성을 어떻게 최적화해야 합니까?\nA. CloudFront에 Lambda@Edge를 사용합니다. B. CloudFront에 Amazon S3 Transfer Acceleration을 사용합니다. C. 다른 가용 영역에 다른 EC2 인스턴스를 오리진 그룹의 일부로 구성합니다. D. 동일한 가용 영역에서 원본 서버 클러스터의 일부로 다른 EC2 인스턴스를 구성합니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에 두 개의 AWS 계정이 있습니다. 프로덕션 및 개발 코드 변경 사항이 있습니다. 개발 계정에서 프로덕션 계정으로 푸시할 준비가 되었습니다. 알파 단계에서는 두 개만 개발 팀의 선임 개발자는 베타 버전의 프로덕션 계정에 액세스해야 합니다. 단계에서 더 많은 개발자가 테스트를 수행하기 위해 액세스해야 할 수도 있습니다. 솔루션 아키텍트는 무엇을 추천해야 합니까?\nA. 각 계정에서 AWS Management 콘솔을 사용하여 두 개의 정책 문서를 생성합니다. 액세스가 필요한 개발자에 대한 정책 B. 개발 계정에 IAM 역할 생성 하나의 IAM 역할에 프로덕션에 대한 액세스 권한 부여 계정 개발자가 역할을 맡도록 허용 C. Development를 지정하는 신뢰 정책을 사용하여 Production 계정에서 IAM 역할 생성 계정. 개발자가 역할을 맡도록 허용합니다. D. 프로덕션 계정에서 IAM 그룹을 생성하고 이를 신뢰 정책의 보안 주체로 추가합니다. 프로덕션 계정을 지정합니다. 그룹에 개발자를 추가합니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사의 동적 웹 사이트는 미국의 온프레미스 서버를 사용하여 호스팅됩니다. NS 이 회사는 유럽에서 제품을 출시하고 있으며 새로운 사이트 로딩 시간을 최적화하기를 원합니다. 유럽 ​​사용자. 사이트의 백엔드는 미국에 있어야 합니다. 제품이 출시되고 있습니다 며칠 안에 즉각적인 솔루션이 필요합니다. 솔루션 설계자는 무엇을 권장해야 합니까?\nA. us-east-1에서 Amazon EC2 인스턴스를 시작하고 사이트를 마이그레이션합니다. B. 웹 사이트를 Amazon S3로 이동합니다. 리전 간 교차 리전 복제를 사용합니다. C. 온프레미스 서버를 가리키는 사용자 지정 오리진과 함께 Amazon CloudFront 사용 D. 온프레미스 서버를 가리키는 Amazon Route 53 지리 근접 라우팅 정책 사용 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 최근 인수한 회사는 AWS에서 자체 인프라를 구축하고 마이그레이션해야 합니다. 한 달 안에 여러 애플리케이션을 클라우드로 전환 각 애플리케이션에는 약 50TB의 데이터가 있습니다. 이전 예정 이전이 완료된 후 이 회사와 모회사는 모두 데이터 센터에서 데이터 센터에 이르기까지 일관된 처리량으로 안전한 네트워크 연결이 필요합니다. 솔루션 설계자는 일회성 데이터 마이그레이션과 지속적인 네트워크를 보장해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 초기 전송 및 지속적인 연결을 위한 AWS Direct Connect B. 초기 전송 및 지속적인 연결을 위한 AWS Site-to-Site VPN C. 초기 전송을 위한 AWS Snowball 및 지속적인 연결을 위한 AWS Direct Connect D. 초기 전송을 위한 AWS Snowball 및 지속적인 연결을 위한 AWS Site-to-Site VPN 정답 풀이\r...\r답: C\r#\r설명 https://aws.amazon.com/directconnect/\n#\r#\r질문\r#\rquestion 한 회사는 현재 공급업체의 Amazon S3에 250TB의 백업 파일을 저장하고 있습니다. 독점 형식. 업체에서 제공하는 Linux 기반 소프트웨어 응용 프로그램을 사용하여 회사는 Amazon S3에서 파일을 검색하고 파일을 업계 표준 형식으로 변환한 다음 Amazon S3에 다시 업로드하려고 합니다. 회사는 관련 데이터 전송 요금을 최소화하고자 합니다. 이 대화로. 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. 데이터가 변환되도록 변환 소프트웨어를 Amazon S3 배치 작업으로 설치합니다. Amazon S3를 떠나지 않고. B. 온프레미스 가상 머신에 변환 소프트웨어를 설치합니다. 변환 수행 가상 머신에서 Amazon S3로 파일을 다시 업로드합니다. C. AWS Snowball Edge 장치를 사용하여 데이터를 전문화하고 변환 소프트웨어를 장치. 데이터 변환을 수행하고 Snowball 디바이스에서 Amazon S3로 파일을 다시 업로드합니다. D. Amazon S3와 동일한 리전에서 Amazon EC2 인스턴스를 시작하고 변환 설치 인스턴스에 소프트웨어. 변환을 수행하고 다음에서 Amazon S3로 파일을 다시 업로드합니다. EC2 인스턴스. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 데이터 웨어하우스에 Amazon Redshift를 사용합니다. 회사는 다음을 보장하고자 합니다. 구성 요소 오류 발생 시 데이터에 대한 높은 내구성. 솔루션 아키텍트는 무엇을 추천해야 합니까?\nA. 동시성 좌석을 활성화합니다. B. 교차 리전 스냅샷을 활성화합니다. C. 데이터 보유 기간을 늘립니다. D. 다중 AZ에 Amazon Redshift를 배포합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 단일 Amazon EC2 인스턴스를 사용하여 AWS에서 웹 애플리케이션을 호스팅하고 있습니다. 확장성과 가용성 향상을 위해 사용자 업로드 문서를 Amazon EBS 볼륨에 저장 회사는 아키텍처를 복제하고 다른 곳에 두 번째 EC2 인스턴스와 EBS 볼륨을 생성했습니다. 가용 영역: Application Load Balancer 뒤에 둘 다 배치 이 변경을 완료한 후 사용자는 다음과 같이 보고했습니다. 웹사이트를 새로 고칠 때마다 문서의 일부 또는 다른 하위 집합을 볼 수 있었지만 모든 문서를 동시에 작성하지 않음 사용자가 모든 문서를 한 번에 볼 수 있습니까?\nA. 두 EBS 볼륨에 모든 문서가 포함되도록 데이터를 복사합니다. B. 사용자를 문서가 있는 서버로 안내하도록 Application Load Balancer 구성 C. 두 EBS 볼륨의 데이터를 Amazon EFS로 복사 Amazon EFS에 문서 D. 두 서버 모두에 요청을 보내도록 Application Load Balancer를 구성합니다. 올바른 서버의 문서 정답 풀이\r...\r답: C\r#\r설명 https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html#how-it-works-ec2 Amazon EFS AWS 클라우드에 파일 스토리지를 제공합니다. Amazon EFS를 사용하면 파일 시스템을 생성하고 파일을 마운트할 수 있습니다. Amazon EC2 인스턴스에서 시스템을 구축한 다음 파일 시스템에서 데이터를 읽고 씁니다. 너 네트워크 파일 시스템 버전 4.0 및 4.1(NFSv4) 프로토콜. 다음과 같은 현재 세대 Linux NFSv4.1 클라이언트를 사용하는 것이 좋습니다. Amazon EFS와 함께 최신 Amazon Linux, Redhat 및 Ubuntu AMI에서 찾을 수 있습니다. 마운트 헬퍼. 지침은 amazon-efs-utils 도구 사용을 참조하십시오. 이 프로토콜을 지원하는 Amazon EC2 Linux Amazon 머신 이미지(AMI) 목록은 NFS를 참조하십시오. 지원하다. 일부 AMI의 경우 NFS 클라이언트를 설치하여 파일 시스템을 Amazon EC2 인스턴스. 지침은 NFS 클라이언트 설치를 참조하십시오. 여러 NFS 클라이언트에서 Amazon EFS 파일 시스템에 동시에 액세스할 수 있으므로 애플리케이션 단일 연결을 넘어서는 확장이 파일 시스템에 액세스할 수 있습니다. 에서 실행 중인 Amazon EC2 인스턴스 동일한 AWS 리전 내의 여러 가용 영역이 파일 시스템에 액세스할 수 있으므로 많은 사용자는 공통 데이터 소스에 액세스하고 공유할 수 있습니다. Amazon EFS가 Amazon EC2와 작동하는 방식 https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html#how-it-works-ec2\n#\r#\r질문\r#\rquestion 회사의 레거시 애플리케이션이 현재 단일 인스턴스 Amazon RDS MySQL에 의존하고 있습니다. 암호화 없는 데이터베이스 새로운 규정 준수 요구 사항으로 인해 이 문서의 모든 기존 및 새 데이터가 데이터베이스를 암호화해야 합니다. 이 작업을 어떻게 수행해야 합니까?\nA. 서버 측 암호화가 활성화된 Amazon S3 버킷 생성 모든 데이터를 Amazon S3로 이동 RDS 인스턴스 삭제 B. 미사용 시 암호화가 활성화된 RDS 다중 AZ 모드 활성화 대기로 장애 조치 수행 원본 인스턴스를 삭제하는 인스턴스 C. RDS 인스턴스의 스냅샷 생성 스냅샷의 암호화된 사본 생성 RDS 복원 암호화된 스냅샷의 인스턴스 D. 미사용 시 암호화가 활성화된 RDS 읽기 전용 복제본 생성 읽기 전용 복제본을 마스터로 승격 애플리케이션을 새 마스터로 전환합니다. 이전 RDS 인스턴스를 삭제합니다. 정답 풀이\r...\r답: C\r#\r설명 Amazon RDS 스냅샷을 암호화하려면 어떻게 해야 합니까?\n다음 단계는 Amazon RDS for MySQL, Oracle, SQL Server, PostgreSQL 또는 마리아DB. 중요: Amazon Aurora를 사용하는 경우 암호화되지 않은 Aurora DB 클러스터 스냅샷을 다음으로 복원할 수 있습니다. AWS Key Management Service(AWS KMS)를 지정하는 경우 암호화된 Aurora DB 클러스터\n115 암호화되지 않은 DB 클러스터 스냅샷에서 복원할 때 암호화 키. 자세한 내용은, Amazon RDS 암호화 DB 인스턴스의 제한 사항을 참조하십시오. Amazon RDS 콘솔을 열고 탐색 창에서 스냅샷을 선택합니다. 암호화할 스냅샷을 선택합니다. 스냅샷 작업에서 스냅샷 복사를 선택합니다. 대상 리전을 선택한 다음 새 DB 스냅샷 식별자를 입력합니다. 암호화 활성화를 예로 변경합니다. 목록에서 마스터 키를 선택한 다음 스냅샷 복사를 선택합니다. 스냅샷 상태를 사용할 수 있게 되면 암호화됨 필드가 True가 되어 스냅샷이 현재 상태임을 나타냅니다. 암호화. 이제 DB의 암호화된 스냅샷이 있습니다. 이 암호화된 DB 스냅샷을 사용하여 복원할 수 있습니다. DB 스냅샷의 DB 인스턴스. https://aws.amazon.com/premiumsupport/knowledge-center/encrypt-rds-snapshots/\n#\r#\r질문\r#\rquestion 회사는 온프레미스 환경과 AWS 간의 보안 연결이 필요합니다. 이것 연결에는 높은 대역폭이 필요하지 않으며 소량의 트래픽을 처리합니다. 연결 빨리 설정해야 합니다. 이러한 유형의 연결을 설정하는 가장 비용 효율적인 방법은 무엇입니까?\nA. 클라이언트 VPN 구현 B. AWS Direct Connect 구현 C. Amazon EC2 53D에서 배스천 호스트를 구현합니다. D. AWS Site-to-Site VPN 연결을 구현합니다. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사는 서비스를 사용하여 2계층 전자상거래 웹사이트를 운영하고 있습니다. 현 건축가 프라이빗에서 Amazon EC2 인스턴스로 트래픽을 전송하는 게시 방향 Elastic Load Balancer를 사용합니다. 서브넷. 정적 콘텐츠는 EC2 인스턴스에서 호스팅되고 동적 콘텐츠는 MySQL 데이터베이스. 응용 프로그램은 미국에서 실행 중입니다. 회사는 최근 시작 유럽 ​​및 호주 사용자에게 판매. 솔루션 설계자는 솔루션을 설계해야 국제 사용자는 향상된 브라우징 경험을 가지고 있습니다. 가장 비용 효율적인 솔루션은 무엇입니까?\nA. Amazon S3에서 전체 웹사이트를 호스팅합니다. B. Amazon CloudFront 및 Amazon S3를 사용하여 정적 이미지를 호스팅합니다. C. 퍼블릭 로드 밸런서 및 EC2 인스턴스 수 늘리기 D. 유럽과 호주의 AWS 리전에 2계층 웹 사이트를 배포합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사에 AWS로 마이그레이션하려는 두 개의 애플리케이션이 있습니다. 두 응용 프로그램 모두 동시에 동일한 파일에 액세스하여 대용량 파일 세트. 두 응용 프로그램 모두 파일을 읽어야 합니다. 낮은 대기 시간으로. 이러한 상황에서 솔루션 설계자는 어떤 아키텍처를 권장해야 합니까?\nA. 두 개의 AWS Lambda 함수를 구성하여 애플리케이션을 실행합니다. Amazon EC2 인스턴스 생성 데이터를 저장할 인스턴스 스토어 볼륨이 있습니다. B. 애플리케이션을 실행하도록 두 개의 AWS Lambda 함수를 구성합니다. 다음을 사용하여 Amazon EC2 인스턴스 생성 데이터를 저장할 Amazon Elastic Block Store(Amazon EBS) 볼륨. C. 두 애플리케이션을 동시에 실행하도록 하나의 메모리 최적화 Amazon EC2 인스턴스를 구성합니다. 프로비저닝된 IOPS로 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성하여 데이터를 저장합니다. D. 두 애플리케이션을 모두 실행하도록 두 개의 Amazon EC2 인스턴스를 구성합니다. Amazon Elastic File 구성 범용 성능 모드 및 버스팅 처리량 모드가 있는 시스템(Amazon EFS) 데이터를 저장합니다. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 미디어 스트리밍 회사는 실시간 데이터를 수집하여 디스크에 최적화된 저장소에 저장합니다. 데이터베이스 시스템이 예상되는 처리량을 얻지 못하고 인메모리를 원합니다. 데이터 복제를 사용하여 더 빠르게 수행하고 고가용성을 제공하는 데이터베이스 스토리지 솔루션입니다. 솔루션 아키텍트는 어떤 데이터베이스를 추천해야 할까요?'\nA. MySQL용 Amazon RDS B. PostgreSQL용 Amazon RDS C. Redis용 Amazon ElastiCache D. Memcached용 Amazon ElastiCache 정답 풀이\r...\r답: C\r#\r설명 https://aws.amazon.com/elasticache/redis-vs-memcached/ AWS의 인메모리 데이터베이스 Redis용 Amazon Elasticache Redis용 Amazon ElastiCache는 밀리초 미만을 제공하는 초고속 인메모리 데이터 스토어입니다. 인터넷 규모의 실시간 애플리케이션에 전력을 공급하기 위한 대기 시간. 개발자는 Redis용 ElastiCache를 다음과 같이 사용할 수 있습니다. 메모리 내 비관계형 데이터베이스. Redis용 ElastiCache 클러스터 구성은 최대 15개의 샤드를 제공하고 고객이 하나의 시스템에서 최대 6.1TB의 인메모리 용량으로 Redis 워크로드를 실행할 수 있습니다. 단일 클러스터. Redis용 ElastiCache는 실행 중인 데이터베이스에서 샤드를 추가 및 제거하는 기능도 제공합니다. 무리. Redis 클러스터 워크로드를 동적으로 확장하고 축소하여 수요의 변화 https://aws.amazon.com/nosql/in-memory/\n#\r#\r질문\r#\rquestion 회사에 Amazon EC2에서 실행되는 사용자 지정 애플리케이션이 있습니다. 인스턴스:\nAmazon S3에서 많은 양의 데이터를 읽습니다. 다단계 분석 수행 결과를 Amazon DynamoDB에 씁니다. 응용 프로그램은 다단계 분석 중에 상당한 수의 대용량 임시 파일을 씁니다. 프로세스 성능은 임시 저장 성능에 따라 다릅니다. 임시 파일을 보관하기 위한 가장 빠른 저장 옵션은 무엇입니까? A. 스토리지용 Transfer Acceleration이 포함된 여러 Amazon S3 버킷 B. 프로비저닝된 IOPS 및 EBS 최적화 기능이 있는 여러 Amazon EBS 드라이브 C. Network Ilie System 버전 4.1(NFSv4.1) 프로토콜을 사용하는 여러 Amazon EFS 볼륨. D. 소프트웨어 RAID 0이 있는 여러 인스턴스 저장소 볼륨. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사는 보험 견적을 처리하는 AWS를 사용하여 웹 애플리케이션을 설계하고 있습니다. 응용 프로그램에서 견적을 요청합니다. 견적은 견적 유형별로 구분해야 합니다. 응답해야 합니다. 솔루션은 설정 및 유지 관리가 간단해야 하며 24시간 이내에 손실되지 않아야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 견적 유형에 따라 여러 Amazon Kinesis 데이터 스트림 생성 웹 구성 적절한 데이터 스트림으로 메시지를 보내는 애플리케이션 애플리케이션의 각 백엔드 그룹 구성 서버가 Kinesis 클라이언트 라이브러리(KCL)를 사용하여 자체 데이터 스트림에서 메시지를 풀링 B. 여러 Amazon Simple Notification Service {Amazon SNS) 주제 생성 및 Amazon SQS 등록 견적 유형에 따라 자신의 SNS 주제에 대기합니다. 게시할 웹 애플리케이션 구성 SNS 주제 대기열로 보내는 메시지 자체 SQS를 작동하도록 각 백엔드 애플리케이션 서버 구성 대기 줄 C. 단일 Amazon Simple Notification Service {Amazon SNS) 주제를 생성하고 Amazon 구독 SNS 주제에 대한 SQS 대기열 적절한 SQS에 메시지를 게시하도록 SNS 메시지 필터링 구성 견적 유형을 기반으로 한 대기열입니다. 자체 SQS를 작동하도록 각 백엔드 애플리케이션 서버 구성 대기 줄. D. 전달할 견적 유형에 따라 여러 Amazon Kinesis Data Firehose 전송 스트림 생성 Amazon Elasticsearch Service {Amazon ES) 클러스터로 데이터 스트림. 웹 애플리케이션 구성 메시지를 적절한 전달 스트림으로 보내기 위해 애플리케이션 서버의 각 백엔드 그룹 구성 Amazon ES에서 메시지를 검색하고 그에 따라 처리 정답 풀이\r...\r답: C\r#\r#\r#\r질문 101-200\r#\r#\r#\r#\r질문\r#\rquestion 회사에 Amazon EC2 인스턴스에서 실행되는 API 기반 인벤토리 보고 애플리케이션이 있습니다. 애플리케이션은 Amazon DynamoDB 테이블에 정보를 저장합니다. 회사의 배포 센터에는 API를 호출하여 사전에 재고를 업데이트하는 온프레미스 배송 애플리케이션이 있습니다. 배송 라벨 인쇄 회사는 여러 번 응용 프로그램 중단을 경험했습니다. 매일 발생하는 트랜잭션 손실 애플리케이션 복원력?\nA. 로컬 데이터베이스에 쓰도록 배송 애플리케이션 수정 B. AWS Lambda를 사용하여 서버리스를 실행하도록 애플리케이션 API 수정 C. EC2 인벤토리 애플리케이션 API를 호출하도록 Amazon API Gateway를 구성합니다. D. Amazon Simple Queue Service(Amazon SQS) 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon S3 버킷을 사용하여 정적 이미지를 저장하는 웹 사이트를 설계하고 있습니다. NS 회사는 대기 시간과 비용을 모두 줄이는 동시에 미래의 모든 요청에 ​​맛보기 응답 시간을 갖기를 원합니다. 솔루션 설계자는 어떤 서비스 구성을 권장해야 합니까?\nA. Amazon S3 앞에 NAT 서버를 배포합니다. B. Amazon S3 앞에 Amazon CloudFront를 배포합니다. C. Amazon S3 앞에 Network Load Balancer를 배포합니다. D. Auto Scaling을 구성하여 웹사이트의 용량을 자동으로 조정합니다. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 웹 애플리케이션은 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 실행됩니다. NS 응용 프로그램을 통해 사용자는 과거 날씨 데이터에 대한 맞춤형 보고서를 작성할 수 있습니다. 보고서 생성은 최대 5분이 소요됩니다. 이러한 장기 실행 요청은 사용 가능한 많은 수신 연결을 사용하므로 시스템이 다른 사용자에게 응답하지 않습니다. 솔루션 아키텍트가 시스템의 응답성을 향상시킬 수 있는 방법은 무엇입니까?\nA. Amazon SQS를 AWS Lambda와 함께 사용하여 보고서를 생성합니다. B. Application Load Balancer의 유휴 시간 제한을 5분으로 늘립니다. C. 요청 제한 시간을 5분으로 늘리기 위해 클라이언트 측 애플리케이션 코드를 업데이트합니다. D. 보고서를 Amazon S3에 게시하고 Amazon CloudFront를 사용하여 사용자에게 다운로드합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 모놀리식 애플리케이션이 최근 AWS로 마이그레이션되었으며 현재 단일 Amazon에서 실행 중입니다. EC2 인스턴스. 애플리케이션 제한으로 인해 자동 확장을 사용하여 확장할 수 없습니다. 애플리케이션. CTO(최고 기술 책임자)는 EC2 인스턴스를 복원하는 자동화된 솔루션을 원합니다. 기본 하드웨어가 실패하는 경우. EC2 인스턴스를 가능한 한 빨리 자동 복구하려면 어떻게 해야 합니까?\nA. 다음과 같은 경우 EC2 인스턴스의 복구를 트리거하는 Amazon CloudWatch 경보를 구성합니다. 장애가 됩니다. B. Amazon CloudWatch 경보가 다음과 같은 경우 CTO에게 알리는 SNS 메시지를 트리거하도록 구성합니다. EC2 인스턴스가 손상되었습니다. C. EC2 인스턴스의 상태를 모니터링하도록 AWS CloudTrail을 구성하고 손상된 경우 트리거된 인스턴스 복구. D. 한 시간에 한 번씩 AWS Lambda 함수를 트리거하도록 Amazon EventBridge 이벤트를 구성합니다. EC2 인스턴스의 상태를 확인하고 EC2 인스턴스가 비정상인 경우 인스턴스 복구를 트리거합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 웹 사이트는 매일 정오에 트래픽 버스트를 수신하는 웹 애플리케이션을 실행합니다. 사용자 매일 새로운 사진과 콘텐츠를 업로드하지만 시간 초과에 대해 불평하고 있습니다. 아키텍처 사용 Amazon EC2 Auto Scaling 그룹 및 사용자 지정 애플리케이션을 시작하는 데 일관되게 1분이 걸립니다. 부팅 시 사용자 요청에 응답하기 전에. 솔루션 설계자는 변화하는 트래픽에 더 잘 대응하기 위해 아키텍처를 어떻게 재설계해야 합니까?\nA. 느린 시작 구성으로 Network Load Balancer를 구성합니다. B. 직접 요청을 서버로 오프로드하도록 Redis용 AWS ElastiCache를 구성합니다. C. 인스턴스 준비 조건으로 Auto Scaling 단계 조정 정책을 구성합니다. D. Application Load Balancer를 오리진으로 사용하도록 Amazon CloudFront를 구성합니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에는 us-east-1에 Development, Testing 및 Production이라는 3개의 VPC가 있습니다. 지역. 3개의 VPC는 ​​온프레미스 데이터 센터에 연결되어야 하며 다음과 같이 설계됩니다. 보안을 유지하고 리소스 공유를 방지하기 위해 분리된 솔루션 설계자는 확장 가능하고 안전한 솔루션 솔루션 설계자는 무엇을 권장해야 합니까?\nA. 다시 연결할 각 VPC에 대해 AWS Direct Connect 연결 및 VPN 연결을 생성합니다. 데이터 센터. B. 모든 VPC에서 프로덕션 VPC로 VPC 피어 생성 AWS Direct Connect 연결 사용 프로덕션 VPC에서 다시 데이터 센터로 C. 모든 VPC의 VPN 연결을 프로덕션 VPC의 VPN으로 연결합니다. VPN 연결 사용 프로덕션 VPC에서 다시 데이터 센터로 D. 네트워크 내에서 네트워크라는 새 VPC 생성 VPC는 ​​다음을 사용하여 AWS Transit Gateway를 생성합니다. 데이터 센터에 다시 AWS Direct Connect 연결 다른 모든 VPC를 네트워크에 연결 VPC. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자가 배포 중인 새 애플리케이션을 위한 클라우드 아키텍처를 설계하고 있습니다. AWS에서 필요에 따라 애플리케이션 노드를 추가 및 제거하는 동안 프로세스가 병렬로 실행되어야 합니다. 처리할 작업의 수에 따라 프로세서 애플리케이션은 상태 비저장 솔루션입니다. 설계자는 응용 프로그램이 느슨하게 연결되어 있고 작업 항목이 영구적으로 저장되어 있는지 확인해야 합니다. 솔루션 설계자는 어떤 디자인을 사용해야 합니까?\nA. 처리해야 하는 작업을 보낼 Amazon SNS 주제 생성 Amazon 생성 프로세서 애플리케이션으로 구성된 머신 이미지(AMI) AMI를 사용합니다. 시작 구성을 사용하여 Auto Scaling 그룹을 생성합니다. CPU 사용량에 따라 노드를 추가 및 제거하는 Auto Scaling 그룹 B. 처리해야 하는 작업을 보관할 Amazon SQS 대기열 생성 Amazon 생성 프로세서 애플리케이션으로 구성된 머신 이미지(AMI) AMI를 사용합니다. 시작 구성을 사용하여 Auto Scaling 그룹을 생성합니다. 네트워크 사용량에 따라 노드를 추가 및 제거하는 Auto Scaling 그룹 C. 처리해야 하는 작업을 보관할 Amazon SQS 대기열 생성 Amazon 생성 프로세서 애플리케이션으로 구성된 머신 이미지(AMI) 다음을 사용하는 시작 템플릿을 생성합니다. AMI 시작 템플릿을 사용하여 Auto Scaling 그룹 생성 Auto에 대한 조정 정책 설정 SQS 대기열의 항목 수에 따라 노드를 추가 및 제거하는 확장 그룹 D. 처리해야 할 작업을 보낼 Amazon SNS 주제 생성 Amazon 생성 프로세서 애플리케이션으로 구성된 머신 이미지(AMI) 다음을 사용하는 시작 템플릿을 생성합니다. AMI 시작 템플릿을 사용하여 Auto Scaling 그룹 생성 Auto에 대한 조정 정책 설정 SNS에 게시된 메시지 수에 따라 노드를 추가 및 제거하는 스케일링 그룹 주제. 정답 풀이\r...\r답: C\r#\r설명 Amazon 단순 대기열 서비스 Amazon Simple Queue Service(SQS)는 다음을 수행할 수 있는 완전 관리형 메시지 대기열 서비스입니다. 마이크로서비스, 분산 시스템 및 서버리스 애플리케이션을 분리하고 확장합니다. SQS 제거 메시지 지향 미들웨어 관리 및 운영과 관련된 복잡성 및 오버헤드, 개발자가 작업을 차별화하는 데 집중할 수 있도록 합니다. SQS를 사용하여 전송, 저장 및 메시지 손실 없이 모든 볼륨에서 소프트웨어 구성 요소 간에 메시지 수신 다른 서비스를 사용할 수 있어야 합니다. AWS 콘솔을 사용하여 몇 분 만에 SQS를 시작하고, 원하는 명령줄 인터페이스 또는 SDK와 세 가지 간단한 명령. SQS는 두 가지 유형의 메시지 대기열을 제공합니다. 표준 대기열은 최대 처리량, 최선의 노력을 제공합니다. 주문 및 최소 한 번 배달. SQS FIFO 대기열은 메시지가 전송된 정확한 순서대로 정확히 한 번 처리됩니다. Amazon SQS 기반 확장 Amazon에서 활동에 대한 응답으로 확장하는 것에 대해 생각할 수 있는 몇 가지 시나리오가 있습니다. SQS 대기열. 예를 들어 사용자가 이미지를 업로드하고 그들을 온라인으로. 이 시나리오에서 각 이미지는 게시하기 전에 크기 조정 및 인코딩이 필요합니다. 앱은 Auto Scaling 그룹의 EC2 인스턴스에서 실행되며 일반적인 업로드 요금. 비정상 인스턴스는 종료되고 교체되어 현재 인스턴스 수준을 다음에서 유지합니다. 항상. 앱은 처리를 위해 이미지의 원시 비트맵 데이터를 SQS 대기열에 배치합니다. 그것 이미지를 처리한 다음 사용자가 볼 수 있는 처리된 이미지를 게시합니다. 이 시나리오의 아키텍처는 이미지 업로드 수가 시간이 지남에 따라 변하지 않는 경우 잘 작동합니다. 그러나 시간이 지남에 따라 업로드 수가 변경되면 동적 확장을 사용하여 Auto Scaling 그룹의 용량. https://aws.amazon.com/sqs/#:~:text=Amazon%20SQS%20leverages%20the%20AWS,queues%20pro 영상%20n https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-using-sqs-queue.html\n#\r#\r질문\r#\rquestion 회사는 개발자가 기존 IAM 정책을 기존 IAM 역할에 연결하여 (과격한 실험과 민첩성 그러나 보안 운영 팀은 개발자는 기존 관리자 정책을 첨부하여 개발자가 다른 보안 정책 우회 솔루션 설계자는 이 문제를 어떻게 해결해야 합니까?\nA. 개발자가 새 정책을 생성할 때마다 알림을 보내도록 Amazon SNS 주제 생성 B. 서비스 제어 정책을 사용하여 조직 단위의 모든 계정에서 IAM 활동을 비활성화합니다. C. 개발자가 정책을 첨부하지 못하도록 하고 모든 IAM 의무를 보안에 할당합니다. 운영팀 D. 연결을 명시적으로 거부하는 개발자 IAM 역할에 대한 IAM 권한 경계 설정 관리자 정책 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사는 온프레미스에서 정적 웹 사이트를 호스팅하고 웹 사이트를 AWS로 마이그레이션하려고 합니다. 웹 사이트는 전 세계 사용자를 위해 가능한 한 빨리 로드되어야 합니다. 가장 비용 효율적인 솔루션 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. 웹 사이트 콘텐츠를 Amazon S3 버킷에 복사 정적 웹 페이지를 제공하도록 버킷 구성 content S3 버킷을 여러 AWS 리전에 복제 B. 웹 사이트 콘텐츠를 Amazon S3 버킷에 복사 정적 웹 페이지를 제공하도록 버킷 구성 콘텐츠 S3 버킷을 오리진으로 사용하여 Amazon CloudFront 구성 C. Apache HTTP를 실행하는 Amazon EBS 지원 Amazon EC2 인스턴스에 웹 사이트 콘텐츠 복사 서버 가장 가까운 오리진을 선택하도록 Amazon Route 53 지리적 위치 라우팅 정책 구성 D. Apache를 실행하는 여러 Amazon EBS 지원 Amazon EC2 인스턴스에 웹 사이트 콘텐츠 복사 여러 AWS 리전의 HTTP 서버 다음을 수행하도록 Amazon CloudFront 지리적 위치 라우팅 정책을 구성합니다. 가장 가까운 원점을 선택 정답 풀이\r...\r답: B\r#\r설명 Amazon CloudFront란 무엇입니까?\nAmazon CloudFront는 정적 및 동적 웹 배포 속도를 높이는 웹 서비스입니다. .html, .css, .js 및 이미지 파일과 같은 콘텐츠를 사용자에게 제공합니다. CloudFront에서 콘텐츠 제공 엣지 로케이션이라고 하는 전 세계 데이터 센터 네트워크를 통해 사용자가 콘텐츠를 요청할 때 CloudFront에서 제공하는 경우 사용자는 가장 낮은 콘텐츠가 최상의 성능으로 전달되도록 지연 시간(시간 지연) Amazon 사용 오리진용 S3 버킷 Amazon S3를 배포용 오리진으로 사용하는 경우 CloudFront에서 Amazon S3 버킷으로 전달하려는 객체. 다음과 같은 모든 방법을 사용할 수 있습니다. Amazon S3에서 객체를 Amazon S3로 가져오기 위해 지원합니다(예: Amazon S3 콘솔 또는 API 또는 타사 도구. 버킷에 계층을 만들어 객체를 저장할 수 있습니다. 다른 Amazon S3 버킷과 마찬가지입니다. 기존 Amazon S3 버킷을 CloudFront 오리진 서버로 사용하면 버킷이 변경되지 않습니다. 그래도; 평소와 같이 Amazon S3 객체를 저장하고 액세스하는 데 계속 사용할 수 있습니다. 표준 Amazon S3 가격. 버킷에 객체를 저장하면 일반 Amazon S3 요금이 발생합니다. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/DownloadDistS3AndCusto mOrigins.h\n#\r#\r질문\r#\rquestion 한 회사가 점수 업데이트를 백엔드 프로세서로 스트리밍하는 모바일 게임을 개발 중입니다. 그런 다음 리더보드에 결과를 게시합니다. 솔루션 설계자는 다음을 수행할 수 있는 솔루션을 설계해야 합니다. 대규모 트래픽 급증을 처리하고 모바일 게임 업데이트를 수신한 순서대로 처리하고 저장합니다. 고가용성 데이터베이스에서 처리된 업데이트. 회사는 또한 최소화하기를 원합니다. 솔루션을 유지 관리하는 데 필요한 관리 오버헤드. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?\nA. Amazon Kinesis Data Streams에 대한 푸시 점수 업데이트. Kinesis Data Streams에서 업데이트 처리 AWS 람다와 함께. 처리된 업데이트를 Amazon DynamoDB에 저장합니다. B. Amazon Kinesis Data Streams에 대한 푸시 점수 업데이트. Amazon 플릿으로 업데이트 처리 Auto Scaling용으로 설정된 EC2 인스턴스. 처리된 업데이트를 Amazon Redshifl에 저장합니다. C. Amazon Simple Notification Service(Amazon SNS) 주제에 대한 푸시 점수 업데이트. 구독 업데이트를 처리하기 위해 SNS 주제에 대한 AWS Lambda 함수. 처리된 업데이트를 SOL에 저장 Amazon EC2에서 실행되는 데이터베이스. D. Amazon Simple Queue Service(Amazon SQS) 대기열에 점수 업데이트를 푸시합니다. 함대를 사용 SQS 대기열에서 업데이트를 처리하기 위한 Auto Scaling이 있는 Amazon EC2 인스턴스. 저장 Amazon RDS 다중 AZ DB 인스턴스 에서 처리된 업데이트 . 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자가 다음 IAM 정책을 구성했습니다. 정책에서 허용하는 작업은 무엇입니까?\nA. AWS Lambda 함수는 모든 네트워크에서 삭제할 수 있습니다. B. AWS Lambda 함수는 모든 네트워크에서 생성할 수 있습니다. C. AWS Lambda 함수는 100.220.0.0/20 네트워크에서 삭제할 수 있습니다. D. AWS Lambda 함수는 220 100.16 0 20 네트워크에서 삭제할 수 있습니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 다중 지역 재해 복구를 사용하여 관계형 데이터베이스를 구현해야 합니다. 1초의 RPO(복구 시점 목표) 및 1분의 RTO(복구 시간 목표). 이를 달성할 수 있는 AWS 솔루션은 무엇입니까?\nA. Amazon Aurora 글로벌 데이터베이스 B. Amazon DynamoDB 전역 테이블. C. 다중 AZ가 활성화된 MySQL용 Amazon RDS. D. 리전 간 스냅샷 복사본이 있는 MySQL용 Amazon RDS. 정답 풀이\r...\r답변: A\r#\rRPO 1초, RTO 1분의 특징 데이터베이스 유형은 오로라입니다. #\r#\r질문\r#\rquestion 회사는 AWS에서 문서 스토리지 애플리케이션을 구축하고 있습니다. 응용 프로그램 실행 여러 가용 영역의 Amazon EC2 인스턴스. 회사는 문서 저장소가 고가용성. 문서는 요청 시 즉시 반환해야 합니다. 리드 엔지니어가 Amazon Elastic Block Store(Amazon EBS)를 사용하여 그러나 가용성 요구 사항을 충족하기 위해 다른 옵션을 고려할 용의가 있습니다. 솔루션 아키텍트는 무엇을 추천해야 합니까?\nA. EBS 볼륨을 정기적으로 스냅샷하고 추가 작업에서 해당 스냅샷을 사용하여 새 볼륨을 빌드합니다. 가용 영역. B. EC2 인스턴스 루트 볼륨에 Amazon EBS를 사용합니다. 빌드하도록 애플리케이션 구성 Amazon S3의 문서 저장소. C. EC2 인스턴스 루트 볼륨에 Amazon EBS를 사용합니다. 빌드하도록 애플리케이션 구성 Amazon S3 Glacier의 문서 저장소. D. EC2 인스턴스에 대해 최소 3개의 프로비저닝된 IOPS EBS 볼륨을 사용합니다. EC2에 볼륨 마운트 RAID 5 구성의 인스턴스. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자가 Amazon에서 고성능 컴퓨팅(HPC) 워크로드를 설계하고 있습니다. EC2 EC2 인스턴스는 서로 자주 통신해야 하며 네트워크가 필요합니다. 짧은 지연 시간과 높은 처리량으로 성능이 충족되는 EC2 구성 요건'?\nA. 하나의 가용 영역에 있는 클러스터 배치 그룹에서 EC2 인스턴스 시작 B. 하나의 가용 영역에서 분산 배치 그룹의 EC2 인스턴스 시작 C. 두 리전의 Auto Scaling 그룹에서 EC2 인스턴스를 시작하고 VPC를 피어링합니다. D. 여러 가용 영역에 걸쳐 있는 Auto Scaling 그룹에서 EC2 인스턴스 시작 정답 풀이\r...\r답변: A\r#\r설명 게재위치 그룹 새 EC2 인스턴스를 시작하면 EC2 서비스는 이러한 방식으로 인스턴스를 배치하려고 시도합니다. 모든 인스턴스가 기본 하드웨어에 분산되어 상관된 오류를 최소화합니다. 배치 그룹을 사용하여 상호 의존적인 인스턴스 그룹의 배치에 영향을 줄 수 있습니다. 작업 부하의 요구 사항을 충족합니다. 작업 부하 유형에 따라 다릅니다. 클러스터 - 가용 영역 내에서 서로 가깝게 인스턴스를 묶습니다. 이 전략을 사용하면 워크로드가 긴밀하게 연결된 노드 대 노드에 필요한 저지연 네트워크 성능 달성 HPC 응용 프로그램의 일반적인 통신입니다. https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/placement-groups.html\n#\r#\r질문\r#\rquestion 회사는 VPC 피어링 전략을 사용하여 단일 리전에서 VPC를 연결하여 다음을 허용합니다. 교차 커뮤니케이션. 최근 계정 생성 및 VPC의 증가로 인해 VPC 피어링 전략을 유지하고 회사는 수백 개의 VPC로 성장할 것으로 예상합니다. 있다 또한 일부 VPC를 사용하여 사이트 간 VPN을 생성하라는 새로운 요청도 있습니다. 솔루션 아키텍트는 여러 계정, VPNS 및 VPN에 대한 중앙 네트워킹 설정을 만드는 작업을 담당합니다. 어떤 네트워킹 솔루션이 이러한 요구 사항을 충족합니까?\nA. 공유 VPC 및 VPN 구성 및 서로 공유 B. 허브 및 스포크를 구성하고 VPC 피어링을 통해 모든 트래픽을 라우팅합니다. C. 모든 VPC와 VPN 간에 AWS Direct Connect를 구성합니다. D. AWS Transit Gateway로 전송 게이트웨이를 구성하고 모든 VPC 및 VPN을 연결했습니다. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사의 웹사이트는 제품을 대중에게 판매하는 데 사용됩니다. 사이트는 Amazon EC2에서 실행됩니다. ALB(Application Load Balancer) 뒤에 있는 Auto Scaling 그룹의 인스턴스도 있습니다. Amazon CloudFront 배포 및 AWS WAF를 사용하여 SQL 주입 공격으로부터 보호 ALB는 CloudFront 배포의 오리진입니다. 보안 로그에 대한 최근 검토 결과 웹사이트 접근을 차단해야 하는 외부 악성 IP 해결 방법 아키텍트는 애플리케이션을 보호하기 위해 무엇을 합니까?\nA. CloudFront 배포에서 네트워크 ACL을 수정하여 악성 IP에 대한 거부 규칙 추가 주소 B. AWS WAF 설정을 수정하여 악성 IP 차단을 위한 IP 일치 조건 추가 주소 C. ALB 뒤에 있는 대상 그룹의 EC2 인스턴스에 대한 네트워크 ACL을 수정하여 거부 악성 IP 주소 D. ALB 뒤에 있는 대상 그룹의 EC2 인스턴스에 대한 보안 그룹을 수정하여 거부 악성 IP 주소 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 현재 대칭 암호화 키를 하드웨어 보안 모듈(HSM)에 저장합니다. 솔루션 설계자는 키 관리를 AWS로 마이그레이션하는 솔루션을 설계해야 합니다. 솔루션은 키 교체를 허용하고 고객이 제공한 키 사용을 지원합니다. 이러한 요구 사항을 충족하려면 키 자료를 어디에 보관해야 합니까?\nA. 아마존 S3 B. AWS Secrets Manager C. AWS Systems Manager 파라미터 스토어 D. AWS 키 관리 서비스(AWS KMS) 정답 풀이\r...\r답변: D\r#\rHSM이 서비스는 키 관리 서비스입니다. #\r#\r질문\r#\rquestion 회사는 사용자의 정보를 수집, 처리 및 저장할 수 있는 잠재적 솔루션을 조사하고 있습니다. 서비스 이용 데이터. 비즈니스 목표는 회사에서 수집할 수 있는 분석 기능을 만드는 것입니다. 표준 SQL 쿼리를 사용하여 신속하게 운영 통찰력을 얻을 수 있습니다. 솔루션은 고가용성이어야 하며 데이터 계층에서 ACID(Atomicity, Consistency, Isolation, and Durability) 규정 준수를 보장합니다. 솔루션 아키텍트가 추천해야 하는 솔루션은 무엇입니까?\nA. Amazon DynamoDB 트랜잭션 사용 B. 다중 AZ 설계에서 Amazon Neptune 데이터베이스 생성 C. 다중 AZ 설계에서 MySQL 데이터베이스용 완전 관리형 Amazon RDS 사용 D. Amazon EBS 처리량 최적화 HDD를 사용하는 Amazon EC2 인스턴스에 PostgreSQL 배포 (st1) 저장. 정답 풀이\r...\r답: C\r#\r설명은 MySQL의 대한 특징입니다. #\r#\r질문\r#\rquestion 회사는 다음에서 실행되는 애플리케이션을 사용하여 전 세계 가입자에게 콘텐츠를 제공합니다. AWS 애플리케이션에는 애플리케이션 뒤의 프라이빗 서브넷에 여러 Amazon EC2 인스턴스가 있습니다. 로드 밸런서(ALB) 최근 저작권 제한 변경으로 인해 최고 정보 책임자 (CIO) 특정 국가에 대한 액세스를 차단하려고 합니다. 이러한 요구 사항을 충족하는 조치는 무엇입니까?\nA. 차단된 국가에서 들어오는 트래픽을 거부하도록 ALB 보안 그룹을 수정합니다. B. 차단된 국가에서 들어오는 트래픽을 거부하도록 EC2 인스턴스에 대한 보안 그룹을 수정합니다. C. Amazon CloudFront를 사용하여 애플리케이션을 제공하고 차단된 국가에 대한 액세스를 거부합니다. D. ALB 수신기 규칙을 사용하여 차단된 트래픽에 대한 액세스 거부 응답을 반환합니다. 국가. 정답 풀이\r...\r답: C\r#\r설명 https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/georestrictions.html \u0026ldquo;특정 국가에 대한 액세스 차단.\u0026rdquo; 지역 차단이라고도 하는 지역 제한을 사용하여 다음을 수행할 수 있습니다. 특정 지리적 위치에 있는 사용자가 귀하가 배포하는 콘텐츠에 액세스하지 못하도록 방지 CloudFront 웹 배포.\n#\r#\r질문\r#\rquestion 회사에 다음이 있는 퍼블릭 서브넷의 Amazon EC2 인스턴스에서 실행되는 웹 서버가 있습니다. 탄력적 IP 주소 기본 보안 그룹은 EC2 인스턴스에 할당됩니다. 기본 네트워크 ACL 모든 트래픽을 차단하도록 수정되었습니다. 솔루션 설계자는 웹 서버에 액세스할 수 있도록 해야 합니다. 포트 443의 모든 곳에서 이 작업을 수행할 단계 조합은 무엇입니까? (2개를 선택하십시오.)\nA. 소스 0.0.0.0/0에서 TCP 포트 443을 허용하는 규칙으로 보안 그룹을 만듭니다. B. TCP 포트 443을 대상 0 0 0 0/0으로 허용하는 규칙으로 보안 그룹을 만듭니다. C. 소스 0.0 0 0/0에서 TCP 포트 443을 허용하도록 네트워크 ACL을 업데이트합니다. D. 네트워크 ACL을 업데이트하여 소스 0.0.0.0/0에서 인바운드/아웃바운드 TCP 포트 443을 허용하고 대상 0.0.0.0/0. E. 소스 0.0.0 0/0 및 아웃바운드 TCP의 인바운드 TCP 포트 443을 허용하도록 네트워크 ACL을 업데이트합니다. 포트 32768-65535 대상 0 0 0.0/0 정답 풀이\r...\r답변: AE\r#\r#\r#\r질문\r#\rquestion 회사에서 웹 포털을 배포하고 있습니다. 회사는 웹 응용 프로그램의 일부는 공개적으로 액세스할 수 있습니다. 이를 달성하기 위해 VPC는 ​​두 개의 퍼블릭 서브넷과 2개의 프라이빗 서브넷. 애플리케이션은 다음의 여러 Amazon EC2 인스턴스에서 실행됩니다. Auto Scaling 그룹. SSL 종료는 EC2 인스턴스에서 오프로드되어야 합니다. 무엇을해야 솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 무엇을 합니까?\nA. 퍼블릭 서브넷에서 Network Load Balancer를 구성합니다. Auto Scaling 그룹 구성 프라이빗 서브넷을 만들고 이를 Application Load Balancer와 연결합니다. B. 퍼블릭 서브넷에서 Network Load Balancer를 구성합니다. Auto Scaling 그룹 구성 퍼블릭 서브넷을 만들고 이를 Application Load Balancer와 연결합니다. C. 퍼블릭 서브넷에서 Application Load Balancer를 구성합니다. Auto Scaling 그룹 구성 프라이빗 서브넷을 만들고 이를 Application Load Balancer와 연결합니다. D. 프라이빗 서브넷에서 Application Load Balancer를 구성합니다. Auto Scaling 그룹 구성 프라이빗 서브넷에서 이를 Application Load Balancer와 연결합니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon Linux EC2 인스턴스 그룹에서 애플리케이션을 실행합니다. 표준 API 호출을 사용하여 로그 파일을 작성합니다. 규정 준수를 위해 모든 로그 파일을 보관해야 합니다. 무기한으로 모든 파일에 동시에 액세스해야 하는 보고 도구에 의해 분석됩니다. 가장 비용 효율적인 솔루션을 제공하기 위해 솔루션 설계자가 사용해야 하는 스토리지 서비스는 무엇입니까?\nA. 아마존 EBS B. 아마존 EFS C. Amazon EC2 인스턴스 스토어 D. 아마존 S3 정답 풀이\r...\r답변: D\r#\r설명 아마존 S3 Amazon S3에 대한 요청은 인증되거나 익명일 수 있습니다. 인증된 액세스에는 다음이 필요합니다. AWS가 요청을 인증하는 데 사용할 수 있는 자격 증명. REST API를 직접 호출할 때 코드에서 유효한 자격 증명을 사용하여 서명을 만들고 서명을 요구. Amazon Simple Storage Service(Amazon S3)는 업계 최고의 확장성, 데이터 가용성, 보안 및 성능을 제공하는 객체 스토리지 서비스입니다. 이는 모든 규모의 고객을 의미하며 업계에서는 이를 사용하여 다음과 같은 다양한 사용 사례에 대해 모든 양의 데이터를 저장하고 보호할 수 있습니다. 웹사이트, 모바일 애플리케이션, 백업 및 복원, 아카이브, 엔터프라이즈 애플리케이션, IoT 장치 및 빅 데이터 분석. Amazon S3는 사용하기 쉬운 관리 기능을 제공하므로 특정 비즈니스, 조직 및 준수 요구 사항. Amazon S3는 99.999999999%(11 9\u0026rsquo;s)의 내구성을 위해 설계되었으며, 전 세계 기업의 수백만 응용 프로그램에 대한 데이터를 저장합니다. https://aws.amazon.com/s3/\n#\r#\r질문\r#\rquestion 금융 서비스 회사에 미국 사용자에게 서비스를 제공하는 웹 애플리케이션이 있고 유럽 ​​애플리케이션은 데이터베이스 계층과 웹 서버 계층으로 구성됩니다. 데이터베이스 계층은 다음으로 구성됩니다. us-east-1 Amazon Route 53 지리 근접 라우팅에서 호스팅되는 MySQL 데이터베이스는 트래픽을 전달하는 데 사용됩니다. 가장 가까운 지역의 인스턴스에 시스템의 성능 검토 결과 유럽 사용자가 미국과 같은 수준의 쿼리 성능을 받지 못하고 있습니다. 성능을 향상시키려면 데이터베이스 계층으로 만들어야 합니까?\nA. 데이터베이스를 Amazon RDS for MySQL로 마이그레이션 유럽 중 한 곳에서 다중 AZ 구성 지역 B. 데이터베이스를 Amazon DynamoDB로 마이그레이션 DynamoDB 전역 테이블을 사용하여 다음으로 복제 활성화 추가 지역 C. 각 리전에 MySQL 인스턴스 배포 MySQL 앞에 Application Load Balancer 배포 기본 인스턴스의 로드 줄이기 D. MySQL 호환 모드에서 Amazon Aurora 글로벌 데이터베이스로 데이터베이스 마이그레이션 유럽 ​​리전 중 하나에서 읽기 전용 복제본 구성 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 한 회사가 3계층 애플리케이션을 AWS로 마이그레이션하고 있습니다. 애플리케이션에는 MySQL이 필요합니다. 데이터 베이스. 과거에는 애플리케이션 사용자가 생성할 때 애플리케이션 성능이 좋지 않다고 보고했습니다. 새로운 항목. 이러한 성능 문제는 사용자가 서로 다른 실시간 보고서를 생성하여 발생했습니다. 근무 시간 동안 응용 프로그램에서. AWS로 이동할 때 애플리케이션의 성능을 향상시키는 솔루션은 무엇입니까?\nA. 프로비저닝된 용량이 있는 Amazon DynamoDB 테이블로 데이터를 가져옵니다. 리팩토링 보고서에 DynamoDB를 사용하는 애플리케이션. B. 컴퓨팅 최적화 Amazon EC2 인스턴스에 데이터베이스를 생성합니다. 컴퓨팅 리소스 보장 온프레미스 데이터베이스를 초과합니다. C. 여러 읽기 전용 복제본이 있는 Amazon Aurora MySQL 다중 AZ DB 클러스터를 생성합니다. 구성 보고서용 애플리케이션 리더 엔드포인트. D. Amazon Aurora MySQL 다중 AZ DB 클러스터를 생성합니다. 백업을 사용하도록 애플리케이션 구성 보고서의 끝점으로 클러스터의 인스턴스. 정답 풀이\r...\r답: C\r#\r설명 Amazon RDS 읽기 전용 복제본, 이제 다중 AZ 배포 지원 오늘부터 MySQL 및 MariaDB용 Amazon RDS 읽기 전용 복제본, 이제 다중 AZ 지원 배포. 읽기 전용 복제본을 다중 AZ와 결합하면 탄력적인 재해 복구 전략을 구축하고 데이터베이스 엔진 업그레이드 프로세스를 단순화하십시오. Amazon RDS 읽기 전용 복제본을 사용하면 데이터베이스의 읽기 전용 복사본을 하나 이상 생성할 수 있습니다. 동일한 AWS 리전 또는 다른 AWS 리전에 있는 인스턴스. 소스 업데이트 그런 다음 데이터베이스가 읽기 전용 복제본에 비동기식으로 복사됩니다. 확장성을 제공할 뿐만 아니라 읽기 작업이 많은 워크로드의 경우 읽기 전용 복제본을 독립 실행형 데이터베이스 인스턴스로 승격할 수 있습니다. 필요할 때. Amazon RDS 다중 AZ 배포는 다음 내에서 데이터베이스 인스턴스에 대한 향상된 가용성을 제공합니다. 단일 AWS 리전. 다중 AZ를 사용하면 데이터가 다른 가용 영역(AZ). 인프라 장애 발생 시 Amazon RDS는 자동 대기로 장애 조치하여 애플리케이션 중단을 최소화합니다. 이제 다중 AZ가 있는 읽기 전용 복제본을 재해 복구(DR) 전략의 일부로 사용할 수 있습니다. 프로덕션 데이터베이스. 잘 설계되고 테스트된 DR 계획은 비즈니스를 유지하는 데 중요합니다. 재해 후 연속성. 원본 데이터베이스와 다른 지역의 읽기 전용 복제본을 사용할 수 있습니다. 대기 데이터베이스로 사용하고 지역적 문제의 경우 새 프로덕션 데이터베이스로 승격 분열. 데이터베이스 엔진 업그레이드 프로세스를 위해 읽기 전용 복제본을 다중 AZ와 결합할 수도 있습니다. 너 프로덕션 데이터베이스 인스턴스의 읽기 전용 복제본을 생성하고 이를 새 데이터베이스로 업그레이드할 수 있습니다. 엔진 버전. 업그레이드가 완료되면 애플리케이션을 중지하고 읽기 전용 복제본을 승격할 수 있습니다. 독립 실행형 데이터베이스 인스턴스로 전환하고 애플리케이션을 전환합니다. 데이터베이스 인스턴스는 이미 다중 AZ 배포이므로 추가 단계가 필요하지 않습니다. Amazon RDS 읽기 전용 복제본 개요 주어진 소스 DB 인스턴스에 대해 하나 이상의 읽기 전용 복제본을 배포하는 것은 다양한 분야에서 의미가 있을 수 있습니다. 다음을 포함한 시나리오: 읽기 중심의 데이터베이스를 위해 단일 DB 인스턴스의 컴퓨팅 또는 I/O 용량 이상으로 확장 워크로드. 이 초과 읽기 트래픽을 하나 이상의 읽기 전용 복제본으로 보낼 수 있습니다. 원본 DB 인스턴스를 사용할 수 없는 동안 읽기 트래픽을 제공합니다. 어떤 경우에는 소스 DB가 예를 들어 백업에 대한 I/O 일시 중단으로 인해 인스턴스가 I/O 요청을 받지 못할 수 있음 예정된 유지 보수. 이러한 경우 읽기 트래픽을 읽기 전용 복제본으로 보낼 수 있습니다. 이 용도로 이 경우 원본 DB 인스턴스 때문에 읽기 전용 복제본의 데이터가 \u0026ldquo;부실\u0026rdquo; 사용할 수 없습니다. 비즈니스 보고 쿼리가 필요할 수 있는 비즈니스 보고 또는 데이터 웨어하우징 시나리오 기본 프로덕션 DB 인스턴스가 아닌 읽기 전용 복제본에 대해 실행합니다. 재해 복구를 구현합니다. 읽기 전용 복제본을 독립 실행형 인스턴스로 승격할 수 있습니다. 소스 DB 인스턴스가 실패하는 경우 재해 복구 솔루션입니다. https://aws.amazon.com/about-aws/whats-new/2018/01/amazon-rds-read-replicas-now-supportmulti-az-deploym https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html\n#\r#\r질문\r#\rquestion VPC-A의 Amazon EC2 인스턴스에서 실행되는 애플리케이션은 다른 인스턴스의 파일에 액세스해야 합니다. VPC-B의 EC2 인스턴스. 둘 다 따로 있습니다. AWS 계정. 네트워크 관리자는 다음을 수행해야 합니다. VPC-A에서 VPC-B의 EC2 인스턴스에 안전하게 액세스할 수 있는 솔루션을 설계합니다. 연결성 단일 실패 지점이나 대역폭 문제가 없어야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. VPC-A와 VPC-B 간에 VPC 피어링 연결을 설정합니다. B. VPC-B에서 실행되는 EC2 인스턴스에 대한 VPC 게이트웨이 엔드포인트를 설정합니다. C. 가상 프라이빗 게이트웨이를 VPC-B에 연결하고 VPC-A에서 라우팅을 활성화합니다. D. VPC-B에서 실행되는 EC2 인스턴스용 프라이빗 가상 인터페이스(VIF)를 생성하고 적절한 추가 VPC-B의 경로. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 재해 발생 시 복구하기 위해 데이터를 AWS에 복제하려고 합니다. 오늘은 시스템 관리자는 NFS 공유에 데이터를 복사하는 스크립트를 가지고 있습니다. 개별 백업 파일은 처리 오류를 처리하기 위해 애플리케이션 관리자가 짧은 대기 시간으로 액세스합니다. 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?\nA. 온프레미스 NFS 공유 대신 Amazon S3 버킷에 데이터를 복사하도록 스크립트 수정 B. 온프레미스 NFS 대신 Amazon S3 Glacier 아카이브에 데이터를 복사하도록 스크립트 수정 공유하다 C. 데이터를 Amazon Elastic File System(Amazon EFS) 볼륨 대신 복사하도록 스크립트 수정 온프레미스 NFS 공유. D. 파일 게이트웨이 가상 어플라이언스용 AWS Storage Gateway에 데이터를 복사하도록 스크립트 수정 온프레미스 NFS 공유 대신. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사는 운영 중에도 가용성이 높아야 하는 결제 애플리케이션을 구축하고 있습니다. 지역 서비스 중단 솔루션 설계자는 다음을 수행할 수 있는 데이터 스토리지 솔루션을 설계해야 합니다. 다른 AWS 리전에서 쉽게 복제 및 사용됩니다. 응용 프로그램은 또한 대기 시간이 짧은 원자성을 필요로 합니다. 즉시 사용할 수 있어야 하는 일관성, 격리 및 내구성(ACID) 트랜잭션 보고서 생성 개발 팀도 SQL을 사용해야 합니다. 이러한 요구 사항을 충족하는 데이터 스토리지 솔루션은 무엇입니까?'\nA. Amazon Aurora 글로벌 데이터베이스 B. Amazon DynamoDB 전역 테이블 C. 교차 리전 복제 및 Amazon Athena가 있는 Amazon S3 D. Amazon Elastic Block Store Amazon EBS가 있는 Amazon EC2 인스턴스의 MySQL) 스냅샷 복제 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 최소한의 요구 사항이 필요한 AWS 내에 다중 인스턴스 애플리케이션을 배포하고 있습니다. 인스턴스 간의 지연 시간. 솔루션 아키텍트는 무엇을 추천해야 합니까?\nA. 클러스터 배치 그룹과 함께 Auto Scaling 그룹을 사용합니다. B. 동일한 AWS 리전에서 단일 가용 영역이 있는 Auto Scaling 그룹을 사용합니다. C. 동일한 AWS 리전에 여러 가용 영역이 있는 Auto Scaling 그룹을 사용합니다. D. 여러 Amazon EC2 전용 호스트가 있는 Network Load Balancer를 대상으로 사용 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에서 여러 Application Load Balancer 뒤에서 웹 사이트를 호스팅하고 있습니다. 회사는 전 세계적으로 콘텐츠에 대한 다양한 배포 권한. 솔루션 아키텍트는 다음을 보장해야 합니다. 배포 권한을 위반하지 않고 사용자에게 올바른 콘텐츠를 제공합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 구성을 선택해야 합니까?\nA. AWS WAF로 Amazon CloudFront를 구성합니다. B. AWS WAF로 Application Load Balancer를 구성합니다. C. 지리적 위치 정책으로 Amazon Route 53을 구성합니다. D. 지리 근접 라우팅 정책으로 Amazon Route 53을 구성합니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 사내 데이터 센터를 통해 정적 웹 사이트를 운영합니다. 회사는 여러 서버가 모든 트래픽을 처리하지만 바쁜 날에는 서비스가 중단되고 웹사이트를 사용할 수 없게 됩니다. 회사는 전 세계적으로 입지를 확장하기를 원하며 3배로 늘릴 계획입니다. 웹사이트 트래픽. 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?\nA. 웹 사이트 콘텐츠를 Amazon S3로 마이그레이션하고 Amazon CloudFront에서 웹 사이트를 호스팅합니다. B. 웹 사이트 콘텐츠를 여러 개의 퍼블릭 탄력적 IP 주소를 사용하여 Amazon EC2 인스턴스로 마이그레이션합니다. AWS 리전. C. 웹사이트 콘텐츠를 Amazon EC2 인스턴스로 마이그레이션하고 부하가 증가함에 따라 수직으로 확장합니다. D. Amazon Route 53을 사용하여 여러 Amazon CloudFront 배포에 로드를 분산합니다. 전 세계적으로 존재하는 각 AWS 리전. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 두 개의 IAM 정책(Policy1 및 Policy2)을 생성했습니다. 두 정책 모두 IAM 그룹에 연결됩니다.\n정책1 { \u0026#34;버전\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;문\u0026#34;: [ { \u0026#34;효과\u0026#34;: \u0026#34;허용\u0026#34;, \u0026#34;행동\u0026#34;: [ \u0026#34;iam:Get*\u0026#34;, \u0026#34;iam:목록*\u0026#34;, \u0026#34;km:목록*\u0026#34;, \u0026#34;ec2:*\u0026#34;, \u0026#34;ds:*\u0026#34;, \u0026#34;로그:가져오기*\u0026#34;, \u0026#34;로그:설명*\u0026#34; ], \u0026#34;자원\u0026#34;: \u0026#34;*\u0026#34; } ] } #\r정책1 { \u0026#34;버전\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;성명\u0026#34;: [ { \u0026#34;효과\u0026#34;: \u0026#34;거부\u0026#34;, \u0026#34;작업\u0026#34;: \u0026#34;ds:삭제\u0026#34;, \u0026#34;자원\u0026#34;: \u0026#34;*\u0026#34; } ] } 클라우드 엔지니어가 IAM 그룹에 IAM 사용자로 추가됩니다. 클라우드 엔지니어는 어떤 조치를 취할까요? 수행할 수 있습니까?\nA. IAM 사용자 삭제 B. 디렉토리 삭제 C. Amazon EC2 인스턴스 삭제 D. Amazon CloudWatch Logs에서 로그 삭제 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 분기별로 액세스되는 데이터에 대한 데이터 스토리지 비용을 최적화하려고 합니다. 회사는 필요할 때 높은 처리량, 짧은 지연 시간 및 빠른 액세스가 필요합니다. 솔루션 아키텍트가 추천해야 하는 S3 스토리지 클래스는?\nA. Amazon S3 Standard-Infrequent Access(S3 Standard-IA)\nB. Amazon S3 Glacier(S3 Glacier)\nC. Amazon S3 Intelligent-Tiering(S3 Intelligent-Tiering)\nD. Amazon S3 표준(S3 표준) 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에 Amazon RDS DB에서 대부분의 메타데이터를 읽는 모바일 게임이 있습니다. 게임의 인기가 높아짐에 따라 개발자들은 게임의 속도 저하를 감지했습니다. 메타데이터 로드 시간 성능 메트릭에 따르면 단순히 데이터베이스를 확장하는 것은 도움이 되지 않습니다. 솔루션 설계자는 스냅샷 복제 및 밀리초 미만의 응답 시간 이러한 문제를 해결하기 위해 솔루션 설계자가 권장해야 하는 사항 문제?\nA. Aurora 복제본을 사용하여 데이터베이스를 Amazon Aurora로 마이그레이션\nB. 전역 테이블이 있는 Amazon DyramoDB로 데이터베이스 마이그레이션\nC. 데이터베이스 앞에 Redis용 Amazon ElastiCache 계층을 추가합니다.\nD. 데이터베이스 앞에 Amazon ElastiCache for Memcached 계층 추가 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사의 웹사이트는 사용자에게 다운로드 가능한 과거 성과 보고서를 제공합니다. NS 웹 사이트에는 전 세계적으로 회사의 웹 사이트 요구 사항을 충족하도록 확장할 수 있는 솔루션이 필요합니다. NS 솔루션은 비용 효율적이어야 합니다. 제공하고 가능한 가장 빠른 응답 시간. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 조합을 권장해야 합니까?\nA. Amazon CloudFront 및 Amazon S3\nB. AWS Lambda 및 Amazon Dynamo\nC. Amazon EC2 Auto Scaling이 있는 Application Load Balancer\nD. 내부 애플리케이션 로드 밸런싱이 있는 Amazon Route 53 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 AWS CloudTrail 로그가 로그 파일을 Amazon S3 버킷에 전달하도록 설정했습니다. 각 개발자 계정. 회사는 간소화를 위해 중앙 AWS 계정을 만들었습니다. 관리 및 감사 검토. 내부 감사자는 CloudTrail 로그에 액세스해야 하지만 액세스해야 합니다. 모든 개발자 계정 사용자에 대해 제한해야 합니다. 솔루션은 안전하고 최적화되어야 합니다. 솔루션 설계자는 이러한 요구 사항을 어떻게 충족해야 합니까?\nA. 각 개발자 계정에서 AWS Lambda 함수를 구성하여 로그 파일을 중앙 파일에 복사합니다. 계정. 감사자의 중앙 계정에서 IAM 역할을 생성합니다. 제공하는 IAM 정책 연결 버킷에 대한 읽기 전용 권한. B. 각 개발자 계정에서 CloudTrail을 구성하여 로그 파일을 S3 버킷의 중앙 계정. 감사자의 중앙 계정에 IAM 사용자를 생성합니다. IAM 정책 연결 버킷에 대한 전체 권한을 제공합니다. C. 각 개발자 계정에서 CloudTrail을 구성하여 로그 파일을 S3 버킷에 전달합니다. 중앙 계정. 감사자의 중앙 계정에서 IAM 역할을 생성합니다. IAM 정책 연결 버킷에 읽기 전용 권한을 제공합니다. D. S3 버킷에서 로그 파일을 복사하도록 중앙 계정에서 AWS Lambda 함수 구성 각 개발자 계정에서. 감사자의 중앙 계정에 IAM 사용자를 생성합니다. IAM 연결 버킷에 대한 전체 권한을 제공하는 정책입니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 보안상의 이유로 프라이빗 서브넷에 여러 Amazon EC2 인스턴스를 설정했습니다. 이러한 인스턴스는 Amazon S3에서 대량의 데이터를 읽고 쓰는 애플리케이션을 호스팅합니다. 정기적으로. 현재 서브넷 라우팅은 NAT를 통해 인터넷으로 향하는 모든 트래픽을 지시합니다. 회사는 게이트웨이의 능력에 영향을 미치지 않으면서 전체 비용을 최적화하기를 원합니다. Amazon S3 또는 외부 인터넷과 통신하기 위한 애플리케이션 솔루션 설계자는 비용을 최적화하기 위해 무엇을 합니까?\nA. 추가 NAT 게이트웨이 생성 NAT 게이트웨이로 라우팅하도록 라우팅 테이블 업데이트 S3 트래픽을 허용하는 네트워크 ACL B. 인터넷 게이트웨이 생성 인터넷 게이트웨이로 트래픽을 라우팅하도록 라우팅 테이블 업데이트 업데이트 S3 트래픽을 허용하는 네트워크 ACL. C. Amazon S3용 VPC 엔드포인트 생성 엔드포인트 정책을 엔드포인트에 연결 경로 업데이트 VPC 엔드포인트로 트래픽을 보내는 테이블 D. VPC 외부에 AWS Lambda 함수를 생성하여 S3 요청을 처리합니다. EC2 인스턴스를 사용하여 Lambda 함수를 호출할 수 있습니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 웹 애플리케이션은 AWS 클라우드에 배포되며 다음과 같은 2계층 아키텍처로 구성됩니다. 웹 계층과 데이터베이스 계층을 포함 웹 서버는 XSS(교차 사이트 스크립팅)에 취약합니다. 공격 솔루션 설계자는 취약점을 수정하기 위해 무엇을 해야 합니까?\nA. 클래식 로드 밸런서 생성 로드 밸런서 뒤에 웹 계층을 배치하고 AWS WAF 활성화 B. 네트워크 로드 밸런서 생성 로드 밸런서 뒤에 웹 계층을 배치하고 AWS WAF 활성화 C. 애플리케이션 로드 밸런서 생성 로드 밸런서 뒤에 웹 계층을 배치하고 AWS WAF 활성화 D. 애플리케이션 로드 밸런서 생성 로드 밸런서 뒤에 웹 계층을 배치하고 AWS Shield Standard 사용 정답 풀이\r...\r답: C\r#\r설명 사이트 간 스크립팅 일치 조건 작업 공격자는 때때로 웹의 취약점을 악용하기 위해 웹 요청에 스크립트를 삽입합니다. 응용 프로그램. 웹의 일부를 식별하기 위해 하나 이상의 사이트 간 스크립팅 일치 조건을 만들 수 있습니다. URI 또는 ​​쿼리 문자열과 같은 요청은 AWS WAF Classic에서 악성 스크립트. 프로세스 후반에 웹 ACL을 생성할 때 허용할지 또는 악성 스크립트가 포함된 것으로 보이는 요청을 차단합니다. 웹 애플리케이션 방화벽 이제 AWS WAF를 사용하여 Application Load Balancer에서 웹 애플리케이션을 보호할 수 있습니다. AWS WAF는 일반 웹으로부터 웹 애플리케이션을 보호하는 데 도움이 되는 웹 애플리케이션 방화벽입니다. 애플리케이션 가용성에 영향을 미치거나 보안을 손상시키거나 과도하게 소비할 수 있는 익스플로잇 자원. https://docs.aws.amazon.com/waf/latest/developerguide/classic-web-acl-xss-conditions.html https://aws.amazon.com/elasticloadbalancing/features/\n#\r#\r질문\r#\rquestion 회사에 시간에 민감한 대량의 데이터를 생성하는 온프레미스 애플리케이션이 있습니다. Amazon S3에 백업되는 데이터. 응용 프로그램이 성장했으며 사용자 불만 사항이 있습니다. 인터넷 대역폭 제한. 솔루션 설계자는 다음을 허용하는 장기적인 솔루션을 설계해야 합니다. Amazon S3에 대한 적시 백업과 인터넷 연결에 대한 영향을 최소화하기 위해 내부 사용자. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. AWS VPN 연결을 설정하고 VPC 게이트웨이 엔드포인트를 통해 모든 트래픽을 프록시합니다. B. 새로운 AWS Direct Connect 연결을 설정하고 이 새로운 연결 C. 매일 AWS Snowball 디바이스 주문 Snowball 디바이스에 데이터를 로드하고 디바이스 반환 매일 AWS로 D. AWS Management Console을 통해 지원 티켓 제출 S3 서비스 제거 요청 계정에서 한도. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion Amazon EC2 인스턴스에서 실행되는 애플리케이션은 다음의 타일에 안전하게 액세스해야 합니다. Amazon Elastic File System(Amazon I 타일 시스템. EFS 타일은 미사용 암호화를 사용하여 저장됩니다. 타일에 액세스하는 가장 안전한 솔루션은 무엇입니까?\nA. Amazon EFS 탑재 시 TLS 활성화\nB. 암호화 키를 애플리케이션 코드에 저장\nC. Amazon EFS 탑재 시 AWS Key Management Service(AWS KMS) 활성화\nD. Amazon S3 버킷에 암호화 키를 저장하고 IAM 역할을 사용하여 EC2 인스턴스에 권한 부여 접근 권한 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 고객 대면 애플리케이션을 설계하고 있습니다. 응용 프로그램은 다음과 같이 예상됩니다. 연중 시간 및 명확하게 정의된 액세스에 따라 다양한 양의 읽기 및 쓰기 가능 일년 내내 패턴. 관리를 위해서는 데이터베이스 감사 및 확장 관리가 필요합니다. AWS 클라우드에서. RPO(복구 시점 목표)는 5시간 미만이어야 합니다. 어떤 솔루션이 이를 달성할 수 있습니까? (2개를 선택하십시오.)\nA. Auto Scaling과 함께 Amazon DynamoDB를 사용합니다. 온디맨드 백업 및 AWS CloudTrail을 사용합니다. B. Auto Scaling과 함께 Amazon DynamoDB를 사용합니다. 온디맨드 백업 및 Amazon DynamoDB 사용 스트림. C. Amazon Redshift를 사용하여 동시성 확장을 구성합니다. 감사 로깅을 활성화합니다. 데이터베이스 수행 4시간마다 스냅샷. D. 프로비저닝된 IOPS와 함께 Amazon RDS를 사용합니다. 데이터베이스 감사 매개변수를 활성화합니다. 공연하다 5시간마다 데이터베이스 스냅샷 E. Auto Scaling과 함께 Amazon RDS를 사용합니다. 데이터베이스 감사 매개변수를 활성화합니다. 백업 구성 보관 기간은 최소 1일입니다. 정답 풀이\r...\r답: AB\r#\r#\r#\r질문\r#\rquestion 경영진은 IPv6이 활성화된 모든 AWS VPC를 배포하기로 결정했습니다. 솔루션 아키텍트가 새 인스턴스를 시작하려고 하고 인스턴스가 없다는 오류를 수신합니다. 서브넷에서 사용 가능한 충분한 IP 주소 공간 솔루션 설계자는 이 문제를 해결하기 위해 무엇을 해야 합니까?\nA. VPC 생성 시 IPv6만 사용했는지 확인합니다. B. 범위가 더 넓은 새 IPv4 서브넷을 생성한 후 인스턴스를 시작합니다. C. 더 넓은 범위의 새로운 IPv6 전용 서브넷을 생성한 후 인스턴스를 시작합니다. D. IPv4 서브넷을 비활성화하고 모든 인스턴스를 IPv6으로만 마이그레이션 완료되면 시작 사례 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 다음 작업에 사용되는 새로운 웹 애플리케이션을 위한 스토리지 아키텍처를 설계 stonng 및 보기 엔지니어링 도면. 모든 애플리케이션 구성 요소는 AWS에 배포됩니다. 하부 구조. 응용 프로그램 설계는 사용자가 대기 시간을 최소화하기 위해 캐싱을 지원해야 합니다. 로드할 엔지니어링 도면. 애플리케이션은 페타바이트의 데이터를 저장할 수 있어야 합니다. 어느 솔루션 설계자가 사용해야 하는 스토리지와 캐싱의 조합은 무엇입니까?\nA. Amazon CloudFront를 사용하는 Amazon S3\nB. Amazon ElastiCache가 포함된 Amazon S3 Glacier\nC. Amazon CloudFront를 사용한 Amazon Elastic Block Store(Amazon EBS) 볼륨\nD. Amazon ElastiCache가 포함된 AWS Storage Gateway 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon S3 버킷에서 정적 웹 사이트를 호스팅하고 있습니다. 아마존 시우드프론트. 이 회사는 미국에 사용자가 있습니다. 캐나다, 유럽 및 비용 절감을 원합니다. 뭐 솔루션 아키텍트가 추천해야 합니까?\nA. CloudFront 캐싱 TTL(Time to Live)을 기본값에서 더 긴 기간으로 조정합니다. B. Lambda@Edge로 CloudFront 이벤트를 구현하여 웹 사이트의 데이터 처리를 실행합니다. C. 서비스가 제공되는 국가의 위치만 포함하도록 CloudFront 가격 등급을 수정합니다. D. CloudFront SSL(Secure Sockets Layer) 인증서를 구현하여 보안을 더 가깝게 서비스를 제공하는 국가의 위치입니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon EC2 인스턴스 집합에서 교육 사이트를 호스팅합니다. 회사는 예상 사이트에 있는 수십 개의 교육 비디오로 구성된 새로운 과정이 매우 인기가 있을 것입니다. 에 출시될 때 일주. 솔루션 설계자는 예상되는 서버 부하를 최소화하기 위해 무엇을 해야 합니까?\nA. Redis용 Amazon ElastiCache에 비디오 저장 다음을 사용하여 비디오를 제공하도록 웹 서버를 업데이트합니다. Elastic ache API B. Amazon Elastic File System(Amazon EFS)에 동영상 저장 웹용 사용자 데이터 스크립트 생성 서버에서 EFS 볼륨을 마운트합니다. C. Amazon S3 버킷에 비디오 저장 오리진이 있는 Amazon CloudFlight 배포 생성 해당 S3 버킷의 액세스 ID(OAI) OAI에 대한 Amazon S3 액세스를 제한합니다. D. Amazon S3 버킷에 비디오를 저장합니다. 액세스할 AWS Storage Gateway 파일 게이트웨이 생성 S3 버킷 웹 서버가 파일 게이트웨이를 탑재할 사용자 데이터 스크립트 생성 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 모든 이메일을 7년 동안 외부에 저장 및 보관해야 한다는 규정 요구 사항을 준수해야 합니다. 관리자가 다음 위치에 압축된 이메일 파일을 생성했습니다. 파일을 AWS 스토리지로 전송하는 관리형 서비스를 원합니다. 솔루션 설계자는 어떤 관리형 서비스를 권장해야 합니까?\nA. Amazon Elastic File System(Amazon EPS) B. 아마존 S3 빙하 C. AWS 백업 D. AWS 스토리지 게이트웨이 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자가 다중 서브넷 VPC 아키텍처를 개발 중입니다. 솔루션은 2개의 가용 영역에 있는 6개의 서브넷으로 구성됩니다. 서브넷은 퍼블릭, 프라이빗 및 데이터베이스 전용 프라이빗 서브넷에서 실행되는 Amazon EC2 인스턴스만 데이터베이스에 액세스할 수 있습니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 퍼블릭 서브넷의 CIDR 블록에 대한 경로를 제외하는 이제 라우팅 테이블을 생성합니다. 라우트 테이블은 데이터베이스 서브넷입니다. B. 공개 인스턴스에서 사용하는 보안 그룹의 침입을 거부하는 보안 그룹 생성 서브넷 Amazon RDS DB 인스턴스에 보안 그룹 연결 C. 프라이빗의 인스턴스가 사용하는 보안 그룹에서 유입을 허용하는 보안 그룹 생성 서브넷. 보안 그룹을 Amazon RDS DB 인스턴스에 연결합니다. D. 퍼블릭 서브넷과 프라이빗 서브넷 사이에 새로운 피어링 연결을 생성합니다. 만들기 프라이빗 서브넷과 데이터베이스 서브넷 간의 다른 피어링 연결. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사에서 기존 워크로드에 대한 AWS Well-Architected Framework 검토를 수행하고 있습니다. AWS에 배포됩니다. 검토 결과 동일한 Amazon EC2에서 실행되는 공개 웹 사이트가 확인되었습니다. 다른 인스턴스를 지원하기 위해 최근에 설치된 Microsoft Active Directory 도메인 컨트롤러로서의 인스턴스 AWS 서비스. 솔루션 설계자는 개선할 새로운 설계를 추천해야 합니다. 아키텍처의 보안을 유지하고 IT 직원의 관리 요구를 최소화합니다. 솔루션 설계자는 무엇을 권장해야 합니까?\nA. AWS Directory Service를 사용하여 관리형 Active Directory를 생성합니다. Active Directory 제거 현재 EC2 인스턴스.\nB. 동일한 서브넷에 다른 EC2 인스턴스를 생성하고 여기에 Active Directory를 다시 설치합니다. 제거 액티브 디렉토리.\nC. AWS Directory Service를 사용하여 Active Directory 커넥터를 생성합니다. 프록시 Active Directory 현재 EC2 인스턴스에서 실행 중인 활성 도메인 컨트롤러에 대한 요청.\nD. SAML(Security Assertion Markup Language) 2.0으로 AWS Single Sign-On(AWS SSO) 활성화 현재 Active Directory 컨트롤러와의 페더레이션. EC2 인스턴스의 보안 그룹을 다음으로 수정합니다. Active Directory에 대한 공개 액세스를 거부합니다. 정답 풀이\r...\r답변: A\r#\r설명 AWS 관리형 Microsoft AD AWS Directory Service를 사용하면 Microsoft Active Directory(AD)를 관리형 서비스로 실행할 수 있습니다. AWS AWS Managed Microsoft AD라고도 하는 Microsoft Active Directory용 디렉터리 서비스는 Windows Server 2012 R2 기반. 이 디렉토리 유형을 선택하고 실행하면 다음과 같이 생성됩니다. 가상 사설 클라우드(VPC)에 연결된 고가용성 도메인 컨트롤러 쌍. NS 도메인 컨트롤러는 선택한 지역의 다른 가용 영역에서 실행됩니다. 호스트 모니터링 및 복구, 데이터 복제, 스냅샷 및 소프트웨어 업데이트가 자동으로 구성되고 당신을 위해 관리. https://docs.aws.amazon.com/directoryservice/latest/admin-guide/directory_microsoft_ad.html\n#\r#\r질문\r#\rquestion 회사에서 AWS에서 확장 가능한 웹 애플리케이션을 호스팅하려고 합니다. 응용 프로그램에 액세스됩니다 전 세계 여러 지역의 사용자가 응용 프로그램 사용자는 다운로드할 수 있습니다. 최대 기가바이트 크기의 고유한 데이터를 업로드할 수 있습니다. 개발 팀은 비용 효율적인 업로드 및 다운로드 대기 시간을 최소화하고 성능을 최대화하는 솔루션입니다. 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. Transfer Acceleration이 포함된 Amazon S3를 사용하여 애플리케이션을 호스팅합니다. B. CacheControl 헤더가 있는 Amazon S3를 사용하여 애플리케이션을 호스팅합니다. C. Auto Scaling 및 Amazon CloudFront를 사용하여 애플리케이션을 호스팅하는 Amazon EC2. D. Auto Scaling과 함께 Amazon EC2 및 Amazon ElastiCache를 사용하여 애플리케이션을 호스팅합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 예산 계획의 일환으로 경영진은 사용자별로 나열된 AWS 청구 항목 보고서를 원합니다. 데이터는 부서 예산을 만드는 데 사용됩니다. 솔루션 아키텍트는 다음을 결정해야 합니다. 이 보고서 정보를 얻는 가장 효율적인 방법입니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. Amazon Athena로 쿼리를 실행하여 보고서를 생성합니다. B. 비용 탐색기에서 보고서를 생성하고 보고서를 다운로드합니다. C. 청구 대시보드에서 청구 내역에 액세스하여 청구서를 다운로드합니다. D. AWS 예산에서 비용 예산을 수정하여 Amazon Simple Email Service(Amazon SES)에 알림을 보냅니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion AWS로 이동할 때 애플리케이션의 성능을 향상시키는 솔루션은 무엇입니까?\nA. 프로비저닝된 용량이 있는 Amazon DynamoDB 테이블로 데이터를 가져옵니다. 리팩토링 보고서에 DynamoDB를 사용하는 애플리케이션. B. 컴퓨팅 최적화 Amazon EC2 인스턴스에 데이터베이스 생성 컴퓨팅 리소스 보장 온프레미스 데이터베이스 초과 C. 여러 읽기 전용 복제본이 있는 Amazon Aurora MySQL 다중 AZ DB 클러스터를 생성합니다. 구성 리더 엔드포인트를 사용하여 보고서를 작성하는 응용 프로그램입니다. D. Amazon Aurora MySQL 다중 AZ DB 클러스터 생성 백업을 사용할 애플리케이션 구성 보고서의 끝점으로 클러스터의 인스턴스. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 테이프 백업 솔루션을 사용하여 주요 애플리케이션 데이터를 매일 오프사이트에 저장하고 있습니다. 데이터 볼륨은 약 50TB입니다. 회사는 규정 준수를 위해 7년 동안 백업을 보관해야 합니다. 목적 백업은 거의 액세스하지 않으며 일반적으로 백업이 필요한 경우 일주일 전에 통지합니다. 회사는 이제 스토리지 비용을 줄이고 클라우드 기반 옵션을 고려하고 있습니다. 테이프 관리의 운영 부담 회사는 또한 전환(ROM 클라우드로의 테이프 백업은 중단을 최소화합니다. 가장 비용 효율적인 스토리지 솔루션은 무엇입니까?'\nA. Amazon Storage Gateway를 사용하여 Amazon Glacier Deep Archive에 백업 B. AWS Snowball Edge를 사용하여 백업을 Amazon S3 Glacier와 직접 통합합니다. C. 백업 데이터를 Amazon S3에 복사하고 Amazon S3로 데이터를 이동하는 수명 주기 정책 생성 빙하 D. Amazon Storage Gateway를 사용하여 Amazon S3에 백업하고 수명 주기 정책을 생성하여 Amazon S3 Glacier에 백업 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에 Amazon EC2에서 6개의 프런트 엔드 웹 서버를 실행하는 다중 계층 애플리케이션이 있습니다. ALB(Application Load Balancer) A 솔루션 뒤의 단일 가용 영역에 있는 Auto Scaling 그룹 설계자는 애플리케이션을 수정하지 않고 고가용성을 위해 인프라를 수정해야 함 솔루션 설계자는 고가용성을 제공하는 어떤 아키텍처를 선택해야 합니까?\nA. 두 리전에서 각각 3개의 인스턴스를 사용하는 Auto Scaling 그룹 생성 B. 2개의 가용 영역 각각에서 3개의 인스턴스를 사용하도록 Auto Scaling 그룹 수정 C. 다른 인스턴스에서 더 많은 인스턴스를 빠르게 생성하는 데 사용할 수 있는 Auto Scaling 템플릿 생성 지역 D. 라운드 로빈 구성에서 Amazon EC2 인스턴스 앞의 ALB를 변경하여 균형 조정 웹 계층으로의 트래픽 정답 풀이\r...\r답: B\r#\r설명 https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html 확장 하나의 가용성이 있는 경우 추가 가용 영역으로 확장 및 로드 밸런싱된 애플리케이션 영역이 비정상이거나 사용할 수 없게 되면 Amazon EC2 Auto Scaling이 새로운 인스턴스를 시작합니다. 영향을 받지 않는 영역. 비정상 가용 영역이 정상 상태로 돌아오면 Amazon EC2 Auto Scaling은 자동으로 애플리케이션 인스턴스를 모든 영역에 균등하게 재분배합니다. Auto Scaling 그룹. Amazon EC2 Auto Scaling에서 새 인스턴스 시작을 시도하여 이를 수행합니다. 인스턴스가 가장 적은 가용 영역. 그러나 시도가 실패하면 Amazon EC2 Auto Scaling 성공할 때까지 다른 가용 영역에서 시작을 시도합니다. 가용성을 추가하여 확장되고 로드 밸런싱된 애플리케이션의 가용성을 확장할 수 있습니다. Auto Scaling 그룹으로 영역을 지정한 다음 로드 밸런서에 대해 해당 영역을 활성화합니다. 당신이 새 가용 영역이 활성화되면 로드 밸런서는 모든 활성화된 영역. https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-add-availability-zone.html\n#\r#\r질문\r#\rquestion 회사는 Amazon RDS가 지원하는 Amazon EC2에서 매우 민감한 애플리케이션을 실행하고 있습니다. 데이터베이스 규정 준수 규정은 모든 개인 식별 정보(Pll)를 암호화된 미사용 이 요구 사항을 충족하기 위해 솔루션 설계자가 권장해야 하는 솔루션 최소한의 인프라 변경으로??\nA. AWS Certificate Manager를 배포하여 인증서 생성 인증서를 사용하여 인증서를 암호화합니다. 데이터베이스 볼륨 B. AWS CloudHSM을 배포합니다. 암호화 키를 생성하고 고객 마스터 키(CMK)를 사용하여 데이터베이스 볼륨을 암호화합니다. C. AWS Key Management Service 고객 마스터 키(AWS KMS)를 사용하여 SSL 암호화 구성 CMK) 데이터베이스 볼륨 암호화 D. 다음을 사용하여 Amazon Elastic Block Store {Amazon EBS) 암호화 및 Amazon RDS 암호화를 구성합니다. 인스턴스 및 데이터베이스 볼륨을 암호화하기 위한 AWS Key Management Service(AWS KMS) 키. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사의 데이터에는 NAS(Network Attached Storage)에 700TB의 백업 데이터가 저장되어 있습니다. 센터 이 백업 데이터는 간헐적인 규제 요청에 액세스할 수 있어야 하며 7년 유지. 회사는 이 백업 데이터를 데이터 센터에서 AWS로 마이그레이션하기로 결정했습니다. 마이그레이션은 1개월 이내에 완료되어야 합니다. 회사에는 500Mbps의 전용 대역폭이 있습니다. 데이터 전송에 사용할 수 있는 공용 인터넷 연결에서. 솔루션 설계자는 최저 비용으로 데이터를 마이그레이션하고 저장하기 위해 무엇을 해야 합니까?\nA. AWS Snowball 디바이스가 데이터를 전송하도록 명령합니다. 수명 주기 정책을 사용하여 파일을 다음으로 전환합니다. Amazon S3 Glacier 딥 아카이브 B. 데이터 센터와 Amazon VPC 사이에 VPN 연결 배포 AWS CLI를 사용하여 온프레미스에서 Amazon S3 Glacier로 데이터를 전송합니다. C. 500Mbps AWS Direct Connect 연결을 프로비저닝하고 데이터를 Amazon S3로 전송합니다. 사용 파일을 Amazon S3 Glacier Deep Archive로 전환하기 위한 수명 주기 정책. D. AWS DataSync를 사용하여 데이터를 전송하고 DataSync 에이전트를 온프레미스에 배포합니다. Amazon S3 Glacier로 온프레미스 NAS 스토리지에서 파일을 복사하는 DataSync 작업 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 애플리케이션에는 개발 환경(DEV) 및 프로덕션 환경이 필요합니다. (PROD) 몇 년 동안. DEV 인스턴스는 정상 업무 시간 동안 매일 10시간 동안 실행됩니다. PROD 인스턴스는 매일 24시간 실행됩니다. 솔루션 아키텍트가 결정해야 하는 비용을 최소화하기 위한 컴퓨팅 인스턴스 구매 전략. 가장 비용 효율적인 솔루션은 무엇입니까?\nA. 스팟 인스턴스가 있는 DEV 및 온디맨드 인스턴스가 있는 PROD B. 온디맨드 인스턴스가 있는 DEV 및 스팟 인스턴스가 있는 PROD C. 정기 예약 인스턴스가 있는 DEV 및 예약 인스턴스가 있는 PROD D. 온디맨드 인스턴스가 있는 DEV 및 정기 예약 인스턴스가 있는 PROD 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사에서 새 AWS 계정을 만들었습니다. 계정이 새로 프로비저닝되었으며 기본 설정으로 변경되었습니다. 회사는 보안에 대해 우려하고 있습니다. AWS 계정 루트 사용자. 루트 사용자를 보호하려면 어떻게 해야 합니까?\nA. 일일 관리 작업을 위한 IAM 사용자 생성 루트 사용자를 비활성화합니다. B. 일일 관리 작업을 위한 IAM 사용자 생성 루트에서 다단계 인증 활성화 사용자. C. 루트 사용자에 대한 액세스 키를 생성합니다. 대신 일일 관리 작업에 액세스 키를 사용하십시오. AWS Management 콘솔의. D. 최상위 솔루션 설계자에게 루트 사용자 자격 증명을 제공합니다. 솔루션 아키텍트 보유 일상적인 관리 작업에 루트 사용자를 사용합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 최근 전 세계로 확장한 회사에서 사용자가 애플리케이션에 액세스할 수 있도록 하려고 합니다. 이러한 지리적 위치에 있습니다. 애플리케이션이 뒤에 있는 Amazon EC2 인스턴스에 배포 중입니다. Auto Scaling 그룹의 Application Load Balancer. 회사는 능력 전환 트래픽이 필요합니다. 한 지역의 자원을 다른 지역으로. 솔루션 아키텍트는 무엇을 추천해야 합니까?\nA. Amazon Route 53 지연 시간 라우팅 정책 구성 B. Amazon Route 53 지리적 위치 라우팅 정책 구성 C. Amazon Route 53 지리 근접성 파울링 정책을 구성합니다. D. Amazon Route 53 다중값 응답 라우팅 정책 구성 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon S3 버킷 내에서 정적 웹 사이트를 호스팅합니다. 솔루션 아키텍트가 필요로 하는 실수로 삭제한 경우 데이터를 복구할 수 있는지 확인합니다. 어떤 조치가 이를 달성할 것입니까?\nA. Amazon S3 버전 관리 활성화 B. Amazon S3 Intelligent-Tiering을 활성화합니다. C. Amazon S3 수명 주기 정책 활성화 D. Amazon S3 교차 리전 복제를 활성화합니다. 정답 풀이\r...\r답변: A\r#\r설명 버전 관리가 활성화되면 데이터를 복구할 수 있으며 파일 삭제, MFA 삭제와 같은 추가 보호 기능도 제공합니다. MFA 삭제는 AWS Management 콘솔이 아닌 CLI 또는 API 상호 작용에 대해서만 작동합니다. 또한 당신은 IAM 사용자 자격 증명을 사용하여 MFA로 버전 DELETE 작업을 수행할 수 없습니다. 루트를 사용해야 합니다. AWS 계정. https://aws.amazon.com/blogs/security/securing-access-to-aws-using-mfa-part-3/ 객체 버전 관리 Amazon S3 버전 관리를 사용하여 하나의 버킷에 여러 버전의 객체를 보관하십시오. 예를 들어, 당신은 my-image.jpg(버전 111111) 및 my-image.jpg(버전 222222)를 단일 버킷에 저장할 수 있습니다. 시즌3 버전 관리는 의도하지 않은 덮어쓰기 및 삭제의 결과로부터 사용자를 보호합니다. 당신은 또한 수 이전 버전에 액세스할 수 있도록 개체를 아카이브하는 데 사용합니다. 버킷에서 명시적으로 S3 버전 관리를 활성화해야 합니다. 기본적으로 S3 버전 관리는 비활성화되어 있습니다. 버전 관리를 활성화했는지 여부에 관계없이 버킷의 각 객체에는 버전 ID가 있습니다. 만약에 버전 관리를 활성화하지 않은 경우 Amazon S3는 버전 ID 값을 null로 설정합니다. S3 버전 관리의 경우 활성화된 경우 Amazon S3는 객체에 대한 버전 ID 값을 할당합니다. 이 값은 다른 것과 구별됩니다. 동일한 키의 버전. https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html\n#\r#\r질문\r#\rquestion 회사는 온프레미스에서 AWS로 3계층 웹 애플리케이션을 마이그레이션하기로 결정합니다. 구름. 새 데이터베이스는 스토리지 용량을 동적으로 확장하고 다음을 수행할 수 있어야 합니다. 테이블 조인. 이러한 요구 사항을 충족하는 AWS 서비스는 무엇입니까?\nA. 아마존 오로라 B. SqlServer용 Amazon RDS C. Amazon DynamoDB 스트림 D. Amazon DynamoDB 온디맨드 정답 풀이\r...\r답변: A\r#\rDynamoDB는 조인이 가능하지 않습니다. (NoSQL) #\r#\r질문\r#\rquestion 웹 애플리케이션은 실시간 처리를 지원하기 위해 Amazon S3에 주문 데이터를 유지해야 합니다. 솔루션 설계자는 확장 가능하고 내결함성이 있는 아키텍처를 만들어야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? (2개 선택)\nA. Amazon DynamoDB 테이블에 주문 이벤트를 씁니다. DynamoDB 스트림을 사용하여 AWS 트리거 페이로드를 구문 분석하고 데이터를 Amazon S3에 쓰는 Lambda 함수. B. Amazon Simple Queue Service(Amazon SQS) 대기열에 주문 이벤트를 씁니다. 대기열을 사용하여 페이로드를 구문 분석하고 데이터를 Amazon S3에 쓰는 AWS Lambda 함수를 트리거합니다. C. Amazon Simple Notification Service(Amazon SNS) 주제에 주문 이벤트를 씁니다. SNS 이용 페이로드를 구문 분석하고 Amazon S3에 데이터를 쓰는 AWS Lambda 함수를 트리거하는 주제 D. Amazon Simple Queue Service(Amazon SQS) 대기열에 주문 이벤트를 씁니다. 아마존을 이용하다 EventBridge(Amazon CloudWatch Events) 규칙은 다음을 구문 분석하는 AWS Lambda 함수를 트리거합니다. 페이로드 및 Amazon S3에 데이터 쓰기 E. Amazon Simple Notification Service(Amazon SNS) 주제에 주문 이벤트 쓰기 Amazon EventBridge(Amazon CloudWatch Events) 규칙은 다음을 수행하는 AWS Lambda 함수를 트리거합니다. 페이로드를 구문 분석하고 데이터를 Amazon S3에 씁니다. 정답 풀이\r...\r답: BE\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon EC2 Linux 인스턴스에서 웹 사이트를 운영합니다. 일부 사례는 faring 문제 해결은 실패한 인스턴스의 스왑 공간이 충분하지 않음을 나타냅니다. 운영팀 리드는 이를 모니터링할 솔루션이 필요합니다. 솔루션 아키텍트는 무엇을 추천해야 합니까?\nA. Amazon CloudWatch SwapUsage 지표 차원을 구성합니다. SwapUsage 모니터링 CloudWatch의 EC2 지표에서 차원.\nB. EC2 메타데이터를 사용하여 정보를 수집한 다음 Amazon CloudWatch 사용자 지정 지표에 게시합니다. CloudWatch에서 SwapUsage 지표를 모니터링합니다.\nC. 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다. 정해진 일정에 따라 적절한 스크립트를 실행합니다. CloudWatch에서 SwapUtilizalion 지표를 모니터링합니다.\nD. EC2 콘솔에서 세부 모니터링을 활성화합니다. Amazon CloudWatch SwapUtilizalion 생성 맞춤 측정항목. CloudWatch에서 SwapUtilization 지표를 모니터링합니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 애플리케이션이 Amazon EC2 인스턴스에서 실행 중입니다. 애플리케이션은 Amazon S3 버킷에 저장됩니다. 버킷은 인터넷 액세스로부터 보호되어야 합니다. VPC 내의 서비스만 버킷에 액세스할 수 있도록 허용합니다. 이를 달성하기 위해 아카이브된 솔루션이 취해야 하는 조치의 조합\u0026rsquo;(2개 선택)\nA. Amazon S3용 VPC 엔드포인트를 생성합니다. B. 버킷에 대한 서버 액세스 로깅 활성화 C. 버킷 ​​정책을 적용하여 S3 엔드포인트에 대한 액세스를 제한합니다. D. 민감한 정보가 있는 버킷에 S3 ACL 추가 E. IAM 정책을 사용하는 사용자가 특정 버킷을 사용하도록 제한 정답 풀이\r...\r답변: AC\r#\r#\r#\r질문\r#\rquestion 응용 프로그램 개발자는 업무용으로 사용할 때 프로덕션 응용 프로그램이 매우 느린 보고 사용자는 다음을 지원하는 Amazon RDS 인스턴스에 대해 대규모 프로덕션 보고서를 실행합니다. 애플리케이션. RDS instance-d에 대한 CPU 및 메모리 사용률 지표는 60%를 초과하지 않는 반면 보고 쿼리가 실행 중입니다. 비즈니스 보고 사용자는 다음 없이 보고서를 생성할 수 있어야 합니다. 애플리케이션 성능에 영향을 미칩니다. 어떤 조치가 이를 달성할 것입니까?\nA. RDS 인스턴스의 크기를 늘립니다. B. 읽기 전용 복제본을 생성하고 여기에 애플리케이션을 연결합니다. C. RDS 인스턴스에서 여러 가용 영역 활성화 D. 읽기 복제를 만들고 여기에 비즈니스 보고서를 연결합니다. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 한 회사는 최근 AWS Direct Connect를 사용하여 하이브리드 클라우드 연결을 구현했으며 현재 Amazon S3로 데이터 마이그레이션. 회사는 자동화할 완전 관리형 솔루션을 찾고 있습니다. 온프레미스 스토리지 시스템과 AWS 스토리지 간의 데이터 복제 가속화 서비스. 솔루션 설계자는 데이터를 비공개로 유지하기 위해 어떤 솔루션을 권장해야 합니까?\nA. 온프레미스 환경에 AWS DataSync 에이전트 배포 복제할 동기화 작업 구성 데이터를 가져와 AWS 서비스 엔드포인트와 연결합니다. B. 온프레미스 환경용 AWS DataSync 에이전트를 배포합니다. 일괄 작업 예약 특정 시점 스냅샷을 AWS에 복제합니다. C. 온프레미스 환경을 위한 AWS Storage Gateway 볼륨 게이트웨이 배포 데이터를 로컬에 저장하고 특정 시점 스냅샷을 AWS에 비동기식으로 백업합니다. D. 온프레미스 환경을 위한 AWS Storage Gateway 파일 게이트웨이를 배포합니다. 다음으로 구성 데이터를 로컬에 저장하고 특정 시점 스냅샷을 AWS에 비동기식으로 백업합니다. 정답 풀이\r...\r답변: A\r#\rDataSync는 계속해서 AWS로 데이터를 보내면서 Storage Gateway에 도달하면 AWS로 이에 대한 액세스를 회신합니다. #\r#\r질문\r#\rquestion 회사는 AWS에 데이터 레이크를 배포할 준비를 하고 있습니다. 솔루션 설계자는 다음을 정의해야 합니다. 암호화 전략 또는 미사용 데이터 m Amazon S3 회사의 보안 정책 상태\n키는 90일마다 교체해야 합니다. 핵심 사용자와 핵심 관리자의 업무를 엄격하게 분리해야 합니다. 키 사용 감사가 가능해야 함 솔루션 설계자는 무엇을 권장해야 합니까? A. 고객 관리형 고객 마스터 키(CMK)를 사용한 AWS KMS 관리형 키(SSE-KMS)를 사용한 서버 측 암호화 B. AWS 관리형 고객 마스터 키(CMK)를 사용한 AWS KMS 관리형 키(SSE-KMS)를 사용한 서버 측 암호화 C. 고객 관리형 고객 마스터 키(CMK)를 사용한 Amazon S3 관리형 키(SSE-S3)를 사용한 서버 측 암호화 D. AWS 관리형 고객 마스터 키(CMK)를 사용한 Amazon S3 관리형 키(SSE-S3)를 사용한 서버 측 암호화 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 한 미디어 회사가 시스템을 AWS 클라우드로 이전할 가능성을 평가하고 있습니다. NS 회사는 비디오에 대해 가능한 최대 I/O 성능과 함께 최소 10TB의 스토리지가 필요합니다. 처리. 미디어 콘텐츠를 저장하기 위한 300TB의 내구성이 뛰어난 스토리지와 충족할 수 있는 900TB의 스토리지 더 이상 사용하지 않는 아카이브 미디어에 대한 요구 사항. 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 어떤 서비스 세트를 권장해야 합니까?\nA. 최대 성능을 위한 Amazon EBS, 내구성 있는 데이터 스토리지를 위한 Amazon S3 및 Amazon S3 기록 보관용 Glacier B. 최대 성능을 위한 Amazon EBS. 내구성 있는 데이터 스토리지를 위한 Amazon EFS 및 Amazon S3 기록 보관용 Glacier C. 최대 성능을 위한 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 스토리지를 위한 Amazon EFS 및 아카이브 스토리지용 Amazon S3 D. 최대 성능을 위한 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 스토리지를 위한 Amazon S3 및 아카이브 스토리지를 위한 Amazon S3 Glacier 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 보안 팀이 팀의 모든 AWS에서 특정 서비스 또는 작업에 대한 액세스를 제한하려고 합니다. 계정. 모든 계정은 AWS Organizations의 대규모 조직에 속합니다. 솔루션은 다음과 같아야 합니다. 확장 가능하고 권한을 유지할 수 있는 단일 지점이 있어야 합니다. 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. 서비스 또는 작업에 대한 액세스를 제공하기 위해 ACL을 생성합니다. B. 계정을 허용하는 보안 그룹을 생성하고 이를 사용자 그룹에 연결 C. 각 계정에 교차 계정 역할을 만들어 서비스 또는 작업에 대한 액세스를 거부합니다. D. 루트 조직 단위에서 서비스 제어 정책을 생성하여 서비스에 대한 액세스를 거부하거나 행위 정답 풀이\r...\r답변: D\r#\r설명 https://docs.aws.amazon.com/organizations/latest/userguide/orgs_manage_policies_scp.html. 서비스 제어 정책 개념 SCP는 계정의 모든 IAM 엔터티에 대한 중앙 액세스 제어를 제공합니다. 그것들을 사용하여 시행할 수 있습니다. 비즈니스의 모든 사람이 따라야 하는 권한입니다. SCP를 사용하여 개발자는 자신의 권한을 더 자유롭게 관리할 수 있습니다. 당신이 정의한 경계 내에서. AWS Organizations를 통해 SCP를 생성하고 적용합니다. 조직을 생성할 때 AWS 조직은 자동으로 루트를 생성하여 모든 계정에 대한 상위 컨테이너를 형성합니다. 당신의 조직. 루트 내에서 조직의 계정을 조직으로 그룹화할 수 있습니다. 단위(OU)를 사용하여 이러한 계정의 관리를 단순화합니다. 단일 내에서 여러 OU를 만들 수 있습니다. 다른 OU 내에 OU를 생성하여 계층 구조를 형성할 수 있습니다. 당신은 할 수 있습니다 조직 루트, OU 및 개별 계정에 SCP를 연결합니다. 루트에 부착된 SCP 및 OU는 모든 OU와 그 안의 계정에 적용됩니다. SCP는 AWS Identity and Access Management(IAM) 정책 언어를 사용합니다. 그러나 그들은하지 않습니다 권한을 부여합니다. SCP를 사용하면 사용 가능한 최대값을 정의하여 권한 가드레일을 설정할 수 있습니다. 계정의 IAM 엔터티에 대한 권한. SCP가 계정에 대한 작업을 거부하는 경우 계정의 엔터티는 IAM 권한이 허용하더라도 해당 작업을 수행할 수 있습니다. NS SCP에 설정된 가드레일은 계정의 모든 IAM 엔터티에 적용되며 여기에는 모든 사용자, 역할 및 계정 루트 사용자. https://aws.amazon.com/blogs/security/how-to-use-service-control-policies-to-set-permissionguardrails-across-a\n#\r#\r질문\r#\rquestion 제조 회사는 기계 장비에 대한 예측 유지 관리를 구현하려고 합니다. 회사는 AWS에 실시간으로 데이터를 보낼 수천 개의 IoT 센서를 설치할 것입니다. 솔루션 설계자는 각 기계 자산에 대해 순서대로 이벤트를 수신하는 솔루션을 구현하는 임무를 맡습니다. 나중에 추가 처리를 위해 데이터를 저장해야 합니다. 어떤 솔루션이 가장 효율적입니까?\nA. 각 장비 자산에 대한 분할이 있는 실시간 이벤트에 Amazon Kinesis Data Streams 사용 Amazon Kinesis Data Firehose를 사용하여 Amazon S3에 데이터 저장 B. 각 장비 자산에 대한 샤드가 있는 실시간 이벤트에 Amazon Kinesis Data Streams 사용 Amazon Kinesis Data Firehose를 사용하여 Amazon EBS에 데이터 저장 C. 각 장비 자산에 대해 하나의 대기열이 있는 실시간 이벤트에 Amazon SQS FIFO 대기열 사용 SQS 대기열에 대한 AWS Lambda 함수를 트리거하여 Amazon EFS에 데이터 저장 D. 각 장비 자산에 대해 하나의 대기열이 있는 실시간 이벤트에 Amazon SQS 표준 대기열 사용 SQS 대기열에서 AWS Lambda 함수를 트리거하여 Amazon S3에 데이터 저장 정답 풀이\r...\r답: C\r#\rKinesis Firehose는 현재 s3 및 redshift만 지원합니다. 설명 Amazon SQS, 정확히 한 번 처리가 가능한 FIFO 대기열 도입 및 표준 가격 인하 대기열 이제 메시지가 필요한 애플리케이션에 Amazon Simple Queue Service(SQS)를 사용할 수 있습니다. FIFO(선입선출) 대기열을 사용하여 엄격한 순서로 정확히 한 번 처리됩니다. 선입선출 큐는 메시지를 보내고 받는 순서가 엄격하게 유지되도록 설계되었습니다. 보존되고 각 메시지는 정확히 한 번 처리됩니다. Amazon SQS는 다음 위치에 메시지를 저장하기 위한 안정적이고 확장성이 뛰어난 관리형 메시지 대기열 서비스입니다. 응용 프로그램 구성 요소 간의 전송. FIFO 대기열은 기존 Amazon SQS를 보완합니다. 높은 처리량, 최선형 주문 및 최소 한 번 배달을 제공하는 표준 대기열. 선입선출 대기열은 기본적으로 표준 대기열과 동일한 기능을 갖지만 다음과 같은 추가 이점을 제공합니다. 주문 및 정확히 한 번 처리를 지원합니다. FIFO 대기열은 도움이 되는 추가 기능을 제공합니다. 메시지 생성자가 의도하지 않은 중복을 보내거나 받는 것을 방지 메시지 소비자. 또한 메시지 그룹은 여러 개의 개별 메시지 스트림을 허용합니다. 같은 대기열 내에서. https://aws.amazon.com/about-aws/whats-new/2016/11/amazon-sqs-introduces-fifo-queues-withexactly-once-pr #\r#\r질문\r#\rquestion 회사에 고정 IP를 사용하는 여러 온프레미스 서버에서 호스팅되는 하이브리드 애플리케이션이 있습니다. 구애. VPC와 온프레미스 간의 연결을 제공하는 VPN이 이미 있습니다. 회로망. 회사는 인터넷용 온프레미스 서버에 TCP 트래픽을 배포하려고 합니다. 사용자. 솔루션 설계자는 가용성과 확장성이 뛰어난 솔루션을 제공하기 위해 무엇을 권장해야 합니까?\nA. 인터넷 연결 NLB(Network Load Balancer) 시작 및 온프레미스 IP 주소 등록 NLB와 함께. B. 인터넷 연결 ALB(Application Load Balancer) 시작 및 온프레미스 IP 주소 등록 알바와 함께. C. Amazon EC2 인스턴스를 시작하고 탄력적 IP 주소를 연결하고 온프레미스 서버에 트래픽을 분산합니다. D. Auto Scaling 그룹에서 퍼블릭 IP 주소로 Amazon EC2 인스턴스 시작 및 배포 온프레미스 서버로의 트래픽. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사가 온프레미스 인프라에서 AWS Cloud One으로 마이그레이션하고 있습니다. 회사의 응용 프로그램은 분산 파일 시스템을 사용하는 Windows 파일 서버 팜에 파일을 저장합니다. 데이터 동기화를 유지하기 위한 복제(DFSR) 솔루션 설계자는 파일 서버 팜을 교체해야 합니다. 솔루션 설계자는 어떤 서비스를 사용해야 합니까?\nA. 아마존 EFS B. 아마존 FSx C. 아마존 S3 D. AWS 스토리지 게이트웨이 정답 풀이\r...\r답: B\r#\rAmazon FSx는 Windows 파일 변형에 파일을 저장합니다. Amazon FSx와 관련하여 Amazon FSx와 함께 가져오는 용 용 Lustre Amazon FSx를 제공합니다. 설명 AWS DataSync를 사용하여 기존 파일을 Windows 파일 서버용 Amazon FSx로 마이그레이션하는 것이 좋습니다. AWS DataSync를 사용하여 Windows 파일 서버 파일 시스템용 Amazon FSx 간에 데이터를 전송합니다. DataSync는 이동 및 복제를 단순화, 자동화 및 가속화하는 데이터 전송 서비스입니다. 인터넷 또는 AWS를 통해 온프레미스 스토리지 시스템과 다른 AWS 스토리지 서비스 간의 데이터 직접 연결. DataSync는 소유권, 시간과 같은 파일 시스템 데이터 및 메타데이터를 전송할 수 있습니다. 스탬프 및 액세스 권한. #\r#\r질문\r#\rquestion 온프레미스에서 웹 애플리케이션을 운영하는 회사가 새로운 출시를 준비하고 있습니다. AWS의 애플리케이션 버전. 회사는 요청을 AWS에서 호스팅하는 또는 URL 쿼리 문자열을 기반으로 하는 온프레미스 호스팅 애플리케이션입니다. 온프레미스 애플리케이션은 인터넷에서 사용할 수 없고 Amazon VPC와 VPN 연결이 설정됩니다. 회사의 데이터 센터. 회사는 이번 출시에 ALB(Application Load Balancer)를 사용하려고 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 두 개의 ALB를 사용하십시오. 하나는 온프레미스용이고 다른 하나는 AWS 리소스용입니다. 각 대상 그룹에 호스트 추가 각 ALB의 URL 쿼리 문자열을 기반으로 Amazon Route 53으로 라우팅합니다. B. 두 개의 ALB를 사용합니다. 하나는 온프레미스용이고 다른 하나는 AWS 리소스용입니다. 대상 그룹에 호스트 추가 각 ALB. URL 쿼리 문자열을 기반으로 EC2 인스턴스에 소프트웨어 라우터를 생성합니다. C. 하나의 ALB를 두 개의 대상 그룹으로 사용합니다. 하나는 AWS 리소스용이고 다른 하나는 온프레미스용입니다. 추가하다 ALB의 각 대상 그룹에 대한 호스트. URL 쿼리 문자열을 기반으로 리스너 규칙을 구성합니다. D. 2개의 AWS Auto Scaling 그룹과 함께 하나의 ALB를 사용합니다. 하나는 AWS 리소스용이고 다른 하나는 on용입니다. 가옥. 각 Auto Scaling 그룹에 호스트를 추가합니다. URL 쿼리 문자열을 기반으로 Amazon Route 53으로 라우팅합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 한 회사는 사용자가 방문하는 장소에 체크인하고, 장소의 순위를 매기고, 그들의 경험에 대한 리뷰를 추가하십시오. 매달 사용자 수 CTO는 현재 데이터베이스를 지원하는 데이터베이스를 두려워합니다. 단일 Amazon RDS가 다음 달에 새로운 로드를 처리하지 못할 수 있습니다. MySQL 인스턴스가 읽기 요청으로 인해 리소스 소진과 관련된 경보를 트리거했습니다. 솔루션 아키텍트는 데이터베이스 계층에서 서비스 중단을 방지하기 위해 무엇을 권장할 수 있습니까? 최소한의 코드 변경으로?\nA. Amazon EMR 클러스터를 생성하고 데이터를 HDFS(Hadoop Distributed File System)로 마이그레이션 복제 계수가 3입니다. B. RDS 읽기 전용 복제본을 생성하고 읽기 전용 트래픽을 읽기 전용 복제본 엔드포인트로 리디렉션합니다. 다중 AZ 배포. C. Amazon ElastiCache 클러스터를 생성하고 모든 읽기 전용 트래픽을 클러스터로 리디렉션합니다. 설정 3개의 가용 영역에 배포할 클러스터. D. Amazon DynamoDB 테이블을 생성하여 RDS 인스턴스를 교체하고 모든 읽기 전용 트래픽을 리디렉션합니다. DynamoDB 테이블로 DynamoDB Accelerator를 활성화하여 기본 테이블에서 트래픽을 오프로드합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사에서 온프레미스 데이터 세트의 보조 복사본에 Amazon S3를 사용하려고 합니다. NS 회사는 이 사본에 액세스할 필요가 거의 없습니다. 스토리지 솔루션의 비용은 최소화되어야 합니다. 이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까?\nA. S3 표준 B. S3 지능형 계층화 C. S3 Standard-Infrequent Access(S3 Standard-IA) D. S3 One Zone-Infrequent Access(S3 One Zone-IA) 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사는 다음 데이터베이스 계층에 대해 프로비저닝된 처리량으로 Amazon DynamoDB를 사용하고 있습니다. 전자 상거래 웹 사이트. 플래시 판매 기간 동안 고객은 데이터베이스가 발생하는 많은 수의 트랜잭션을 처리할 수 없습니다. 이로 인해 회사는 손실 트랜잭션 정상 기간 동안 데이터베이스는 적절하게 수행됩니다. 어떤 솔루션이 회사가 직면한 성능 문제를 해결합니까?\nA. 플래시 판매 중 DynamoDB를 온디맨드 모드로 전환 B. 빠른 메모리 성능을 위해 DynamoDB Accelerator 구현 C. Amazon Kinesis를 사용하여 DynamoDB로 처리할 트랜잭션을 대기열에 넣습니다. D. Amazon Simple Queue Service(Amazon SQS)를 사용하여 DynamoDB에 대한 트랜잭션 대기열 처리 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 한 회사에 Amazon DynamoDB를 기반으로 하는 데이터 저장소가 있는 모바일 채팅 애플리케이션이 있습니다. 사용자는 가능한 한 짧은 대기 시간으로 새 메시지를 읽기를 원합니다. 솔루션 아키텍트 최소한의 애플리케이션 변경이 필요한 최적의 솔루션을 설계해야 합니다. 솔루션 설계자는 어떤 방법을 선택해야 합니까?\nA. 새 메시지 테이블에 대해 Amazon DynamoDB Accelerator(DAX)를 구성합니다. 코드를 다음으로 업데이트 DAX 끝점을 사용합니다. B. 증가된 읽기 로드를 처리하기 위해 DynamoDB 읽기 전용 복제본을 추가합니다. 다음을 가리키도록 애플리케이션 업데이트 읽기 전용 복제본의 읽기 엔드포인트. C. DynamoDB의 새 메시지 테이블에 대한 읽기 용량 단위 수를 두 배로 늘립니다. 계속 기존 DynamoDB 엔드포인트를 사용합니다. D. Redis용 Amazon ElastiCache 캐시를 애플리케이션 스택에 추가합니다. 응용 프로그램을 다음으로 업데이트 DynamoDB 대신 Redis 캐시 엔드포인트를 가리킵니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에 AWS에 배포된 웹 사이트가 있습니다. 데이터베이스 백엔드는 Amazon RDS에서 호스팅됩니다. 확장 요구 사항을 지원하기 위해 기본 인스턴스와 5개의 읽기 전용 복제본이 있는 MySQL용. 읽기 전용 복제본 사용자 경험을 지원하기 위해 기본 인스턴스보다 1초 이상 지연되지 않아야 합니다. 웹 사이트의 트래픽은 계속 증가하고 복제본은 최대 로드로 인해 검색 결과가 일관되지 않을 때 사용자의 불만이 발생함 A 솔루션 아키텍트는 최소한의 변경으로 복제 지연을 최대한 줄여야 합니다. 애플리케이션 코드 또는 운영 요구 사항 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 데이터베이스를 Amazon Aurora MySQL로 마이그레이션 MySQL 읽기 전용 복제본을 Aurora로 교체 복제본 및 Aurora Auto Scaling 활성화 B. 데이터베이스 앞에 Amazon ElastiCache for Redis 클러스터를 배포합니다. 데이터베이스 읽기 끝점을 쿼리하기 전에 캐시를 확인하십시오. C. Amazon RDS에서 Amazon EC2 컴퓨팅 인스턴스에서 실행되는 MySQL로 데이터베이스를 마이그레이션합니다. 모든 복제본 노드에 대해 매우 큰 컴퓨팅 최적화 인스턴스를 선택합니다. D. 데이터베이스를 Amazon DynamoDB로 마이그레이션 초기에 많은 읽기 용량 프로비저닝 온디맨드 용량 확장이 활성화된 상태에서 필요한 처리량을 지원하는 단위(RCU) 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 Amazon S3와 함께 Amazon CloudFront를 사용하는 솔루션을 설계해야 합니다. 정적 웹 사이트를 저장합니다. 회사 보안 정책에 따라 모든 웹사이트 트래픽을 검사해야 합니다. AWS WAF에 의해. 솔루션 설계자는 이러한 요구 사항을 어떻게 충족해야 합니까?\nA. AWS WAF Amazon 리소스 이름(ARN)에서 오는 요청만 수락하도록 S3 버킷 정책을 구성합니다. B. S3 오리진에서 콘텐츠를 요청하기 전에 들어오는 모든 요청을 AWS WAF로 전달하도록 Amazon CloudFront를 구성합니다. C. Amazon CloudFront IP 주소가 Amazon S3에만 액세스하도록 허용하는 보안 그룹을 구성합니다. AWS WAF를 CloudFront에 연결합니다. D. 원본 액세스 ID(OAI)를 사용하여 S3 버킷에 대한 액세스를 제한하도록 Amazon CloudFront 및 Amazon S3를 구성합니다. 배포에서 AWS WAF를 활성화합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 재난 대응 팀은 최근 폭풍 피해에 대한 이미지를 수집하기 위해 드론을 사용하고 있습니다. NS 대응 팀의 노트북에는 이미지를 전송하고 처리할 수 있는 스토리지 및 컴퓨팅 용량이 부족합니다. 자료. 팀에는 처리를 위한 Amazon EC2 인스턴스와 다음을 위한 Amazon S3 버킷이 있습니다. 스토리지, 네트워크 연결이 간헐적이고 신뢰할 수 없습니다. 이미지를 처리해야 합니다. 피해를 평가합니다. 솔루션 아키텍트는 무엇을 추천해야 합니까?\nA. AWS Snowball Edge 디바이스를 사용하여 이미지를 처리하고 저장합니다. B. 간헐적으로 Amazon Simple Queue Service(Amazon SOS)에 이미지 업로드 EC2 인스턴스에 대한 연결. C. Amazon Kinesis Data Firehose가 다음을 대상으로 하는 여러 전송 스트림을 생성하도록 구성합니다. 스토리지용 S3 버킷과 이미지 처리용 EC2 인스턴스. D. 하드웨어 어플라이언스에 사전 설치된 AWS Storage Gateway를 사용하여 연결을 사용할 수 있게 되면 이미지를 처리하는 Amazon S3. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 그룹에는 Amazon S3 버킷을 나열하고 해당 버킷에서 객체를 삭제할 수 있는 권한이 필요합니다. 버킷. 관리자는 버킷에 대한 액세스를 제공하고 다음 IAM 정책을 생성했습니다. 해당 정책을 그룹에 적용했습니다. 그룹은 버킷의 객체를 삭제할 수 없습니다. 그 회사 최소 권한 액세스 규칙을 따릅니다.\n{ \u0026#34;버전\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;성명\u0026#34;: [ { \u0026#34;행동\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34;, \u0026#34;s3:오브젝트 삭제\u0026#34; ], \u0026#34;자원\u0026#34;: [ \u0026#34;arn:aws:s3:::버킷 이름\u0026#34; ], \u0026#34;효과\u0026#34;: \u0026#34;허용\u0026#34; } ] } #\rA. 옵션 A\n\u0026#34;행동\u0026#34;: [ \u0026#34;s3:*객체\u0026#34; ], \u0026#34;자원\u0026#34;: [ \u0026#34;arn:aws:s3:::버킷 이름/*\u0026#34; ], \u0026#34;효과\u0026#34; \u0026#34;허용\u0026#34; #\rB. 옵션 B\n\u0026#34;행동\u0026#34;: [ \u0026#34;s3:*\u0026#34; ], \u0026#34;자원\u0026#34;: [ \u0026#34;arn:aws:s3:::버킷 이름/*\u0026#34; ], \u0026#34;효과\u0026#34; \u0026#34;허용\u0026#34; #\rC. 옵션 C\n\u0026#34;행동\u0026#34;: [ \u0026#34;s3:*오브젝트 삭제\u0026#34; ], \u0026#34;자원\u0026#34;: [ \u0026#34;arn:aws:s3:::버킷 이름*\u0026#34; ], \u0026#34;효과\u0026#34; \u0026#34;허용\u0026#34; #\rD. 옵션 D\n\u0026#34;행동\u0026#34;: [ \u0026#34;s3:*오브젝트 삭제\u0026#34; ], \u0026#34;자원\u0026#34;: [ \u0026#34;arn:aws:s3:::버킷 이름/*\u0026#34; ], \u0026#34;효과\u0026#34; \u0026#34;허용\u0026#34; 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion Amazon EC2 인스턴스에서 호스팅되는 회사의 애플리케이션은 Amazon S3에 액세스해야 합니다. 버킷. 데이터 민감도로 인해 트래픽은 인터넷을 통과할 수 없습니다. 액세스를 구성하시겠습니까?\nA. Amazon Route 53을 사용하여 프라이빗 호스팅 영역을 생성합니다.\nB. VPC에서 Amazon S3용 VPC 게이트웨이 엔드포인트를 구성합니다.\nC. EC2 인스턴스와 S3 버킷 간에 AWS PrivateLink를 구성합니다.\nD. VPC와 S3 버킷 간에 사이트 간 VPN 연결을 설정합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon S3에 기밀 데이터를 저장할 준비를 하고 있습니다. 규정 준수를 위해 데이터는 유휴 상태에서 암호화되어야 합니다. 암호화 키 사용은 감사 목적으로 기록되어야 합니다. 열쇠 매년 순환해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족하고 운영상 가장 효율적입니까?\nA. 고객 제공 키를 사용한 서버 측 암호화(SSE-C) B. Amazon S3 관리형 키를 사용한 서버 측 암호화(SSE-S3) C. 수동 교체가 있는 AWS KMS(SSE-KMS) 고객 마스터 키(CMK)를 사용한 서버 측 암호화 D. 자동 교체 기능이 있는 AWS KMS(SSE-KMS) 고객 마스터 키(CMK)를 사용한 서버 측 암호화 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 한 회사는 사용자가 방문하는 장소에 체크인하고, 장소의 순위를 매기고, 그들의 경험에 대한 리뷰를 추가하십시오. 매달 사용자 수 CTO는 현재 데이터베이스를 지원하는 데이터베이스를 두려워합니다. 단일 Amazon RDS가 다음 달에 새로운 로드를 처리하지 못할 수 있습니다. MySQL 인스턴스가 읽기 요청으로 인해 리소스 소진과 관련된 경보를 트리거했습니다. 솔루션 아키텍트는 데이터베이스 계층에서 서비스 중단을 방지하기 위해 무엇을 권장할 수 있습니까? 최소한의 코드 변경으로?\nA. RDS 읽기 전용 복제본을 생성하고 읽기 전용 트래픽을 읽기 전용 복제본 엔드포인트로 리디렉션합니다. 다중 AZ 배포. B. Amazon EMR 클러스터를 생성하고 데이터를 HDFS(Hadoop Distributed File System)로 마이그레이션 복제 계수가 3입니다. C. Amazon ElastiCache 클러스터를 생성하고 모든 읽기 전용 트래픽을 클러스터로 리디렉션합니다. 설정 3개의 가용 영역에 배포할 클러스터. D. Amazon DynamoDB 테이블을 생성하여 RDS 인스턴스를 교체하고 모든 읽기 전용 트래픽을 리디렉션합니다. DynamoDB 테이블로 DynamoDB Accelerator를 활성화하여 기본 테이블에서 트래픽을 오프로드합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 가상 서버 기반 워크로드를 AWS로 마이그레이션할 계획입니다. 애플리케이션 서버가 지원하는 인터넷 연결 로드 밸런서. 애플리케이션 서버는 패치에 의존 인터넷 호스팅 리포지토리에서 솔루션 설계자가 권장해야 하는 서비스 퍼블릭 서브넷에서 호스팅됩니까? (2개를 선택하십시오.)\nA. NAT 게이트웨이 B. Amazon RDS DB 인스턴스 C. 애플리케이션 로드 밸런서 D. Amazon EC2 애플리케이션 서버 E. Amazon Elastic File System(Amazon EFS) 볼륨 정답 풀이\r...\r답변: AC\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 이미지 카탈로그에 액세스하고 사용자에게 이미지 사용자 정의 요청을 제출하는 기능 이미지 사용자 정의 매개변수는 AWS API Gateway API로 전송된 모든 요청은 요청 시 사용자 지정 이미지가 생성되며, 사용자는 클릭하여 맞춤형 이미지를 보거나 다운로드할 수 있는 링크를 받게 됩니다. 이미지를 보고 사용자 정의하는 데 가용성이 높아야 합니다. 가장 비용 효율적인 솔루션은 무엇입니까? 이러한 요구 사항을 충족하려면?\nA. Amazon EC2 인스턴스를 사용하여 원본 이미지를 요청된 사용자 지정으로 조작 원본 이미지와 조작된 이미지를 Amazon S3에 저장 앞에 Elastic Load Balancer 구성 EC2 인스턴스의 B. AWS Lambda를 사용하여 원본 이미지를 요청된 사용자 지정으로 조작 원본 및 조작된 이미지를 Amazon S3에 저장 S3 버킷을 오리진으로 사용하여 Amazon CloudFront 배포 구성 C. AWS Lambda를 사용하여 원본 이미지를 요청된 사용자 지정으로 조작 Amazon S3의 원본 이미지 및 Amazon DynamoDB의 조작된 이미지 Elastic 구성 Amazon EC2 인스턴스 앞의 로드 밸런서 D. Amazon EC2 인스턴스를 사용하여 원본 이미지를 요청된 사용자 지정으로 조작 원본 이미지를 Amazon S3에 저장하고 조작된 이미지를 Amazon DynamoDB Configure에 저장합니다. S3 버킷을 오리진으로 사용하는 Amazon CloudFront 배포 정답 풀이\r...\r답: B\r#\r설명 AWS Lambda는 서버를 프로비저닝하거나 관리하지 않고도 코드를 실행할 수 있는 컴퓨팅 서비스입니다. AWS Lambda는 필요할 때만 코드를 실행하고 몇 가지 요청에서 자동으로 확장합니다. 하루에 초당 수천. 사용한 컴퓨팅 시간에 대해서만 비용을 지불합니다. 코드가 실행되고 있지 않을 때 요금이 부과됩니다. AWS Lambda를 사용하면 거의 모든 유형의 코드를 실행할 수 있습니다. 애플리케이션 또는 백엔드 서비스 - 모두 관리가 필요 없습니다. AWS Lambda는 높은 수준에서 코드를 실행합니다. -가용성 컴퓨팅 인프라 및 컴퓨팅 리소스의 모든 관리를 수행합니다. 서버 및 운영 체제 유지 관리, 용량 프로비저닝 및 자동 확장 포함, 코드 모니터링 및 로깅. AWS에서 제공하는 언어 중 하나로 코드를 제공하기만 하면 됩니다. 람다 지원합니다. S3에 정적 콘텐츠를 저장하면 많은 이점이 있습니다. 하지만 최적화를 돕기 위해 비용을 효과적으로 관리하면서 애플리케이션의 성능과 보안을 콘텐츠를 제공하고 보호하기 위해 S3 버킷과 함께 작동하도록 Amazon CloudFront를 설정합니다. 클라우드프론트 정적 및 동적 웹 콘텐츠, 비디오를 전달하는 CDN(콘텐츠 전송 네트워크) 서비스입니다. 전 세계의 스트림 및 API를 안전하고 대규모로 제공합니다. 설계상 데이터를 외부로 전달합니다. CloudFront는 S3에서 사용자에게 직접 제공하는 것보다 비용 효율적일 수 있습니다. CloudFront는 엣지 로케이션이라고 하는 전 세계 데이터 센터 네트워크를 통해 콘텐츠를 제공합니다. 사용 콘텐츠를 캐시하고 제공하는 에지 서버는 콘텐츠를 위치에 더 가깝게 제공하여 성능을 향상시킵니다. 시청자가 있습니다. CloudFront는 전 세계에 에지 서버를 보유하고 있습니다. https://docs.aws.amazon.com/lambda/latest/dg/welcome.html https://aws.amazon.com/blogs/networking-and-content-delivery/amazon-s3-amazon-cloudfront-amatch-made-in\n#\r#\r질문\r#\rquestion 회사에 Amazon SQS에 메시지를 게시하는 애플리케이션이 있습니다. 다른 애플리케이션이 폴링합니다. l/O 집약적인 작업에서 메시지를 대기열에 넣고 처리합니다. 회사에 서비스 수준이 있습니다. 수신 사이에 경과할 수 있는 최대 시간을 지정하는 계약(SLA) 메시지 및 사용자에 대한 응답 회사의 메시지 증가로 인해 SLA를 일관되게 충족하는 데 어려움이 있습니다. 솔루션 설계자는 애플리케이션의 처리 시간을 개선하고 이를 보장하기 위해 무엇을 해야 합니까? 모든 수준에서 부하를 처리할 수 있습니까?\nA. 처리에 사용된 인스턴스에서 Amazon 머신 이미지(AMI) 생성 인스턴스를 만들고 더 큰 크기로 바꿉니다. B. 처리에 사용되는 인스턴스에서 Amazon 머신 이미지(AMI) 생성 인스턴스를 만들고 Amazon EC2 전용 인스턴스로 교체합니다. C. 자동 생성 처리에 사용된 인스턴스에서 Amazon 머신 이미지(AMI) 생성 시작 구성에서 이 이미지를 사용하는 확장 그룹 대상 추적으로 그룹 구성 총 CPU 사용률을 70% 미만으로 유지하는 정책 D. 자동 생성을 처리하는 데 사용되는 인스턴스에서 Amazon 머신 이미지(AMI) 생성 시작 구성에서 이 이미지를 사용하는 확장 그룹 대상 추적으로 그룹 구성 SQS 대기열에서 가장 오래된 메시지의 수명을 기반으로 한 정책 정답 풀이\r...\r답변: D\r#\rSLA는 이에 대한 응답을 받았습니다. #\r#\r질문\r#\rquestion 회사는 7개의 Amazon EC2 인스턴스를 사용하여 AWS에서 웹 애플리케이션을 호스팅합니다. 회사는 DNS에 대한 응답으로 모든 정상적인 EC2 인스턴스의 IP 주소를 반환하도록 요구합니다. 쿼리. 이 요구 사항을 충족하려면 어떤 정책을 사용해야 합니까?\nA. 단순 라우팅 정책 B. 지연 라우팅 정책 다. 다중값 라우팅 정책 D. 지리적 위치 라우팅 정책 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 정규 기간 동안 최소 4개의 Amazon EC2 인스턴스가 필요한 애플리케이션에 의존합니다. 트래픽이 최고조에 달할 때 최대 12개의 EC2 인스턴스까지 확장해야 합니다. 응용 프로그램은 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. Auto Scaling 그룹에 EC2 인스턴스 배포 최소값을 4로, 최대값을 M으로 설정하고, ~와 함께 가용 영역 A에 2개, 가용 영역 B에 2개 B. Auto Scaling 그룹에 EC2 인스턴스 배포 최소값을 4로, 최대값을 12로 설정하고, 가용 영역 A의 4개 모두 C. Auto Scaling 그룹에 EC2 인스턴스 배포 최소값을 8로, 최대값을 12로 설정하고, ~와 함께 가용 영역 A의 4개 및 가용 영역 B의 4개 D. Auto Scaling 그룹에 EC2 인스턴스 배포 최소값을 8로, 최대값을 12로 설정합니다. 가용 영역 A의 8개 모두 정답 풀이\r...\r답: C\r#\r4개 이란 말을 하는 것입니다. #\r#\r질문\r#\rquestion 회사는 최근에 내부 보안 표준을 업데이트했습니다. 회사는 이제 모든 Amazon S3 버킷 및 Amazon Elastic Block Store(Amazon EBS) 볼륨이 암호화되었는지 확인 내부 보안 전문가가 만들고 주기적으로 키를 교체합니다. 회사에서 찾고 있는 이 목표를 달성하기 위한 기본 소프트웨어 기반 AWS 서비스입니다. 솔루션 설계자는 솔루션으로 무엇을 권장해야 합니까?\nA. 고객 마스터 키(CMK)와 함께 AWS Secrets Manager를 사용하여 마스터 키 구성 요소 및 루틴을 적용하여 주기적으로 새 CMK를 생성하고 AWS Secrets Manager에서 교체합니다. B. 고객 마스터 키(CMK)와 함께 AWS Key Management Service(AWS KMS)를 사용하여 마스터 저장 키 구성 요소 및 라우팅을 적용하여 주기적으로 새 키를 다시 생성하고 AWS KMS에서 교체합니다. C. 고객 마스터 키(CMK)가 있는 AWS CloudHSM 클러스터를 사용하여 마스터 키 구성 요소 저장 루틴을 적용하고 주기적으로 새 키를 재생성하고 CloudHSM 클러스터 노드에서 교체합니다. D. 고객 마스터 키(CMK) 키와 함께 AWS Systems Manager Parameter Store를 사용하여 저장 마스터 키 자료 및 루틴을 적용하여 주기적으로 새 자료를 재생성하고 매개변수 저장소. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 엔지니어링 팀이 AWS Lambda 함수를 개발 및 배포하고 있습니다. 팀은 다음을 수행해야 합니다. AWS IAM에서 역할을 생성하고 정책을 관리하여 Lambda 함수의 권한을 구성합니다. 팀에 대한 권한을 어떻게 구성하여 최소 개념을 준수해야 합니까? 특권?\nA. 관리형 정책이 연결된 IAM 역할 생성 엔지니어링 팀과 Lambda 함수가 이 역할을 맡도록 허용 B. lAMFullAccess 정책이 연결된 엔지니어링 팀용 IAM 그룹을 생성합니다. 팀의 모든 사용자를 이 IAM 그룹에 추가합니다. C. Lambda 함수에 대한 실행 역할을 생성합니다. 이러한 Lambda 함수와 관련된 권한 경계가 있는 관리형 정책 연결 D. Lambda 기능과 관련된 권한 경계가 있는 관리형 정책이 연결된 IAM 역할 생성 엔지니어링 팀이 이 역할을 맡도록 허용합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에서 MySQL 데이터베이스를 온프레미스에서 AWS로 마이그레이션하려고 합니다. 그 회사 최근에 비즈니스에 심각한 영향을 미치는 데이터베이스 중단을 경험했습니다. 이 작업을 수행하려면 다시는 발생하지 않기 위해 회사는 AWS에서 데이터 손실을 최소화하는 안정적인 데이터베이스 솔루션을 원합니다. 모든 트랜잭션을 적어도 두 개의 노드에 저장합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 3개의 가용 영역에 있는 3개의 노드에 동기식 복제를 사용하여 Amazon RDS DB 인스턴스를 생성합니다. B. 데이터를 동기식으로 복제할 수 있도록 다중 AZ 기능이 활성화된 Amazon RDS MySQL DB 인스턴스 생성 C. Amazon RDS MySQL DB 인스턴스를 생성한 다음 데이터를 동기식으로 복제하는 별도의 AWS 리전에 읽기 전용 복제본을 생성합니다. D. AWS Lambda 함수를 트리거하여 Amazon RDS MySQL DB 인스턴스에 데이터를 동기적으로 복제하는 MySQL 엔진이 설치된 Amazon EC2 인스턴스를 생성합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 사용자 데이터를 캡처하고 미래를 위해 저장하는 음식 주문 애플리케이션을 구축했습니다. 분석 애플리케이션의 정적 프런트 엔드는 Amazon EC2 인스턴스에 배포됩니다. 프런트 엔드 애플리케이션은 별도의 EC2 인스턴스에서 실행되는 백엔드 애플리케이션으로 요청을 보냅니다. 그런 다음 백엔드 애플리케이션은 Amazon RDS에 데이터를 저장합니다. 아키텍처를 분리하고 확장 가능하게 만드시겠습니까?\nA. Amazon S3를 사용하여 Amazon EC2에 실행 요청을 보내는 프런트 엔드 애플리케이션 제공 백엔드 애플리케이션 백엔드 애플리케이션은 Amazon RDS에서 데이터를 처리하고 저장합니다. B. Amazon S3를 사용하여 프런트 엔드 애플리케이션을 제공하고 Amazon Simple에 요청 쓰기 Notification Service(Amazon SNS) 주제 HTTP/HTTPS에 Amazon EC2 인스턴스 구독 주제의 끝점 및 Amazon RDS에서 데이터를 처리 및 저장 C. EC2 인스턴스를 사용하여 프런트 엔드를 제공하고 Amazon SQS 대기열에 요청을 작성합니다. Auto Scaling 그룹의 백엔드 인스턴스 및 처리 및 저장할 대기열 깊이에 따라 확장 Amazon RDS의 데이터 D. Amazon S3를 사용하여 정적 프런트 엔드 애플리케이션을 제공하고 Amazon API에 요청 보내기 Amazon SQS 대기열에 요청을 작성하는 게이트웨이 백엔드 인스턴스를 자동 Amazon RDS에서 데이터를 처리하고 저장하기 위해 대기열 깊이에 따라 그룹 및 규모 조정 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사는 사용 중인 두 개의 NAT 인스턴스가 더 이상 회사의 응용 프로그램에 필요한 트래픽. 솔루션 설계자가 솔루션을 구현하려고 합니다. 고가용성 내결함성 및 자동 확장성 솔루션 설계자가 해야 할 일 추천하다?\nA. 두 개의 NAT 인스턴스를 제거하고 동일한 가용성에 있는 두 개의 NAT 게이트웨이로 교체합니다. 존. B. 서로 다른 NAT 인스턴스에 대해 Network Load Balancer와 함께 Auto Scaling 그룹을 사용합니다. 가용 영역. C. 두 개의 NAT 인스턴스를 제거하고 가용성이 다른 두 개의 NAT 게이트웨이로 교체 구역. D. 두 NAT 인스턴스를 서로 다른 가용 영역의 스팟 인스턴스로 교체하고 네트워크 로드 밸런서. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 정적 단일 페이지를 위한 저지연 솔루션을 설계해야 합니다. 사용자 정의 도메인 이름을 사용하여 사용자가 액세스하는 애플리케이션. 솔루션은 서버리스여야 하며, 전송 중 암호화되고 비용 효율적입니다. 솔루션 설계자는 어떤 AWS 서비스와 기능 조합을 사용해야 합니까? (2개를 선택하십시오.)\nA. 아마존 S3 B. 아마존 EC2 C. AWS Fargate D. 아마존 클라우드프론트 E. 탄력적 로드 밸런서 정답 풀이\r...\r답변: 광고\r#\r#\r#\r질문\r#\rquestion 회사는 매일 데이터를 처리하고 작업 결과는 Amazon S3 버킷, 1주일 동안 매일 분석한 후 즉시 액세스 가능한 상태로 유지 비정기 분석 현재의 대안으로 가장 비용 효율적인 스토리지 솔루션은 무엇입니까? 구성?\nA. 30일 후에 객체를 삭제하도록 수명 주기 정책 구성 B. 30일 후에 객체를 Amazon S3 Glacier로 전환하도록 수명 주기 정책을 구성합니다. C. 30일 후에 객체를 Amazon S3 Standard-Infrequent Access(S3 Standard-IA)로 전환하도록 수명 주기 정책 구성 D. 30일 후에 객체를 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)로 전환하도록 수명 주기 정책을 구성합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에 많은 Amazon EC2 인스턴스를 사용하여 완료하는 매우 동적인 배치 처리 작업이 있습니다. 작업은 본질적으로 상태 비저장이며 부정적인 영향 없이 언제든지 시작 및 중지할 수 있습니다. 일반적으로 완료하는 데 총 60분 이상이 소요됩니다. 회사는 솔루션 설계자에게 작업 요구 사항을 충족하는 확장 가능하고 비용 효율적인 솔루션을 설계하도록 요청했습니다. 솔루션 설계자는 무엇을 권장해야 합니까?\nA. EC2 스팟 인스턴스 구현 B. EC2 예약 인스턴스 구매 C. EC2 온디맨드 인스턴스 구현 D. AWS Lambda에서 처리 구현 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에 다음을 사용하는 목록 온프레미스 서버에서 실행되는 라이브 채팅 애플리케이션이 있습니다. 웹소켓. 회사에서 애플리케이션을 AWS로 마이그레이션하려는 애플리케이션 트래픽은 다음과 같습니다. 일관성이 없으며 회사는 앞으로 더 많은 트래픽이 급증할 것으로 예상합니다. 회사는 서버 유지 관리나 고급 용량 없이 확장성이 뛰어난 솔루션을 원합니다. 계획 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. Amazon DynamoDB 테이블을 데이터 저장소로 사용하여 Amazon API Gateway 및 AWS Lambda 사용 프로비저닝된 용량에 대해 DynamoDB 테이블 구성 B. Amazon DynamoDB 테이블과 함께 Amazon API Gateway 및 AWS Lambda를 데이터 저장소로 사용 온디맨드 용량을 위한 DynaiWDB 테이블 구성 C. Amazon DynamoDB 테이블을 데이터 저장소로 사용하여 Auto Scaling 그룹의 Application Load Balancer 뒤에서 Amazon EC2 인스턴스 실행 온디맨드 용량에 대해 DynamoDB 테이블 구성 D. Amazon DynamoDB 테이블을 데이터 저장소로 사용하여 Auto Scaling 그룹의 Network Load Balancer 뒤에서 Amazon EC2 인스턴스 실행 프로비저닝된 용량에 대해 DynamoDB 테이블 구성 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 디렉토리 서비스 및 DNS를 포함한 핵심 네트워크 서비스를 호스팅합니다. 온프레미스 데이터 센터에서 데이터 센터는 AWS Direct Connect(DX)를 사용하여 AWS 클라우드에 연결됩니다. 빠르고 비용 효율적이며 일관된 액세스가 필요한 추가 AWS 계정이 계획되어 있습니다. 이러한 네트워크 서비스 최소한의 운영 오버헤드로 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 구현해야 합니까?\nA. 각각의 새 계정에 DX 연결을 생성합니다. 네트워크 트래픽을 온프레미스 서버로 라우팅합니다. B. 필요한 모든 서비스에 대해 DX VPC에서 VPC 엔드포인트 구성 네트워크 트래픽을 온프레미스 서버로 라우팅합니다. C. 각각의 새 계정과 DX VPp 간에 VPN 연결을 생성하고 네트워크 트래픽을 온프레미스 서버로 라우팅합니다. D. 계정 간에 AWS Transit Gateway 구성 Transit Gateway에 DX를 할당하고 네트워크 트래픽을 온프레미스 서버로 라우팅 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사는 제품에 대한 수요가 증가함에 따라 성장을 경험하고 있습니다. 트래픽 급증 시 기존 구매 애플리케이션이 느림 애플리케이션이 모놀리식 3계층 동기 트랜잭션을 사용하고 때때로 애플리케이션에서 병목 현상을 확인하는 애플리케이션 계층 A 솔루션 설계자는 필요한 애플리케이션 응답을 충족할 수 있는 솔루션을 설계해야 합니다. 트래픽 볼륨 스파이크를 고려하는 동안. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 더 큰 Amazon EC2 인스턴스 크기를 사용하여 애플리케이션 인스턴스를 수직으로 확장합니다. B. AWS에 Oracle RAC를 도입하여 애플리케이션의 지속성 계층을 수평적으로 확장 C. Auto Scaling 그룹 및 Application Load Balancer를 사용하여 웹 및 애플리케이션 계층을 수평으로 확장 D. 비동기식 AWS Lambda 호출과 함께 Amazon Simple Queue Service(Amazon SQS)를 사용하여 애플리케이션과 데이터 계층을 분리합니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에 AWS로 마이그레이션하려는 143TB MySQL 데이터베이스가 있습니다. 사용할 계획입니다 Amazon Aurora MySQL은 앞으로 플랫폼으로 사용됩니다. 회사에는 100Mbps AWS Direct가 있습니다. Amazon VPC에 연결합니다. 어떤 솔루션이 회사의 요구 사항을 충족하고 시간이 가장 적게 소요됩니까?\nA. Amazon S3용 게이트웨이 엔드포인트 사용 Amazon S3로 데이터 마이그레이션 Aurora로 데이터 가져오기 B. Direct Connect 링크를 500Mbps로 업그레이드합니다. Amazon S3에 데이터 복사 Aurora로 데이터 가져오기 C. AWS Snowmobile을 주문하고 데이터베이스 백업을 복사합니다. AWS에서 데이터를 Amazon S3로 가져오도록 합니다. 백업을 Aurora로 가져오기 D. 4개의 50TB AWS Snowball 디바이스를 주문하고 여기에 데이터베이스 백업을 복사합니다. AWS에서 데이터를 Amazon S3로 가져오도록 합니다. 데이터를 Aurora로 가져오기 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사에 AWS Lambda 함수를 사용하여 다운로드하는 애플리케이션 워크플로가 있습니다. Amazon S3에서 파일 암호 해독 이러한 파일은 AWS Key Management Service를 사용하여 암호화됩니다. 고객 마스터 키(AWS KMS CMK) 솔루션 설계자는 다음을 수행할 솔루션을 설계해야 합니다. 필요한 권한이 올바르게 설정되었는지 확인하십시오. 이를 수행하는 작업 조합은 무엇입니까? (2개를 선택하십시오.)\nA. kms.decrypt 권한을 Lambda 함수의 리소스 정책에 연결합니다. B. KMS 키의 정책에서 Lambda IAM 역할에 대한 암호 해독 권한 부여 C. KMS 키의 정책에서 Lambda 리소스 정책에 대한 암호 해독 권한을 부여합니다. D. kms:decrypt 권한이 있는 새 IAM 정책을 생성하고 정책을 Lambda 함수에 연결 E. kms 암호 해독 권한이 있는 새 IAM 역할을 생성하고 실행 역할을 Lambda 함수에 연결합니다. 정답 풀이\r...\r답: BE\r#\r#\r#\r질문 201-300\r#\r#\r#\r질문\r#\rquestion 회사의 애플리케이션은 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 실행됩니다. (ALB) 여러 가용 영역에 걸쳐 Amazon EC2 Auto Scaling 그룹에서 실행되는 인스턴스 매월 1일 자정에 월말일 때 응용 프로그램이 훨씬 느려집니다. 재무 계산 일괄 실행 이로 인해 EC2 인스턴스의 CPU 사용률이 100%로 즉시 최고점에 도달합니다. 애플리케이션을 방해하는 요소 솔루션 설계자가 해야 할 일 애플리케이션이 워크로드를 처리하고 다운타임을 방지할 수 있도록 권장합니까?\nA. ALB 앞에 Amazon CloudFront 배포 구성 B. CPU 사용률을 기반으로 EC2 Auto Scaling Simple Scaling 정책 구성 C. 월별 일정에 따라 EC2 Auto Scaling 예약 조정 정책을 구성합니다. D. EC2 인스턴스에서 일부 워크로드를 제거하도록 Amazon ElastiCache 구성\n정답 풀이\r...\r답: C\r#\r설명 Amazon EC2 Auto Scaling에 대한 예약 조정 예약된 조정을 사용하면 자신의 조정 일정을 설정할 수 있습니다. 예를 들어 매주 웹 애플리케이션에 대한 트래픽은 수요일에 증가하기 시작하여 목요일에 높게 유지되며, 금요일부터 감소하기 시작합니다. 예측 가능한 트래픽을 기반으로 확장 작업을 계획할 수 있습니다. 웹 애플리케이션의 패턴. 스케일링 작업은 시간의 함수로 자동으로 수행됩니다. 날짜. https://docs.aws.amazon.com/autoscaling/ec2/userguide/schedule_time.html\n#\r#\r질문\r#\rquestion 회사에 Auto Scaling 그룹에 속해 있고 종종 여러 Linux가 있는 빌드 서버가 있습니다. 실행 중인 인스턴스. 빌드 서버에는 작업 및 구성을 위해 일관되고 마운트 가능한 공유 NFS 스토리지가 필요합니다. 솔루션 설계자가 권장해야 하는 스토리지 옵션은 무엇입니까?\nA. 아마존 S3 B. 아마존 FSx C. Amazon Elastic Block Store(Amazon EBS) D. Amazon Elastic File System(Amazon EFS) 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사 웹 사이트는 Application Load Balancer 뒤의 Amazon EC2 인스턴스에서 실행됩니다. (ALB) 웹사이트에는 동적 콘텐츠와 정적 콘텐츠가 혼합되어 있습니다. 웹사이트가 느립니다. 전 세계 사용자의 웹사이트 성능을 향상시킬 조치는 무엇입니까?\nA. Amazon CloudFront 배포를 생성하고 ALB를 오리진으로 구성한 다음 CloudFront 배포를 가리키도록 Amazon Route 53 레코드를 업데이트합니다. B. ALB에 대한 지연 시간 기반 Amazon Route 53 레코드 생성 그런 다음 더 큰 인스턴스 크기로 새 EC2 인스턴스를 시작하고 ALB에 인스턴스를 등록합니다. C. 4월 출시 사용자에게 더 가까운 다른 리전에서 동일한 웹 애플리케이션을 호스팅하는 EC2 인스턴스. 그런 다음 교차 리전 VPC 피어링을 사용하여 동일한 ALB에 인스턴스를 등록합니다. D. 사용자에게 가장 가까운 리전의 Amazon S3 버킷에서 웹 사이트를 호스팅하고 ALB 및 EC2 인스턴스를 삭제한 다음 S3 버킷을 가리키도록 Amazon Route 53 레코드를 업데이트합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 미디어 공유 애플리케이션을 구축 중이며 Amazon S3를 사용하기로 결정했습니다. 저장. 미디어 파일이 업로드되면 회사는 썸네일을 만드는 다단계 프로세스를 시작합니다. 이미지에서 개체를 식별하고 비디오를 표준 형식 및 해상도로 코드 변환하고 추출 메타데이터를 Amazon DynamoDB 테이블에 저장합니다. 메타데이터는 검색 및 항해. 트래픽 양은 가변적임 불필요한 비용. 솔루션 설계자는 이 워크로드를 지원하기 위해 무엇을 권장해야 합니까?\nA. Amazon S3에 콘텐츠를 업로드하는 데 사용되는 웹 사이트 또는 모바일 앱에 처리 기능을 구축합니다. 객체가 업로드될 때 필요한 데이터를 DynamoDB 테이블에 저장합니다. B. 객체가 S3 버킷에 저장될 때 AWS Step Functions 트리거 Step Functions 보유 객체를 처리하는 데 필요한 단계를 수행한 다음 DynamoDB 테이블에 메타데이터를 씁니다. C. 객체가 S3 버킷에 저장될 때 AWS Lambda 함수를 트리거합니다. function start AWS Batch를 통해 객체를 처리하는 단계를 수행합니다. 객체 데이터를 완료 시 DynamoDB 테이블 D. 객체가 다음과 같을 때 AWS Lambda 함수를 트리거하여 DynamoDB 테이블에 초기 항목을 저장합니다. Amazon S3에 업로드됩니다. Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행되는 프로그램 사용 unprocess를 위해 인덱스를 폴링하려면 프로그램을 사용하여 처리를 수행하십시오. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 전자 상거래 회사의 솔루션 설계자가 애플리케이션 로그 데이터를 백업하려고 합니다. Amazon S3 솔루션 설계자는 로그에 액세스하는 빈도 또는 어떤 로그에 액세스할지 확신할 수 없습니다. 회사가 비용을 최대한 낮추고자 하는 적절한 S3 스토리지 클래스. 이러한 요구 사항을 충족하려면 어떤 S3 스토리지 클래스를 구현해야 합니까?\nA. S3 빙하 B. S3 지능형 계층화 C. S3 Standard-Infrequent Access(S3 Standard-IA) D. S3 One Zone-Infrequent Access(S3 One Zone-IA) 정답 풀이\r...\r답: B\r#\r설명 S3 지능형 계층화 S3 Intelligent-Tiering은 최적화를 원하는 고객을 위해 설계된 새로운 Amazon S3 스토리지 클래스입니다. 성능에 영향을 주지 않고 데이터 액세스 패턴이 변경되면 스토리지 비용이 자동으로 운영 오버헤드. S3 Intelligent-Tiering은 두 액세스 계층(빈번한 액세스 및 드물게 액세스) 간에 데이터를 이동하여 자동 비용 절감 액세스 - 액세스 패턴이 변경될 때 알 수 없거나 액세스 패턴이 변경되는 데이터에 이상적입니다. . S3 Intelligent-Tiering은 두 개의 액세스 계층에 객체를 저장합니다. 하나는 빈번한 액세스에 최적화된 계층입니다. 그리고 드물게 액세스하도록 최적화된 또 다른 저비용 계층. 소규모 월간 모니터링을 위해 객체당 자동화 요금, S3 Intelligent-Tiering은 액세스 패턴을 모니터링하고 객체를 이동합니다. 30일 연속 액세스되지 않은 액세스 계층. 없다 S3 Intelligent-Tiering의 검색 수수료. 자주 액세스하지 않는 계층의 개체가 나중에 액세스되는 경우 자주 액세스하는 계층으로 자동으로 다시 이동합니다. S3 내의 액세스 계층 간에 객체를 이동할 때 추가 계층화 요금이 적용되지 않습니다. Intelligent-Tiering 스토리지 클래스. S3 Intelligent-Tiering은 99.9%의 가용성과 99.999999999% 내구성, S3와 동일한 짧은 대기 시간 및 높은 처리량 성능 제공 기준. https://aws.amazon.com/about-aws/whats-new/2018/11/s3-intelligent-tiering/\n#\r#\r질문\r#\rquestion 온라인 쇼핑 애플리케이션은 Amazon RDS 다중 AZ DB 인스턴스에 액세스합니다. 데이터 베이스 성능이 애플리케이션을 느리게 합니다. 차세대 인스턴스 유형으로 업그레이드한 후, 유의미한 성능 향상은 없었습니다. 분석에 따르면 약 700 IOPS가 유지되고 일반적인 쿼리가 장기간 실행되며 메모리 사용률이 높습니다. 솔루션 설계자는 이러한 문제를 해결하기 위해 어떤 애플리케이션 변경을 권장해야 합니까?\nA. RDS 인스턴스를 Amazon Redshift 클러스터로 마이그레이션하고 매주 가비지 수집 활성화 B. 장기 실행 쿼리를 새로운 다중 AZ RDS 데이터베이스로 분리하고 필요한 데이터베이스를 쿼리하도록 애플리케이션을 수정합니다. C. 2노드 Amazon ElastiCache 클러스터를 배포하고 클러스터를 먼저 쿼리하고 필요한 경우에만 데이터베이스를 쿼리하도록 애플리케이션을 수정합니다. D. 일반적인 쿼리를 위한 Amazon Simple Queue Service(Amazon SQS) FIFO 대기열을 생성하고 먼저 쿼리하고 필요한 경우에만 데이터베이스를 쿼리합니다.\n정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 모든 객체가 Amazon S3에 업로드되도록 솔루션 설계자는 무엇을 해야 합니까? 버킷이 암호화되어 있습니까?\nA. PutObject에 s3 x-amz-acl 헤더 세트가 없는 경우 거부하도록 버킷 정책 업데이트 B. PutObject에 private로 설정된 s3 x-amz-acl 헤더가 없는 경우 거부하도록 버킷 정책 업데이트 C. PutObject에 aws SecureTransport 헤더가 true로 설정되지 않은 경우 거부하도록 버킷 정책 업데이트 D. PutObject에 x-amz-server-side-encryption 헤더 세트가 없는 경우 거부하도록 버킷 정책 업데이트 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사는 지난 몇 년간 Amazon RDS 인스턴스에 분석 데이터를 저장해 왔습니다. 연령. 회사는 솔루션 설계자에게 사용자가 이 데이터에 액세스할 수 있는 솔루션을 찾도록 요청했습니다. API를 사용하면 애플리케이션이 비활성 기간을 경험할 것으로 예상되지만 몇 초 안에 트래픽 버스트 수신 솔루션 설계자가 제안해야 하는 솔루션은 무엇입니까?\nA. Amazon API Gateway를 설정하고 Amazon ECS를 사용합니다. B. Amazon API Gateway를 설정하고 AWS Elastic Beanstalk를 사용합니다. C. Amazon API Gateway 설정 및 AWS Lambda 함수 사용 D. Amazon API Gateway 설정 및 Auto Scaling과 함께 Amazon EC2 사용 정답 풀이\r...\r답: C\r#\r설명 AWS 람다 Lambda를 사용하면 거의 모든 유형의 애플리케이션 또는 백엔드 서비스에 대한 코드를 실행할 수 있습니다. 관리. 코드를 업로드하기만 하면 Lambda가 실행 및 확장에 필요한 모든 것을 처리합니다. 고가용성으로 코드를 작성합니다. 다른 AWS에서 자동으로 트리거되도록 코드를 설정할 수 있습니다. 서비스를 이용하거나 웹 또는 모바일 앱에서 직접 호출할 수 있습니다. 아마존 API 게이트웨이 Amazon API Gateway는 개발자가 쉽게 생성, 게시, 모든 규모에서 API를 유지 관리, 모니터링 및 보호합니다. API는 애플리케이션이 액세스할 수 있는 \u0026ldquo;정문\u0026rdquo; 역할을 합니다. 백엔드 서비스의 데이터, 비즈니스 로직 또는 기능. API 게이트웨이를 사용하여 다음을 생성할 수 있습니다. 실시간 양방향 통신 애플리케이션을 가능하게 하는 RESTful API 및 WebSocket API. API 게이트웨이는 컨테이너화된 서버리스 워크로드와 웹 애플리케이션을 지원합니다. API 게이트웨이는 최대 수십만 개의 수락 및 처리와 관련된 모든 작업을 처리합니다. 트래픽 관리, CORS 지원, 권한 부여 및 액세스를 포함한 동시 API 호출 제어, 조절, 모니터링 및 API 버전 관리. API Gateway에는 최소 수수료가 없습니다. 시작 비용. 수신한 API 호출과 외부로 전송된 데이터 양에 대해 비용을 지불합니다. API Gateway 계층형 가격 책정 모델을 사용하면 API 사용량이 확장됨에 따라 비용을 줄일 수 있습니다. https://aws.amazon.com/lambda/ https://aws.amazon.com/api-gateway/\n#\r#\r질문\r#\rquestion 회사의 애플리케이션이 이벤트의 단일 리전에서 Amazon EC2 인스턴스에서 실행 중입니다. 솔루션 설계자가 리소스를 두 번째 지역 솔루션 설계자는 이를 달성하기 위해 어떤 조합의 조치를 취해야 합니까? (2개 선택)\nA. EC2 인스턴스에서 볼륨을 분리하고 Amazon S3에 복사 B. 새 리전의 Amazon 머신 이미지(AMI)에서 새 EC2 인스턴스 시작 C. 새 리전에서 새 EC2 인스턴스를 시작하고 Amazon S3에서 새 리전으로 볼륨 복사 사례 D. EC2 인스턴스의 Amazon 머신 이미지(AMI)를 복사하고 다른 리전을 지정합니다. 목적지 E. Amazon S3에서 Amazon Elastic Block Store(Amazon EBS) 볼륨 복사 및 EC2 시작 해당 EBS 볼륨을 사용하는 대상 리전의 인스턴스 정답 풀이\r...\r답변: BD\r#\r설명 교차 리전 EC2 AMI 복사 AWS 리전에 걸쳐 있는 애플리케이션을 구축하기를 원한다는 것을 알고 있으며 다음을 제공하기 위해 노력하고 있습니다. 그렇게 하는 데 필요한 서비스와 기능을 제공합니다. 우리는 EBS Snapshot을 시작하면서 시작했습니다. 작년 말 복사 기능. 이 기능을 통해 리전에서 다음으로 스냅샷을 복사할 수 있습니다. 단 몇 번의 클릭으로 지역. 또한 지난 달 데이터 전송 비용을 크게(26%에서 83%) 절감했습니다. 두 개 이상의 AWS 리전에서 운영하는 데 비용이 적게 듭니다. 오늘 우리는 새로운 기능인 Amazon 머신 이미지(AMI) 복사를 소개합니다. AMI Copy를 사용하면 AWS 리전 간에 Amazon 머신 이미지를 쉽게 복사할 수 있습니다. AMI Copy는 여러 다음을 포함한 주요 시나리오: 간단하고 일관된 다중 지역 배포 - 한 지역에서 다른 지역으로 AMI를 복사할 수 있습니다. 동일한 AMI를 기반으로 일관된 인스턴스를 다른 지역으로 쉽게 시작할 수 있습니다. 확장성 - 귀사의 요구 사항을 충족하는 세계적 규모의 애플리케이션을 보다 쉽게 ​​설계하고 구축할 수 있습니다. 위치에 관계없이 사용자. 성능 - 애플리케이션을 배포하고 중요한 위치를 찾아 성능을 높일 수 있습니다. 응용 프로그램의 구성 요소를 사용자에게 더 가깝게 만듭니다. 당신은 또한 활용할 수 있습니다 인스턴스 유형 또는 기타 AWS 서비스와 같은 지역별 기능. 더 높은 가용성 - AWS 리전 전반에 걸쳐 애플리케이션을 설계 및 배포하여 유효성. 새 AMI가 사용 가능 상태가 되면 복사가 완료된 것입니다. https://aws.amazon.com/blogs/images/AWS/ec2-ami-copy-between-regions/\n#\r#\r질문\r#\rquestion 회사는 애플리케이션 로드 뒤의 Amazon EC2 인스턴스에서 웹 서비스를 실행합니다. 밸런서 인스턴스는 두 개의 가용성 그룹에 걸쳐 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 회사는 필요한 서비스 수준을 충족하기 위해 모든 라임에서 최소한의 투어 인스턴스가 필요합니다. 비용을 낮게 유지하면서 계약(SLA) SLA를 준수합니까?\nA. 짧은 휴지 기간으로 대상 추적 조정 정책 추가 B. 더 큰 인스턴스 유형을 사용하도록 Auto Scaling 그룹 시작 구성 변경 C. 3개의 가용 영역에서 6개의 서버를 사용하도록 Auto Scaling 그룹 변경 D. 2개의 가용 영역에서 8개의 서버를 사용하도록 Auto Scaling 그룹 변경 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 운영 팀에는 IAM 정책을 직접 적용해서는 안 된다는 표준이 있습니다. 사용자. 일부 신규 회원은 이 기준을 따르지 않았습니다. 운영 관리자는 다음이 필요합니다. 첨부된 정책으로 사용자를 쉽게 식별할 수 있는 방법입니다. 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. AWS CloudTrail을 사용하여 모니터링 B. 매일 실행할 AWS Config 규칙 생성 C. Amazon SNS에 IAM 사용자 변경 사항 게시 D. 사용자 수정 시 AWS Lambda 실행 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 회사의 관리형 스토리지 솔루션을 설계해야 합니다. 고성능 기계 학습을 포함하는 애플리케이션 이 애플리케이션은 AWS Fargate에서 실행됩니다. 연결된 스토리지는 파일에 동시 액세스하고 고성능을 제공해야 합니다. 솔루션 설계자가 권장하는 스토리지 옵션은 무엇입니까?\nA. 애플리케이션에 대한 Amazon S3 버킷을 생성하고 Fargate가 Amazon S3와 통신할 IAM 역할을 설정합니다. B. Amazon FSx for Lustre 파일 공유를 생성하고 Fargate가 FSx for Lustre와 통신할 수 있도록 IAM 역할을 설정합니다. C. Amazon Elastic File System(Amazon EFS) 파일 공유를 생성하고 Fargate가 Amazon EFS와 통신할 수 있도록 하는 IAM 역할을 설정합니다. D. 애플리케이션에 대한 Amazon Elastic Block Store(Amazon EBS) 볼륨을 생성하고 Fargate가 Amazon EBS와 통신할 수 있도록 하는 IAM 역할을 설정합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사에서 Amazon EC2를 사용하여 빅 데이터 분석 워크로드를 실행하고 있습니다. 이러한 변수 워크로드는 매일 밤 실행되며 다음 날 업무 시작까지 완료하는 것이 중요합니다. NS 솔루션 설계자는 가장 비용 효율적인 솔루션을 설계하는 임무를 받았습니다. 어떤 솔루션이 이를 달성할 것입니까?\nA. 스팟 플릿 B. 스팟 인스턴스 C. 예약 인스턴스 D. 온디맨드 인스턴스 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. 응용 프로그램은 다음 위치에 배포됩니다. us-east-1 리전의 3개 가용 영역에 있는 프라이빗 서브넷. 인스턴스는 다음을 수행할 수 있어야 합니다. 파일을 다운로드하기 위해 인터넷에 연결 지역. 인터넷 중단이 발생하지 않도록 구현해야 하는 솔루션 연결성?\nA. 각 가용 영역의 프라이빗 서브넷에 NAT 인스턴스를 배포합니다. B. 각 가용 영역의 퍼블릭 서브넷에 NAT 게이트웨이를 배포합니다. C. 각 가용 영역의 프라이빗 서브넷에 전송 게이트웨이를 배포합니다. D. 각 가용 영역의 퍼블릭 서브넷에 인터넷 게이트웨이를 배포합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사에 AWS Lambda 함수를 호출하는 애플리케이션이 있음 최근 코드 검토에서 발견됨 소스 코드에 저장된 데이터베이스 자격 증명 데이터베이스 자격 증명은 다음에서 제거해야 합니다. Lambda 소스 코드 자격 증명은 안전하게 저장되고 지속적으로 순환되어야 합니다. 보안 정책 요구 사항을 충족하기 위한 기반 솔루션 설계자가 충족하기 위해 권장해야 하는 사항 이러한 요구 사항은?\nA. AWS CloudHSM에 암호 저장 Lambda 함수를 검색할 수 있는 역할과 연결 키 ID가 지정된 CloudHSM의 비밀번호 B. AWS Secrets Manager에 암호를 저장합니다. Lambda 함수를 다음을 수행할 수 있는 역할과 연결합니다. 비밀 ID가 지정된 Secrets Manager에서 비밀번호 검색 C. 데이터베이스 암호를 Lambda 함수와 연결된 환경 변수로 이동 실행 시 환경 변수에서 비밀번호 검색 D. AWS Key Management Service(AWS KMS)에 암호 저장 Lambda 함수 연결 키 ID가 지정된 AWS KMS에서 암호를 검색할 수 있는 역할 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 개발 팀이 다른 회사와 협력하여 통합 제품. 다른 회사는 Amazon Simple Queue Service(Amazon SQS) 대기열에 액세스해야 합니다. 개발팀 계정에 포함되어 있습니다. 다른 회사에서 대기열을 폴링하려고 합니다. 그렇게 하기 위해 자신의 계정 권한을 포기하지 않고. 솔루션 설계자는 SQS 대기열에 대한 액세스를 어떻게 제공해야 합니까?\nA. SQS 대기열에 대한 다른 회사 액세스를 제공하는 인스턴스 프로필을 생성합니다. B. 다른 회사에 SQS 대기열에 대한 액세스를 제공하는 IAM 정책을 생성합니다. C. SQS 대기열에 대한 다른 회사 액세스를 제공하는 SQS 액세스 정책을 만듭니다. D. 다른 서비스를 제공하는 Amazon Simple Notification Service(Amazon SNS) 액세스 정책을 생성합니다. SQS 대기열에 대한 회사 액세스. 정답 풀이\r...\r답: C\r#\rSQS 엑엑엑세스 중독을 쫓고 있습니다. #\r#\r질문\r#\rquestion 회사에서 데이터 처리를 위해 하이브리드 워크로드를 실행하려고 합니다. 데이터는 다음과 같아야 합니다. NFS 프로토콜을 사용하여 로컬 데이터 처리를 위해 온프레미스 애플리케이션에서 액세스해야 하며 또한 추가 분석 및 배치 처리를 위해 AWS 클라우드에서 액세스할 수 있습니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. AWS Storage Gateway 파일 게이트웨이를 사용하여 AWS에 파일 스토리지를 제공한 다음 분석을 수행합니다. AWS 클라우드의 이 데이터에 대해 B. AWS 스토리지 게이트웨이 테이프 게이트웨이를 사용하여 로컬 데이터의 백업을 AWS에 복사한 다음 AWS 클라우드에서 이 데이터에 대한 분석을 수행합니다. C. 저장 볼륨 구성의 AWS Storage Gateway 볼륨 게이트웨이를 사용하여 정기적으로 로컬 데이터의 스냅샷을 생성한 다음 데이터를 AWS에 복사합니다. D. 캐시된 볼륨 구성에서 AWS Storage Gateway 볼륨 게이트웨이를 사용하여 모든 AWS 클라우드에 로컬 스토리지를 만든 다음 클라우드에서 이 데이터에 대한 분석을 수행합니다. 정답 풀이\r...\r답변: A\r#\rNFS는 파일을 통해 전송됩니다. #\r#\r질문\r#\rquestion 회사에 여러 Amazon EC2 인스턴스에 배포된 다중 계층 애플리케이션이 있습니다. Auto Scaling 그룹. Amazon RDS for Oracle 인스턴스는 Oracle 전용 PUSQL을 사용하는 데이터 계층인 애플리케이션입니다. 기능. 애플리케이션에 대한 트래픽이 꾸준히 증가하고 있어 EC2 인스턴스가 i RDS 인스턴스에 과부하가 걸리면 스토리지가 부족해집니다. Auto Scaling 그룹에는 모든 조정 메트릭과 최소 정상 인스턴스 수만 정의합니다. 회사는 다음과 같이 예측합니다. 트래픽은 안정되기 전에 안정적이지만 예측할 수 없는 속도로 계속 증가할 것입니다. 솔루션 설계자는 시스템이 증가된 교통? (2개 선택)\nA. RDS for Oracle 인스턴스에서 스토리지 Auto Scaling을 구성합니다. B. 데이터베이스를 Amazon Aurora로 마이그레이션하여 Auto Scaling 스토리지 사용 C. 사용 가능한 스토리지 공간 부족에 대한 Oracle 인스턴스용 RDS에 대한 경보를 구성합니다. D. 평균 CPU를 스케일링 메트릭으로 사용하도록 Auto Scaling 그룹을 구성합니다. E. Auto Scaling 그룹이 평균 여유 메모리를 스케일링 메트릭으로 사용하도록 구성합니다. 정답 풀이\r...\r답변: AC\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon S3를 객체 스토리지 솔루션으로 사용합니다. 회사에는 수천 개의 S3가 있습니다. 데이터를 저장하는 데 사용합니다. 일부 S3 버킷에는 다른 버킷보다 액세스 빈도가 낮은 데이터가 있습니다. NS 솔루션 설계자는 수명 주기 정책이 일관되게 구현되지 않았거나 구현되고 있음을 발견했습니다. 부분적으로. 그 결과 데이터가 고가의 스토리지에 저장됩니다. 어떤 솔루션이 개체의 가용성을 손상시키지 않으면서 비용을 절감할 수 있습니까?\nA. S3 ACL 사용 B. Amazon Elastic Block Store EBS) 자동 스냅샷 사용 C. S3 지능형 계층화 스토리지 사용 D. S3 One Zone-Infrequent Access(S3 One Zone-IA)를 사용합니다. 정답 풀이\r...\r답: C\r#\rB\n#\r#\r질문\r#\rquestion 한 회사는 최근에 대한 정보를 중앙 집중화하기 위해 새로운 감사 시스템을 배포했습니다. Amazon EC2 인스턴스용 운영 체제 버전, 패치 및 설치된 소프트웨어. 솔루션 설계자는 EC2 Auto Scaling 그룹을 통해 프로비저닝된 모든 인스턴스가 성공적으로 전송되도록 해야 합니다. 시작 및 종료되는 즉시 감사 시스템에 보고합니다. 어떤 솔루션이 이러한 목표를 가장 효율적으로 달성합니까?\nA. 예약된 AWS Lambda 함수를 사용하고 모든 EC2 인스턴스에서 원격으로 스크립트를 실행하여 데이터를 감사 시스템에 제공합니다. B. EC2 Auto Scaling 수명 주기 후크를 사용하여 사용자 지정 스크립트를 실행하여 감사 시스템에 데이터 전송 인스턴스가 시작되고 종료될 때. C. EC2 Auto Scaling 시작 구성을 사용하여 전송할 사용자 데이터를 통해 사용자 지정 스크립트를 실행합니다. 인스턴스가 시작되고 종료될 때 감사 시스템에 데이터를 전송합니다. D. 인스턴스 운영 체제에서 사용자 정의 스크립트를 실행하여 감사 시스템에 데이터를 보냅니다. 인스턴스가 시작되고 종료될 때 EC2 Auto Scaling 그룹에서 실행할 스크립트를 구성합니다. 종료. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자가 금융 시장의 성과를 분석하는 시스템을 설계하고 있습니다. 시장이 닫혀 있는 동안 시스템은 매 4시간 동안 일련의 컴퓨팅 집약적인 작업을 실행합니다. 밤 컴퓨팅 작업을 완료하는 데 걸리는 시간은 일정하게 유지될 것으로 예상되며 작업을 완료할 수 없습니다. 시작되면 중단됨 일단 완료되면 시스템은 최소 1년 동안 실행될 것으로 예상됨 시스템 비용을 줄이려면 어떤 유형의 Amazon EC2 인스턴스를 사용해야 합니까?\nA. 스팟 인스턴스 B. 온디맨드 인스턴스 C. 표준 예약 인스턴스 D. 정기 예약 인스턴스 정답 풀이\r...\r답변: D\r#\r정기예약은 사용시간이 정해져 있지 않습니다. #\r#\r질문\r#\rquestion 회사는 웹사이트에서 검색 가능한 항목 저장소를 유지 관리합니다. 넥타이 데이터는 천만 개 이상의 행을 포함하는 MySQL용 Amazon RDS 데이터베이스 테이블 데이터베이스에는 2TB의 범용 SSD(gp2) 스토리지. 매일 이 데이터에 대한 수백만 건의 업데이트가 있습니다. 회사의 웹사이트 회사는 일부 작업이 10초 이상 걸리는 것을 발견했습니다. 데이터베이스 스토리지 성능이 병목 현상이라고 판단한 솔루션 성능 문제를 해결합니까?\nA. 스토리지 유형을 프로비저닝된 IOPS SSD(io1)로 변경합니다. B. 인스턴스를 메모리 최적화 인스턴스 클래스로 변경 C. 인스턴스를 버스트 가능한 성능 DB 인스턴스 클래스로 변경 D. MySQL 기본 비동기식 복제로 다중 AZ RDS 읽기 전용 복제본 활성화 정답 풀이\r...\r답: B\r#\r병목 현상이 발생했습니다. #\r#\r질문\r#\rquestion AWS에서 호스팅되는 애플리케이션에 성능 문제가 발생하고 애플리케이션 공급업체는 추가 문제 해결을 위해 로그 파일 분석을 수행하려고 합니다. 로그 파일은 다음 위치에 저장됩니다. Amazon S3이며 크기는 10GB입니다. 애플리케이션 소유자는 공급업체에서 로그 파일을 사용할 수 있도록 합니다. 제한된 시간 동안. 이 작업을 수행하는 가장 안전한 방법은 무엇입니까?\nA. S3 객체에 대한 공개 읽기를 활성화하고 공급업체에 대한 링크를 제공합니다. B. 파일을 Amazon WorkDocs에 업로드하고 공개 링크를 공급업체와 공유합니다. C. 미리 서명된 URL을 생성하고 만료되기 전에 공급업체가 로그 파일을 다운로드하도록 합니다. D. 공급업체가 S3 버킷 및 애플리케이션에 대한 액세스 권한을 제공할 IAM 사용자를 생성합니다. 억지로 시키다 다단계 인증. 정답 풀이\r...\r답: C\r#\r설명 다른 사람과 개체 공유 기본적으로 모든 개체는 비공개입니다. 개체 소유자만 이러한 개체에 액세스할 수 있는 권한이 있습니다. 그러나 개체 소유자는 선택적으로 미리 서명된 URL을 생성하여 다른 사람과 개체를 공유할 수 있습니다. 자체 보안 자격 증명을 사용하여 개체를 다운로드할 수 있는 시간 제한 권한을 부여합니다. 객체에 대해 미리 서명된 URL을 생성할 때 보안 자격 증명을 제공하고 다음을 지정해야 합니다. 버킷 이름, 객체 키, HTTP 메서드(객체를 다운로드하는 GET) 및 만료를 지정합니다. 날짜와 시간. 미리 서명된 URL은 지정된 기간 동안만 유효합니다. 그러면 미리 서명된 URL을 받는 사람이 개체에 액세스할 수 있습니다. 예를 들어 동영상이 있는 경우 버킷에 있고 버킷과 객체가 모두 비공개인 경우 다음을 통해 다른 사람과 비디오를 공유할 수 있습니다. 미리 서명된 URL을 생성합니다. https://docs.aws.amazon.com/AmazonS3/latest/dev/ShareObjectPreSignedURL.html\n#\r#\r질문\r#\rquestion ELB 애플리케이션 로드 뒤의 Amazon EC2 인스턴스에서 웹 사이트를 실행하는 회사 밸런서. DNS에는 Amazon Route 53이 사용됩니다. 회사는 다음과 같은 백업 웹 사이트를 설정하려고 합니다. 기본 웹사이트가 다음과 같은 경우 사용자가 연결할 수 있는 전화번호 및 이메일 주소가 포함된 메시지 아래에. 회사는 이 솔루션을 어떻게 배포해야 합니까?\nA. 백업 웹사이트에 Amazon S3 웹사이트 호스팅을 사용하고 Route 53 장애 조치 라우팅 정책을 사용합니다. B. 백업 웹사이트 및 Route 53 지연 라우팅 정책에 Amazon S3 웹사이트 호스팅을 사용합니다. C. 다른 AWS 리전에 애플리케이션을 배포하고 장애 조치 라우팅을 위해 ELB 상태 확인을 사용합니다. D. 다른 AWS 리전에 애플리케이션을 배포하고 기본 리전에서 서버 측 리디렉션을 사용합니다. 웹사이트. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 AWS에서 제품 정보 웹 페이지를 호스팅합니다. 기존 솔루션은 Auto Scaling 그룹의 Application Load Balancer 뒤에 있는 여러 Amazon C2 인스턴스. NS 웹사이트는 또한 사용자 지정 DNS 이름을 사용하고 전용 SSL을 사용하여 HTTPS와만 통신합니다. 자격증. 회사는 신제품 출시를 계획하고 있으며 사용자가 전 세계에서 새로운 웹사이트에서 최고의 경험을 할 수 있습니다. 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 해야 합니까?\nA. Amazon CloudFront를 사용하도록 애플리케이션을 재설계합니다. B. AWS Elastic Beanstalk를 사용하도록 애플리케이션을 재설계합니다. C. Network Load Balancer를 사용하도록 애플리케이션을 재설계합니다. D. Amazon S3 정적 웹 사이트 호스팅을 사용하도록 애플리케이션을 재설계합니다. 정답 풀이\r...\r답변: A\r#\r설명 Amazon CloudFront란 무엇입니까?\nAmazon CloudFront는 정적 및 동적 웹 배포 속도를 높이는 웹 서비스입니다. .html, .css, .js 및 이미지 파일과 같은 콘텐츠를 사용자에게 제공합니다. CloudFront에서 콘텐츠 제공 엣지 로케이션이라고 하는 전 세계 데이터 센터 네트워크를 통해 사용자가 콘텐츠를 요청할 때 CloudFront에서 제공하는 경우 사용자는 가장 낮은 레이턴시(시간 지연)를 최소화하여 콘텐츠가 최상의 성능으로 전달되도록 합니다. 콘텐츠가 지연 시간이 가장 짧은 엣지 로케이션에 이미 있는 경우 CloudFront에서 콘텐츠를 제공합니다. 즉시. 콘텐츠가 해당 엣지 로케이션에 없는 경우 CloudFront 는 Amazon S3 버킷, MediaPackage 채널 또는 HTTP 서버(예: 웹 서버) 귀하가 귀하의 콘텐츠의 최종 버전에 대한 소스로 식별한 것입니다. 예를 들어 당신이 CloudFront가 아닌 기존 웹 서버에서 이미지를 제공합니다. 예를 들어, URL http://example.com/sunsetphoto.png를 사용하여 이미지, sunsetphoto.png. 사용자는 이 URL로 쉽게 이동하여 이미지를 볼 수 있습니다. 그러나 그들은 아마도 그들의 요청은 상호 연결된 복잡한 컬렉션을 통해 한 네트워크에서 다른 네트워크로 라우팅되었습니다. 이미지를 찾을 때까지 인터넷을 구성하는 네트워크. CloudFront는 AWS를 통해 각 사용자 요청을 라우팅하여 콘텐츠 배포 속도를 높입니다. 콘텐츠를 가장 잘 제공할 수 있는 엣지 로케이션으로 백본 네트워크를 연결합니다. 일반적으로 이것은 최종 사용자에게 가장 빠른 전송을 제공하는 CloudFront 엣지 서버입니다. AWS 네트워크 사용 사용자의 요청이 통과해야 하는 네트워크의 수를 크게 줄입니다. 성능을 향상시킵니다. 사용자는 파일의 첫 번째 바이트를 로드하는 데 걸리는 지연 시간을 줄이고 더 높은 데이터 전송 속도. 또한 파일(개체라고도 함)의 복사본으로 인해 안정성과 가용성이 향상됩니다. 이제 전 세계 여러 엣지 로케이션에 보관(또는 캐시)됩니다. https://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/Introduction.html\n#\r#\r질문\r#\rquestion 솔루션 설계자가 레거시 문서 관리 애플리케이션을 최적화하기 위해 노력하고 있습니다. 온프레미스 데이터 센터의 Microsoft Windows Server에서 실행됩니다. 응용 프로그램은 큰 네트워크 파일 공유에 있는 파일 수 CIO는 온-프레미스를 줄이기 위해 온프레미스 스토리지를 AWS로 이동하여 데이터 센터 공간을 확보하고 스토리지 비용을 최소화합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 수행해야 합니까?\nA. AWS Storage Gateway 파일 게이트웨이를 설정합니다. B. Amazon Elastic File System(Amazon EFS) 설정 C. AWS Storage Gateway를 볼륨 게이트웨이로 설정 D. Amazon Elastic Block Store(Amazon EBS) 볼륨을 설정합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 사내 데이터베이스 서버를 위한 내구성 있는 백업 스토리지 솔루션이 필요한 회사 온프레미스 애플리케이션이 빠른 복구를 위해 이러한 백업에 대한 액세스를 유지하도록 합니다. NS 회사는 이러한 백업의 대상으로 AWS 스토리지 서비스를 사용할 것입니다. 솔루션 설계자는 최소한의 운영 오버헤드로 솔루션 설계 솔루션을 설계해야 하는 솔루션 구현하다?\nA. AWS Storage Gateway 파일 게이트웨이를 온프레미스에 배포하고 Amazon S3와 연결합니다. 버킷 B. 데이터베이스를 AWS Storage Gateway 볼륨 게이트웨이에 백업하고 다음을 사용하여 액세스합니다. 아마존 S3 API. C. 데이터베이스 백업 파일을 Amazon Elastic Block Store(Amazon EBS) 볼륨으로 전송 Amazon EC2 인스턴스에 연결됩니다. D. 데이터베이스를 AWS Snowball 디바이스에 직접 백업하고 수명 주기 규칙을 사용하여 데이터 이동 Amazon S3 Glacier Deep Archive로. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 여러 Amazon EC2 인스턴스를 사용하여 데이터를 수집하는 애플리케이션을 실행합니다. 해당 사용자 데이터는 처리되어 장기 보관을 위해 Amazon S3로 전송됩니다. 애플리케이션에 따르면 EC2 인스턴스가 실행되지 않는 기간이 길었습니다. used 솔루션 설계자는 활용도를 최적화하고 비용을 절감하는 솔루션을 설계해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 온디맨드 인스턴스가 있는 Auto Scaling 그룹에서 Amazon EC2를 사용합니다. B. 온디맨드 인스턴스와 함께 Amazon Lightsail을 사용하도록 애플리케이션 구축 C. Amazon CloudWatch 크론 작업을 생성하여 EC2 인스턴스가 없을 때 자동으로 중지합니다. 활동 D. Amazon Simple Queue Service에서 이벤트 중심 설계를 사용하도록 애플리케이션 재설계 (Amazon SQS) 및 AWS Lambda. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자가 개발자가 새로운 전자 상거래 쇼핑 카트를 디자인하도록 돕고 있습니다. AWS 서비스를 사용하는 애플리케이션. 개발자는 현재 데이터베이스 스키마를 확신하지 못하며 다음을 기대합니다. 전자 상거래 사이트가 성장함에 따라 변경합니다. 솔루션은 복원력과 능력이 높아야 합니다. 읽기 및 쓰기 용량을 자동으로 확장합니다. 이러한 요구 사항을 충족하는 데이터베이스 솔루션은 무엇입니까?\nA. Amazon Aurora PostgreSQL B. 온디맨드가 활성화된 Amazon DynamoDB C. DynamoDB 스트림이 활성화된 Amazon DynamoDB D. Amazon SQS 및 Amazon Aurora PostgreSQL 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 3계층 웹 애플리케이션은 고객의 주문을 처리합니다. 웹 계층은 다음으로 구성됩니다. 3개의 EC2 인스턴스로 구성된 중간 계층인 Application Load Balancer 뒤에 있는 Amazon EC2 인스턴스 Amazon SQS를 사용하여 웹 계층에서 분리됩니다. 및 Amazon DynamoDB 백엔드. 피크 타임에는 사이트를 사용하여 주문을 제출한 고객은 받기까지 평소보다 훨씬 오래 기다려야 합니다. 긴 처리 시간으로 인한 확인. 솔루션 설계자는 이러한 요소를 줄여야 합니다. 처리 시간.\n이를 달성하는 데 가장 효과적인 조치는 무엇입니까?\nA. SQS 대기열을 Amazon Kinesis Data Firehose로 교체합니다. B. DynamoDB 백엔드 계층 앞에서 ​​Redis용 Amazon ElastiCache를 사용합니다. C. Amazon CloudFront 배포를 추가하여 웹 계층에 대한 응답을 캐시합니다. D. Amazon EC2 Auto Scaling을 사용하여 SOS 대기열을 기반으로 중간 계층 인스턴스 확장 깊이. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사는 사용자 데이터를 캡처하고 미래를 위해 저장하는 음식 주문 애플리케이션을 구축했습니다. 분석 애플리케이션의 정적 프런트 엔드는 Amazon EC2 인스턴스에 배포됩니다. 프런트 엔드 애플리케이션은 별도의 EC2 인스턴스에서 실행되는 백엔드 애플리케이션으로 요청을 보냅니다. 그런 다음 백엔드 애플리케이션은 Amazon RDS에 데이터를 저장합니다. 아키텍처를 분리하고 확장 가능하게 만드시겠습니까?\nA. Amazon S3를 사용하여 프런트 엔드 애플리케이션을 제공하고 Amazon Simple에 요청 쓰기 Notification Service(Amazon SNS) 주제 HTTP/HTTPS에 Amazon EC2 인스턴스 구독 주제의 끝점 및 Amazon RDS에서 데이터를 처리 및 저장 B. Amazon S3를 사용하여 Amazon EC2에 실행 요청을 보내는 프런트 엔드 애플리케이션 제공 백엔드 애플리케이션 백엔드 애플리케이션은 Amazon RDS에서 데이터를 처리하고 저장합니다. C. EC2 인스턴스를 사용하여 프런트 엔드를 제공하고 Amazon SQS 대기열에 요청을 작성합니다. Auto Scaling 그룹의 백엔드 인스턴스 및 처리 및 저장할 대기열 깊이에 따라 확장 Amazon RDS의 데이터 D. Amazon S3를 사용하여 정적 프런트 엔드 애플리케이션을 제공하고 Amazon API에 요청 보내기 Amazon SQS 대기열에 요청을 작성하는 게이트웨이 백엔드 인스턴스를 자동 Amazon RDS에서 데이터를 처리하고 저장하기 위해 대기열 깊이에 따라 그룹 및 규모 조정 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 마이그레이션 중인 영구 데이터베이스에 대한 솔루션을 설계해야 합니다. 온프레미스에서 AWS로. 데이터베이스에는 데이터베이스에 따라 64,000 IOPS가 필요합니다. 관리자. 가능한 경우 데이터베이스 관리자는 단일 Amazon Elastic Block을 사용하려고 합니다. 데이터베이스 인스턴스를 호스팅할 저장소(Amazon EBS) 볼륨. 데이터베이스 관리자의 기준을 효과적으로 충족하는 솔루션은 무엇입니까?\nA. 13 I/O 최적화 제품군의 인스턴스를 사용하고 로컬 임시 스토리지를 활용하여 IOPS 요구 사항. B. Amazon EBS 프로비저닝된 IOPS SSD(io1)로 Nitro 기반 Amazon EC2 인스턴스 생성 볼륨 첨부. 64,000 IOPS를 갖도록 볼륨을 구성합니다. C. Amazon Elastic File System(Amazon EFS) 볼륨을 생성하고 데이터베이스 인스턴스에 매핑하고 볼륨을 사용하여 데이터베이스에 필요한 IOPS를 달성합니다. D. 두 개의 볼륨을 프로비저닝하고 각각에 32,000 IOPS를 할당합니다. 운영 체제에서 논리 볼륨 생성 IOPS 요구 사항을 달성하기 위해 두 볼륨을 집계하는 시스템 수준입니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자가 고성능 컴퓨팅(HPC)을 위한 스토리지를 설계하고 있습니다. Amazon Linux 기반 환경. 워크로드는 많은 양의 데이터를 저장하고 처리합니다. 공유 스토리지와 헤비 컴퓨팅이 필요한 엔지니어링 도면. 어떤 스토리지 옵션이 최적의 솔루션이 될까요?\nA. Amazon Elastic File System(Amazon EFS) B. Lustre용 Amazon FSx C. Amazon EC2 인스턴스 스토어 D. Amazon EBS 프로비저닝된 IOPS SSD(io1) 정답 풀이\r...\r답: B\r#\r설명 Lustre용 Amazon FSx Amazon FSx for Lustre는 Lustre 파일을 기반으로 AWS에서 제공하는 새로운 완전 관리형 서비스입니다. 체계. Amazon FSx for Lustre는 빠른 처리에 최적화된 고성능 파일 시스템을 제공합니다. 머신 러닝, 고성능 컴퓨팅(HPC), 비디오 처리, 금융 등의 워크로드 모델링 및 전자 설계 자동화(EDA). FSx for Lustre를 사용하면 고객이 필요에 따라 Lustre 파일 시스템을 생성하고 이를 Amazon S3 버킷. 파일 시스템 생성의 일부로 Lustre는 버킷의 객체를 읽고 파일 시스템 메타데이터에 추가합니다. 그러면 VPC의 모든 Lustre 클라이언트가 데이터에 액세스할 수 있습니다. 고속 Lustre 파일 시스템에 캐시됩니다. 이는 HPC 워크로드에 이상적입니다. 복잡성을 관리할 필요 없이 최적화된 Lustre 파일 시스템의 속도를 얻을 수 있습니다. Lustre 클러스터 배포, 최적화 및 관리. 또한 파일 시스템이 기본적으로 Amazon S3와 함께 작동하도록 하면 시스템을 종료할 수 있습니다. Lustre 파일 시스템은 필요하지 않지만 다른 AWS 서비스를 통해 Amazon S3의 객체에 계속 액세스할 수 있습니다. FSx for Lustre를 사용하면 HPC 작업의 출력을 다시 Amazon S3에 쓸 수도 있습니다.\n#\r#\r질문\r#\rquestion 회사의 운영 팀에 알림을 보내도록 구성된 기존 Amazon S3 버킷이 있습니다. 버킷 내에서 새 객체가 생성될 때 Amazon SQS 대기열입니다. 개발팀도 새 객체가 생성될 때 이벤트를 수신하려고 합니다. 기존 운영 팀 워크플로는 그대로 남아 있습니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 다른 SQS 대기열 생성 버킷의 S3 이벤트를 업데이트하여 다음과 같은 경우 새 대기열도 업데이트합니다. 새로운 객체가 생성됩니다. B. Amazon S3만 대기열에 액세스하도록 허용하는 새 SQS 대기열 생성, Amazon S3 업데이트 새 개체가 생성될 때 이 대기열을 업데이트합니다. C. 업데이트를 위한 Amazon SNS 주제 및 SQS 대기열을 생성합니다. 이벤트를 보낼 버킷 업데이트 새로운 주제. Amazon SNS를 폴링하도록 두 대기열을 모두 업데이트합니다. D. 버킷 업데이트를 위한 Amazon SNS 주제 및 SQS 대기열을 생성합니다. 보낼 버킷 업데이트 새 주제에 대한 이벤트 주제의 두 대기열에 대한 구독을 추가합니다. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 마케팅 회사는 통계 분석을 위해 Amazon S3 버킷에 CSV 파일을 저장하고 있습니다. Amazon EC2 인스턴스의 애플리케이션에는 에 저장된 CSV 데이터를 효율적으로 처리할 수 있는 권한이 필요합니다. S3 버킷. EC2 인스턴스에 S3 버킷에 대한 액세스 권한을 가장 안전하게 부여하는 작업은 무엇입니까?\nA. 리소스 기반 정책을 S3 버킷에 연결 B. S3 버킷에 대한 특정 권한이 있는 애플리케이션의 IAM 사용자 생성 C. IAM 역할을 EC2 인스턴스 프로파일에 대한 최소 권한 권한과 연결 D. API에 사용할 인스턴스의 애플리케이션을 위해 EC2 인스턴스에 직접 AWS 자격 증명을 저장합니다. 전화 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 매월 통화 녹음을 저장합니다. 통계적으로 녹음된 데이터는 1년 이내에 무작위로 참조되지만 1년 후에는 거의 액세스되지 않는 파일 1년보다 새로운 파일 old는 가능한 한 빨리 쿼리하고 검색해야 합니다. 오래된 파일 검색의 지연은 허용됩니다. 솔루션 설계자는 기록된 데이터를 최소한의 비용으로 저장해야 합니다. 가장 비용 효율적인 솔루션은 무엇입니까?\nA. Amazon S3 Glacier에 개별 파일을 저장하고 S3에서 생성된 객체 태그에 검색 메타데이터를 저장합니다. Glacier 쿼리 S3 Glacier 태그 및 S3 Glacier에서 파일 검색 B. Amazon S3에 개별 파일 저장 수명 주기 정책을 사용하여 파일을 Amazon S3 Glacier로 이동 ~ 후에 일년. Amazon S3 또는 S3 Glacier에서 파일을 쿼리하고 검색합니다. C. Amazon S3 사용 수명 주기에서 개별 파일을 아카이브하고 각 아카이브에 대한 검색 메타데이터를 저장합니다. 1년 후 파일을 Amazon S3 Glacier로 이동하는 정책 검색을 통해 파일을 쿼리 및 검색 Amazon S3의 메타데이터용 D. Amazon S3에 개별 파일 보관 수명 주기 정책을 사용하여 파일을 Amazon S3 Glacier로 이동 1년 후 Amazon DynamoDB에 검색 메타데이터 저장 DynamoDB에서 파일을 쿼리하고 Amazon S3 또는 S3 Glacier에서 검색 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사의 웹 애플리케이션이 여러 Linux Amazon EC2 인스턴스를 사용하고 데이터를 저장하고 있습니다. Amazon EBS 볼륨에서. 회사는 복원력을 높일 수 있는 솔루션을 찾고 있습니다. 장애 시 적용하고 원자성, 일관성, 절연 및 내구성(ACID). 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 해야 합니까?\nA. 각 가용 영역의 EC2 인스턴스에서 애플리케이션을 시작합니다. 각 EC2 인스턴스에 EBS 볼륨을 연결합니다. B. 여러 가용 영역에 걸쳐 Auto Scaling 그룹이 있는 Application Load Balancer 생성 각 EC2 인스턴스에 인스턴스 스토어 탑재 C. 여러 가용 영역에 걸쳐 Auto Scaling 그룹이 있는 Application Load Balancer를 생성합니다. Amazon EFS에 데이터를 저장하고 각 인스턴스에 대상을 탑재합니다. D. 여러 가용 영역에 걸쳐 Auto Scaling 그룹이 있는 Application Load Balancer 생성 Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA)를 사용하여 데이터 저장 정답 풀이\r...\r답: C\r#\r설명 Amazon EFS가 Amazon EC2와 작동하는 방식 다음 그림은 Amazon EFS 파일 시스템에 액세스하는 VPC의 예를 보여줍니다. 여기서 EC2 VPC의 인스턴스에는 파일 시스템이 마운트되어 있습니다. 이 그림에서 VPC에는 3개의 가용 영역이 있으며 각 가용 영역에는 하나의 탑재 대상이 생성됩니다. 동일한 가용성 내의 탑재 대상에서 파일 시스템에 액세스하는 것이 좋습니다. 존. 가용 영역 중 하나에는 두 개의 서브넷이 있습니다. 그러나 마운트 대상은 하나만 생성됩니다. 서브넷의. Auto Scaling의 이점 더 나은 내결함성. Amazon EC2 Auto Scaling은 인스턴스가 비정상 상태일 때 감지하여 종료할 수 있습니다. 그것을 대체할 인스턴스를 시작합니다. 다음을 사용하도록 Amazon EC2 Auto Scaling을 구성할 수도 있습니다. 여러 가용 영역. 하나의 가용 영역을 사용할 수 없게 되면 Amazon EC2 Auto Scaling 보상하기 위해 다른 인스턴스에서 인스턴스를 시작할 수 있습니다. 더 나은 가용성. Amazon EC2 Auto Scaling은 애플리케이션이 항상 올바른 권한을 갖도록 보장합니다. 현재 트래픽 수요를 처리할 수 있는 용량. 더 나은 비용 관리. Amazon EC2 Auto Scaling은 용량을 동적으로 늘리거나 줄일 수 있습니다. 필요에 따라. 사용한 EC2 인스턴스에 대해 비용을 지불하기 때문에 인스턴스를 시작하여 비용을 절약할 수 있습니다. 필요할 때 종료하고 필요하지 않을 때 종료합니다. https://docs.aws.amazon.com/efs/latest/ug/how-it-works.html#how-it-works-ec2 https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-benefits.html\n#\r#\r질문\r#\rquestion 북미에 시설을 갖춘 회사입니다. 유럽과 아시아는 새로운 분산형을 설계하고 있습니다. 글로벌 공급망 및 제조 프로세스를 최적화하기 위한 애플리케이션입니다. 하나에 예약된 주문 대륙은 1초 이내에 모든 지역에서 볼 수 있어야 합니다. 데이터베이스는 다음을 지원할 수 있어야 합니다. 짧은 RTO(복구 시간 목표)로 장애 조치 제조에 영향을 미치지 않도록 하십시오. 솔루션 설계자는 무엇을 권장해야 합니까?\nA. Amazon DynamoDB 전역 테이블 사용 B. Amazon Aurora 글로벌 데이터베이스 사용 C. 리전 간 읽기 전용 복제본과 함께 MySQL용 Amazon RDS 사용 D. 리전 간 읽기 전용 복제본과 함께 PostgreSQL용 Amazon RDS 사용 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 전 세계 도시의 온도, 습도 및 대기압 데이터를 수집합니다. 여러 대륙. 사이트당 매일 수집되는 평균 데이터 볼륨은 500GB입니다. 각 사이트에는 초고속 인터넷이 있습니다 연결. 회사의 일기 예보 애플리케이션은 단일 지역을 기반으로 하며 매일 데이터. 이러한 모든 글로벌 사이트에 대한 데이터를 집계하는 가장 빠른 방법은 무엇입니까?\nA. 대상 버킷에서 Amazon S3 Transfer Acceleration을 활성화합니다. 멀티파트 업로드를 사용하여 대상 버킷에 사이트 데이터를 직접 업로드합니다. B. 가장 가까운 AWS 리전의 Amazon S3 버킷에 사이트 데이터를 업로드합니다. 리전 간 S3 사용 대상 버킷에 객체를 복사하기 위한 복제. C. 가장 가까운 AWS 리전의 Amazon S3 버킷에 사이트 데이터를 업로드합니다. 리전 간 S3 사용 대상 버킷에 객체를 복사하기 위한 복제. D. 폐쇄 리전의 Amazon EC2 인스턴스에 데이터를 업로드합니다. Amazon EBS에 데이터 저장 용량. 하루는 EBS 스냅샷을 만들어 중앙 집중식 리전에 복사합니다. EBS 볼륨 복원 중앙 집중식 지역에서 매일 데이터에 대한 분석을 실행합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 의료 회사는 매우 민감한 환자 기록을 저장합니다. 규정 준수는 다음을 요구합니다. 여러 사본을 서로 다른 위치에 저장 각 기록은 7년 동안 보관해야 합니다. 그 회사 기록을 즉시 정부 기관에 제공하기 위한 서비스 수준 계약(SLA)이 있습니다. 처음 30일 이후에는 그 후 4시간의 요청. 솔루션 아키텍트는 무엇을 추천해야 합니까?\nA. 교차 리전 복제가 활성화된 Amazon S3 사용 30일 후 데이터를 Amazon으로 전환 수명 주기 정책을 사용하는 S3 Glacier B. CORS(교차 출처 리소스 공유)가 활성화된 Amazon S3를 사용합니다. 30일 후 전환 수명 주기 정책을 사용하여 Amazon S3 Glacier에 데이터를 전송합니다. C. 교차 리전 복제가 활성화된 Amazon S3 사용 30일 후 데이터를 Amazon으로 전환 수명 주기 정책을 사용하여 S3 Glacier Deep Achieve D. 교차 출처 리소스 공유(GORS)가 활성화된 Amazon S3 사용 30일 후 전환 수명 주기 정책을 사용하여 Amazon S3 Glacier Deep Archive로 데이터 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 온프레미스 애플리케이션을 실행하는 회사는 애플리케이션을 AWS로 마이그레이션하여 탄력성과 가용성을 높입니다. 현재 아키텍처는 Microsoft SQL Server 데이터베이스를 사용합니다. 읽기 활동이 많습니다. 회사는 대체 데이터베이스 옵션을 탐색하고 마이그레이션하려고 합니다. 필요한 경우 데이터베이스 엔진. 4시간마다 개발팀은 프로덕션의 전체 사본을 작성합니다. 데이터베이스를 사용하여 테스트 데이터베이스를 채웁니다. 이 기간 동안 사용자는 대기 시간을 경험합니다. 솔루션 설계자는 대체 데이터베이스로 무엇을 권장해야 합니까?\nA. 다중 AZ Aurora 복제본과 함께 Amazon Aurora를 사용하고 테스트를 위해 mysqldump에서 복원 데이터 베이스. B. 다중 AZ Aurora 복제본과 함께 Amazon Aurora를 사용하고 다음을 위해 Amazon RDS에서 스냅샷 복원 테스트 데이터베이스. C. 다중 AZ 배포 및 읽기 전용 복제본과 함께 Amazon RDS for MySQL을 사용하고 대기 테스트 데이터베이스의 인스턴스. D. 다중 AZ 배포 및 읽기 전용 복제본과 함께 SQL Server용 Amazon RDS 사용 및 복원 테스트 데이터베이스에 대한 RDS의 스냅샷. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 솔루션 아키텍트는 다음을 제공하고자 하는 회사를 위한 보안 솔루션을 설계하고 있습니다. AWS Organizations를 통해 개별 AWS 계정을 보유한 개발자 표준 보안 제어. 개별 개발자는 자신의 AWS 계정 루트 사용자 수준 액세스 권한을 갖기 때문에 솔루션 설계자는 필수 AWS CloudTrail 구성이 새 개발자 계정에 적용된 내용은 수정되지 않습니다. 이러한 요구 사항을 충족하는 작업은 무엇입니까?\nA. CloudTrail에 대한 변경을 금지하는 IAM 정책을 생성하고 이를 루트 사용자에게 연결합니다. B. 조직 추적을 사용하여 개발자 계정 내에서 CloudTrail에 새 추적 생성 옵션이 활성화되었습니다. C. CloudTrail에 대한 변경을 금지하는 SCP(서비스 제어 정책)를 생성하고 연결합니다. 개발자 계정. D. 변경 사항만 허용하는 정책 조건으로 CloudTrail에 대한 서비스 연결 역할을 생성합니다. 마스터 계정의 Amazon 리소스 이름(ARN). 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에 2개의 가용 영역에 걸쳐 Amazon EC2 인스턴스에서 실행되는 웹 사이트가 있습니다. 회사는 특정 휴일에 트래픽 급증을 예상하고 있으며 일관된 사용자를 제공하기를 원합니다. 경험. 솔루션 설계자는 이 요구 사항을 어떻게 충족할 수 있습니까?\nA. 단계적 스케일링을 사용하십시오. B. 간단한 스케일링을 사용합니다. C. 수명 주기 후크를 사용합니다. D. 예약된 확장을 사용합니다. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자가 애플리케이션을 위한 다중 지역 재해 복구 솔루션을 설계하고 있습니다. 공개 API 액세스를 제공합니다. 애플리케이션은 사용자 데이터와 함께 Amazon EC2 인스턴스를 사용합니다. 애플리케이션 코드와 MySQL 데이터베이스용 Amazon RDS를 로드하는 스크립트 복구 시간 목표 (RTO)는 3시간이고 RPO(복구 시점 목표)는 24시간입니다. 가장 낮은 비용으로 이러한 요구 사항을 충족하는 아키텍처는 무엇입니까?\nA. 지역 장애 조치를 위해 Application Load Balancer를 사용하십시오. userdata 스크립트를 사용하여 새 EC2 인스턴스를 배포합니다. 각 리전에 별도의 RDS 인스턴스 배포 B. 리전 장애 조치에 Amazon Route 53 사용 userdata 스크립트로 새 EC2 인스턴스 배포 백업 리전에서 RDS 인스턴스의 읽기 전용 복제본 생성 C. 퍼블릭 API 및 리전 장애 조치에 Amazon API Gateway 사용 다음을 사용하여 새 EC2 인스턴스 배포 userdata 스크립트 백업 리전에서 RDS 인스턴스의 MySQL 읽기 전용 복제본 생성 D. 리전 장애 조치에 Amazon Route 53 사용 사용자 데이터 scnpt가 있는 새 EC2 인스턴스 배포 API, 백업을 위해 매일 RDS 인스턴스의 스냅샷 생성 백업에 스냅샷 복제 지역 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 애플리케이션은 프라이빗 서브넷의 Amazon EC2 인스턴스에서 실행됩니다. 응용 프로그램은 다음을 수행해야 합니다. Amazon DynamoDB 테이블에 액세스합니다. 보장하면서 테이블에 액세스하는 가장 안전한 방법은 무엇입니까? 트래픽이 AWS 네트워크를 벗어나지 않는다는 것은 무엇입니까?\nA. DynamoDB용 VPC 엔드포인트를 사용합니다. B. 퍼블릭 서브넷에서 NAT 게이트웨이를 사용합니다. C. 프라이빗 서브넷에서 NAT 인스턴스를 사용합니다. D. VPC에 연결된 인터넷 게이트웨이를 사용합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에는 Management 및 Production이라는 두 개의 VPC가 있습니다. 관리 VPC는 ​​다음을 사용합니다. 데이터 센터의 단일 장치에 연결하기 위한 고객 게이트웨이를 통한 VPN The Production VPC는 연결된 두 개의 AWS Direct Connect 연결이 있는 가상 프라이빗 게이트웨이를 사용합니다. NS 관리 및 프로덕션 VPC는 ​​모두 단일 VPC 피어링 연결을 사용하여 통신을 허용합니다. 응용 프로그램 사이. 솔루션 설계자는 이 아키텍처의 단일 장애 지점을 완화하기 위해 무엇을 해야 합니까?\nA. 관리 VPC와 프로덕션 VPC 간에 VPN 세트를 추가합니다. B. 두 번째 가상 프라이빗 게이트웨이를 추가하고 관리 VPC에 연결 C. 두 번째 고객 게이트웨이 장치에서 관리 VPC에 두 번째 VPN 세트 추가 D. 관리 VPC와 프로덕션 VPC 간에 두 번째 VPC 피어링 연결을 추가합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 데이터 센터 공급자로부터 일관되지 않은 서비스를 받습니다. 자연재해로 피해를 입은 지역에 본사를 두고 있습니다. 회사가 완전히 마이그레이션할 준비가 되지 않았습니다. AWS 클라우드로 전환하지만 온프레미스 데이터 센터의 경우 AWS에서 장애 환경을 원합니다. 실패. 회사는 외부 공급업체와 연결되는 웹 서버를 운영합니다. AWS 및 다음에서 사용 가능한 데이터 건물은 균일해야 합니다. 다운타임이 가장 적은 솔루션 설계자는 어떤 솔루션을 권장해야 합니까?\nA. Amazon Route 53 장애 조치 레코드를 구성합니다. Amazon EC2 인스턴스에서 애플리케이션 서버 실행 Auto Scaling 그룹의 Application Load Balancer 뒤에 있습니다. 다음을 사용하여 AWS Storage Gateway 설정 Amazon S3에 데이터를 백업하기 위한 저장 볼륨. B. Amazon Route 53 장애 조치 레코드를 구성합니다. 다음에서 AWS CloudFormation 템플릿 실행 Application Load Balancer 뒤에서 Amazon EC2 인스턴스를 생성하는 스크립트. AWS 스토리지 설정 Amazon S3에 데이터를 백업하기 위한 저장 볼륨이 있는 게이트웨이. C. Amazon Route 53 장애 조치 레코드를 구성합니다. AWS Direct Connect 연결 설정 VPC와 데이터 센터. Auto Scaling 그룹의 Amazon EC2에서 애플리케이션 서버를 실행합니다. 실행 AWS CloudFormation 템플릿을 실행하여 애플리케이션 로드를 생성하는 AWS Lambda 함수 밸런서. D. Amazon Route 53 장애 조치 레코드를 구성합니다. AWS Lambda 함수를 실행하여 AWS 실행 두 개의 Amazon EC2 인스턴스를 시작하기 위한 CloudFormation 템플릿. 다음을 사용하여 AWS Storage Gateway 설정 Amazon S3에 데이터를 백업하기 위한 저장 볼륨. 간에 AWS Direct Connect 연결을 설정합니다. VPC와 데이터 센터. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon S3 게이트웨이 엔드포인트가 신뢰할 수 있는 버킷만 이 요구 사항을 충족하기 위해 솔루션 설계자가 구현해야 하는 방법은 무엇입니까?\nA. 회사의 신뢰할 수 있는 VPC에서만 트래픽을 허용하는 회사의 신뢰할 수 있는 각 S3 버킷에 대한 버킷 정책을 생성합니다. B. 회사의 S3 게이트웨이 엔드포인트 ID에서만 트래픽을 허용하는 회사의 신뢰할 수 있는 각 S3 버킷에 대한 버킷 정책을 생성합니다. C. 회사의 신뢰할 수 있는 VPC가 아닌 다른 VPC의 액세스를 차단하는 회사의 각 S3 게이트웨이 엔드포인트에 대한 S3 엔드포인트 정책을 생성합니다. D. 신뢰할 수 있는 S3 버킷의 Amazon 리소스 이름(ARN)에 대한 액세스를 제공하는 회사의 각 S3 게이트웨이 엔드포인트에 대한 S3 엔드포인트 정책을 생성합니다. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion Solutions Architect는 AWS에서 호스팅될 웹 애플리케이션을 설계해야 합니다. 사용자가 S3 버킷에 저장된 프리미엄 공유 콘텐츠에 대한 액세스 권한을 구매할 수 있습니다. 결제 시, 사용자가 액세스를 거부하기 전에 콘텐츠를 14일 동안 다운로드할 수 있습니다. 다음은 가장 덜 복잡한 구현입니까?\nA. 오리진 액세스 ID(OAI)가 있는 Amazon CloudFront 배포 사용 서명된 URL의 디자인을 통해 파일에 대한 액세스를 제공하기 위해 Amazon S3 오리진과 함께 배포 14일이 지난 데이터를 제거하는 Lambda 함수. B. S3 버킷을 사용하고 타일에 대한 직접 액세스 제공 a DynamoDH 테이블 기준에 따라 14일이 지난 데이터를 제거하도록 Lambda 함수를 구성합니다. Amazon DynamoDB에 쿼리 C. OAI와 함께 Amazon CloudFront 배포 사용 Amazon S3로 배포 구성 서명된 URL을 통해 파일에 대한 액세스를 제공하는 출처 URL의 경우 14일 D. OAI와 함께 Amazon CloudFront 배포 사용 Amazon S3로 배포 구성 서명된 URL을 통해 파일에 대한 액세스를 제공하는 출처 만료를 설정하도록 애플리케이션을 설계합니다. URL에 대해 60분, 필요에 따라 URL 재생성 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 기반으로 세금 계산에 대한 조회를 자동화하는 API를 사용자에게 제공합니다. 항목 가격에. 회사는 휴가철에 더 많은 문의를 받습니다. 느린 응답 시간. 솔루션 설계자는 확장 가능하고 탄력적인 솔루션을 설계해야 합니다. 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. Amazon EC2 인스턴스에서 호스팅되는 API를 제공합니다. EC2 인스턴스는 필요한 API 요청이 이루어질 때의 계산. B. API Gateway가 통과하는 항목 이름을 수락하는 Amazon API Gateway를 사용하여 REST API 설계 세금 계산을 위해 AWS Lambda에 대한 항목 이름 C. 두 개의 Amazon EC2 인스턴스가 있는 Application Load Balancer를 생성합니다. EC2 인스턴스는 받은 항목 이름에 대한 세금을 계산합니다. D. Amazon EC2에서 호스팅되는 API와 연결하는 Amazon API Gateway를 사용하여 REST API 설계 인스턴스 API 게이트웨이는 세금 계산을 위해 항목 이름을 수락하고 EC2 인스턴스에 전달합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 다양한 AWS 리전에서 ALB(Application Load Balancer)를 사용합니다. ALB 일년 내내 급증 및 감소할 수 있는 일관되지 않은 트래픽 수신 팀은 연결을 활성화하기 위해 온프레미스 방화벽에 있는 ALB의 IP 주소를 허용해야 합니다. 최소한의 구성 변경으로 가장 확장 가능한 솔루션은 무엇입니까?\nA. AWS Lambda 스크립트를 작성하여 다른 리전에 있는 ALB의 IP 주소를 가져옵니다. ALB의 IP 주소를 허용하는 온프레미스 방화벽의 규칙입니다. B. 다른 리전의 모든 ALB를 NLB(Network Load Balancer)로 마이그레이션 모든 NLB의 탄력적 IP 주소를 허용하도록 온프레미스 방화벽의 규칙을 업데이트합니다. C. AWS Global Accelerator 시작 다른 리전의 ALB를 액셀러레이터에 등록합니다. 업데이트 가속기와 연결된 고정 IP 주소를 허용하는 온프레미스 방화벽의 규칙입니다. D. 한 지역에서 NLB(Network Load Balancer) 실행 ALB의 사설 IP 주소 등록 NLB가 있는 m개의 다른 리전 탄력적 IP를 허용하도록 온프레미스 방화벽의 규칙을 업데이트합니다. NLB에 첨부된 주소. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 Windows IIS(인터넷 정보 서비스) 웹을 마이그레이션해야 합니다. AWS에 애플리케이션. 애플리케이션은 현재 사용자의 온프레미스에서 호스팅되는 파일 공유에 의존합니다. 네트워크 연결 스토리지(NAS). 설계된 솔루션은 IIS 웹 서버 마이그레이션을 제안했습니다. 약속 준수 파일로 공유에 대한 어떤 대체품이 가장 탄력 있고 내구성이 있습니까?\nA. 파일 공유를 Amazon RDS로 마이그레이션합니다. B. 타일 공유를 AWS Storage Gateway로 마이그레이션 C. 파일 공유를 Amazon FSx 또는 Windows 파일 서버로 마이그레이션합니다. D. 타일 공유를 Amazon Elastic File System(Amazon EFS)으로 마이그레이션 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 컨테이너에 애플리케이션을 구축하고 있습니다. 이 회사는 온프레미스 개발 및 운영 서비스를 온프레미스 데이터 센터에서 AWS로 마이그레이션하려고 합니다. 경영진은 프로덕션 시스템이 클라우드에 구애받지 않고 동일한 구성을 사용해야 한다고 말합니다. 및 프로덕션 시스템 전반에 걸친 관리자 도구. 솔루션 아키텍트는 매니지드 오픈 소스 소프트웨어를 정렬할 솔루션입니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. EC2 인스턴스 작업자 노드가 있는 Amazon EC2에서 컨테이너를 시작합니다. B. Amazon Elastic Kubernetes Service(Amazon EKS) 및 EKS 작업자 노드에서 컨테이너를 시작합니다. C. AWS Fargate를 사용하여 Amazon Elastic Containers 서비스(Amazon ECS)에서 컨테이너 시작 인스턴스. D. Amazon EC2를 사용하여 Amazon Elastic Container Service(Amazon EC)에서 컨테이너 시작 인스턴스 작업자 노드. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 현재 Amazon RDS MySQL이 지원하는 웹 애플리케이션을 운영하고 있습니다. 데이터베이스 매일 실행되고 암호화되지 않은 자동화된 백업이 있습니다. 보안 감사가 필요합니다. 암호화될 미래의 백업과 암호화되지 않은 백업이 파기될 것입니다. 이전 백업을 파괴하기 전에 최소한 하나의 암호화된 백업을 만드십시오. 향후 백업을 위해 암호화를 활성화하시겠습니까?\nA. 백업이 저장되는 Amazon S3 버킷에 대한 기본 암호화 활성화 B. 암호화 활성화 확인을 토글하도록 데이터베이스 구성의 백업 섹션을 수정합니다. 상자 C. 데이터베이스의 스냅샷 생성 암호화된 스냅샷에 복사 데이터베이스 복원 암호화된 스냅샷 D. MySQL용 RDS에서 암호화된 읽기 전용 복제본 활성화 암호화된 읽기 전용 복제본을 다음으로 승격합니다. 기본 원본 데이터베이스 인스턴스를 제거합니다. 정답 풀이\r...\r답: C\r#\r설명 그러나 암호화되지 않은 DB 스냅샷의 복사본을 암호화할 수 있기 때문에 효과적으로 추가할 수 있습니다. 암호화되지 않은 DB 인스턴스로 암호화합니다. 즉, DB 인스턴스의 스냅샷을 생성할 수 있습니다. 그런 다음 해당 스냅샷의 암호화된 복사본을 만듭니다. 그런 다음 다음에서 DB 인스턴스를 복원할 수 있습니다. 암호화된 스냅샷, 따라서 원본 DB 인스턴스 DB 인스턴스의 암호화된 복사본이 있습니다. 암호화된 항목은 암호화를 비활성화하도록 수정할 수 없습니다. 암호화되지 않은 DB 인스턴스 또는 암호화되지 않은 읽기의 암호화된 읽기 전용 복제본을 가질 수 없습니다. 암호화된 DB 인스턴스의 복제본. 암호화된 읽기 전용 복제본은 원본 DB 인스턴스와 동일한 키로 암호화되어야 합니다. 동일한 AWS 리전에 있습니다. 암호화되지 않은 백업이나 스냅샷은 암호화된 DB 인스턴스로 복원할 수 없습니다. 한 AWS 리전에서 다른 AWS 리전으로 암호화된 스냅샷을 복사하려면 KMS 키를 지정해야 합니다. 대상 AWS 리전의 식별자입니다. KMS 암호화 키가 AWS에만 해당되기 때문입니다. 생성된 지역입니다. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/Overview.Encryption.html\n#\r#\r질문\r#\rquestion 회사는 AWS에서 웹 사이트를 호스팅합니다. 회사는 변동성이 큰 수요를 해결하기 위해 Amazon EC2 Auto Scaling을 구현했습니다. 경영진은 회사가 특히 3계층 애플리케이션의 프런트 엔드에서 인프라를 과도하게 프로비저닝하고 있다고 우려하고 있습니다. 솔루션 설계자는 성능에 영향을 주지 않으면서 비용을 최적화해야 합니다. 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. 예약 인스턴스에서 Auto Scaling을 사용합니다. B. 예약된 조정 정책과 함께 Auto Scaling을 사용합니다. C. 일시 중단-재개 기능과 함께 Auto Scaling 사용 D. 대상 추적 조정 정책과 함께 Auto Scaling을 사용합니다. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사는 기가바이트의 csv에서 작동하는 레거시 온프레미스 분석 애플리케이션을 사용합니다. 파일 및 몇 개월 분량의 데이터를 나타냅니다. 레거시 응용 프로그램은 증가하는 csv 파일 크기를 처리할 수 없습니다. 새로운 csv 파일은 다양한 데이터 소스에서 중앙 온프레미스 스토리지 위치로 매일 추가됩니다. 회사는 사용자가 AWS 분석을 배우는 동안 레거시 애플리케이션을 계속 지원하기를 원합니다. 서비스 이를 달성하기 위해 솔루션 설계자는 모든 csv의 동기화된 사본 두 개를 유지하려고 합니다. 온프레미스 및 Amazon S3의 파일 솔루션 설계자가 권장해야 하는 솔루션은 무엇입니까?\nA. AWS DataSync를 온프레미스에 배포합니다. csv 파일을 지속적으로 복제하도록 DataSync 구성 회사의 온프레미스 스토리지와 회사의 S3 버킷 사이 B. 온프레미스 파일 게이트웨이 배포 csv 파일을 파일에 기록하도록 데이터 소스 구성 게이트웨이 레거시 분석 애플리케이션이 파일 게이트웨이를 가리키도록 합니다. 파일 게이트웨이는 복제해야 합니다. csv 파일을 Amazon S3로 C. 온프레미스 볼륨 게이트웨이를 배포합니다. csv 파일을 볼륨 게이트웨이. 레거시 분석 애플리케이션이 볼륨 게이트웨이를 가리키도록 합니다. 볼륨 게이트웨이 데이터를 Amazon S3에 복제해야 합니다. D. AWS DataSync 온프레미스 배포 csv 파일을 지속적으로 복제하도록 DataSync 구성 온프레미스와 Amazon Elastic File System(Amazon EFS) 간 Amazon에서 복제 활성화 회사의 S3 버킷에 대한 EFS. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 사용자가 백업 정적 오류 페이지 기본 웹사이트를 사용할 수 없습니다. 기본 웹사이트의 DNS 레코드가 호스팅되는 위치 도메인이 ALB(Application Load Balancer)를 가리키는 Amazon Route 53 솔루션 설계자가 회사의 요구 사항을 충족하는 동시에 변경 및 인프라 오버헤드?\nA. Route 53 별칭 레코드가 ALB 중 하나인 Amazon CloudFront 배포를 가리키도록 합니다. origins 그런 다음 배포에 대한 사용자 지정 오류 페이지를 만듭니다. B. Route 53 액티브-패시브 장애 조치 구성 설정 호스팅된 정적 오류 페이지로 트래픽 전달 Route 53 상태 확인에서 ALB 엔드포인트가 건강에 해로운 C. 지연 기반 라우팅 정책을 사용하도록 Route 53 레코드 업데이트 백업 정적 오류 페이지 추가 Amazon S3 버킷 내에서 호스팅된 레코드로 트래픽이 가장 응답성이 높은 끝점 D. ALB와 Amazon EC2 인스턴스를 호스팅하는 Route 53 활성-활성 구성을 설정합니다. 엔드포인트로서의 정적 오류 페이지 Route 53은 상태가 확인된 경우에만 인스턴스에 요청을 보냅니다. ALB에 실패 정답 풀이\r...\r답: B\r#\r설명 능동-수동 장애 조치 기본 리소스 또는 리소스 그룹이 필요한 경우 활성-수동 장애 조치 구성을 사용합니다. 대부분의 시간을 사용할 수 있고 보조 리소스 또는 리소스 그룹이 모든 기본 리소스를 사용할 수 없게 되는 경우를 대비하여 대기 상태에 있어야 합니다. 질문에 답할 때, Route 53에는 정상적인 기본 리소스만 포함됩니다. 모든 기본 리소스가 비정상인 경우 Route 53은 DNS 쿼리에 대한 응답으로 정상적인 보조 리소스만 포함하기 시작합니다. 하나의 기본 레코드와 하나의 보조 레코드로 활성-수동 장애 조치 구성을 생성하려면, 레코드를 만들고 라우팅 정책에 대해 장애 조치를 지정하기만 하면 됩니다. 기본 리소스가 다음과 같을 때 정상이면 Route 53은 기본 레코드를 사용하여 DNS 쿼리에 응답합니다. 기본 리소스가 다음과 같을 때 비정상인 경우 Route 53은 보조 레코드를 사용하여 DNS 쿼리에 응답합니다. Amazon Route 53이 연쇄 실패를 방지하는 방법 연쇄 실패에 대한 첫 번째 방어 수단으로 각 요청 라우팅 알고리즘(예: 가중치 및 장애 조치)에는 최후의 수단 모드가 있습니다. 이 특수 모드에서는 모든 레코드가 비정상으로 간주되면 Route 53 알고리즘은 모든 레코드를 정상으로 간주하도록 되돌아갑니다. 예를 들어 여러 호스트에서 애플리케이션의 모든 인스턴스가 상태 확인 요청을 거부하는 경우 Route 53 DNS 서버는 어쨌든 응답을 선택하고 DNS를 반환하지 않고 반환합니다. 응답하거나 NXDOMAIN(존재하지 않는 도메인) 응답을 반환합니다. 애플리케이션이 응답할 수 있는 사용자는 여전히 상태 확인에 실패하므로 구성 오류에 대한 보호 기능을 제공합니다. 마찬가지로, 애플리케이션이 오버로드되고 엔드포인트 3개 중 1개가 상태 확인에 실패하면 Route 53 DNS 응답에서 제외된 경우 Route 53은 두 서버 간에 응답을 배포합니다. 나머지 끝점. 나머지 엔드포인트가 추가 로드를 처리할 수 없고 실패하면 Route 53은 다음으로 되돌아갑니다. 세 끝점 모두에 요청을 배포합니다. https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-types.html https://docs.aws.amazon.com/Route53/latest/DeveloperGuide/dns-failover-problems.html\n#\r#\r질문\r#\rquestion 회사에 데이터를 두 부분으로 처리하는 레거시 애플리케이션이 있습니다. 프로세스가 첫 번째보다 오래 걸리므로 회사는 신청서를 두 가지 형식으로 다시 작성하기로 결정했습니다. 독립적으로 확장할 수 있는 Amazon ECS에서 실행되는 마이크로서비스. 솔루션 설계자는 마이크로서비스를 어떻게 통합해야 합니까?\nA. 마이크로서비스 1에서 코드를 구현하여 Amazon S3 버킷으로 데이터를 보냅니다. S3 이벤트 알림 사용 마이크로서비스를 호출하기 위해 2. B. 마이크로서비스 1에서 코드를 구현하여 Amazon SNS 주제에 데이터 게시하기 코드 구현하기 이 주제를 구독하려면 마이크로 서비스 2 C. 마이크로서비스 1에서 코드를 구현하여 Amazon Kinesis Data Firehose로 데이터를 보냅니다. 코드 구현 마이크로 서비스 2에서 Kinesis Data Firehose에서 읽을 수 있습니다. D. 마이크로서비스 1에서 코드를 구현하여 Amazon SQS 대기열로 데이터를 전송합니다. 큐에서 메시지를 처리하는 마이크로 서비스 2 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사에서 뉴스 콘텐츠를 호스팅하는 다중 계층 웹 응용 프로그램을 실행합니다. 응용 프로그램이 실행됩니다. Application Load Balancer 뒤의 Amazon EC2 인스턴스에서. EC2 Auto에서 실행되는 인스턴스 여러 가용 영역에 걸쳐 그룹을 조정하고 Amazon Aurora 데이터베이스를 사용합니다. 솔루션 설계자는 요청 속도의 주기적인 증가에 대해 애플리케이션의 탄력성을 높여야 합니다. 솔루션 설계자는 어떤 아키텍처를 구현해야 합니까? (2개 선택)\nA. AWS Shield를 추가합니다. B. Aurora 복제본 추가 C. AWS Direct Connect 추가 D. AWS Global Accelerator를 추가합니다. E. Application Load Balancer 앞에 Amazon CloudFront 배포 추가 정답 풀이\r...\r답변: DE\r#\r설명 AWS 글로벌 액셀러레이터 지연 시간에 민감한 애플리케이션을 위한 가속화 특히 게임, 미디어, 모바일 앱 및 금융과 같은 영역의 많은 응용 프로그램에는 다음이 필요합니다. 뛰어난 사용자 경험을 위한 매우 짧은 대기 시간. 사용자 경험을 개선하기 위해 Global Accelerator 사용자 트래픽을 클라이언트에 가장 가까운 애플리케이션 엔드포인트로 보내 인터넷을 줄입니다. 대기 시간 및 지터. Global Accelerator는 Anycast를 사용하여 가장 가까운 엣지 로케이션으로 트래픽을 라우팅하고, 그런 다음 AWS 글로벌 네트워크를 통해 가장 가까운 리전 엔드포인트로 라우팅합니다. 글로벌 액셀러레이터 네트워크 성능의 변화에 ​​빠르게 반응하여 사용자의 애플리케이션 성능을 향상시킵니다. 아마존 클라우드프론트 Amazon CloudFront는 데이터를 안전하게 전송하는 빠른 CDN(콘텐츠 전송 네트워크) 서비스입니다. 짧은 대기 시간, 높은 전송 속도로 전 세계 고객에게 비디오, 애플리케이션 및 API 제공 개발자 친화적인 환경. https://docs.aws.amazon.com/global-accelerator/latest/dg/introduction-benefits-of-migrating.html\n#\r#\r질문\r#\rquestion 회사의 애플리케이션이 Auto Scaling 그룹 내의 Amazon EC2 인스턴스에서 실행 중입니다. Elastic Load Balancer 뒤에서 애플리케이션의 이력을 기반으로 회사는 매년 휴일 동안의 교통체증 솔루션 설계자는 자동차가 확장 그룹은 사전에 용량을 늘려 애플리케이션에 대한 성능 영향을 최소화합니다. 사용자 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. Amazon CloudWatch 경보를 생성하여 CPU 사용률이 초과할 때 EC2 인스턴스를 확장합니다. 90% B. 예상 기간 전에 Auto Scaling 그룹을 확장하기 위해 반복되는 예약된 작업을 생성합니다. 피크 수요의 C. Auto Scaling 그룹의 최소 및 최대 EC2 인스턴스 수를 늘리십시오. 피크 수요 기간 D. 다음과 같은 경우 알림을 보내도록 Amazon Simple Notification Service(Amazon SNS) 알림을 구성합니다. Auto Scaling EC2_INSTANCE_LAUNCH 이벤트가 있습니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사에서 Linux 기반 웹 서버 그룹을 AWS로 마이그레이션하고 있습니다. 웹 서버는 일부 콘텐츠에 대해 공유 파일 저장소의 파일에 액세스 마이그레이션 날짜를 맞추기 위해 최소한의 변경 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 해야 합니까?\nA. 웹 서버에 액세스할 수 있는 Amazon S3 Standard 버킷을 생성합니다. B. Amazon S3 버킷을 오리진으로 사용하여 Amazon CloudFront 배포 구성 C. Amazon Elastic File System(Amazon EFS) 볼륨을 생성하고 모든 웹 서버에 탑재 D. Amazon Elastic Block Store(Amazon EBS) 프로비저닝된 IOPS SSD(io1) 볼륨 구성 및 모든 웹 서버에 마운트하십시오. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에서 데이터베이스와 통신할 웹 애플리케이션을 AWS에서 호스팅하려고 합니다. VPC 내에서. 애플리케이션은 가용성이 높아야 합니다. 솔루션 아키텍트는 무엇을 추천해야 합니까?\nA. 로드 밸런서 뒤에서 웹 서버를 호스팅할 두 개의 Amazon EC2 인스턴스를 생성한 다음 대규모 인스턴스에 데이터베이스를 배포합니다. B. 웹용 Auto Scaling 그룹을 사용하여 여러 가용 영역에 로드 밸런서 배포 여러 가용 영역에 Amazon RDS를 배포합니다. C. 웹 서버용 Auto Scaling 그룹이 있는 퍼블릭 서브넷에 로드 밸런서를 배포하고, 그런 다음 프라이빗 서브넷의 Amazon EC2 인스턴스에 데이터베이스를 배포합니다. D. Auto Scaling 그룹이 있는 두 개의 웹 서버를 배포하고 두 개를 가리키는 도메인을 구성합니다. 웹 서버를 구축한 다음 여러 가용 영역에 데이터베이스 아키텍처를 배포합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 1회에 한 번씩 다양한 소스로부터 정형 및 반정형 데이터를 수신합니다. 일. 솔루션 설계자는 빅 데이터 처리 프레임워크를 활용하는 솔루션을 설계해야 합니다. SQL 쿼리 및 비즈니스 인텔리전스 도구를 사용하여 데이터에 액세스할 수 있어야 합니다. 솔루션 설계자는 가장 고성능의 솔루션을 구축하기 위해 무엇을 권장해야 합니까?\nA. AWS Glue를 사용하여 데이터를 처리하고 Amazon S3를 사용하여 데이터 저장 B. Amazon EMR을 사용하여 데이터를 처리하고 Amazon Redshift를 사용하여 데이터 저장 C. Amazon EC2를 사용하여 데이터를 처리하고 Amazon Elastic Block Store(Amazon EBS)를 사용하여 데이터 저장 D. Amazon Kinesis Data Analytics를 사용하여 데이터 및 Amazon Elastic File System(Amazon EFS) 처리 데이터를 저장하기 위해 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사의 웹 애플리케이션이 애플리케이션 뒤의 Amazon EC2 인스턴스에서 실행 중입니다. 로드 밸런서. 회사는 최근 정책을 변경하여 이제 애플리케이션이 다음과 같아야 합니다. 특정 국가에서만 액세스할 수 있습니다. 이 요구 사항을 충족하는 구성은 무엇입니까?\nA. EC2 인스턴스에 대한 보안 그룹을 구성합니다. B. Application Load Balancer에서 보안 그룹을 구성합니다. C. VPC의 Application Load Balancer에서 AWS WAF를 구성합니다. D. EC2 인스턴스가 포함된 서브넷에 대해 네트워크 ACL을 구성합니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에서 워크로드를 AWS로 마이그레이션하려고 합니다. 최고 정보 보안 책임자 모든 데이터는 클라우드에 저장될 때 암호화되어 있어야 합니다. 회사는 완전한 것을 원한다 암호화 키 수명 주기 관리 제어. 회사는 즉시 키 자료를 제거하고 키 사용을 감사할 수 있어야 합니다. AWS CloudTrail과 독립적입니다. 선택한 서비스는 다른 스토리지 서비스와 통합되어야 합니다. AWS에서 사용됩니다. 이러한 보안 요구 사항을 충족하는 서비스는 무엇입니까?\nA. CloudHSM 클라이언트가 있는 AWS CloudHSM B. AWS CloudHSM을 사용한 AWS 키 관리 서비스(AWS KMS) C. 외부 키 구성 요소 원본이 있는 AWS Key Management Service(AWS KMS) D. AWS 관리형 고객 마스터 키(CMK)가 있는 AWS Key Management Service(AWS KMS) 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon S3 버킷에 파일을 업로드하는 데 사용되는 애플리케이션을 호스팅합니다. 업로드된 파일은 메타데이터를 추출하기 위해 처리되며 5초 미만이 소요됩니다. 볼륨 그리고 업로드 빈도는 시간당 몇 개의 파일에서 수백 개의 동시 업로드에 이르기까지 다양합니다. 회사는 솔루션 설계자에게 다음을 충족할 비용 효율적인 아키텍처를 설계하도록 요청했습니다. 이러한 요구 사항. 솔루션 설계자는 무엇을 권장해야 합니까?\nA. S3 API 호출을 기록하도록 AWS CloudTrail 추적 구성 AWS AppSync를 사용하여 파일 처리 B. AWS Lambda를 호출하도록 S3 버킷 내에서 객체 생성 이벤트 알림 구성 파일을 처리하는 기능. C. Amazon Kinesis Data Streams가 데이터를 처리하고 Amazon S3로 전송하도록 구성 AWS 호출 파일을 처리하는 Lambda 함수 D. 업로드된 파일을 처리하도록 Amazon Simple Notification Service(Amazon SNS) 주제 구성 아마존 S3로. AWS Lambda 함수를 호출하여 파일을 처리합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 한 회사는 모든 주문을 Amazon RDS에 저장하는 온라인 쇼핑 애플리케이션을 호스팅합니다. PostgreSQL 단일 AZ DB 인스턴스 관리는 단일 실패 지점을 제거하기를 원하며 솔루션 설계자에게 애플리케이션 코드에 대한 변경이 필요합니다.\n어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 데이터베이스를 수정하여 기존 데이터베이스 인스턴스를 다중 AZ 배포로 변환 인스턴스 및 다중 AZ 옵션 지정. B. 새 RDS 다중 AZ 배포 생성 현재 RDS 인스턴스의 스냅샷을 생성하고 복원 스냅샷이 있는 새로운 다중 AZ 배포 C. 다른 가용 영역에 PostgreSQL 데이터베이스의 읽기 전용 복제본 생성 Amazon 사용 노선 데이터베이스 전체에 요청을 분산하기 위한 53개의 가중 레코드 세트. D. RDS for PostgreSQL 데이터베이스를 최소한의 Amazon EC2 Auto Scaling 그룹에 배치합니다. 2개의 그룹 크기 Amazon Route 53 가중 레코드 세트를 사용하여 인스턴스 간에 요청을 분산합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사의 웹 애플리케이션은 Amazon RDS PostgreSQL DB 인스턴스를 사용하여 애플리케이션 데이터. 매월 초 결산 기간 중 회계사는 다음과 같은 대규모 쿼리를 실행합니다. 높은 사용량으로 인해 데이터베이스 성능에 영향을 줍니다. 회사는 영향을 최소화하기를 원합니다. 보고 활동이 웹 응용 프로그램에 있는 것입니다. 최소한의 데이터로 데이터베이스에 미치는 영향을 줄이기 위해 솔루션 설계자는 무엇을 해야 합니까? 노력?\nA. 읽기 전용 복제본을 만들고 복제본으로 트래픽을 직접 보고합니다. B. 다중 AZ 데이터베이스를 생성하고 대기 트래픽을 보고합니다. C. 교차 리전 읽기 전용 복제본을 만들고 복제본으로 트래픽을 직접 보고합니다. D. Amazon Redshift 데이터베이스를 생성하고 Amazon Redshift 데이터베이스로 트래픽을 보고합니다. 정답 풀이\r...\r답변: A\r#\r설명 https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html Amazon RDS MariaDB, MySQL, Oracle, PostgreSQL 및 Microsoft SQL Server DB 엔진의 기본 제공 원본 DB에서 읽기 전용 복제본이라는 특수한 유형의 DB 인스턴스를 생성하는 복제 기능 사례. 원본 DB 인스턴스에 대한 업데이트는 읽기 전용 복제본에 비동기식으로 복사됩니다. 너 애플리케이션에서 읽기 쿼리를 읽기 복제본. 읽기 전용 복제본을 생성할 때 먼저 기존 DB 인스턴스를 원본으로 지정합니다. 그럼 아마존 RDS는 소스 인스턴스의 스냅샷을 생성하고 스냅샷에서 읽기 전용 인스턴스를 생성합니다. 그런 다음 Amazon RDS는 DB 엔진에 대한 비동기 복제 방법을 사용하여 읽기를 업데이트합니다. 원본 DB 인스턴스에 변경 사항이 있을 때마다 복제본. 읽기 전용 복제본은 DB로 작동합니다. 읽기 전용 연결만 허용하는 인스턴스입니다. 애플리케이션은 동일한 방식으로 읽기 전용 복제본에 연결됩니다. 모든 DB 인스턴스에 적용됩니다. Amazon RDS는 원본 DB 인스턴스의 모든 데이터베이스를 복제합니다. https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_ReadRepl.html\n#\r#\r질문\r#\rquestion 회사는 AWS에서 고성능 컴퓨팅(HPC) 워크로드를 실행합니다. 워크로드 긴밀하게 결합된 노드 간 통신을 통해 대기 시간이 짧은 네트워크 성능과 높은 네트워크 처리량이 필요했습니다. Amazon EC2 인스턴스는 컴퓨팅 및 스토리지에 적합한 크기입니다. 기본 옵션을 사용하여 시작됩니다. 솔루션 설계자는 워크로드의 성능을 개선하기 위해 무엇을 제안해야 합니까?\nA. Amazon EC2 인스턴스를 시작하는 동안 클러스터 배치 그룹 선택 B. Amazon EC2 인스턴스를 시작하는 동안 전용 인스턴스 테넌시 선택 C. Amazon EC2 인스턴스를 시작하는 동안 Elastic Inference 액셀러레이터 선택 D. Amazon EC2 인스턴스를 시작하는 동안 필요한 용량 예약을 선택합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에 데이터를 수신할 수 있는 REST 기반 인터페이스가 있는 애플리케이션이 있습니다. 타사 공급업체로부터 거의 실시간으로 애플리케이션을 받으면 애플리케이션을 처리하고 저장합니다. 추가 분석을 위한 데이터. 애플리케이션이 Amazon EC2 인스턴스에서 실행 중입니다. 타사 공급업체는 데이터를 애플리케이션. 데이터 볼륨이 급증하면 컴퓨팅 용량이 최대 한도에 도달하고 응용 프로그램이 모든 요청을 처리할 수 없습니다. 보다 확장 가능한 솔루션을 제공하기 위해 솔루션 설계자는 어떤 설계를 권장해야 합니까?\nA. Amazon Kinesis Data Streams를 사용하여 데이터 수집 AWS Lambda를 사용하여 데이터 처리 기능. B. 기존 애플리케이션 위에 Amazon API Gateway를 사용합니다. 할당량이 있는 사용 계획 생성 Iimit 타사 공급업체의 경우. C. Amazon Simple Notification Service(Amazon SNS)를 사용하여 데이터 수집 EC2 인스턴스 배치 Application Load Balancer 뒤에 있는 Auto Scaling 그룹. D. 애플리케이션을 컨테이너로 다시 패키징합니다. Amazon Elastic Container를 사용하여 애플리케이션 배포 Auto Scaling 그룹과 함께 EC2 시작 유형을 사용하는 서비스(Amazon ECS). 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 모든 Amazon Elastic Block Store(Amazon EBS)가 암호화되지 않은 EBS 스냅샷에서 복원된 볼륨은 암호화됩니다. 건축가는 이것을 달성하기 위해 무엇을합니까?\nA. AWS 리전에 대해 기본적으로 EBS 암호화 활성화 B. 특정 볼륨에 대해 기본적으로 EBS 암호화 활성화 C. 새 볼륨 생성 및 암호화에 사용할 대칭 고객 마스터 키(CMK) 지정 D. 새 볼륨을 생성하고 다음에 사용할 비대칭 고객 마스터 키(CMK)를 지정합니다. 암호화. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에 스토리지 용량이 부족한 온프레미스 데이터 센터가 있습니다. NS 회사는 대역폭 비용을 최소화하면서 스토리지 인프라를 AWS로 마이그레이션하려고 합니다. 솔루션은 추가 비용 없이 데이터를 즉시 검색할 수 있어야 합니다. 이러한 요구 사항을 어떻게 충족할 수 있습니까?\nA. Amazon S3 Glacier Vault를 배포하고 신속 검색을 활성화합니다. 프로비저닝된 검색 활성화 작업 부하 용량 B. 캐시된 볼륨을 사용하여 AWS Storage Gateway를 배포합니다. Storage Gateway를 사용하여 데이터 저장 자주 액세스하는 데이터 하위 집합의 복사본을 로컬로 유지하면서 Amazon S3. C. 저장된 볼륨을 사용하여 AWS Storage Gateway를 배포하여 데이터를 로컬에 저장합니다. Storage Gateway를 사용하여 데이터의 특정 시점 스냅샷을 Amazon S3에 비동기식으로 백업 D. AWS Direct Connect를 배포하여 온프레미스 데이터 센터에 연결합니다. AWS 스토리지 구성 데이터를 로컬에 저장하기 위한 게이트웨이. Storage Gateway를 사용하여 potnt-tn-time 비동기식 백업 데이터의 스냅샷을 Amazon S3로 전송합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 사용자 데이터를 AWS에 저장합니다. 데이터는 최대 사용량으로 지속적으로 사용됩니다. 업무 시간. 액세스 패턴은 다양하며 일부 데이터는 한 번에 몇 달 동안 사용되지 않습니다. 솔루션 설계자는 가장 높은 수준의 내구성을 유지하면서 비용을 선택해야 합니다. 고가용성 유지. 이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까?\nA. Amazon S3 표준 B. Amazon S3 지능형 계층화 C. Amazon S3 Glacier 딥 아카이브 D. Amazon S3 One Zone-Infrequent Access(S3 One Zone-IA) 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 온라인 사진 응용 프로그램을 통해 사용자는 사진을 업로드하고 이미지 편집 작업을 수행할 수 있습니다. 응용 프로그램은 유료 사용자가 제출하는 무료 및 유료 사진의 두 가지 클래스를 제공합니다 무료 사용자가 제출한 사진이 Amazon S3에 업로드되기 전에 처리되고 작업이 정보가 Amazon SQS로 전송됩니다. 솔루션 설계자는 어떤 구성을 권장해야 합니까?\nA. 하나의 SQS FIFO 대기열을 사용합니다. 유료 사진이 먼저 처리되도록 더 높은 우선 순위를 지정합니다. B. 두 개의 SQS FIFO 대기열을 사용합니다. 하나는 유료이고 다른 하나는 무료입니다. 짧은 폴링을 사용하도록 무료 대기열을 설정합니다. 긴 폴링을 사용하는 유료 대기열 C. 두 개의 SQS 표준 대기열을 하나는 유료로, 다른 하나는 무료로 사용하여 Amazon EC2 인스턴스를 다음과 같이 구성합니다. 무료 대기열보다 유료 대기열에 대한 폴링을 우선시합니다. D. 하나의 SQS 표준 대기열을 사용합니다. 유료 사진의 가시성 제한 시간을 0으로 설정하십시오. 유료 사진이 먼저 처리되도록 가시성 설정의 우선 순위를 지정하는 Amazon EC2 인스턴스 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 민감한 사용자 데이터를 Amazon S3에 저장할 계획입니다. 내부 보안 규정 준수 데이터를 Amazon S3로 전송하기 전에 요구 사항 mandata 암호화. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 권장해야 합니까?\nA. 고객이 제공한 암호화 키를 사용한 서버 측 암호화 B. Amazon S3 관리형 암호화 키를 사용한 클라이언트 측 암호화 C. AWS key Management Service(AWS KMS)에 저장된 키를 사용한 서버 측 암호화 D. AWS Key Management Service(AWS KMS)에 저장된 마스터 키로 클라이언트 측 암호화 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사에서는 Amazon S3 버킷에 있는 모든 객체 버전을 최신 상태로 유지해야 합니다. 개체 버전은 처음 30일 동안 자주 액세스되며 그 이후에는 거의 액세스하지 않습니다. 액세스하고 5분 이내에 검색할 수 있어야 합니다. 이전 개체 버전은 영구적으로 보관해야 합니다. 거의 액세스되지 않으며 1주일 이내에 검색할 수 있습니다. 모든 스토리지 솔루션은 가용성 및 높은 내구성 이러한 요구 사항을 충족하기 위해 솔루션 설계자가 권장해야 하는 사항 가장 비용 효율적인 방식으로 요구 사항을 충족합니까?\nA. S3 Standard에서 현재 객체 버전을 이동하는 버킷에 대한 S3 수명 주기 정책 생성 30일 후에 S3 Glacier에 저장하고 1일 후에 이전 객체 버전을 S3 Glacier로 이동합니다. B. S3 Standard에서 현재 객체 버전을 이동하는 버킷에 대한 S3 수명 주기 정책 생성 30일 후 S3 Glacier에 저장하고 이전 객체 버전을 S3 Glacier Deep Archive로 이동 1일 후 C. S3 Standard에서 현재 객체 버전을 이동하는 버킷에 대한 S3 수명 주기 정책 생성 30일 후 S3 Standard-infrequent Access(S3 Standard-IA)에 저장하고 이전 객체 이동 1일 후 S3 Glacier Deep Archive로 버전 D. S3 Standard에서 현재 객체 버전을 이동하는 버킷에 대한 S3 수명 주기 정책 생성 30일 후 S3 One Zone-Infrequent Access(S3 One Zone-IA)에 저장하고 이전 객체 이동 1일 후 S3 Glacier Deep Archive로 버전 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 한 회사는 데이터가 없는 작은 데이터 클로짓 내의 지점 사무실에서 애플리케이션을 실행합니다. 가상화된 컴퓨팅 리소스. 애플리케이션 데이터는 NFS 볼륨에 저장됩니다. 규정 준수 표준에는 NFS 볼륨의 매일 오프사이트 백업이 필요합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. AWS Storage Gateway 파일 게이트웨이를 온프레미스에 설치하여 Amazon S3에 데이터를 복제합니다. B. 온프레미스에 AWS Storage Gateway 파일 게이트웨이 하드웨어 어플라이언스를 설치하여 데이터 복제 아마존 S3로. C. 온프레미스에 볼륨이 저장된 AWS Storage Gateway 볼륨 게이트웨이를 설치하여 데이터를 Amazon S3로 전송합니다. D. 복제를 위해 온프레미스에 캐시된 볼륨이 있는 AWS Storage Gateway 볼륨 게이트웨이 설치 데이터를 Amazon S3로 전송합니다. 정답 풀이\r...\r답: B\r#\r설명 https://aws.amazon.com/storagegateway/file/ AWS Storage Gateway 하드웨어 어플라이언스\n하드웨어 기기 Storage Gateway는 기존 VMware 지원에 추가하여 하드웨어 어플라이언스로 사용할 수 있습니다. ESXi, Microsoft Hyper-V 및 Amazon EC2. 즉, 이제 스토리지를 사용할 수 있습니다. 가상화된 환경, 서버급 하드웨어 또는 IT가 없는 상황에서의 게이트웨이 관리하는 데 필요한 전문 기술을 갖춘 직원. 에서 가전제품을 주문할 수 있습니다. 전용 IT가 없는 지점, 창고 및 \u0026ldquo;전초 기지\u0026rdquo; 사무실로 배송하기 위한 Amazon.com 자원. 설정(분 후에 보게 되겠지만)은 빠르고 쉬우며 3개의 스토리지에 액세스할 수 있습니다. 솔루션: 파일 게이트웨이 - NFS 또는 SMB를 통해 액세스할 수 있는 Amazon S3에 대한 파일 인터페이스입니다. 파일은 S3로 저장됩니다. 객체를 사용하여 수명 주기 관리 및 교차 지역 복제와 같은 특수 S3 기능을 사용할 수 있습니다. AWS Lambda 함수를 트리거하고, Amazon Athena 쿼리를 실행하고, 다음을 사용할 수 있습니다. Amazon Macie는 민감한 데이터를 검색하고 분류합니다. https://aws.amazon.com/blogs/aws/new-aws-storage-gateway-hardware-appliance/\n#\r#\r질문\r#\rquestion 글로벌 이벤트 주최자는 일일 보고서를 정적 HTML 페이지로 온라인에 게시하려고 합니다. 페이지는 전 세계 사용자로부터 수백만 건의 조회수를 생성할 것으로 예상됩니다. Amazon S3 버킷 솔루션 설계자는 효율적이고 효과적인 설계를 요청받았습니다. 솔루션 솔루션 설계자는 이를 달성하기 위해 어떤 조치를 취해야 합니까?\nA. 파일에 대해 미리 서명된 URL 생성 B. 모든 리전에 교차 리전 복제 사용 C. Amazon Route 53의 지리 근접 기능 사용 D. S3 버킷을 오리진으로 하는 Amazon CloudFront 사용 정답 풀이\r...\r답변: D\r#\r설명 Amazon S3 오리진, MediaPackage 채널 및 웹 배포용 사용자 지정 오리진 사용 오리진용 Amazon S3 버킷 Amazon S3를 배포용 오리진으로 사용하면 CloudFront에서 Amazon S3 버킷에 전달할 객체를 배치합니다. 당신은 무엇이든 사용할 수 있습니다 객체를 Amazon S3로 가져오기 위해 Amazon S3에서 지원하는 메서드(예: Amazon S3 콘솔, API 또는 타사 도구. 버킷에 계층을 생성하여 저장할 수 있습니다. 다른 Amazon S3 버킷과 마찬가지로 객체. 기존 Amazon S3 버킷을 CloudFront 오리진 서버로 사용하면 버킷이 변경되지 않습니다. 그래도; 평소와 같이 Amazon S3 객체를 저장하고 액세스하는 데 계속 사용할 수 있습니다. 표준 Amazon S3 가격. 버킷에 객체를 저장하면 일반 Amazon S3 요금이 발생합니다. 오리진에 대한 웹 사이트 엔드포인트로 구성된 Amazon S3 버킷 사용 Amazon을 설정할 수 있습니다. CloudFront를 사용하여 사용자 지정 오리진으로 웹 사이트 엔드포인트로 구성된 S3 버킷. CloudFront 배포를 구성할 때 오리진에 대해 Amazon S3 정적 웹 사이트를 입력합니다. 버킷의 호스팅 엔드포인트. 이 값은 Amazon S3 콘솔의 속성에 표시됩니다. 탭의 정적 웹 사이트 호스팅 창에서 예를 들어: http://bucket-name.s3-website-region.amazonaws.com Amazon S3 정적 웹 사이트 엔드포인트 지정에 대한 자세한 내용은 웹 사이트 엔드포인트를 참조하십시오. Amazon Simple Storage Service 개발자 안내서. 이 형식의 버킷 이름을 오리진으로 지정하면 Amazon S3 리디렉션을 사용할 수 있습니다. 및 Amazon S3 사용자 오류 또는 문서. Amazon S3 기능에 대한 자세한 내용은 다음을 참조하십시오. Amazon S3 문서. Amazon S3 버킷을 CloudFront 오리진 서버로 사용해도 변경되지 않습니다. 당신은 할 수 있습니다 평소와 같이 계속 사용하면 일반 Amazon S3 요금이 부과됩니다.\nhttps://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/DownloadDistS3AndCusto mOrigins.h\n#\r#\r질문\r#\rquestion 데이터베이스는 고도로 경험하는 Amazon RDS MYSQL 5.6 다중 AZ DB 인스턴스에 있습니다. 동적 읽기. 애플리케이션 개발자는 읽기 성능을 테스트할 때 상당한 속도 저하를 감지합니다. 보조 AWS 리전. 개발자는 1초 미만의 읽기를 제공하는 솔루션을 원합니다. 복제 대기 시간. 솔루션 설계자는 무엇을 권장해야 합니까?\nA. (그는 보조 리전. B. 교차 리전 복제본을 사용하여 데이터베이스를 Amazon Aurora로 마이그레이션합니다. C. 보조에서 다른 MySQL용 RDS 읽기 전용 복제본을 생성합니다. D. Amazon ElastiCache를 구현하여 데이터베이스 쿼리 성능을 개선합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 데이터 과학 팀은 야간 로그 처리를 위한 스토리지가 필요합니다. 로그의 크기 및 수 알 수 없으며 24시간 동안만 지속됩니다. 가장 비용 효율적인 솔루션은 무엇입니까?\nA. 아마존 S3 빙하 B. 아마존 S3 표준 C. Amazon S3 지능형 계층화 D. Amazon S3 One Zone-Infrequent Access {S3 One Zone-IA) 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 미디어 회사는 웹사이트에서 사용자 클릭을 추적하고 실시간에 가까운 추천을 제공하는 분석. 애플리케이션에는 Amazon EC2의 뒤꿈치가 있습니다. 웹 사이트에서 데이터를 수신하고 Amazon RDS DB 인스턴스로 데이터를 보내는 인스턴스 다른 EC2 인스턴스 집합은 지속적으로 확인하는 애플리케이션 부분을 호스팅합니다. 데이터베이스 변경 및 SQL 쿼리 실행을 통해 권장 사항을 제공합니다. 경영진은 인프라를 분리하기 위해 재설계를 요청했습니다. 솔루션은 다음을 보장해야 합니다. 데이터 분석가는 데이터만 분석하기 위해 SQL을 작성하고 있습니다. 배포 중에 데이터가 손실될 수 없습니다. 솔루션 아키텍트는 무엇을 추천해야 합니까?\nA. Amazon Kinesis Data Streams를 사용하여 웹 사이트에서 데이터 캡처 Kinesis Data Firehose를 사용하여 Amazon S3에 데이터를 유지하고 Amazon Athena를 사용하여 데이터 쿼리 B. Amazon Kinesis Data Streams를 사용하여 웹 사이트에서 데이터를 캡처합니다. 데이터를 쿼리하는 Kinesis Data Analytics 및 Amazon S3에 데이터를 유지하는 Kinesis Data Firehose C. Amazon Simple Queue Service(Amazon SQS)를 사용하여 웹 사이트에서 데이터를 캡처하고, EC2 인스턴스 집합을 유지하고, Auto Scaling 그룹 구성에서 더 큰 인스턴스 유형으로 변경 D. Amazon Simple Notification Service(Amazon SNS)를 사용하여 웹 사이트에서 데이터를 수신하고 쿼리를 실행하고 데이터를 유지하는 AWS Lambda 함수에 메시지를 프록시하여 데이터를 유지하려면 Amazon RDS를 Amazon Aurora Serverless로 변경 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 인터넷 연결 애플리케이션 로드 뒤에 있는 VPC에 API를 배포했습니다. 밸런서(ALB) API를 클라이언트로 사용하는 애플리케이션은 다음의 두 번째 계정에 배포됩니다. NAT 게이트웨이 뒤에 있는 개인 서브넷. 클라이언트 애플리케이션에 대한 요청이 증가하면 NAT 게이트웨이 비용이 예상보다 높습니다. 솔루션 설계자가 ALB를 내부용으로 구성했습니다. NAT 게이트웨이 비용을 줄이는 아키텍처 변경 조합은 무엇입니까?(2개 선택)\nA. 두 VPC 간에 VPC 피어링 연결을 구성합니다. 비공개를 사용하여 API에 액세스 주소 B. 두 VPC 간에 AWS Direct Connect 연결을 구성합니다. 다음을 사용하여 API에 액세스 개인 주소. C. API에 대한 ClassicLink 연결을 클라이언트 VPC로 구성합니다. 다음을 사용하여 API에 액세스합니다. 클래식링크 주소. D. API에 대한 PrivateLink 연결을 클라이언트 VPC로 구성합니다. 다음을 사용하여 API에 액세스 PrivateLink 주소. E. 두 계정 간의 AWS Resource Access Manager 연결 구성 API에 액세스 개인 주소를 사용하여 정답 풀이\r...\r답변: 광고\r#\r#\r#\r질문\r#\rquestion 제품 팀이 많은 양의 데이터를 저장할 새 애플리케이션을 만들고 있습니다. 여러 Amazon EC2 Linux 인스턴스에 의해 매시간 분석되고 수정됩니다. 애플리케이션 팀 필요한 공간의 양이 향후 6개월 동안 계속 증가할 것이라고 생각합니다. 솔루션 설계자가 이러한 요구 사항을 지원하기 위해 취해야 하는 조치는 무엇입니까?\nA. Amazon EBS 볼륨에 데이터 저장 애플리케이션 인스턴스에 EBS 볼륨 탑재 B. Amazon EFS 파일 시스템에 데이터 저장 애플리케이션 인스턴스에 파일 시스템 탑재 C. Amazon S3 Glacier에 데이터 저장 애플리케이션에 대한 액세스를 허용하도록 볼트 정책 업데이트 인스턴스 D. Amazon S3 Standard-Infrequent Access(S3 Standard-IA)에 데이터 저장 버킷 업데이트 애플리케이션 인스턴스에 대한 액세스를 허용하는 정책 정답 풀이\r...\r답: B\r#\r설명 Amazon Elastic 파일 시스템 Amazon Elastic File System(Amazon EFS)은 간단하고 확장 가능한 완전 관리형 탄력적 NFS 파일을 제공합니다. AWS 클라우드 서비스 및 온프레미스 리소스와 함께 사용하기 위한 시스템입니다. 필요에 따라 확장할 수 있도록 구축되었습니다. 애플리케이션을 중단하지 않고 페타바이트를 추가하고 추가할 때 자동으로 확장 및 축소 파일을 제거하여 증가에 따라 용량을 프로비저닝하고 관리할 필요가 없습니다. Amazon EFS는 수천 개의 Amazon EC2에 대한 대규모 병렬 공유 액세스를 제공하도록 설계되었습니다. 애플리케이션이 높은 수준의 집계 처리량 및 IOPS를 달성할 수 있도록 하는 인스턴스 일관된 짧은 대기 시간. Amazon EFS는 홈 디렉터리에서 비즈니스 크리티컬 애플리케이션. 고객은 EFS를 사용하여 기존 엔터프라이즈 애플리케이션을 리프트 앤 시프트할 수 있습니다. AWS 클라우드로. 기타 사용 사례에는 빅 데이터 분석, 웹 서비스 및 콘텐츠 관리, 애플리케이션 개발 및 테스트, 미디어 및 엔터테인먼트 워크플로, 데이터베이스 백업, 컨테이너 보관. Amazon EFS는 여러 가용 영역(AZ) 내부 및 전체에 데이터를 저장하는 지역 서비스입니다. 높은 가용성과 내구성. Amazon EC2 인스턴스는 AZ, 리전, 온프레미스 서버는 AWS Direct Connect 또는 AWS VPN을 사용하여 액세스할 수 있습니다. https://aws.amazon.com/efs/\n#\r#\r질문\r#\rquestion 응용 프로그램을 사용하면 회사 본사의 사용자가 제품 데이터에 액세스할 수 있습니다. 제품 데이터는 Amazon RDS MySQL DB 인스턴스에 저장됩니다. 운영 팀은 애플리케이션 성능이 저하되고 쓰기 트래픽에서 읽기 트래픽을 분리하려고 합니다. 솔루션 설계자는 애플리케이션의 성능을 신속하게 최적화해야 합니다. 솔루션 설계자는 무엇을 권장해야 합니까?\nA. 기존 데이터베이스를 다중 AZ 배포로 변경합니다. 기본 데이터베이스의 읽기 요청을 제공합니다. 가용 영역 B. 기존 데이터베이스를 다중 AZ 배포로 변경 보조 가용 영역 C. 데이터베이스에 대한 읽기 전용 복제본 생성 절반의 컴퓨팅 및 소스 데이터베이스로서의 스토리지 리소스 D. 데이터베이스에 대한 읽기 전용 복제본 생성 동일한 컴퓨팅 및 소스 데이터베이스로서의 스토리지 리소스 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion AWS에서 실행되는 애플리케이션은 Amazon Aurora 다중 AZ 배포를 사용합니다. 데이터베이스 성능 메트릭을 평가할 때 솔루션 설계자는 데이터베이스가 읽기로 인해 높은 I/O가 발생하고 데이터베이스에 대한 쓰기 요청에 대기 시간이 추가됩니다. 솔루션 설계자는 쓰기 요청에서 읽기 요청을 분리하기 위해 무엇을 합니까?\nA. Amazon Aurora 데이터베이스에서 read-through 캐싱 활성화 B. 다중 AZ 대기 인스턴스에서 읽도록 애플리케이션 업데이트 C. 읽기 전용 복제본을 생성하고 적절한 엔드포인트를 사용하도록 애플리케이션 수정 D. 두 번째 Amazon Aurora 데이터베이스를 생성하고 기본 데이터베이스에 읽기 전용 복제본으로 연결합니다. 정답 풀이\r...\r답: C\r#\r설명 Amazon RDS 읽기 전용 복제본 Amazon RDS 읽기 전용 복제본은 RDS 데이터베이스(DB)에 대해 향상된 성능과 내구성을 제공합니다. 인스턴스. 이를 통해 단일 DB 인스턴스의 용량 제약을 넘어 탄력적으로 확장할 수 있습니다. 읽기가 많은 데이터베이스 워크로드. 지정된 소스 DB 인스턴스의 복제본을 하나 이상 생성할 수 있습니다. 데이터의 여러 복사본에서 대용량 애플리케이션 읽기 트래픽을 제공하여 총 읽기 처리량. 읽기 전용 복제본은 독립 실행형이 되어야 할 때 승격될 수도 있습니다. DB 인스턴스. 읽기 전용 복제본은 Amazon RDS for MySQL, MariaDB, PostgreSQL, Oracle, 및 SQL Server 및 Amazon Aurora. MySQL, MariaDB, PostgreSQL, Oracle 및 SQL Server 데이터베이스 엔진의 경우 Amazon RDS는 다음을 생성합니다. 소스 DB 인스턴스의 스냅샷을 사용하는 두 번째 DB 인스턴스. 그런 다음 엔진의 네이티브를 사용합니다. 소스 DB가 변경될 때마다 읽기 전용 복제본을 업데이트하는 비동기식 복제 사례. 읽기 전용 복제본은 읽기 전용 연결만 허용하는 DB 인스턴스로 작동합니다. 애플리케이션은 DB 인스턴스와 마찬가지로 읽기 전용 복제본에 연결할 수 있습니다. 아마존 RDS 원본 DB 인스턴스의 모든 데이터베이스를 복제합니다. Amazon Aurora는 SSD 지원 가상화 기술을 사용하여 읽기 전용 복제본의 이점을 더욱 확장합니다. 데이터베이스 워크로드를 위해 특별히 제작된 스토리지 계층. Amazon Aurora 복제본은 동일한 내용을 공유합니다. 기본 스토리지를 소스 인스턴스로 사용하여 비용을 절감하고 데이터를 복제 노드. Amazon Aurora를 사용한 복제에 대한 자세한 내용은 온라인을 참조하십시오. 선적 서류 비치.\nhttps://aws.amazon.com/rds/features/read-replicas/\n#\r#\r질문\r#\rquestion 회사에서 비즈니스 크리티컬 데이터 세트를 Amazon S3로 마이그레이션할 계획입니다. 현재 솔루션 설계는 us-east-1 리전에서 단일 S3 버킷을 사용하고 저장을 위해 버전 관리가 활성화되어 있습니다. 데이터세트. 회사의 재해 복구 정책에 따르면 모든 데이터는 여러 AWS 리전입니다. 솔루션 설계자는 S3 솔루션을 어떻게 설계해야 합니까?\nA. 다른 리전에서 추가 S3 버킷을 생성하고 교차 리전 복제를 구성합니다. B. 다른 리전에서 추가 S3 버킷 생성 및 교차 출처 리소스 공유 구성 (CORS). C. 다른 리전에서 버전 관리를 사용하여 추가 S3 버킷을 생성하고 리전 간 복제를 구성합니다. D. 다른 리전에서 버전 관리가 포함된 추가 S3 버킷 생성 및 교차 출처 구성 리소스(CORS). 정답 풀이\r...\r답: C\r#\r설명 객체 버전 관리 Amazon S3 버전 관리를 사용하여 하나의 버킷에 여러 버전의 객체를 보관하십시오. 예를 들어, 당신은 my-image.jpg(버전 111111) 및 my-image.jpg(버전 222222)를 단일 버킷에 저장할 수 있습니다. 시즌3 버전 관리는 의도하지 않은 덮어쓰기 및 삭제의 결과로부터 사용자를 보호합니다. 당신은 또한 수 이전 버전에 액세스할 수 있도록 개체를 아카이브하는 데 사용합니다. 버킷에서 명시적으로 S3 버전 관리를 활성화해야 합니다. 기본적으로 S3 버전 관리는 비활성화되어 있습니다. 버전 관리를 활성화했는지 여부에 관계없이 버킷의 각 객체에는 버전 ID가 있습니다. 만약에 버전 관리를 활성화하지 않은 경우 Amazon S3는 버전 ID 값을 null로 설정합니다. S3 버전 관리의 경우 활성화된 경우 Amazon S3는 객체에 대한 버전 ID 값을 할당합니다. 이 값은 다른 것과 구별됩니다. 동일한 키의 버전. 버전 관리 활성화 및 일시 중단은 버킷 수준에서 수행됩니다. 버전 관리를 활성화하면 기존 버킷에서 이미 버킷에 저장된 객체는 변경되지 않습니다. 버전 ID(null), 내용 및 권한은 동일하게 유지됩니다. 버킷에 대해 S3 버전 관리를 활성화한 후 각 객체는 버킷에 추가된 버전은 동일한 버전의 다른 버전과 구별되는 버전 ID를 얻습니다. 열쇠. CORS(교차 출처 리소스 공유) CORS(Cross-Origin Resource Sharing)는 클라이언트 웹 애플리케이션이 도메인은 다른 도메인의 리소스와 상호 작용합니다. CORS 지원을 통해 Amazon S3로 풍부한 클라이언트 측 웹 애플리케이션을 구축하고 Amazon S3에 대한 교차 출처 액세스를 선택적으로 허용할 수 있습니다. 자원. https://docs.aws.amazon.com/AmazonS3/latest/dev/ObjectVersioning.html https://docs.aws.amazon.com/AmazonS3/latest/dev/cors.html\n#\r#\r질문\r#\rquestion 회사에 액세스해야 하는 프라이빗 서브넷에서 실행되는 Amazon EC2 인스턴스가 있습니다. 패치 및 업데이트를 다운로드할 수 있는 공개 웹사이트. 회사는 외부 웹사이트가 EC2 인스턴스 IP 주소를 확인하거나 연결을 시작하십시오. 솔루션 아키텍트는 어떻게 이 목표를 달성할 수 있습니까?\nA. 사설 서브넷과 공용 사이트가 배포된 네트워크 간에 사이트 간 VPN 연결을 만듭니다. B. 퍼블릭 서브넷에 NAT 게이트웨이 생성 프라이빗 서브넷에서 NAI 게이트웨이를 통해 아웃바운드 트래픽 라우팅 C. 배포된 EC2 인스턴스가 퍼블릭 웹사이트의 IP 주소 범위에서만 액세스를 허용하는 프라이빗 서브넷에 대한 네트워크 ACL을 생성합니다. D. 공개 웹 사이트의 IP 주소 범위에서만 연결을 허용하는 보안 그룹을 만듭니다. 보안 그룹을 EC2 인스턴스에 연결합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 한 회사가 AWS 클라우드에서 공개 웹 애플리케이션 출시를 준비하고 있습니다. 아키텍처는 Elastic Load Balancer(ELB) 뒤에 있는 VPC 내의 Amazon EC2 인스턴스로 구성됩니다. NS 타사 서비스는 DNS에 사용됩니다. 회사의 솔루션 설계자가 솔루션을 추천해야 합니다. 대규모 DDoS 공격을 탐지하고 보호하려면 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 계정에서 Amazon GuardDuty 활성화 B. EC2 인스턴스에서 Amazon Inspector 활성화 C. AWS Shield를 활성화하고 여기에 Amazon Route 53을 할당합니다. D. AWS Shield Advanced를 활성화하고 ELB를 할당합니다. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에 다른 AWS 리전에 배포된 애플리케이션에 액세스하는 글로벌 사용자가 있습니다. 공개 고정 IP 주소를 노출합니다. 사용자가 액세스할 때 성능이 저하됩니다. 인터넷을 통한 신청. 솔루션 설계자는 인터넷 대기 시간을 줄이기 위해 무엇을 권장해야 합니까?\nA. AWS Global Accelerator를 설정하고 엔드포인트를 추가합니다. B. 여러 리전에 AWS Direct Connect 위치를 설정합니다. C. 애플리케이션에 액세스할 수 있도록 Amazon CloudFront 배포를 설정합니다. D. 트래픽을 라우팅하도록 Amazon Route 53 지리 근접 라우팅 정책을 설정합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자가 최근에 마이그레이션된 워크로드의 보안 검토를 수행하고 있습니다. NS 워크로드는 뒤에 있는 Auto Scaling 그룹의 Amazon EC2 인스턴스로 구성된 웹 애플리케이션입니다. 애플리케이션 로드 밸런서. 솔루션 설계자는 보안 태세를 개선하고 리소스에 대한 DDoS 공격의 영향. 어떤 솔루션이 가장 효과적입니까?\nA. 요금 기반 규칙을 사용하여 AWS WAF ACL 구성 다음을 수행하는 Amazon CloudFront 배포를 생성합니다. Application Load Balancer를 가리킵니다. CloudFront 배포에서 EAF ACL 활성화 B. 식별된 공격을 공통 취약점에 추가하는 사용자 지정 AWS Lambda 함수 생성 잠재적인 DDoS 공격을 포착하기 위한 풀입니다. 식별된 정보를 사용하여 네트워크 ACL 수정 액세스 차단. C. VPC 흐름 로그를 활성화한 다음 Amazon S3에 저장합니다. 다음을 수행하는 사용자 지정 AWS Lambda 함수를 생성합니다. DDoS 공격을 찾는 로그를 구문 분석합니다. 식별된 소스 IP를 차단하도록 네트워크 ACL 수정 구애. D. Amazon GuardDuty를 활성화하고 작성된 결과를 구성합니다. 10 Amazon GloudWatch 생성 Amazon Simple Notification Service를 트리거하는 DDoS 알림에 대한 Cloud Watch 이벤트가 있는 이벤트 (Amazon SNS) Amazon SNS가 찾고 있는 로그를 구문 분석하는 사용자 지정 AWS 람다 함수를 호출하도록 합니다. DDoS 공격에 대해 식별된 소스 IP 주소를 차단하도록 네트워크 ACL 수정 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에 기존 파일 공유 서비스가 없습니다. 새 프로젝트에는 파일 저장소에 대한 액세스 권한이 필요합니다. 온프레미스 데스크톱용 드라이브로 탑재할 수 있습니다. 파일 서버는 사용자를 인증해야 합니다. 스토리지에 액세스할 수 있기 전에 Active Directory 도메인. Active Directory 사용자가 데스크탑에 스토리지를 드라이브로 탑재할 수 있는 서비스는 무엇입니까?\nA. 아마존 S3 빙하 B. AWS 데이터싱크 C. AWS Snowball 엣지 D. AWS 스토리지 게이트웨이 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자는 무엇을 권장해야 합니까?\nA. 보조 리전의 Amazon EC2에 MySQL 설치 B. 교차 리전 복제본을 사용하여 데이터베이스를 Amazon Aurora로 마이그레이션 C. 보조 리전에서 다른 MySQL용 RDS 읽기 전용 복제본 생성 D. Amazon ElastiCache를 구현하여 데이터베이스 쿼리 성능 향상 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 게임 회사는 단일 가용 영역에 여러 Amazon EC2 인스턴스를 보유하고 있습니다. Layer 4의 최고기술책임자(CTO)가 원하는 멀티플레이어 게임 아키텍처를 고가용성 및 비용 효율적으로 만듭니다. 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 해야 합니까? (2개를 선택하십시오.)\nA. EC2 인스턴스 수를 늘립니다. B. EC2 인스턴스 수 줄이기 C. EC2 인스턴스 앞에 Network Load Balancer를 구성합니다. D. EC2 인스턴스 앞에 Application Load Balancer 구성 E. 여러 가용 영역에서 인스턴스를 추가하거나 제거하도록 Auto Scaling 그룹 구성 자동으로. 정답 풀이\r...\r답변: CE\r#\r설명 네트워크 로드 밸런서 개요 Network Load Balancer는 OSI(Open Systems Interconnection)의 네 번째 계층에서 작동합니다. 모델. 초당 수백만 개의 요청을 처리할 수 있습니다. 로드 밸런서가 연결을 수신한 후 요청 시 기본 규칙에 대한 대상 그룹에서 대상을 선택합니다. TCP를 열려고 시도합니다. 리스너 구성에 지정된 포트에서 선택한 대상에 연결합니다. 로드 밸런서에 대해 가용 영역을 활성화하면 Elastic Load Balancing이 로드를 생성합니다. 가용 영역의 밸런서 노드. 기본적으로 각 로드 밸런서 노드는 트래픽을 가용 영역에만 등록된 대상입니다. 교차 영역 로드 밸런싱을 활성화하면 각 로드가 밸런서 노드는 활성화된 모든 가용 영역의 등록된 대상에 트래픽을 분산합니다. 을위한 자세한 내용은 가용 영역을 참조하십시오. 로드 밸런서에 대해 여러 가용 영역을 활성화하고 각 대상 그룹이 활성화된 각 가용 영역에 하나 이상의 대상이 있는 경우 사용자의 내결함성이 증가합니다. 응용 프로그램. 예를 들어, 하나 이상의 대상 그룹에 정상적인 대상이 없는 경우 가용 영역, DNS에서 해당 서브넷의 IP 주소를 제거하지만 로드 다른 가용 영역의 밸런서 노드는 트래픽을 라우팅하는 데 계속 사용할 수 있습니다. 클라이언트가 그렇지 않은 경우 TTL(Time-to-Live)을 준수하고 DNS에서 제거된 후 IP 주소로 요청을 보냅니다. 요청이 실패합니다. TCP 트래픽의 경우 로드 밸런서는 프로토콜 기반의 플로우 해시 알고리즘을 사용하여 대상을 선택하고, 소스 IP 주소, 소스 포트, 대상 IP 주소, 대상 포트 및 TCP 시퀀스 번호. 클라이언트의 TCP 연결은 소스 포트와 시퀀스 번호가 다르며 다른 대상으로 라우팅됩니다. 각 개별 TCP 연결은 수명 동안 단일 대상으로 라우팅됩니다. 연결. UDP 트래픽의 경우 로드 밸런서는 프로토콜 기반의 플로우 해시 알고리즘을 사용하여 대상을 선택하고, 출발지 IP 주소, 출발지 포트, 목적지 IP 주소, 목적지 포트. UDP 흐름은 동일합니다. 소스와 대상을 포함하므로 평생 동안 단일 대상으로 일관되게 라우팅됩니다. 다른 UDP 흐름은 서로 다른 소스 IP 주소와 포트를 가지므로 서로 다른 대상으로 라우팅될 수 있습니다. Auto Scaling 그룹에는 논리적으로 취급되는 Amazon EC2 인스턴스 모음이 포함되어 있습니다. 자동 확장 및 관리를 위한 그룹화. Auto Scaling 그룹은 또한 상태 확인 교체 및 조정 정책과 같은 Amazon EC2 Auto Scaling 기능을 사용합니다. Auto Scaling 그룹의 인스턴스 수를 유지하는 것과 자동 조정은 모두 Amazon EC2 Auto Scaling 서비스의 핵심 기능. Auto Scaling 그룹의 크기는 원하는 인스턴스 수에 따라 다릅니다. 용량. 수동으로 또는 자동 크기 조정을 사용하여 수요에 맞게 크기를 조정할 수 있습니다. Auto Scaling 그룹은 원하는 용량을 충족하기에 충분한 인스턴스를 시작하여 시작합니다. 그것은 유지 그룹의 인스턴스에 대한 주기적인 상태 확인을 수행하여 이 인스턴스 수. NS Auto Scaling 그룹은 인스턴스가 건강에 해로운. 인스턴스가 비정상이 되면 그룹은 비정상 인스턴스를 종료하고 이를 대체하기 위해 다른 인스턴스를 시작합니다. https://docs.aws.amazon.com/elasticloadbalancing/latest/network/introduction.html https://docs.aws.amazon.com/autoscaling/ec2/userguide/AutoScalingGroup.html\n#\r#\r질문\r#\rquestion 회사에서 레거시 워크로드를 AWS 클라우드로 이동하고 있습니다. 워크로드 파일은 Amazon EC2 인스턴스를 통해 공유, 추가 및 자주 액세스 생성된 파일은 시간이 지남에 따라 때때로 액세스됩니다. 솔루션 설계자는 무엇을 해야 합니까? 추천하다?\nA. Amazon Elastic Block Store(Amazon)가 연결된 Amazon EC2 인스턴스를 사용하여 데이터를 저장합니다. EBS) 데이터 볼륨 B. AWS Storage Gateway 볼륨 게이트웨이를 사용하여 데이터를 저장하고 거의 액세스하지 않는 데이터를 다음으로 내보냅니다. 아마존 S3 스토리지 C. 수명 주기 관리가 활성화된 Amazon Elastic File System(Amazon EFS)을 사용하여 데이터 저장 거의 액세스하지 않는 데이터의 경우 D. 데이터를 S3 StandardInfrequent Access(S3 Standard-IA)로 이동하도록 활성화된 S3 수명 주기 정책과 함께 Amazon S3를 사용하여 데이터 저장 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사는 여러 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. 애플리케이션 Amazon SQS 대기열의 메시지를 처리하여 Amazon RDS 테이블에 쓰고 삭제합니다. 대기열의 메시지 RDS 테이블에서 가끔 중복 레코드가 발견됨 SQS 대기열 중복 메시지를 포함하지 않음 아카이브된 솔루션은 메시지를 보장하기 위해 무엇을 해야 합니까 한 번만 처리되나요?\nA. CreateQueue API 호출을 사용하여 새 대기열 생성 B. AddPermission API 호출을 사용하여 적절한 권한 추가 C. ReceiveMessage API 호출을 사용하여 적절한 대기 시간을 설정합니다. D. ChangeMessageVisibility API 호출을 사용하여 가시성 시간 초과를 늘립니다. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 솔루션 설계자가 새로운 정적 웹 사이트의 배포를 계획하고 있습니다. 솔루션은 비용을 최소화하고 99% 이상의 가용성을 제공합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 버전 관리가 비활성화된 한 AWS 리전의 Amazon S3 버킷에 애플리케이션을 배포합니다. B. 2개의 AWS 리전과 2개의 가용성에서 실행되는 Amazon EC2 인스턴스에 애플리케이션 배포 구역. C. 버전 관리 및 교차 리전 복제가 있는 Amazon S3 버킷에 애플리케이션 배포 활성화. D. 하나의 AWS 리전과 하나의 AWS 리전에서 실행되는 Amazon EC2 인스턴스에 애플리케이션을 배포합니다. 가용 영역. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 통신에 UDP를 사용하는 실시간 승수 게임을 개발 중입니다. Auto Scaling 그룹의 클라이언트와 서버 간 수요 급증이 예상되는 낮 시간, 따라서 게임 서버 플랫폼은 그에 따라 적응해야 합니다. 개발자는 게이머 점수를 저장하고 개입 없이 확장되는 데이터베이스 솔루션의 기타 비관계형 데이터. 솔루션 설계자는 어떤 솔루션을 권장해야 합니까?\nA. 트래픽 분산에는 Amazon Route 53을 사용하고 데이터 저장에는 Amazon Aurora Serverless를 사용하십시오. B. 트래픽 분산에는 Network Load Balancer를 사용하고 데이터에는 Amazon DynamoDB 온디맨드 사용 저장. C. 트래픽 분산에는 Network Load Balancer를 사용하고 데이터 저장에는 amazon Aura Global을 사용합니다. D. 트래픽 분산에는 Application Load Balancer를 사용하고 다음에는 Amazon DynamoDB 글로벌 테이블을 사용합니다. 데이터 저장고 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon EC2 인스턴스 집합을 사용하여 온프레미스 데이터에서 데이터를 수집하고 있습니다. 소스. 데이터는 JSON 형식이며 수집 속도는 최대 1MB/s입니다. EC2일 때 인스턴스가 재부팅되면 진행 중인 데이터가 손실됩니다. 회사의 데이터 과학 팀이 쿼리하려고 합니다. 거의 실시간으로 수집된 데이터. 다음 중 데이터 손실을 최소화하면서 확장 가능한 거의 실시간 데이터 쿼리를 제공하는 솔루션은 무엇입니까?\nA. Amazon Kinesis Data Streams에 데이터를 게시합니다. Kinesis Data Analytics를 사용하여 데이터를 쿼리합니다. B. Amazon Redshift를 대상으로 하여 Amazon Kinesis Data Firehose에 데이터를 게시합니다. 사용 Amazon Redshift를 사용하여 데이터를 쿼리합니다. C. 수집된 데이터를 EC2 인스턴스 스토어에 저장 다음을 사용하여 Amazon Kinesis Data Firehose에 데이터 게시 Amazon S3를 대상으로 합니다. Amazon Athena를 사용하여 데이터를 쿼리합니다. D. 수집된 데이터를 Amazon Elastic Block Store(Amazon EBS) 볼륨에 저장합니다. 에 데이터 게시 Redis용 Amazon ElastiCache. Redis 채널을 구독하여 데이터를 쿼리하세요. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 한 회사는 이전에 데이터 웨어하우스 솔루션을 AWS로 마이그레이션했습니다. 회사는 또한 AWS Direct Connect 연결. 회사 사무실 사용자는 다음을 사용하여 데이터 웨어하우스를 쿼리합니다. 시각화 도구. 데이터 웨어하우스에서 반환하는 쿼리의 평균 크기는 50MB이며 각 쿼리는 시각화 도구에서 보낸 웹 페이지는 약 500KB입니다. 데이터에서 반환된 결과 집합 창고는 캐시되지 않습니다. 회사에 가장 낮은 데이터 전송 송신 비용을 제공하는 솔루션은 무엇입니까?\nA. 온프레미스에서 시각화 도구를 호스팅하고 인터넷을 통해 직접 데이터 웨어하우스를 쿼리합니다. B. 데이터 웨어하우스와 동일한 AWS 리전에서 시각화 도구를 호스팅합니다. 를 통해 액세스 인터넷. C. 온프레미스에서 시각화 도구를 호스팅하고 Direct를 통해 직접 데이터 웨어하우스를 쿼리합니다. 동일한 AWS 리전의 위치에서 연결을 연결합니다. D. 데이터 웨어하우스와 동일한 AWS 리전에서 시각화 도구를 호스팅하고 다음을 통해 액세스합니다. 동일한 지역의 위치에서 직접 연결 연결. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사에 산발적인 사용 패턴이 있는 웹 응용 프로그램이 있습니다. 에서 사용량이 많습니다. 매월 초, 매주 초에 보통 사용량, 기간 동안 예측할 수 없는 사용량 그 주. 애플리케이션은 웹 서버와 내부에서 실행되는 MySQL 데이터베이스 서버로 구성됩니다. 데이터 센터. 회사는 애플리케이션을 AWS 클라우드로 옮기고자 하며 다음을 선택해야 합니다. 데이터베이스 수정이 필요하지 않은 비용 효율적인 데이터베이스 플랫폼입니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. Amazon DynamoDB B. MySQL용 Amazon RDS C. MySQL 호환 Amazon Aurora Serverless D. Auto Scaling 그룹의 Amazon EC2에 배포된 MySQL 정답 풀이\r...\r답: C\r#\r#\r#\r질문 301-\r#\r#\r#\r질문\r#\rquestion 회사는 AWS 클라우드에 대한 보안 연결을 위해 Site-to-Site VPN 연결을 사용하고 있습니다. 온프레미스의 리소스. Amazon에 대한 VPN 연결을 통한 트래픽 증가로 인해 EC2 인스턴스, 사용자가 느린 VPN 연결을 경험하고 있습니다. VPN을 개선할 솔루션 처리량?\nA. 처리량을 확장하기 위해 동일한 네트워크에 대해 여러 고객 게이트웨이를 구현합니다. B. 동일한 비용의 다중 경로 라우팅이 있는 전송 게이트웨이를 사용하고 VPN 터널을 추가합니다. C. 동일한 비용의 다중 경로 라우팅 및 다중 채널로 가상 사설 게이트웨이 구성 D. VPN 구성의 터널 수를 늘려 처리량을 다음 이상으로 확장합니다. 기본 제한 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon ECS를 사용하여 애플리케이션을 실행합니다. 애플리케이션은 크기가 조정된 버전을 생성합니다. 원본 이미지의 이미지를 가져온 다음 Amazon S3 API를 호출하여 크기가 조정된 이미지를 Amazon S3에 저장합니다. 솔루션 설계자는 애플리케이션에 Amazon S3에 대한 액세스 권한이 있는지 어떻게 확인할 수 있습니까?\nA. Amazon ECS에서 읽기/쓰기 액세스를 허용하도록 AWS IAM에서 S3 역할을 업데이트한 다음 다시 시작합니다. 컨테이너. B. S3 권한이 있는 IAM 역할을 생성한 다음 해당 역할을 작업에서 taskRoleArn으로 지정합니다. 정의. C. Amazon ECS에서 Amazon S3로의 액세스를 허용하는 보안 그룹 생성 및 시작 업데이트 ECS 클러스터에서 사용하는 구성입니다. D. S3 권한이 있는 IAM 사용자를 생성한 다음 ECS용 Amazon EC2 인스턴스를 다시 시작합니다. 이 계정으로 로그인한 동안 클러스터. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사는 AWS에서 사용자의 센서 데이터를 수집하는 3계층 환경을 보유하고 있습니다. 장치. 트래픽은 NLB(Network Load Balancer)를 통해 Amazon EC2 인스턴스로 흐릅니다. 웹 계층, 마지막으로 데이터베이스 호출을 수행하는 애플리케이션 계층의 EC2 인스턴스 솔루션 설계자는 웹 계층으로 전송되는 데이터의 보안을 개선하기 위해 수행해야 합니까?\nA. TLS 수신기를 구성하고 NLB에 서버 인증서를 추가합니다. B. AWS Shield Advanced 구성 및 NLB에서 AWS WAF 활성화 C. 로드 밸런서를 Application Load Balancer로 변경하고 여기에 AWS WAF를 연결합니다. D. AWS 키를 사용하여 EC2 인스턴스에서 Amazon Elastic Block Store(Amazon EBS) 볼륨 암호화 관리 서비스(AWS KMS) 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 AWS 클라우드 배포를 검토하여 다음 사람이 데이터에 액세스하지 못하도록 하고 있습니다. 적절한 권한이 없는 사람. 솔루션 아키텍트는 열려 있는 모든 Amazon S3 버킷 및 모든 S3 버킷 구성 변경 기록. 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. 적절한 규칙으로 AWS Config 서비스 활성화 B. 적절한 검사를 통해 AWS Trusted Advisor를 활성화합니다. C. AWS SDK를 사용하여 버킷 보고서를 생성하는 스크립트 작성 D. Amazon S3 서버 액세스 로깅을 활성화하고 Amazon CloudWatch Events를 구성합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 최대 200GB의 저장 공간. 응용 프로그램은 아침과 저녁에 최고조에 달하는 드물게 사용됩니다. 디스크 I/O는 다양하지만 최고 3,000 IOPS입니다. 회사의 최고 재무 책임자(CFO)가 걱정하는 비용을 절감하고 솔루션 설계자에게 가장 비용 효율적인 스토리지 옵션을 추천해 달라고 요청했습니다. 성능을 희생하지 않습니다. 솔루션 설계자는 어떤 솔루션을 권장해야 합니까?\nA. Amazon EBS 콜드 HDD(sc1) B. Amazon EBS 범용 SSD(gp2) C. Amazon EBS 프로비저닝된 IOPS SSD(io1) D. Amazon EBS 처리량 최적화 HDD(st1) 정답 풀이\r...\r답: B\r#\r범용 SSD는 최대 3,000 IOPS가 가능합니다. #\r#\r질문\r#\rquestion 한 회사가 AWS에서 호스팅되는 비디오 변환 애플리케이션을 개발 중입니다. 응용 프로그램은 무료 계층과 유료 계층의 두 가지 계층으로 제공됩니다. 유료 계층의 사용자는 자신의 비디오를 갖게 됩니다. 먼저 변환된 다음 트리 계층 사용자가 자신의 비디오를 변환합니다. 이러한 요구 사항을 충족하고 가장 비용 효율적인 솔루션은 무엇입니까?\nA. 유료 계층용 FIFO 대기열 1개와 무료 계층용 표준 대기열 1개 B. 모든 파일 유형에 대한 단일 FIFO Amazon Simple Queue Service(Amazon SQS) 대기열 C. 모든 파일 유형에 대한 단일 표준 Amazon Simple Queue Service(Amazon SQS) 대기열 D. 2개의 표준 Amazon Simple Queue Service(Amazon SQS) 대기열과 유료 계층용 대기열 및 하나는 프리 티어용 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 한 회사는 최근 새로운 유형의 인터넷 연결 센서를 출시했습니다. 회사는 각각 대량의 데이터를 스트리밍하도록 설계된 수천 개의 센서가 판매될 것으로 예상 중앙 위치에 두 번째. 솔루션 설계자는 데이터를 수집하고 저장하는 솔루션을 설계해야 합니다. 엔지니어링 팀이 밀리초 응답으로 거의 실시간으로 분석할 수 있습니다. 솔루션 설계자는 어떤 솔루션을 권장해야 합니까?\nA. Amazon SQS 대기열을 사용하여 데이터를 수집합니다. AWS Lambda 함수로 데이터를 소비하고, 그런 다음 Amazon Redshift에 데이터를 저장합니다. B. Amazon SOS 대기열을 사용하여 데이터를 수집합니다. AWS Lambda 함수로 데이터를 소비하고, 그런 다음 Amazon DynamoDB에 데이터를 저장합니다. C. Amazon Kinesis Data Streams를 사용하여 데이터를 수집합니다. AWS Lambda로 데이터 소비 그런 다음 Amazon Redshift에 데이터를 저장합니다. D. Amazon Kinesis Data Streams를 사용하여 데이터를 수집합니다. AWS Lambda로 데이터 소비 그런 다음 Amazon DynamoDB에 데이터를 저장합니다. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사는 사용자가 업로드한 Amazon S3 lo store 이미지를 사용할 계획입니다. 이미지 Amazon S3에서 저장 시 암호화해야 하는 회사는 관리 및 키를 교체하지만 해당 키에 액세스할 수 있는 사람을 제어하려고 합니다. 건축가는 이것을 달성하기 위해 사용합니까?\nA. S3 버킷에 저장된 키를 사용한 서버 측 암호화 B. 고객 제공 키를 사용한 서버 측 암호화(SSE-C) C. Amazon S3 관리형 키를 사용한 서버 측 암호화(SSE-S3) D. AWS KMS 관리형 키(SSE-KMS)를 사용한 서버 측 암호화 정답 풀이\r...\r답변: D\r#\r설명 링크: https://docs.aws.amazon.com/AmazonS3/latest/dev/serv-side-encryption.html \u0026ldquo;AWS Key Management Service에 저장된 고객 마스터 키(CMK)를 사용한 서버 측 암호화 (SSE-KMS)는 SSE-S3와 유사하지만 이 서비스 사용에 대한 몇 가지 추가 혜택과 요금이 있습니다. 추가 보호를 제공하는 CMK 사용에 대한 별도의 권한이 있습니다. Amazon S3의 객체에 대한 무단 액세스. SSE-KMS는 또한 감사 추적을 제공합니다. CMK가 언제 누구에 의해 사용되었는지 보여줍니다.\u0026rdquo; 서버 측 암호화: SSE-KMS 사용 서버 측 암호화의 세 가지 모드인 SSE-S3, SSE-C 또는 SSE-KMS. SSE-S3를 사용하려면 Amazon S3에서 데이터 및 마스터 암호화 키를 관리해야 합니다. 자세한 내용은 SSE-S3에 대한 정보는 Amazon S3 관리형 암호화로 서버 측 암호화를 사용하여 데이터 보호를 참조하십시오. 키(SSE-S3). SSE-C를 사용하려면 암호화 키를 관리해야 합니다. SSE-C에 대한 자세한 내용은 다음을 참조하십시오. 고객 제공 암호화 키(SSE-C)로 서버 측 암호화를 사용하여 데이터 보호. SSE-KMS는 AWS에서 데이터 키를 관리해야 하지만 고객 마스터 키(CMK)는 사용자가 관리해야 합니다. AWS KMS. 이 주제의 나머지 부분에서는 AWS에서 서버 측 암호화를 사용하여 데이터를 보호하는 방법에 대해 설명합니다. KMS 관리 키(SSE-KMS). Amazon S3 콘솔 또는 API를 사용하여 암호화를 요청하고 CMK를 선택할 수 있습니다. 콘솔에서, 해당 상자를 선택하여 암호화를 수행하고 목록에서 CMK를 선택합니다. 아마존을 위해 S3 API, 암호화를 지정하고 GET 또는 PUT에서 적절한 헤더를 설정하여 CMK를 선택합니다. 요구. https://docs.aws.amazon.com/kms/latest/developerguide/services-s3.html#sse\n#\r#\r질문\r#\rquestion 회사에 프라이빗 서브넷의 Amazon EC2 인스턴스에서 실행되는 애플리케이션이 있습니다. NS 애플리케이션은 Amazon S3에 데이터를 저장하고 검색해야 합니다. 비용을 줄이기 위해 회사는 비용 효율적인 방식으로 AWS 리소스 구성 회사는 이를 어떻게 달성해야 합니까?\nA. NAT 게이트웨이를 배포하여 S3 버킷에 액세스 B. AWS Storage Gateway를 배포하여 S3 버킷에 액세스 C. S3 버킷에 액세스하기 위해 S3 게이트웨이 엔드포인트 배포 D. S3 버킷에 액세스하기 위해 S3 인터페이스 엔드포인트를 배포합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사에서 AWS 리전을 온프레미스의 재해 복구 위치로 사용하려고 합니다. 하부 구조. 회사는 10TB의 기존 데이터를 보유하고 있으며 온프레미스 데이터 센터에는 1Gbps의 인터넷 연결. 솔루션 설계자는 회사가 기존 솔루션을 가질 수 있도록 솔루션을 찾아야 합니다. 암호화되지 않은 채널을 사용하여 전송하지 않고 72시간 내에 AWS에서 데이터를 전송합니다. 솔루션 설계자는 어떤 솔루션을 선택해야 합니까?\nA. FTP를 사용하여 초기 10TB의 데이터를 AWS로 보냅니다. B. AWS Snowball을 사용하여 초기 10TB의 데이터를 AWS로 보냅니다. C. Amazon VPC와 회사 데이터 센터 간에 VPN 연결을 설정합니다. D. Amazon VPC와 회사 데이터 간에 AWS Direct Connect 연결 설정 센터. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 AWS에서 온라인 마켓플레이스 웹 애플리케이션을 실행합니다. 응용 프로그램 제공 피크 시간 동안 수십만 명의 사용자. 회사는 확장 가능하고 실시간에 가까운 수백만 건의 금융 거래 내역을 다른 여러 내부 기관과 공유하는 솔루션 응용 프로그램. 또한 트랜잭션은 에 저장되기 전에 민감한 데이터를 제거하기 위해 처리되어야 합니다. 저지연 검색을 위한 문서 데이터베이스. 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?\nA. 트랜잭션 데이터를 Amazon DynamoDB에 저장합니다. DynamoDB에서 규칙을 설정하여 제거 쓰기 시 모든 트랜잭션의 민감한 데이터. DynamoDB 스트림을 사용하여 트랜잭션 공유 다른 응용 프로그램과 데이터. B. 트랜잭션 데이터를 Amazon Kinesis Data Firehose로 스트리밍하여 Amazon에 데이터 저장 DynamoDB 및 Amazon S3. Kinesis Data Firehose와 AWS Lambda 통합을 사용하여 제거 민감한 데이터. 다른 애플리케이션은 Amazon S3에 저장된 데이터를 사용할 수 있습니다. C. 트랜잭션 데이터를 Amazon Kinesis Data Streams로 스트리밍합니다. AWS Lambda 통합을 사용하여 모든 트랜잭션에서 민감한 데이터를 제거한 다음 Amazon에 트랜잭션 데이터를 저장합니다. 다이나모DB. 다른 애플리케이션은 Kinesis 데이터 스트림의 트랜잭션 데이터를 사용할 수 있습니다. D. 일괄 처리된 트랜잭션 데이터를 Amazon S3에 파일로 저장합니다. AWS Lambda를 사용하여 모든 파일 처리 Amazon S3에서 파일을 업데이트하기 전에 민감한 데이터를 제거하십시오. 그런 다음 Lambda 함수는 다음을 저장합니다. Amazon DynamoDB의 데이터. 다른 애플리케이션은 Amazon에 저장된 트랜잭션 파일을 사용할 수 있습니다. 에스3. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에는 다양한 부서에 대해 여러 AWS 계정이 있습니다. 부서 중 하나 다른 모든 부서와 Amazon S3 버킷을 공유하려고 합니다. 가장 적은 노력이 필요한 솔루션은 무엇입니까?\nA. 버킷에 대해 교차 계정 S3 복제 활성화 B. 버킷에 대한 사전 서명된 URL을 생성하고 다른 부서와 공유 C. 다른 부서에 대한 교차 계정 액세스를 허용하도록 S3 버킷 정책 설정 D. 부서별 IAM 사용자 생성 및 읽기 전용 IAM 정책 구성 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 자전거 공유 회사는 자전거의 위치를 ​​추적하기 위해 다계층 아키텍처를 개발하고 있습니다. 회사는 피크 작동 시간 동안 자전거를 기존의 데이터 포인트에서 사용하려고 합니다. 분석 플랫폼 솔루션 설계자는 지원하기 위해 가장 실행 가능한 다중 계층 옵션을 결정해야 합니다. 이 아키텍처 데이터 포인트는 REST API에서 액세스할 수 있어야 합니다. 위치 데이터를 저장하고 검색하기 위한 요구 사항은 무엇입니까?\nA. Amazon S3와 함께 Amazon Athena 사용 B. AWS Lambda와 함께 Amazon API Gateway 사용 C. Amazon Redshift와 함께 Amazon QuickSight 사용 D. Amazon Kinesis Data Analytics와 함께 Amazon API Gateway 사용 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사에서 Amazon S3에 액세스할 수 없어야 하는 새 클라우드 엔지니어를 고용했습니다. 회사 기밀이라는 버킷. 클라우드 엔지니어는 읽고 쓸 수 있어야 합니다. AdminTools라는 S3 버킷. 어떤 IAM 정책이 이러한 요구 사항을 충족합니까?\nA. 옵션 A B. 옵션 B C. 옵션 C D. 옵션 D 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 등록된 아래 여러 비즈니스 라인에 대해 여러 웹사이트를 호스팅하고 있습니다. 상위 도메인. 이러한 웹사이트에 액세스하는 사용자는 적절한 백엔드 Amazon EC2로 라우팅됩니다. 하위 도메인을 기반으로 하는 인스턴스. 웹 사이트는 정적 웹 페이지, 이미지 및 서버 측을 호스팅합니다. PHP 및 JavaScript와 같은 스크립트. 일부 웹사이트는 업무 시작 후 처음 2시간 동안 최대 액세스를 경험합니다. 하루 종일 사용. 솔루션 아키텍트는 다음과 같은 솔루션을 설계해야 합니다. 비용을 낮게 유지하면서 이러한 트래픽 패턴에 맞게 용량을 자동으로 조정합니다. 이러한 요구 사항을 충족하는 AWS 서비스 또는 기능의 조합은 무엇입니까? (2개를 선택하십시오.)\nA. AWS 배치 B. 네트워크 로드 밸런서 C. 애플리케이션 로드 밸런서 D. Amazon EC2 Auto Scaling E. Amazon S3 웹사이트 호스팅 정답 풀이\r...\r답변: DE\r#\r#\r#\r질문\r#\rquestion 회사에서 NoSQL 데이터베이스 클러스터를 Amazon EC2로 마이그레이션하고 있습니다. 데이터베이스 최소 3개의 데이터 복사본을 유지하기 위해 데이터를 자동으로 복제합니다. I/O 처리량 서버가 가장 높은 우선 순위입니다. 솔루션 설계자는 마이그레이션에 어떤 인스턴스 유형을 권장해야 합니까?\nA. 인스턴스 스토어가 있는 스토리지 최적화 인스턴스 B. Amazon Elastic Block Store(Amazon EBS) 볼륨이 있는 버스트 가능한 범용 인스턴스 C. Amazon Elastic Block Store(Amazon EBS) 최적화가 활성화된 메모리 최적화 인스턴스 D. Amazon Elastic Block Store(Amazon EBS) 최적화가 활성화된 컴퓨팅 최적화 인스턴스 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 애플리케이션은 Amazon RDS MySQL DB 인스턴스를 사용합니다. RDS 데이터베이스가 낮아지고 있습니다. 디스크 공간에. 다운타임 없이 디스크 공간을 늘리고자 하는 솔루션 설계자 최소한의 노력으로 요구 사항?\nA. RDS에서 스토리지 자동 크기 조정을 활성화합니다. B. RDS 데이터베이스 인스턴스 크기 늘리기 C. RDS 데이터베이스 인스턴스 스토리지 유형을 프로비저닝된 IOPS로 변경합니다. D. RDS 데이터베이스 백업, 저장 용량 증가, 데이터베이스 복원 및 중지 이전 인스턴스 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 애플리케이션은 여러 가용 영역의 Amazon EC2 인스턴스에서 실행됩니다. Application Load Balancer 뒤의 Amazon EC2 Auto Scaling 그룹에서 실행되는 인스턴스 애플리케이션은 EC2 인스턴스의 CPU 사용률이 40% 또는 거의 40%일 때 가장 잘 수행됩니다. 솔루션 설계자가 모든 인스턴스에서 원하는 성능을 유지하기 위해 수행해야 하는 그룹?\nA. 간단한 조정 정책을 사용하여 Auto Scaling 그룹을 동적으로 조정합니다. B. 대상 추적 정책을 사용하여 Auto Scaling 그룹을 동적으로 확장합니다. C. AWS Lambda 함수를 사용하여 원하는 Auto Scaling 그룹 용량 업데이트 D. 예약된 조정 작업을 사용하여 Auto Scaling 그룹을 확장 및 축소합니다. 정답 풀이\r...\r답변:\r#\r#\r#\r질문\r#\rquestion 회사는 애플리케이션 로드를 사용하여 3개의 AWS 리전에 애플리케이션을 배포하고 있습니다. Balancer Amazon Route 53은 이러한 리전 간에 트래픽을 분산하는 데 사용됩니다. 솔루션 설계자가 가장 높은 성능을 제공하기 위해 사용해야 하는 Route 53 구성 경험?\nA. 대기 시간 정책을 사용하여 A 레코드를 생성합니다. B. 지리적 위치 정책으로 A 레코드를 생성합니다. C. 장애 조치 정책으로 CNAME 레코드를 생성합니다. D. 지리 근접성 정책으로 CNAME 레코드를 생성합니다. 정답 풀이\r...\r답변: A\r#\r#\r#\r질문\r#\rquestion 회사는 Amazon S3 버킷을 외부 공급업체와 공유해야 합니다. 버킷 소유자 모든 개체에 액세스할 수 있어야 합니다. S3 버킷을 공유하려면 어떤 조치를 취해야 합니까?\nA. 요청자 지불 버킷이 되도록 버킷 업데이트 B. 교차 출처 리소스 공유(CPORS)를 활성화하도록 버킷 업데이트 C. 사용자가 객체를 업로드할 때 전체 버킷 소유자 권한을 부여하도록 요구하는 버킷 정책 생성 D. 사용자가 객체를 업로드할 때 버킷 소유자에게 전체 제어 권한을 부여하도록 요구하는 IAM 정책을 생성합니다. 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사 웹 사이트에서 Amazon RDS MySQL 다중 AZ DB 인스턴스를 사용하고 있습니다. 트랜잭션 데이터 저장. 내부 배치용 데이터를 가져오기 위해 이 DB 인스턴스를 쿼리하는 다른 내부 시스템이 있습니다. 처리. RDS DB 인스턴스는 내부 시스템이 데이터를 가져오는 속도를 크게 저하시킵니다. 이것 웹 사이트의 읽기 및 쓰기 성능에 영향을 미치고 사용자는 응답 시간이 느려집니다. 어떤 솔루션이 웹사이트의 성능을 향상시킬 것입니까?\nA. MySQL 데이터베이스 대신 RDS PostgreSQL DB 인스턴스를 사용하십시오. B. Amazon ElastiCache를 사용하여 웹 사이트에 대한 쿼리 응답을 캐시합니다. C. 현재 RDS MySQL Multi.AZ DB 인스턴스에 가용 영역을 추가합니다. D. RDS DB 인스턴스에 읽기 전용 복제본을 추가하고 읽기를 쿼리하도록 내부 시스템을 구성합니다. 레플리카. 정답 풀이\r...\r답변: D\r#\r설명 Amazon RDS 읽기 전용 복제본 향상된 성능 애플리케이션에서 읽기 쿼리를 라우팅하여 소스 DB 인스턴스의 로드를 줄일 수 있습니다. 읽기 전용 복제본으로 읽기 전용 복제본을 사용하면 용량 제약을 넘어 탄력적으로 확장할 수 있습니다. 읽기가 많은 데이터베이스 워크로드를 위한 단일 DB 인스턴스. 읽기 전용 복제본이 다음으로 승격될 수 있기 때문에 마스터 상태인 경우 샤딩 구현의 일부로 유용합니다. 읽기 성능을 더욱 극대화하기 위해 Amazon RDS for MySQL을 사용하면 테이블 인덱스를 추가할 수 있습니다. 해당 인덱스가 마스터에 존재하지 않고 읽기 전용 복제본으로 직접 전송됩니다. https://aws.amazon.com/rds/features/read-replicas/\n#\r#\r질문\r#\rquestion 회사는 분기별로 액세스되는 데이터에 대한 데이터 스토리지 비용을 최적화하려고 합니다. 회사는 필요할 때 높은 처리량, 짧은 지연 시간 및 빠른 액세스가 필요합니다. 솔루션 아키텍트가 추천해야 하는 S3 스토리지 클래스는?\nA. Amazon S3 Glacier(S3 Glacier) B. Amazon S3 표준(S3 표준) C. Amazon S3 Intelligent-Tiering(S3 Intelligent-Tiering) D. Amazon S3 Standard-Infrequent Access(S3 Standard-IA) 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사는 애플리케이션 로드 뒤의 Amazon EC2 인스턴스에서 웹 서비스를 실행합니다. 밸런서 인스턴스는 두 가용 영역에 걸쳐 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 회사는 필요한 서비스 수준을 충족하기 위해 모든 라임에서 최소 4개의 인스턴스가 필요합니다. 비용을 낮게 유지하면서 계약(SLA). 가용 영역이 실패하는 경우 회사는 어떻게 SLA를 계속 준수할 수 있습니까?\nA. 짧은 휴지 기간으로 대상 추적 조정 정책 추가 B. 더 큰 인스턴스 유형을 사용하도록 Auto Scaling 그룹 시작 구성 변경 C. 3개의 가용 영역에서 6개의 서버를 사용하도록 Auto Scaling 그룹 변경 D. 2개의 가용 영역에서 8개의 서버를 사용하도록 Auto Scaling 그룹 변경 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion Amazon EC2 인스턴스에서 실행되는 애플리케이션은 Amazon DynamoDB에 액세스해야 합니다. table EC2 인스턴스와 DynamoDB 테이블이 모두 동일한 AWS 계정에 있음 솔루션 건축가는 필요한 권한을 구성해야 합니다. EC2 인스턴스에서 DynamoDB 테이블에 대한 최소 권한 액세스를 허용하는 솔루션은 무엇입니까?\nA. DynamoDB 테이블에 대한 액세스를 허용하는 적절한 정책으로 IAM 역할을 생성합니다. 이 IAM 역할을 EC2 인스턴스에 할당하기 위한 인스턴스 프로파일 B. DynamoDB 테이블에 대한 액세스를 허용하는 적절한 정책으로 IAM 역할을 생성합니다. 역할을 맡도록 허용하는 신뢰 관계 정책 문서에 대한 EC2 인스턴스 C. 적절한 정책으로 IAM 사용자를 생성하여 DynamoDB 테이블에 대한 액세스를 허용합니다. Amazon S3 버킷의 자격 증명을 가져와 애플리케이션 코드 내에서 직접 읽습니다. D. DynamoDB 테이블에 대한 액세스를 허용하는 적절한 정책으로 IAM 사용자를 생성합니다. 애플리케이션은 IAM 자격 증명을 로컬 스토리지에 안전하게 저장하고 이를 사용하여 DynamoDB 호출 정답 풀이\r...\r답변: A\r#\rs\n#\r#\r질문\r#\rquestion 회사는 현재 보유하고 있는 Amazon EC2 인스턴스의 필요성을 재평가해야 합니다. Auto Scaling 그룹에서 프로비저닝됩니다. 현재 Auto Scaling 그룹은 최소 2개의 가용 영역에 걸쳐 2개의 인스턴스 및 최대 4개의 인스턴스. 솔루션 아키텍트 Amazon CloudWatch 지표를 검토한 결과 EC2의 CPU 사용률이 일관되게 낮다는 사실을 발견했습니다. 인스턴스. 솔루션 설계자는 활용도를 극대화하는 동시에 애플리케이션이 내결함성을 유지합니까?\nA. 일부 EC2 인스턴스를 제거하여 나머지 인스턴스의 활용도를 높입니다. B. CPU가 적은 인스턴스의 Amazon Elastic Block Store(Amazon EBS) 용량 늘리기 이용. C. Auto Scaling 그룹 조정 정책을 수정하여 더 높은 CPU 사용률에 따라 축소 및 축소 메트릭. D. 더 작은 인스턴스 유형을 사용하는 새로운 시작 구성을 생성합니다. 기존 자동 업데이트 스케일링 그룹. 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사는 온프레미스 애플리케이션을 AWS로 마이그레이션할 준비를 하고 있습니다. 응용 프로그램 서버와 Microsoft SQL Server 데이터베이스로 구성됩니다. 데이터베이스를 마이그레이션할 수 없습니다. SQL Server 기능이 응용 프로그램의 NET 코드에서 사용되기 때문에 다른 엔진으로 이동합니다. NS 회사는 운영 및 관리 오버헤드 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. 다중 AZ 배포의 Amazon EC2에 SQL Server 설치 B. 다중 AZ 배포에서 SQL Server용 Amazon RDS로 데이터를 마이그레이션합니다. C. 다중 AZ 복제본이 있는 SQL Server용 Amazon RDS에 데이터베이스를 배포합니다. D. 교차 리전 다중 AZ 배포에서 SQL Server용 Amazon RDS로 데이터 마이그레이션 정답 풀이\r...\r답: B\r#\r#\r#\r질문\r#\rquestion 회사에서 일부 의심스러운 IP 주소의 액세스 요청을 보고 있습니다. 보안팀 동일한 CIDR 범위에 있는 다른 IP 주소의 요청을 검색합니다. 솔루션 설계자는 팀에 무엇을 추천해야 합니까?\nA. 보안의 인바운드 테이블에 규칙을 추가하여 해당 CIDR 범위의 트래픽을 거부합니다. B. 보안 그룹의 아웃바운드 테이블에 규칙을 추가하여 해당 CIDR 범위의 트래픽을 거부합니다. C. 네트워크 ACL의 인바운드 테이블에 다른 규칙보다 낮은 번호로 거부 규칙을 추가합니다. D. 다른 것보다 낮은 규칙 번호로 네트워크 ACL의 아웃바운드 테이블에 거부 규칙을 추가합니다. 규칙. 정답 풀이\r...\r답: C\r#\r#\r#\r질문\r#\rquestion 회사에서 수 테라바이트의 데이터를 AWS로 전송할 계획입니다. 데이터가 수집됩니다 선박에서 오프라인. 회사는 데이터를 전송하기 전에 복잡한 변환을 실행하려고 합니다. 솔루션 설계자는 이 마이그레이션을 위해 어떤 AWS 서비스를 권장해야 합니까?\nA. AWS 스노우볼 B. AWS 스노우모빌 C. AWS Snowball Edge 스토리지 최적화 D. AWS Snowball Edge 컴퓨팅 최적화 정답 풀이\r...\r답변: D\r#\r#\r#\r질문\r#\rquestion 회사의 거의 실시간 스트리밍 애플리케이션이 AWS As에서 실행 중입니다. 작업은 데이터에서 실행되며 완료하는 데 30분이 소요됩니다. 대량의 수신 데이터로 인한 대기 시간 솔루션 설계자는 확장 가능하고 성능 향상을 위한 서버리스 솔루션 솔루션이 수행해야 하는 단계의 조합 건축가 테이크? (2개 선택)\nA. Amazon Kinesis Data Firehose를 사용하여 데이터 수집 B. AWS Step Functions와 함께 AWS Lambda를 사용하여 데이터 처리 C. AWS Database Migration Service(AWS DMS)를 사용하여 데이터 수집 D. Auto Scaling 그룹의 Amazon EC2 인스턴스를 사용하여 데이터 처리 E. Amazon Elastic Container Service(Amazon ECS)와 함께 AWS Fargate를 사용하여 데이터를 처리합니다. 정답 풀이\r...\r답변: AE\r#\r#\r#\r질문\r#\rquestion Amazon EC2 관리자가 IAM 그룹과 연결된 다음 정책을 생성했습니다. 여러 사용자를 포함합니다. 이 정책의 효과는 무엇입니까?\n{ \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;ec2:TerminateInstances\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;IpAddress\u0026#34;: { \u0026#34;aws:SourceIP\u0026#34;: \u0026#34;10.100.100.0/24\u0026#34; } } }, { \u0026#34;Effect\u0026#34;: \u0026#34;Deny\u0026#34;, \u0026#34;Action\u0026#34;: \u0026#34;ec2:*\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringNotEquls\u0026#34;: { \u0026#34;aws:Region\u0026#34;: \u0026#34;us-east-1\u0026#34; } } } ] } A. 사용자는 us-east-1을 제외한 모든 AWS 리전에서 EC2 인스턴스를 종료할 수 있습니다. B. 사용자는 IP 주소가 10.100인 EC2 인스턴스를 종료할 수 있습니다. us-east-1 리전의 1001 C. 사용자는 사용자의 소스 IP가 다음과 같을 때 us-east-1 리전에서 EC2 인스턴스를 종료할 수 있습니다. 10.100.100.254 D. 사용자의 소스 IP가 다음과 같은 경우 사용자는 us-east-1 리전에서 EC2 인스턴스를 종료할 수 없습니다. 10.100.100. 254 정답 풀이\r...\r답: C\r#\r"},{"id":61,"href":"/cloud/docs/Azure/MicrosoftAzure/Azure06/","title":"Azure BigData","section":"Azure docs","content":"\rAzure BigData\r#\r#\rMicrosoft Azure는 빅 데이터 및 분석 솔루션을 제공하기 위해 광범위한 기술 및 서비스를 지원합니다. #\r#\rAzure Synapse Analytics\r#\r#\rMPP(대규모 병렬 처리)를 활용하여 페타바이트 단위의 데이터에서 복잡한 쿼리를 빠르게 실행하는 클라우드 기반 EDW(Enterprise Data Warehouse)를 사용하여 대규모로 분석 실행 #\r#\rAzure HDInsight\r#\r#\r클라우드의 관리형 Hadoop 클러스터를 사용하여 대량의 데이터 처리 #\r#\rAzure Databricks\r#\r#\rAzure의 다른 빅 데이터 서비스와 통합할 수 있는 Apache Spark 기반의 공동 작업용 분석 서비스입니다. #\r"},{"id":62,"href":"/cloud/docs/AWS/AWSSAA/SAA_all/","title":"aws SAA 총정리","section":"AWS SAA 시험정리","content":"\raws 총정리\r#\rGlobal service = can`t choose a region IAN\r#\r#\rIAM (Identity and Access Management, Global service) root account create by default, shouldn`t be used or shared Users are people within your organization, and can be grouped Group only contain users, not other groups -\u0026gt; Group can`t contain other group Users don`t have to belong to a group, and usre can belong to multiple groups User or Groups can be assigned JSON documents called polcies These polices define the permissions of the users In AWS you apply the least privilege principle: don`t give more permissions than a user needs #\rIAM Policies inheritance consists of\nVersion : policy language version, always include \u0026ldquo;2012-10-17\u0026rdquo; Id : an identifier for the policy (optional) Statement : one or more individual statements (required) Satements consists of\nSid : an identifier for the statement (optional) Effect : whether the statement aloows or denies access (Allow, Deny) Principal: account/user/role to which this policy applied to Action : list of actions this policy allows or denies Resource : list of resources to which the actions applied to Condition : conditions for when this policy is in effect (optional) #\rIAN Password Policy\nStrong passwords = higher security for your account In AWS, you can setup a password policy: Set a minimum password length Requrire specific character types: including uppercase letters lowercase letters numbers non-alphanumeric charcters Allow all IAM users to change their own passwords Require users to change their password after some time (password expiration) Prevent password rescue MFA\nMFA ( Multi Factor Authentication ) MFA = password you know + security device you own Virtual MFA device google authenticator(phone only), Authy (Multi-device) Universal 2nd Factor (U2F) Security Key #\rTo access AWS AWS Management console / password + MFA AWS Command Line Interface(CLI) / access keys AWS Software Deveploper Kit (SDK) / acccess Keys #\rCloud shell \u0026rsquo;\u0026rsquo;\u0026rsquo; · 미국 동부 (오하이오 주) · 미국 동부 (버지니아 주) · 미국 서부 (오리건 주) · 아시아 태평양 (뭄바이) · 아시아 태평양 (시드니) · 아시아 태평양(도쿄) · 유럽(프랑크푸르트) · 유럽(아일랜드) \u0026rsquo;'' #\r#\rEC2\r#\rOn-Demand Instanceds ( Pay for what you use) : short workload, predictble pricing Reserved ( Up to 75% discount compared to On-demand) : (MINIMUM 1 Year) Reserved Instances : Long workloads Convertible Reserved Instances : long workloads with flexible instances can change the EC2 instance type Up to 54% dicount Scheduled Reserved Instances : example - every Thursday between 3 and 6 pm Spot Insances : short workloads, cheap, can lose instances (less reliable) Can get discount of up to 90% compared to On-demand Instances that you can \u0026ldquo;lose\u0026rdquo; at any point of time if your max price is less than the current spot price Dedicated Hosts : book an entire physical server, control instance placemenet Allocated for your account for a 3-year period reservation More expensive Useful for software that have complicated licensing model (BYOL-Bring Your Own License) Or for companies thay have strong regulatory or compliance needs #\r#\rElastic IP\r#\r#\rcan only have 5 Elastic IP in account (can ask AWS to increase that) "},{"id":63,"href":"/cloud/docs/Azure/MicrosoftAzure/Azure07/","title":"Azure AI","section":"Azure docs","content":"\rAzure AI\r#\r#\r클라우드 컴퓨팅과 관련된 AI는 광범위한 서비스에 기반을 두고 있으며, 그 중 Machine Learning이 핵심입니다. Machine Learning은 컴퓨터에서 기존 데이터를 사용하여 미래 동작, 결과 및 추세를 예측하는 데이터 과학 기술입니다. Machine Learning을 사용하면 컴퓨터에서 명시적으로 프로그래밍하지 않고 학습합니다. #\r#\rAzure Machine Learning\r#\r#\r서비스 기계 학습 모델의 개발, 교육, 테스트, 배포, 관리 및 추적에 사용할 수 있는 클라우드 기반 환경입니다. 모델을 자동으로 생성하여 사용자에 맞게 조정할 수 있습니다. 이를 사용하면 로컬 머신의 학습을 시작한 다음, 클라우드로 확장할 수 있습니다. #\r#\rAzure Machine Learning Studio\r#\r미리 빌드된 기계 학습 알고리즘 및 데이터 처리 모듈을 사용하여 기계 학습 솔루션을 빌드, 테스트, 배포할 수 있는 끌어서 놓기 방식의 시각적 공동 작업 영역 #\r#\rCognitive Services\r#\r#\r밀접한 관련이 있는 제품 세트 #\r#\rVision\r#\r#\r사진과 동영상의 스마트한 식별, 캡션, 인덱싱, 중재를 수행하는 이미지 처리 알고리즘 #\r#\rSpeech\r#\r#\r음성을 텍스트로 변환하거나, 음성을 인증에 사용하거나, 앱에 화자 인식을 추가 #\r#\r지식 매핑\r#\r#\r지능형 추천 및 의미 체계 검색 등의 작업을 해결하기 위해 복잡한 정보와 데이터를 매핑 #\r#\rBing Search\r#\r#\rAdd Bing Search API를 앱에 추가하고 단일 API 호출 기능을 활용하여 수십억 개의 웹 페이지, 이미지, 동영상 및 뉴스를 철저히 검색하는 기능을 활용가능 #\r#\r자연어 처리\r#\r#\r미리 빌드된 스크립트를 사용하여 자연어를 처리하고, 감정을 평가하고, 사용자가 원하는 것을 인식 #\r"},{"id":64,"href":"/cloud/docs/AWS/AWSSAA/SAA-17/","title":"SAA02-기출","section":"AWS SAA 시험정리","content":"\r기출문제\r#\r#\rQ1\r#\r회사는 Amazon S3를 사용하여 기밀 감사 문서를 저장합니다.S3 버킷은 버킷 정책을 사용하여 최소 권한의 원칙에 따라 감사 팀 IAM 사용자 자격 증명에 대한 액세스를 제한합니다.회사 관리자는 S3 버킷에서 실수로 문서를 삭제하는 것에 대해 우려하고 있으며 보다 안전한 솔루션을 원합니다. 솔루션 설계자는 감사 문서를 보호하기 위해 무엇을 해야 합니까?\nA. S3 버킷에서 버전 관리 및 MFA 삭제 기능을 활성화합니다. B. 각 감사 팀 IAM 사용자 계정에 대한 IAM 사용자 자격 증명에서 멀티 팩터 인증 (MFA) 을 활성화합니다. C. 감사 팀의 IAM 사용자 계정에 S3 수명 주기 정책을 추가하여 감사 날짜 동안 S3:DeleteOB|ect 작업을 거부합니다. D. AWS 키 관리 서비스 (AWS KMS\u0026gt;를 사용하여 S3 버킷을 암호화하고 감사 팀 IAM 사용자 계정이 KMS 키에 액세스하지 못하도록 제한합니다. #\rAnswer\r...\rAnswer: A\r#\rQ2\r#\rAWS Trusted Advisor에서 비용 최적화 검사를 검토한 후, 팀은 계정에 30일이 넘은 10,000개의 Amazon Elastic Block Store (Amazon EBS) 스냅샷이 있다는 것을 알게 되었습니다.팀은 자원의 수명주기에 대한 더 나은 거버넌스를 구현해야한다고 판단할 때. 팀이 최소한의 노력으로 EBS 스냅샷의 수명 주기 관리를 자동화하기 위해 어떤 조치를 취해야 합니까?(두 개 선택)\nA. AWS Backup을 사용하여 백업 계획 생성 및 예약 B. EBS 스냅샷을 Amazon S3에 복사한 다음 S3 버킷에 수명 주기 구성을 생성합니다. C. Amazon DLM (데이터 수명 주기 관리자) 사용 D. Amazon EventBridge (Amazon CloudWatch 이벤트) 에서 예약된 이벤트를 사용하고 AWS 스텝 함수를 호출하여 스냅샷을 관리합니다. E. AWS 시스템 관리자에서 백업을 예약하고 실행합니다. #\rAnswer\r...\rAnswer: D E\r#\rQ3\r#\r회사는 적절한 승인 없이 누구도 데이터에 액세스하지 못하도록 AWS 클라우드 배포를 검토하고 있습니다.솔루션 설계자는 열려 있는 모든 Amazon S3 버킷을 식별하고 S3 버킷 구성 변경 사항을 기록해야 합니다.솔루션 설계자는이를 달성하기 위해 무엇을해야합니까?\nA. 적절한 규칙을 사용하여 AWS Config 서비스를 활성화합니다. B. 적절한 검사를 통해 AWS 트러스트 어드바이저를 활성화합니다. C. AWS SDK를 사용하여 버킷 보고서 생성 스크립트 작성 D. Amazon S3 서버 액세스 로깅을 활성화하고 Amazon CloudWatch 이벤트를 구성합니다. #\rAnswer\r...\rAnswer: A\r#\rQ4\r#\r회사는 글로벌 영업 팀에서 사용 빈도가 낮은 액세스 패턴으로 온-프레미스 MySQL 데이터베이스를 보유하고 있습니다.영업 팀은 데이터베이스를 다운타임을 최소화해야 합니다.한 데이터베이스 관리자가 향후 더 많은 사용자를 예상하여 특정 인스턴스 유형을 선택하지 않고 이 데이터베이스를 AWS로 마이그레이션하려고 합니다. 솔루션 설계자가 권장해야 하는 서비스는 무엇입니까?\nA. Amazon Aurora B. MySQL용 Amazon Aurora 서버리스 C. Amazon Redshift 스펙트럼 D. MySQL용 Amazon RDS #\rAnswer\r...\rAnswer: B\r#\rQ5\r#\r회사는 Amazon S3에 백업되는 시간에 민감한 대량의 데이터를 생성하는 온프레미스 애플리케이션을 보유하고 있습니다 .응용 프로그램이 성장하고 인터넷 대역폭 제한에 대한 사용자의 불만이 있습니다.솔루션 설계자는 Amazon S3에 적시에 백업할 수 있고 내부 사용자의 인터넷 연결에 미치는 영향을 최소화하면서 장기 솔루션을 설계해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. VPC 게이트웨이 엔드포인트를 통해 AWS VPN 연결을 설정하고 모든 트래픽을 프록시합니다. B. 새 AWS Direct Connect 연결을 설정하고 이 새 연결을 통해 백업 트래픽을 직접 지정 C. 일일 AWS Snowball 디바이스 주문 데이터를 Snowball 디바이스에 로드하고 디바이스를 AWS로 매일 반환합니다. D. AWS 관리 콘솔을 통해 지원 티켓 제출 계정에서 S3 서비스 제한을 제거하도록 요청하십시오. #\rAnswer\r...\rAnswer: B\r#\rQ6\r#\r솔루션 설계자는 개발자가 AWS 서비스를 사용하여 새로운 전자 상거래 장바구니 애플리케이션을 설계할 수 있도록 지원하고 있습니다.개발자는 현재 데이터베이스 스키마에 대해 확신하지 못하고 전자 상거래 사이트가 증가함에 따라 변경을 기대합니다.이 솔루션은 복원력이 뛰어나고 읽기 및 쓰기 용량을 자동으로 확장할 수 있어야 합니다. 이러한 요구 사항을 충족하는 데이터베이스 솔루션은 무엇입니까?\nA. Amazon Aurora Postgre시SQL B. 온 디맨드로 활성화된 Amazon DynamoDB C. DynamoDB 스트림이 활성화된 Amazon DynamoDB D. Amazon SQS 및 Amazon Aurora Postgre스 SQL #\rAnswer\r...\rAnswer: B\r#\rQ7\r#\r회사는 AWS에서 호스팅되는 비디오 변환 애플리케이션을 개발하고 있습니다.이 애플리케이션은 프리 티어와 유료 티어의 두 가지 계층으로 제공됩니다.유료 계층의 사용자는 먼저 동영상을 변환한 다음 트리 티어 사용자가 동영상을 변환하게 됩니다.이러한 요구 사항을 충족하고 가장 비용 효율적인 솔루션은 무엇입니까?\nA. 유료 티어에 대한 FIFO 대기열 1개 및 프리 티어에 대한 표준 대기열 1개 B. 모든 파일 형식에 대한 단일 FIFO Amazon 단순 대기열 서비스 (Amazon SQS) 대기열 C. 모든 파일 형식에 대한 단일 표준 Amazon SQS (단순 대기열 서비스) 대기열 D. 두 개의 표준 Amazon SQS (Amazon SQS) 대기열 (유료 티어용 대기열, 다른 하나는 프리 티어용입니다. #\rAnswer\r...\rAnswer: D\r#\rQ8\r#\r회사는 us-east-1 리전의 Amazon S3 버킷에서 정적 웹 사이트 콘텐츠를 호스팅합니다.Amazon CloudFront 오리진을 통해 해당 버킷에 대한 교차 리전 복제는 ap-southeast-1 리전에서 버킷의 두 번째 복사본을 생성하도록 설정되어 있습니다.경영진은 웹 사이트에 더 높은 가용성을 제공하는 솔루션을 원합니다.가용성 향상을 위해 솔루션 설계자가 수행해야 하는 작업 조합은 무엇입니까?(두 개를 선택합니다.)\nA. 두 버킷 모두 CloudFront 오리진에 추가 B. Amazon Route 53에 장애 조치 라우팅 구성 C. Amazon Route 53에서 복제본 버킷을 가리키는 레코드 생성 D. ap-southeast-1 버킷을 가리키는 추가 CloudFront 오리진 생성 E. us-east-1 버킷을 기본 버킷으로, ap-southeast-1 버킷을 보조 버킷으로 사용하여 CloudFront 오리진 그룹을 설정합니다. #\rAnswer\r...\rAnswer: D E\r#\rQ9\r#\r회사는 여러 가용 영역 (AZ) 에 여러 프라이빗 서브넷이 있고 AZ 중 하나에 퍼블릭 서브넷이 하나씩 있는 VPC를 만들었습니다.퍼블릭 서브넷은 NAT 게이트웨이를 시작하는 데 사용됩니다.프라이빗 서브넷에는 NAT 게이트웨이를 사용하여 인터넷에 연결하는 인스턴스가 있습니다.AZ 장애가 발생한 경우, 회사는 인스턴스에 인터넷 연결 문제가 전혀 발생하지 않고 백업 계획이 준비되어 있는지 확인하려고 합니다. 솔루션 설계자가 가장 높은 가용성을 권장해야하는 솔루션은 무엇입니까?\nA. 동일한 AZ에 NAT 게이트웨이가 있는 새 퍼블릭 서브넷 만들기 두 NAT 게이트웨이 간에 트래픽 분산 B. 현재 퍼블릭 서브넷에 Amazon EC2 NAT 인스턴스 생성 NAT 게이트웨이와 NAT 인스턴스 간에 트래픽 배포 C. 퍼블릭 서브넷 만들기 각 AZ에서 각 서브넷에서 NAT 게이트웨이 시작 프라이빗 서브넷에서 각 A2에서 해당 NAT 게이트웨이로의 트래픽 구성 D. 동일한 퍼블릭 서브넷에 Amazon EC2 NAT 인스턴스 생성 NAT 게이트웨이를 NAT 인스턴스로 바꾸고 적절한 조정 정책이 있는 Auto Scaling 그룹과 인스턴스를 연결합니다. #\rAnswer\r...\rAnswer: C\r#\rQ10\r#\r회사는 정보를 읽고 데이터베이스에 쓰는 새로운 애플리케이션을 AWS에 배포할 계획입니다.이 회사는 두 개의 서로 다른 AWS 지역에 애플리케이션을 배포하고 각 애플리케이션이 해당 지역의 데이터베이스에 쓰기를 원합니다.두 지역의 데이터베이스는 이러한 요구 사항을 충족하기 위해 사용해야하는 데이터를 동기화 상태로 유지해야합니다.\nA. Amazon S3 교차 리전 복제와 함께 Amazon Athena 사용 B. 각 리전의 MySQL용 RDS 클러스터 간 변경 데이터 캡처와 함께 AWS 데이터베이스 마이그레이션 서비스 (AWS DMS) 를 사용합니다. C. 글로벌 테이블과 함께 Amazon DynamoDB 사용 D. 리전 간 읽기 전용 복제본과 함께 PostgreSQL용 Amazon RDS 사용 #\rAnswer\r...\rAnswer: C\r#\rQ11\r#\r회사는 Auto Scaling 그룹의 애플리케이션 로드 밸런서 (ALB) 뒤에 Amazon EC2 인스턴스에서 전자 상거래 웹 사이트를 운영하고 있습니다.사이트에 관련 된 성능 문제가 발생 하는 IP 주소가 변경되는 불법 외부 시스템에서 높은 요청 속도보안 팀은 웹 사이트에 대한 잠재적 인 DDoS 공격에 대해 걱정하고 있습니다. 회사는 합법적인 사용자에게 최소한의 영향을 미치는 방식으로 불법 들어오는 요청을 차단해야 합니다 솔루션 설계자는 무엇을 권장합니까?\nA. Amazon 검사기를 배포하고 ALB와 연결합니다. B. AWS WAF를 배포하고 이를 cthe ALB와 연결하고 속도 제한 규칙을 구성합니다. C. ALB와 연결된 네트워크 ACL에 규칙을 배포하여 들어오는 트래픽을 차단합니다. D. GuardDuty 구성 시 Amazon GuardDuty 배포 및 속도 제한 보호 활성화 #\rAnswer\r...\rAnswer: B\r#\rQ12\r#\r회사가 프라이빗 서브넷의 Amazon EC2 인스턴스에서 실행되는 애플리케이션을 보유하고 있습니다.애플리케이션은 Amazon S3에 데이터를 저장하고 검색해야 합니다. 비용을 줄이기 위해 회사는 비용 효율적인 방식으로 AWS 리소스를 구성하려고 합니다. 회사는 어떻게 이것을 달성해야합니까?\nA. S3 버킷에 액세스하기 위해 NAT 게이트웨이를 배포합니다. B. S3 버킷에 액세스하기 위한 AWS 스토리지 게이트웨이 배포 C. S3 게이트웨이 엔드포인트를 배포하여 S3 버킷에 액세스합니다. D. S3 인터페이스 엔드 포인트를 배포하여 S3 버킷에 액세스합니다. #\rAnswer\r...\rAnswer: C\r#\rQ13\r#\r솔루션 설계자가 다중 서브넷 VPC 아키텍처를 개발하고 있습니다.이 솔루션은 두 개의 가용 영역에 있는 6개의 서브넷으로 구성됩니다.서브넷은 퍼블릭, 프라이빗 및 데이터베이스 전용으로 정의됩니다. 프라이빗 서브넷에서 실행되는 Amazon EC2 인스턴스만 데이터베이스에 액세스할 수 있어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 퍼블릭 서브넷의 CIDR 블록에 대한 경로를 제외하는 지금 라우팅 테이블을 생성합니다. 라우팅 테이블을 데이터베이스 서브넷에 연결합니다. B. 퍼블릭 서브넷의 인스턴스가 사용하는 보안 그룹으로부터의 수신을 거부하는 보안 그룹 생성 보안 그룹을 Amazon RDS DB 인스턴스에 연결 C. 프라이빗 서브넷의 인스턴스가 사용하는 보안 그룹으로부터의 수신을 허용하는 보안 그룹을 생성합니다.보안 그룹을 Amazon RDS DB 인스턴스에 연결합니다. D. 퍼블릭 서브넷과 프라이빗 서브넷 간에 새 피어링 연결을 만듭니다.프라이빗 서브넷과 데이터베이스 서브넷 간에 다른 피어링 연결을 생성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ14\r#\r회사가 온프레미스 Windows 서버에서 실행되는 Microsoft NET 애플리케이션을 보유하고 있습니다. 애플리케이션은 Oracle 데이터베이스 스탠다드 에디션 서버를 사용하여 데이터를 저장합니다. 이 회사는 AWS로의 마이그레이션을 계획하고 있으며 애플리케이션을 이동하는 동안 개발 변경을 최소화하고자 합니다.AWS 애플리케이션 환경은 가용성이 높아야 합니다. 이러한 요구 사항을 충족하기 위해 회사는 어떤 조치를 취해야 합니까?(두 개 선택)\nA. NET Core를 실행하는 AWS Lambda 함수를 사용하여 서버를 사용하지 않는 애플리케이션을 리팩터링 B. 다중 AZ 배포에서 NET 플랫폼을 사용하여 AWS Elastic Beanstalk에서 애플리케이션 호스트 변경 C. Amazon Linux Amazon 머신 이미지 (AMI) 를 사용하여 Amazon EC2에서 실행되도록 애플리케이션을 재플랫폼합니다. D. 다중 AZ 배포에서 AWS 데이터베이스 마이그레이션 서비스 (AWS DMS) 를 사용하여 Oracle 데이터베이스에서 Amazon DynamoDB로 마이그레이션 E. 다중 AZ 배포에서 AWS 데이터베이스 마이그레이션 서비스 (AWS DMS) 를 사용하여 Oracle 데이터베이스에서 Amazon RDS의 Oracle로 마이그레이션합니다. #\rAnswer\r...\rAnswer: B E\r#\rQ15\r#\r회사가 애플리케이션 로드 밸런서 뒤에 있는 Amazon CC2 인스턴스에서 웹 서비스를 실행합니다. Amazon EC2 Auto Scaling 그룹에서 실행되는 인스턴스는 비용을 낮추면서 필요한 서비스 수준 계약 (SLA) 을 충족하기 위해 회사의 모든 가용 영역에서 최소 투어 인스턴스가 필요합니다.가용 영역이 뒤틀리는 경우 회사는 어떻게 SLA를 준수할 수 있습니까?\nA. 휴지 기간이 짧은 대상 추적 조정 정책 추가 B. 더 큰 인스턴스 유형을 사용하도록 Auto Scaling 그룹 시작 구성을 변경합니다. C. 세 개의 가용 영역에서 6개의 서버를 사용하도록 Auto Scaling 그룹 변경 D. 두 가용 영역에서 8개의 서버를 사용하도록 Auto Scaling 그룹 변경 #\rAnswer\r...\rAnswer: C\r#\rQ16\r#\r회사에서 Amazon S3 버킷에 있는 모든 버전의 객체를 보존해야 합니다. 현재 객체 버전은 처음 30일 동안 자주 액세스되며, 그 이후에는 거의 액세스되지 않으며 5분 이내에 검색할 수 있어야 합니다. 이전 객체 버전은 영원히 유지되어야 하며, 거의액세스 할 수 있으며 1 주 이내에 검색 할 수 있습니다.모든 스토리지 솔루션은 가용성과 내구성이 뛰어나야 함 가장 경제적인 방식으로 이러한 요구 사항을 충족하려면 솔루션 설계자가 권장해야 하는 것은 무엇입니까?\nA. 30일 후에 S3 표준 스토리지에서 S3 Glacier로 현재 객체 버전을 이동하고 1일 후에 이전 객체 버전을 S3 Glacier로 이동하는 버킷에 대한 S3 수명 주기 정책을 생성합니다. B. 30일 후에 S3 표준 스토리지에서 S3 Glacier로 현재 객체 버전을 이동하고 1일 후 이전 객체 버전을 S3 Glacier Deep Archive로 이동하는 버킷에 대한 S3 수명 주기 정책을 생성합니다. C. 30일 후 현재 객체 버전을 S3 표준 스토리지에서 S3 Standard-infrequent Access (S3 Standardd-IA) 로 이동하고 1일 후 이전 객체 버전을 S3 Glacier Deep Archive로 이동하는 버킷에 대한 S3 수명 주기 정책을 생성합니다. D. 30일 후 현재 객체 버전을 S3 표준 스토리지에서 S3 1영역 자주 사용되지 않는 액세스 (S3 원 영역-IA) 로 이동하고 1일 후 이전 객체 버전을 S3 Glacier Deep Archive로 이동하는 버킷에 대한 S3 수명 주기 정책을 생성하고, #\rAnswer\r...\rAnswer: A\r#\rQ17\r#\r회사는 AWS로 마이그레이션하려는 두 개의 애플리케이션을 보유하고 있습니다.두 응용 프로그램 모두 동일한 파일에 동시에 액세스하여 많은 파일 집합을 처리합니다.두 응용 프로그램 모두 짧은 대기 시간으로 파일을 읽어야합니다.이 상황에 대해 솔루션 설계자가 권장해야하는 아키텍처는 무엇입니까?\nA. 애플리케이션을 실행하도록 두 개의 AWS Lambda 함수를 구성합니다.인스턴스 스토어 볼륨이 있는 Amazon EC2 인스턴스를 생성하여 데이터를 저장합니다. B. 애플리케이션을 실행하도록 두 개의 AWS Lambda 함수를 구성합니다.Amazon EBS (Elastic Block Store) 볼륨이 있는 Amazon EC2 인스턴스를 생성하여 데이터를 저장합니다. C. 두 애플리케이션을 동시에 실행하도록 메모리 최적화 Amazon EC2 인스턴스 하나를 구성합니다. 프로비저닝된 IOPS를 사용하여 Amazon EBS (Elastic Block Store) 볼륨을 생성하여 데이터를 저장합니다. D. 두 애플리케이션을 모두 실행하도록 두 Amazon EC2 인스턴스를 구성합니다.Amazon EFS (Elastic File System) 를 범용 성능 모드와 버스트 처리량 모드로 구성하여 데이터를 저장합니다. #\rAnswer\r...\rAnswer: D\r#\rQ18\r#\r한 솔루션 설계자는 여러 가용 영역에 배포되는 웹 애플리케이션용 공유 스토리지 솔루션을 설계하고 있습니다.웹 애플리케이션은 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행됩니다. 이 회사는 컨텐츠를 자주 변경할 것으로 예상하므로 솔루션의 일관성이 강해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 웹 콘텐츠를 저장할 Amazon S3 버킷을 생성합니다. Amazon CloudFront를 사용하여 콘텐츠를 전송합니다. B. Amazon EFS (Elastic 파일 시스템) 파일 시스템을 생성하여 개별 EC2 인스턴스에 마운트합니다. C. 공유 Amazon Elastic Block Store (Amazon EBS) 볼륨을 생성하고 이를 개별 EC2 인스턴스에 마운트합니다. D. AWS DataSync를 사용하여 Auto Scaling 그룹의 EC2 호스트 간에 데이터를 지속적으로 동기화할 수 있습니다. #\rAnswer\r...\rAnswer: B\r#\rQ19\r#\r솔루션 설계자는 지사에 있는 네트워크 연결 파일 시스템에서 Amazon S3 Glacier로 750TB의 데이터를 전송하는 임무를 맡습니다. 이 솔루션은 지사의 낮은 대역폭 인터넷 연결이 포화되는 것을 방지해야 합니다. 가장 비용 효율적인 솔루션이란 무엇입니까?\nA. Amazon S3 버킷에 대한 사이트 간 VPN 터널을 생성하고 파일을 직접 전송 VPC 엔드포인트를 적용하기 위한 버킷 정책 생성 B. 10 AWS Snowball 어플라이언스를 주문하고 S3 Glacier 저장소를 대상으로 선택 VPC 엔드포인트를 적용하기 위한 버킷 정책 생성 C. 네트워크 연결 파일 시스템을 Amazon S3에 마운트하고 파일을 직접 복사합니다.S3 객체를 Amazon S3 Glacier로 이전하는 수명 주기 정책 생성 D. 10개의 AWS Snowball 어플라이언스를 주문하고 Amazon S3 버킷을 대상으로 선택합니다.S3 객체를 Amazon S3 Glacier로 이전하는 수명 주기 정책 생성 #\rAnswer\r...\rAnswer: D\r#\rQ20\r#\r회사는 백엔드 프로세서로 점수 업데이트를 스트리밍한 다음 결과를 리더보드에 게시하는 모바일 게임을 개발 중입니다.솔루션 설계자는 대규모 트래픽 급증을 처리하고, 모바일 게임 업데이트를 수신 순서대로 처리하며, 처리된 업데이트를 고가용성 데이터베이스에 저장할 수 있는 솔루션을 설계해야 합니다.또한 솔루션을 유지 관리하는 데 필요한 관리 부담을 최소화하려고 합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?\nA. Amazon Kinesis 데이터 스트림에 대한 푸시 점수 업데이트AWS Lambda를 사용하여 Kinesis 데이터 스트림의 업데이트를 처리합니다.처리된 업데이트를 Amazon DynamoDB에 저장합니다. B. Amazon Kinesis 데이터 스트림에 대한 점수 업데이트 푸시Auto Scaling을 위해 설정된 Amazon EC2 인스턴스 집합으로 업데이트를 처리합니다.처리된 업데이트를 Amazon Redshifl에 저장합니다. C. Amazon SNS (단순 알림 서비스) 주제에 대한 푸시 점수 업데이트SNS 주제에 AWS Lambda 함수를 구독하여 업데이트를 처리합니다.처리된 업데이트를 Amazon EC2에서 실행 중인 SOL 데이터베이스에 저장합니다. D. Amazon SOS (단순 대기열 서비스) 대기열에 대한 점수 업데이트 푸시 Auto Scaling과 함께 Amazon EC2 인스턴스 집합을 사용하여 SQS 대기열의 업데이트를 처리합니다.처리된 업데이트를 Amazon RDS 다중 AZ DB 인스턴스에 저장합니다. #\rAnswer\r...\rAnswer: A\r#\rQ21\r#\r회사는 온-프레미스 SQL 데이터베이스에 데이터를 저장하는 전자 상거래 응용 프로그램을 보유하고 있습니다.이 회사는 이 데이터베이스를 AWS로 마이그레이션하기로 결정했습니다.그러나 마이그레이션의 일환으로 이 회사는 일반적인 읽기 요청에 대해 밀리초 미만의 응답을 얻을 수 있는 방법을 찾고자 합니다.솔루션 설계자는 속도 증가가 가장 중요합니다. 데이터베이스 읽기에서 반환되는 부실 데이터의 비율이 적다는 것을 알고 있습니다. 솔루션 설계자는 무엇을 권장해야합니까?\nA. Amazon RDS 읽기 전용 복제본을 구축합니다. B. 데이터베이스를 더 큰 인스턴스 유형으로 빌드합니다. C. Amazon ElastiCache를 사용하여 데이터베이스 캐시 구축 D. Amazon ES (Elastic 검색 서비스) 를 사용하여 데이터베이스 캐시 구축 #\rAnswer\r...\rAnswer: C\r#\rQ22\r#\r회사는 인공 지능 및 기계 학습 연구를 수행하는 고객에게 데이터 세트를 판매합니다 (AIMU. 데이터 세트는 US-easl-1 리전의 Amazon S3 버킷에 저장되는 대용량 형식의 파일입니다.이 회사는 고객이 특정 데이터 세트에 대한 액세스 권한을 구매하는 데 사용하는 웹 애플리케이션을 호스팅합니다.웹 애플리케이션은 애플리케이션 로드 밸런서 뒤의 변이하는 Amazon EC2 인스턴스에 배포됩니다. 구매 후 고객은 파일에 액세스할 수 있는 S3 서명된 URL을 받게 됩니다.고객은 북미와 유럽에 분산되어 있습니다.이 회사는 데이터 전송과 관련된 비용을 절감하고자 하며 성능을 유지하거나 개선하고자 하는 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떻게 해야 합니까?\nA. 기존 S3 버킷에 S3 Transfer Acceleration기 구성 고객 요청을 S3 Transfer Acceleration화 엔드 포인트로 직접 S3 서명된 URL을 계속 사용하여 액세스 제어 B. 기존 S3 버킷을 오리진으로 사용하여 Amazon CloudFront 배포 고객이 CloudFront URL로 요청하여 액세스 제어를 위해 CloudFront 서명된 URL로 전환 C. 라이트 Ducket 간 S3 교차 리전 복제를 사용하여 eu-centtal-1 리전에서 두 번째 S3 Ducket 설정 고객 요청을 가장 가까운 리전으로 전달합니다.액세스 제어를 위해 S3 서명된 URL을 계속 사용합니다. D. 데이터 집합 및 사용자 스트리밍을 사용하도록 웹 애플리케이션을 수정하여 기존 S3 버킷에서 데이터를 읽도록 웹 애플리케이션을 구성하여 애플리케이션에서 직접 액세스 제어를 구현합니다. #\rAnswer\r...\rAnswer: B\r#\rQ23\r#\r회사는 컨테이너에 애플리케이션을 구축하고 있습니다.이 회사는 사내 개발 및 운영 서비스를 온프레미스 데이터 센터에서 AWS로 마이그레이션하려고 합니다.관리 부서에서는 프로덕션 시스템이 클라우드에 종속되지 않아야 하며 프로덕션 시스템 전체에서 동일한 구성 및 관리자 도구를 사용해야 한다고 말합니다.솔루션 설계자는 오픈 소스 소프트웨어를 정렬할 관리형 솔루션을 설계해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. EC2 인스턴스 작업자 노드를 사용하여 Amazon EC2에서 컨테이너를 시작합니다. B. Amazon Elastic Kubernetes 서비스 (Amazon EKS) 및 EKS 워커 노드에서 컨테이너를 시작합니다. C. AWS Fargate 인스턴스로 Amazon Elastic 컨테이너 서비스 (Amazon ECS) 에서 컨테이너를 시작합니다. D. Amazon EC2 인스턴스 작업자 노드를 사용하여 Amazon EC (탄력적 컨테이너 서비스) 에서 컨테이너를 시작합니다. #\rAnswer\r...\rAnswer: B\r#\rQ24\r#\r회사는 컨텐츠 관리 시스템을 서버 웹 애플리케이션을 구축하고 있습니다.콘텐츠 관리 시스템은 애플리케이션 로드 밸런서 (ALB) 뒤에 있는 Amazon EC2 인스턴스에서 실행됩니다.EC2 인스턴스는 가용 영역 전체에서 Auto Scaling 그룹에서 실행됩니다.사용자는 컨텐츠 관리 시스템에서 파일, 블로그 및 기타 웹 사이트 자산을 지속적으로 추가 및 업데이트하고 있습니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. Auto Scaling 그룹 수명 주기 정책에서 EC2 사용자 데이터를 업데이트하여 가장 최근에 시작된 EC2 인스턴스에서 웹 사이트 자산을 복사합니다.최신 EC2 인스턴스에서만 웹 사이트 자산을 변경하도록 ALB를 구성합니다. B. 웹 사이트 자산을 Amazon EFS (Elastic 파일 시스템) Me 시스템에 복사 EFS m 시스템을 로컬로 마운트하도록 각 EC2 인스턴스를 구성합니다.EFS 파일 시스템에 저장된 웹 사이트 자산을 참조하도록 웹 사이트 호스팅 응용 프로그램을 구성합니다. C. 웹 사이트 자산을 Amazon S3 버킷에 복사 각 EC2 인스턴스가 S3 버킷에서 연결된 Amazon EBS (Amazon Basic 블록 스토어) 볼륨으로 웹 사이트 자산을 다운로드하는지 확인합니다.파일을 최신 상태로 유지하려면 매시간에 한 번씩 S3 sync 명령을 실행합니다. D. 웹 사이트 자산과 함께 Amazon Elastic Block Store (Amazon EBS) 스냅샷을 복원합니다.새 EBS EC2 인스턴스가 시작될 때 EBS 스냅샷을 보조 EBS 볼륨으로 연결합니다.보조 EBS 볼륨에 저장된 웹 사이트 자산을 참조하도록 웹 사이트 호스팅 애플리케이션을 구성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ25\r#\r회사가 관계형 데이터베이스를 실행하는 온프레미스 서버를 보유하고 있습니다. 현재 데이터베이스는 여러 위치에 있는 사용자에게 높은 읽기 트래픽을 제공합니다. 회사는 최소한의 노력으로 AWS로 마이그레이션하려고 합니다. 데이터베이스 솔루션은 재해 복구를 지원해야 하며 회사의 현재트래픽 흐름입니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. Amazon RDS에서 다중 AZ와 하나 이상의 읽기 전용 복제본이 있는 데이터베이스 사용 B. Amazon RDS에서 다중 AZ 및 예비 복제본이 하나 이상 있는 데이터베이스 사용 C. 서로 다른 AWS 리전의 여러 Amazon EC2 인스턴스에서 호스팅되는 데이터베이스 사용 D. Amazon EC2 인스턴스에서 호스팅되는 데이터베이스를 다른 가용 영역의 애플리케이션 로드 밸런서 뒤에 사용합니다. #\rAnswer\r...\rAnswer: A\r#\rQ26\r#\r한 회사는 두 개의 프라이빗 서브넷에서 Amazon EC2 인스턴스에서 호스팅되는 애플리케이션을 보유하고 있습니다.솔루션 설계자는 최소한의 관리 노력으로 공용 인터넷에서 응용 프로그램을 사용할 수 있도록해야합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. 로드 밸런서를 생성하고 프라이빗 인스턴스와 동일한 가용 영역에서 두 개의 퍼블릭 서브넷을 연결합니다.로드 밸런서에 프라이빗 인스턴스를 추가합니다. B. 로드 밸런서를 생성하고 프라이빗 인스턴스와 동일한 가용 영역에서 두 개의 프라이빗 서브넷을 연결합니다.로드 밸런서에 프라이빗 인스턴스를 추가합니다. C. 프라이빗 서브넷에 있는 인스턴스의 Amazon 머신 이미지 (AMI) 생성 및 복원 퍼블릭 서브넷에서 로드 밸런서를 생성하고 퍼블릭 인스턴스와 동일한 가용 영역에서 두 개의 퍼블릭 서브넷을 연결합니다. D. 프라이빗 서브넷에 있는 인스턴스의 Amazon 머신 이미지 (AMI) 를 생성하고 퍼블릭 서브넷에서 복원합니다.로드 밸런서를 생성하고 퍼블릭 인스턴스와 동일한 가용 영역에서 두 개의 프라이빗 서브넷을 연결합니다. #\rAnswer\r...\rAnswer: A\r#\rQ27\r#\r회사는 응용 프로그램 매트가 상점에 마케팅 서비스를 제공하고있다.이 서비스는 매장 고객의 이전 구매를 기반으로 합니다.상점은 SFTP를 통해 회사에 거래 데이터를 업로드, 데이터는 처리 및 새로운 마케팅을 생성하기 위해 분석 파일 중 일부는 200GB 크기를 초과 할 수 있습니다.. 최근, 이 회사는 매장 중 일부는 개인 식별 정보가 포함 된 파일을 업로드 한 것을 발견 (PII) 매트는 포함되지 않아야.회사는 Pl을 다시 공유하면 관리자에게 알림을 받기를 원합니다. 또한 이 회사는 문제 해결을 자동화하려고 합니다.솔루션 설계자는 LEAS F 개발 노력으로 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?\nA. Amazon S3 버킷을 보안 전송 지점으로 사용 Amazon 검사기를 사용하여 버킷의 객체를 스캔합니다.객체에 Pl이 포함된 경우 S3 수명 주기 정책을 트리거하여 Pl이 포함된 객체를 제거합니다. B. Amazon S3 버킷을 보안 전송 지점으로 사용합니다.Amazon Macie를 사용하여 버킷의 객체를 스캔합니다. 객체에 Pl이 포함된 경우 Amazon SNS (단순 알림 서비스) 를 사용하여 관리자에게 Pl이 포함된 객체를 제거하라는 알림을 트리거합니다. C. AWS Lambda 함수에서 사용자 지정 스캐닝 알고리즘을 구현합니다.객체가 버킷에 로드될 때 함수를 트리거합니다.객체에 PLL이 포함된 경우 Amazon SNS (단순 알림 서비스) 를 사용하여 관리자에게 PII가 포함된 객체를 제거하도록 알림을 트리거합니다. D. AWS Lambda 함수에서 사용자 지정 스캐닝 알고리즘을 구현합니다.객체가 버킷에 로드될 때 함수를 트리거합니다.객체에 Pl이 포함된 경우 Amazon SES (단순 이메일 서비스) 를 사용하여 관리자에게 알림을 트리거하고 S3 수명 주기 정책을 트리거하여 Pl이 포함된 객체를 제거합니다. #\rAnswer\r...\rAnswer: A\r#\rQ28\r#\r솔루션 설계자는 개인 식별 정보 (Pll) 를 Amazon S3 버킷에 저장하는 시스템을 설계하고 있습니다.규정 준수 및 규제 요구 사항으로 인해 마스터 키와 암호화되지 않은 데이터는 모두 AWS로 전송해서는 안 됩니다. 설계자가 선택해야 하는 Amazon S3 암호화 기술은 무엇입니까?\nA. AWS 키 관리 서비스 {AWS KMS) 관리형 고객 마스터 키 (CMK) 를 사용한 Amazon S3 클라이언트 측 암호화 B. AWS KMS 관리형 암호화 키를 사용한 Amazon S3 서버 측 암호화 (SSE-KMS) C. 클라이언트 측 마스터 키를 사용한 Amazon S3 클라이언트 측 암호화 D. 고객이 제공한 암호화 키 (SSE-C) 를 사용한 Amazon S3 서버 측 암호화 #\rAnswer\r...\rAnswer: C\r#\rQ29\r#\rAmazon EC2 인스턴스에 호스팅되는 회사의 웹 사이트는 Amazon S3에 저장된 분류된 데이터를 처리합니다. 보안 문제로 인해 회사는 EC2 리소스와 Amazon S3 간에 사설 보안 연결이 필요합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. VPC 엔드포인트에서 액세스를 허용하도록 S3 버킷 정책을 설정합니다. B. S3 버킷에 대한 읽기/쓰기 액세스 권한을 부여하는 IAM 정책을 설정합니다. C. 프라이빗 서브넷 외부의 리소스에 액세스하도록 NAT 게이트웨이를 설정합니다. D. S3 버킷에 액세스하기 위한 액세스 키 ID 및 보안 액세스 키 설정 #\rAnswer\r...\rAnswer: A\r#\rQ30\r#\r회사는 디렉터리 서비스 및 DNS를 포함한 핵심 네트워크 서비스를 온프레미스 데이터 센터에 호스팅합니다.데이터 센터는 AWS Direct Connect (DX) 를 사용하여 AWS 클라우드에 연결됩니다. 이러한 네트워크 서비스에 대한 빠르고 비용 효율적이며 일관된 액세스가 필요한 추가 AWS 계정이 계획되어 있습니다.오버 헤드?\nA. 각 새 계정에 DX 연결 만들기 네트워크 트래픽을 온-프레미스 서버로 라우팅 B. DX VPC에서 필요한 모든 서비스에 대해 VPC 엔드 포인트 구성 네트워크 트래픽을 온 프레미스 서버로 라우팅합니다. C. 각각의 새 계정과 DX VPC 간에 VPN 연결을 만들고 네트워크 트래픽을 온프레미스 서버로 라우팅 D. 계정 간 AWS 전송 게이트웨이 구성 전송 게이트웨이에 DX를 할당하고 네트워크 트래픽을 온 프레미스 서버로 라우팅 #\rAnswer\r...\rAnswer: D\r#\rQ31\r#\rVPC-A의 Amazon EC2 인스턴스에서 실행되는 애플리케이션은 다른 VPC-B에서 EC2 인스턴스를 생성합니다.둘 다 분리되어 있습니다.AWS 계정네트워크 관리자는 VPC-A에서 VOC-B의 EC2 인스턴스에 안전하게 액세스할 수 있는 솔루션을 설계해야 합니다.접속 시 단일 장애 지점 또는 대역폭 문제가 발생하지 않아야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. VPC-A와 VPC-B 간에 VPC 피어링 연결을 설정합니다. B. VPC-B에서 실행 중인 EC2 인스턴스에 대해 VPC 게이트웨이 엔드포인트를 설정합니다. C. VPC-B에 가상 프라이빗 게이트웨이를 연결하고 VPC-A에서 라우팅을 활성화합니다. D. VPC-B에서 실행 중인 EC2 인스턴스에 대한 프라이빗 가상 인터페이스 (VIF) 를 생성하고 VPC-B에서 적절한 경로를 추가합니다. #\rAnswer\r...\rAnswer: A\r#\rQ32\r#\r회사에서 비즈니스 크리티컬 데이터 세트를 Amazon S3로 마이그레이션할 계획입니다.현재 솔루션 설계에서는 us-east-1 리전의 단일 S3 버킷을 사용하여 데이터 세트를 저장할 수 있습니다.이 회사의 재해 복구 정책에는 모든 데이터가 여러 AWS 리전이라고 명시되어 있습니다.솔루션 설계자는 S3 솔루션을 어떻게 설계해야합니까?\nA. 다른 리전에 S3 버킷을 추가로 생성하고 교차 리전 복제를 구성합니다. B. 다른 리전에서 S3 버킷을 추가로 생성하고 CORS (원본 간 리소스 공유) 를 구성합니다. C. 다른 리전에서 버전 관리를 사용하여 추가 S3 버킷을 생성하고 교차 리전 복제를 구성합니다. D. 다른 리전에서 버전 관리를 사용하여 추가 S3 버킷을 생성하고 CORS (교차 원본 리소스) 를 구성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ33\r#\r솔루션 설계자는 2 단계 주문 프로세스를위한 응용 프로그램을 설계하고 있습니다. 첫 번째 단계는 동기식이며 약간의 대기 시간으로 사용자에게 반환해야합니다. 두 번째 단계는 더 오래 걸리므로 별도의 구성 요소로 구현됩니다 주문은 정확히 한 번 처리해야하며 순서대로 처리해야합니다솔루션 설계자는 이러한 구성 요소를 어떻게 통합해야합니까?\nA. Amazon SQS FIFO 대기열 사용 B. Amazon SQS 표준 대기열과 함께 AWS Lambda 함수 사용 C. SNS 주제를 생성하고 해당 주제에 대한 Amazon SQS FIFO 대기열을 구독합니다. D. SNS 주제를 생성하고 해당 주제에 대한 Amazon SQS 표준 대기열을 구독합니다. #\rAnswer\r...\rAnswer: A\r#\rQ34\r#\r솔루션 설계자가 다음 IAM 정책을 구성했습니다. 어떤 작업이 정책에 의해 허용됩니까?\nA. AWS Lambda 함수는 모든 네트워크에서 삭제할 수 있습니다. B. AWS Lambda 함수는 모든 네트워크에서 생성할 수 있습니다. C. AWS Lambda 함수는 100.220.0.0/20 네트워크에서 삭제할 수 있습니다. D. 220 100.16.0/20 네트워크에서 AWS Lambda 함수를 삭제할 수 있습니다. #\rAnswer\r...\rAnswer: C\r#\rQ35\r#\r회사는 수 테라바이트의 데이터를 AWS로 전송할 계획입니다.데이터는 선박에서 오프라인으로 수집됩니다. 이 회사는 데이터를 전송하기 전에 복잡한 변환을 실행하려고 합니다.솔루션 설계자가 이 마이그레이션을 위해 권장해야 하는 AWS 서비스는 무엇입니까?\nA. AWS Snowball B. AWS Snowmobile C. AWS Snowball Edge 스토리지 최적화 D. AWS Snowball Edge 컴퓨팅 최적화 #\rAnswer\r...\rAnswer: D\r#\rQ36\r#\r솔루션 설계자는 엔지니어링 도면을 돌고 보는 데 사용되는 새로운 웹 애플리케이션을 위한 스토리지 아키텍처를 설계하고 있습니다.모든 애플리케이션 구성 요소는 AWS 인프라에 배포됩니다. 응용 프로그램 설계에서는 사용자가 엔지니어링 도면이 로드될 때까지 기다리는 시간을 최소화하기 위해 캐싱을 지원해야 합니다.응용 프로그램은 페타바이트의 데이터를 저장할 수 있어야 합니다.솔루션 설계자는 어떤 스토리지 및 캐싱 조합을 사용해야 합니까?\nA. Amazon CloudFront가 있는 Amazon S3 B. Amazon S3 Glacier와 Amazon ElastiCache C. Amazon CloudFront를 사용하는 Amazon Elastic Block Store (Amazon EBS) 볼륨 D. Amazon ElastiCache 기반 AWS 스토리지 게이트웨이 #\rAnswer\r...\rAnswer: A\r#\rQ37\r#\r회사는 현재 250TB의 백업 파일을 공급업체의 독점 형식으로 Amazon S3에 저장하고 있습니다.공급업체에서 제공하는 Linux 기반 소프트웨어 애플리케이션을 사용하여 Amazon S3에서 파일을 검색하고, 파일을 업계 표준 형식으로 변환한 다음, Amazon S3에 다시 업로드하려고 합니다.회사는 이 대화와 관련된 데이터 전송 요금을 최소화하려고 합니다. 이를 달성하기 위해 솔루션 설계자는 무엇을해야합니까?\nA. 변환 소프트웨어를 Amazon S3 배치 작업으로 설치하면 Amazon S3에서 벗어나지 않고 데이터가 변환됩니다. B. 온-프레미스 가상 컴퓨터에 변환 소프트웨어를 설치합니다.변환을 수행하고 가상 시스템에서 Amazon S3로 파일을 다시 업로드합니다. C. AWS Snowball Edge 디바이스를 사용하여 데이터를 전문가로 처리하고 변환 소프트웨어를 디바이스에 설치합니다. 데이터 변환을 수행하고 Snowball 디바이스에서 Amazon S3에 파일을 다시 업로드합니다. D. Amazon S3와 동일한 리전에서 Amazon EC2 인스턴스를 시작하고 변환 소프트웨어를 인스턴스에 설치합니다.변환을 수행하고 EC2 인스턴스에서 Amazon S3로 파일을 다시 업로드합니다. #\rAnswer\r...\rAnswer: D\r#\rQ38\r#\r웹 애플리케이션을 개발하는 회사는 여러 지역에서 수백 개의 ALB (애플리케이션 로드 밸런서) 를 출시했습니다.회사는 허용 목록 (또는 방화벽 장치에 있는 모든 로드 밸런서의 IP) 을 만들려고 합니다.솔루션 설계자는 이 요청을 처리할 수 있는 일회성 고가용성 솔루션을 찾고 있으며, 이는 방화벽에서 허용해야 하는 IP 수를 줄이는 데도 도움이 됩니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 권장해야합니까?\nA. 다른 리전의 모든 ALB에 대한 IP를 추적하기 위해 AWS Lambda 함수를 생성합니다. 이 목록을 새로 고치십시오. B. 탄력적 IP를 사용하여 NLB (네트워크 부하 분산 장치) 를 설정합니다.모든 ALB의 프라이빗 IP를 이 NLB의 대상으로 등록합니다. C. AWS Global Accelerator를 시작하고 모든 리전에 대한 엔드포인트를 생성합니다.다른 지역에있는 모든 ALB를 해당 엔드 포인트에 등록하십시오. D. Amazon EC2 인스턴스를 설정하고, 이 EC2 인스턴스에 탄력적 IP를 할당하고, 모든 ALB로 트래픽을 전달하는 프록시로 인스턴스를 구성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ39\r#\r전자 상거래 회사는 AWS에서 멀티 티어 애플리케이션을 실행하고 있습니다.프런트 엔드 및 백엔드 계층은 모두 Amazon EC2에서 실행되며 데이터베이스는 MySQL용 Amazon RDS에서 실행됩니다.백엔드 계층은 RDS 인스턴스와 통신합니다.성능 저하를 일으키는 데이터베이스에서 동일한 데이터 세트를 반환하는 호출이 자주 발생합니다.백엔드의 성능을 향상시키기 위해 어떤 조치를 취해야 합니까?\nA. Amazon SNS를 구현하여 데이터베이스 호출을 저장합니다. B. Amazon ElastiCache를 구현하여 대규모 데이터 세트를 캐시합니다. C. MySQL용 RDS를 구현하여 데이터베이스 호출을 캐시합니다. D. Amazon Kinesis Data Firehose를 구현하여 데이터베이스에 대한 호출을 스트리밍합니다. #\rAnswer\r...\rAnswer: B\r#\rQ40\r#\rAmazon EC2 인스턴스에서 실행되는 애플리케이션은 Amazon Elastic File System (Amazon I 파일 시스템) 의 파일에 안전하게 액세스해야 합니다 .EFS 파일은 유휴 상태에서 암호화를 사용하여 저장됩니다.파일에 액세스하기위한 솔루션이 가장 안전합니까?\nA. Amazon EFS를 마운트할 때 TLS B. 암호화 키를 응용 프로그램의 코드에 저장 C. Amazon EFS를 마운트할 때 AWS KMS (키 관리 서비스) 활성화 D. Amazon S3 버킷에 암호화 키를 저장하고 IAM 역할을 사용하여 EC2 인스턴스 액세스 권한을 부여합니다. #\rAnswer\r...\rAnswer: A\r#\rQ41\r#\r회사는 30일 이내에 데이터 센터에서 AWS 클라우드로 20TB의 데이터를 마이그레이션해야 합니다.회사의 네트워크 대역폭은 15Mbps로 제한되며 사용률이 70% 를 초과할 수 없습니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. AWS Snowball를 사용합니다. B. AWS DataSync 사용 C. 보안 VPN 연결을 사용합니다. D. Amazon S3 Transfer Acceleration을 사용합니다. #\rAnswer\r...\rAnswer: A\r#\rQ42\r#\r솔루션 설계자가 정적 콘텐츠를 Amazon EC2 인스턴스에 호스팅되는 퍼블릭 웹 사이트에서 Amazon S3 버킷으로 옮기고 있습니다.Amazon CloudFront 배포는 정적 자산. EC2 인스턴스에서 사용하는 보안 그룹은 제한된 IP 범위 집합에 대한 액세스를 제한합니다. 정적 콘텐츠에 대한 액세스는 유사하게 제한되어야합니다.이러한 요구 사항을 충족하는 단계 조합은 무엇입니까?(두 개를 선택합니다.)\nA. OAI (원본 액세스 ID) 를 만들어 배포와 연결합니다.OAI만 객체를 읽을 수 있도록 버킷 정책의 권한을 변경합니다. B. EC2 보안 그룹에 존재하는 것과 동일한 IP 제한을 포함하는 AWS WAF 웹 ACL을 생성합니다.이 새 웹 ACL을 CloudFront 배포와 연결합니다. C. 현재 EC2 보안 그룹에 존재하는 것과 동일한 IP 제한을 포함하는 새 보안 그룹을 생성합니다.이 새 보안 그룹을 CloudFront 배포와 연결합니다. D. 현재 EC2 보안 그룹에 존재하는 것과 동일한 IP 제한을 포함하는 새 보안 그룹을 생성합니다.이 새 보안 그룹을 정적 콘텐츠를 호스팅하는 S3 버킷과 연결합니다. E. 새 IAM 역할을 생성하고 해당 역할을 배포와 연결합니다.새로 생성된 IAM 역할만 읽기 및 다운로드 권한을 갖도록 S3 버킷 또는 S3 버킷 내의 파일에 대한 권한을 변경합니다. #\rAnswer\r...\rAnswer: A, B\r#\rQ43\r#\r한 회사가 워크로드를 AWS로 마이그레이션하려고 합니다.최고 정보 보안 책임자는 클라우드에 저장될 때 저장된 모든 데이터를 암호화하도록 요구합니다.이 회사는 암호화 키 수명주기 관리를 완벽하게 제어하기를 원합니다. 이 회사는 AWS CloudTrail과 독립적으로 키 자료를 즉시 제거하고 키 사용을 감사할 수 있어야 합니다.선택한 서비스는 AWS에서 사용될 다른 스토리지 서비스와 통합되어야 합니다.이러한 보안 요구 사항을 충족하는 서비스는 무엇입니까?\nA. CloudHSM 클라이언트를 사용하는 AWS CloudHSM B. AWS 클라우드를 사용하는 AWS KMS (키 관리 서비스) C. 외부 키 자료 출처가 있는 AWS KMS (키 관리 서비스) D. AWS 관리형 고객 마스터 키 (CMK) 가 포함된 AWS 키 관리 서비스 (AWS KMS) #\rAnswer\r...\rAnswer: B\r#\rQ44\r#\r회사는 Elastic Load Balancer 뒤에 Amazon EC2 인스턴스에서 실행될 새로운 서비스를 설계하고 있습니다. 그러나 대부분의 웹 서비스 클라이언트는 방화벽에 허용 된 IP 주소에만 연결할 수 있습니다. 솔루션 설계자는 고객의 요구를 충족하기 위해 무엇을 권장해야합니까?\nA. 탄력적 IP 주소가 연결된 네트워크 로드 밸런서입니다. B. 탄력적 IP 주소가 연결된 애플리케이션 로드 밸런서 C. 탄력적 IP 주소를 가리키는 Amazon Route 53 호스팅 영역의 A 레코드 D. 로드 밸런서 앞에 프록시로 실행되는 퍼블릭 IP 주소가 있는 EC2 인스턴스 #\rAnswer\r...\rAnswer: A\r#\rQ45\r#\r개발 팀은 다른 팀이 액세스 할 수있는 웹 사이트를 호스팅해야합니다. 웹 사이트 콘텐츠. HTML, CSS, 클라이언트 측 자바 스크립트 및 이미지로 구성되어야 합니다. 웹 사이트를 호스팅하는 데 가장 비용 효율적인 방법은 무엇입니까?\nA. 웹 사이트를 컨테이너화하고 AWS Fargate에 호스팅합니다. B. Amazon S3 버킷을 만들고 웹 사이트를 호스팅합니다. C. 웹 사이트를 호스팅할 Amazon EC2 인스턴스에 웹 서버를 배포합니다. D. Express is 프레임워크를 사용하는 AWS Lambda 대상을 사용하여 애플리케이션 로드 밸런서를 구성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ46\r#\r회사가 가상 서버 기반 워크로드를 AWS로 마이그레이션할 계획입니다. 이 회사는 애플리케이션 서버가 지원하는 인터넷 연결 로드 밸런서를 보유하고 있습니다. 응용 프로그램 서버는 인터넷 호스팅 저장소의 패치에 의존합니다. 솔루션 설계자가 퍼블릭 서브넷에서 호스팅하도록 권장하는 서비스는 무엇입니까?(두 개를 선택합니다.)\nA. NAT 게이트웨이 B. Amazon RDS DB 인스턴스 C. 애플리케이션 로드 밸런서 D. Amazon EC2 애플리케이션 서버 E. Amazon EFS (Elastic 파일 시스템) 볼륨 #\rAnswer\r...\rAnswer: A C\r#\rQ47\r#\r회사는 대량의 데이터를 병렬로 처리하는 애플리케이션을 배포하고 있습니다.이 회사는 워크로드에 Amazon EC2 인스턴스를 사용할 계획입니다. 노드 간 지연 시간을 최소화할 수 있도록 네트워크 아키텍처를 구성해야 합니다. 어떤 네트워크 솔루션 조합이 이러한 요구 사항을 충족합니까?(두 개 선택)\nA. 여러 가용 영역에 EC2 인스턴스 배포 B. 각 EC2 인스턴스에 Elastic 패브릭 어댑터 (EFA) 연결 C. EC2 인스턴스를 단일 가용 영역에 배치 D. Amazon EBS (Elastic Block Store) 최적화 인스턴스 유형 사용 E. 클러스터 배치 그룹에서 EC2 인스턴스 실행 #\rAnswer\r...\rAnswer: C E\r#\rQ48\r#\r회사에서 AWS 자격 증명이 없는 특정 사용자에게 Amazon S3의 파일을 전송합니다. 이러한 사용자에게는 제한된 시간 동안 액세스 권한이 부여되어야 합니다. 솔루션 설계자는 이러한 요구 사항을 안전하게 충족하기 위해 무엇을 해야 합니까?\nA. Amazon S3 버킷에서 퍼블릭 액세스를 활성화합니다. B. 미리 서명된 URL을 생성하여 사용자와 공유합니다. C. AWS KMS를 사용하여 파일을 암호화하고 사용자에게 키를 제공합니다. D. 사용자에게 GetObject 권한을 부여하는 IAM 역할을 생성하고 할당합니다. #\rAnswer\r...\rAnswer: B\r#\rQ49\r#\r한 제조 회사가 기계 장비에 대한 예측 유지 관리를 구현하고자 합니다. 회사는 실시간으로 AWS로 데이터를 전송할 수 있는 수천 개의 IOT 센서를 설치합니다. 솔루션 설계자는 각 기계에 대해 순서대로 이벤트를 수신하는 솔루션을 구현해야 합니다.자산을 사용하고 나중에 추가 처리를 위해 데이터를 저장했는지 확인하십시오. 어떤 솔루션이 가장 효율적입니까?\nA. 각 장비 자산에 대한 파티션이 있는 실시간 이벤트에 Amazon Kinesis Data Streams 사용 Amazon Kinesis Data Firehose를 사용하여 Amazon S3에 데이터 저장 B. Amazon Kinesis Data Streams을 사용하여 각 장비 자산에 대한 샤드가 포함된 실시간 이벤트에 Amazon Kinesis Data Firehose를 사용하여 Amazon EBS에 데이터 저장 C. 실시간 이벤트에 Amazon SQS FIFO 대기열을 사용하여 각 장비 자산에 대해 하나의 대기열을 사용하여 SQS 대기열에 대한 AWS Lambda 함수를 트리거하여 Amazon EFS에 데이터를 저장합니다. D. Amazon SQS 표준 대기열을 사용하여 각 장비 자산에 대해 하나의 대기열을 사용하여 SQS 대기열에서 AWS Lambda 함수를 트리거하여 Amazon S3에 데이터를 저장합니다. #\rAnswer\r...\rAnswer: A\r#\rQ50\r#\r회사는 사용 요청을 수집하기 위해 사용되는 비동기 API를 소유하고 있으며 요청 유형에 따라 처리를 위해 요청을 적절한 마이크로서비스로 디스패치합니다.이 회사는 Amazon API 게이트웨이를 사용하여 API 프런트엔드를 배포하고, Amazon DynamoDB를 호출하여 사용자 요청을 저장하는 AWS Lambda 함수를 사용하고 있습니다. 이 회사는 예산이 허용하는 만큼 DynamoDB 처리량을 프로비저닝했지만 가용성 문제가 계속 발생하여 사용자 요청이 손실되고 있습니다. 솔루션 설계자는 기존 사용자에게 영향을 주지 않으면서 이 문제를 해결하기 위해 무엇을해야합니까?\nA. 서버 측 제한 제한을 사용하여 API 게이트웨이에 제한 추가 B. DynamoDB Accelerator (DAX) 및 LamdDA를 사용하여 DynamoDB에 대한 쓰기 버퍼링 C. DynamoDB에서 사용자 요청이 있는 레이블에 대한 보조 인덱스를 생성합니다. D. Amazon SQS (단순 대기열 서비스) 대기열 및 Lambda를 사용하여 DynamoDB에 대한 쓰기를 버퍼링합니다. #\rAnswer\r...\rAnswer: D\r#\rQ51\r#\r솔루션 설계자는 버전 관리가 활성화된 상태로 Amazon S3에 호스팅되는 웹 사이트를 자주 업데이트해야 하는 솔루션을 설계하고 있습니다. 규정 준수를 위해 이전 버전의 객체는 자주 액세스되지 않으므로 2년 후에 삭제해야 합니다.솔루션 설계자는 최저 비용으로 이러한 요구 사항을 충족하기 위해 무엇을 권장해야 합니까?\nA. S3 배치 작업을 사용하여 객체 태그를 교체합니다. 수정된 태그를 기반으로 객체를 만료시킵니다. B. 이전 버전의 객체를 S3 Glacier로 전환하도록 S3 수명 주기 정책을 구성합니다.2 년 후 객체 만료 C. 추가 처리를 위해 이전 객체를 Amazon SQS (단순 대기열 서비스) 대기열로 전송하는 버킷에서 S3 이벤트 알림을 활성화합니다. D. 이전 객체 버전을 새 버킷으로 복제합니다.S3 수명 주기 정책을 사용하여 객체 만료 2년 후 새 버킷에서 #\rAnswer\r...\rAnswer: B\r#\rQ52\r#\r회사는 3 계층의 무국적 웹 애플리케이션을 보유하고 있습니다.회사의 웹 및 애플리케이션 계층은 Amazon EBS (Elastic Block Store) 루트 볼륨이 있는 Auto Scaling 그룹의 Amazon BC2 인스턴스에서 실행되며, 데이터베이스 계층은 PostgreSQL용 Amazon RDS에서 실행됩니다. 이 회사의 RPO (복구 시점 목표) 는 2시간입니다. 솔루션 설계자는 이 환경에서 백업을 활성화하기 위해 무엇을 권장해야 합니까?\nA. 2시간마다 EC2 인스턴스 및 데이터베이스의 EBS 볼륨 스냅샷 생성 B. 스냅샷 수명 주기 정책을 구성하여 EBS 스냅샷을 생성하고 Amazon RDS에서 RPO를 충족하도록 자동 데이터베이스 백업을 구성합니다. C. 2시간마다 EC2 인스턴스의 EBS 볼륨 스냅샷 생성 2시간마다 실행되도록 Amazon RDS에서 자동 데이터베이스 백업을 구성합니다. D. 웹 및 애플리케이션 계층의 최신 Amazon 머신 이미지 (AMI) 보존 일일 Amazon RDS 스냅샷을 구성하고 시점 복구를 사용하여 RPO를 충족합니다. #\rAnswer\r...\rAnswer: D\r#\rQ53\r#\r회사의 프로덕션 애플리케이션이 Amazon RDS MySQL DB 인스턴스에서 OLTP (온라인 트랜잭션 처리) 트랜잭션을 실행합니다. 회사는 동일한 데이터에 액세스할 수 있는 새로운 보고 도구를 출시합니다. 보고 도구는 가용성이 높고 프로덕션 애플리케이션의 성능에 영향을 주지 않아야 합니다. 어떻게 이것을 달성 할 수 있습니까?\nA. 프로덕션 RDS DB 인스턴스의 시간별 스냅샷 생성 B. 프로덕션 RDS DB 인스턴스의 다중 AZ RDS 읽기 전용 복제본 생성 C. 프로덕션 RDS DB 인스턴스의 여러 RDS 읽기 전용 복제본 생성 읽기 전용 복제본을 Auto Scaling 그룹에 배치 D. 프로덕션 RDS DB 인스턴스의 단일 AZ RDS 읽기 전용 복제본 생성 복제본에서 두 번째 단일 AZ RDS 읽기 전용 복제본 생성 #\rAnswer\r...\rAnswer: B\r#\rQ54\r#\r회사는 온-프레미스 서버를 사용하여 응용 프로그램을 호스팅합니다. 스토리지 용량이 부족합니다. 애플리케이션은 블록 스토리지와 NFS 스토리지를 모두 사용합니다. 이 회사는 기존 애플리케이션을 다시 설계하지 않고도 로컬 캐싱을 지원하는 고성능 솔루션을 필요로 합니다. 이러한 요구 사항을 충족하기 위해 솔루션 설계자가 수행해야 하는 작업 조합은 무엇입니까?(두 개를 선택합니다.)\nA. Amazon S3를 파일 시스템으로 온프레미스 서버에 마운트합니다. B. NFS 스토리지를 대체할 AWS 스토리지 게이트웨이 파일 게이트웨이를 배포합니다. C. AWS Snowball Edge를 배포하여 온프레미스 서버에 NFS 마운트를 프로비저닝합니다. D. 블록 스토리지를 대체할 AWS 스토리지 게이트웨이 볼륨 게이트웨이를 배포합니다. E. Amazon EFS (Elastic Fife System) 볼륨을 배포하고 온프레미스 서버에 마운트합니다. #\rAnswer\r...\rAnswer: D E\r#\rQ55\r#\r회사는 향후 1주일 동안 지속될 이벤트를 위해 특정 AWS 리전의 세 가지 특정 가용 영역에서 Amazon EC2 용량을 보장해야 합니다. EC2 용량을 보장하려면 어떻게 해야 합니까?\nA. 필요한 리전을 지정하는 예약 인스턴스를 구매합니다. B. 필요한 리전을 지정하는 온디맨드 용량 예약을 생성합니다. C. 필요한 리전 및 3개의 가용 영역을 지정하는 예약 인스턴스를 구매합니다. D. 필요한 리전과 3개의 가용 영역을 지정하는 온디맨드 용량 예약을 생성합니다. #\rAnswer\r...\rAnswer: A\r#\rQ56\r#\r자전거 공유 회사는 피크 작동 시간 동안 자전거의 위치를 추적하기 위해 다중 계층 아키텍처를 개발하고 있습니다. 이 회사는 이러한 데이터 요소를 기존 데이터 포인트에서 사용하려고 합니다. 분석 플랫폼을 지원합니다. 솔루션 설계자는 이 아키텍처를 지원하기 위해 가장 실행 가능한 다중 계층 옵션을 결정해야 합니다.데이터 포인트는 REST API에서 액세스할 수 있어야 합니다. 위치 데이터 저장 및 검색에 대한 이러한 요구 사항을 충족하는 작업은 무엇입니까?\nA. Amazon S3와 함께 Amazon Athena를 사용하십시오. B. AWS Lambda와 함께 Amazon API 게이트웨이를 사용합니다. C. Amazon Redshift와 함께 Amazon QuickSight 사용 D. Amazon Kinesis Data Analytics과 함께 Amazon API 게이트웨이를 사용하십시오. #\rAnswer\r...\rAnswer: A\r#\rQ57\r#\r솔루션 설계자는 공용 API 액세스를 제공하는 애플리케이션용 다중 지역 재해 복구 솔루션을 설계하고 있습니다.애플리케이션에서는 Amazon EC2 인스턴스를 사용자 데이터 스크립트와 함께 사용하여 애플리케이션 코드를 로드하고 MySQL용 Amazon RDS를 사용합니다. RTO (복구 시간 목표) 는 3시간이고 RPO (복구 시점 목표) 는 24시간입니다. 최저 비용으로 이러한 요구 사항을 충족하는 아키텍처는 무엇입니까?\nA. 리전 장애 조치에 애플리케이션 로드 밸런서를 사용합니다.사용자 데이터 스크립트를 사용하여 새 EC2 인스턴스를 배포합니다.각 리전에서 별도의 RDS 인스턴스 배포 B. 리전 장애 조치에 Amazon Route 53 사용 사용자 데이터 스크립트를 사용하여 새 EC2 인스턴스 배포 백업 리전에 RDS 인스턴스의 읽기 전용 복제본 생성 C. 퍼블릭 API에 Amazon API 게이트웨이 사용 및 리전 장애 조치 사용자 데이터 스크립트를 사용하여 새 EC2 인스턴스 배포 백업 리전에 RDS 인스턴스의 MySQL 읽기 전용 복제본 생성 D. 리전 장애 조치를 위한 Amazon Route 53 사용 API용 사용자 데이터 스냅과 함께 새 EC2 인스턴스를 배포하고 백업을 위해 매일 RDS 인스턴스의 스냅샷 생성 백업 지역에 스냅샷을 복제 #\rAnswer\r...\rAnswer: D\r#\rQ58\r#\r회사는 6 년 동안 데이터를 저장해야합니다. 회사는 언제든지 데이터를 즉시 액세스할 수 있어야 하지만 자주 액세스할 필요는 없습니다. 이러한 요구 사항을 충족하면서 비용을 절감하려면 어떤 수명주기 조치를 취해야 합니까?\nA. 객체를 Amazon S3 표준에서 Amazon S3 표준 Standard Infrequent Access (S3 Standard IA) 로 전환 B. 5 년 후에 만료되는 전환 객체 C. Amazon S3 표준에서 Amazon S3 One Zone-Infrequent Access (S3 One Zone IA) 로 객체 전환 D. Amazon S3 표준에서 Amazon S3 Glacier로 객체 전환 #\rAnswer\r...\rAnswer: A\r#\rQ59\r#\r솔루션 설계자는 사용자가 기본 웹 사이트를 사용할 수 없는 백업 정적 오류 페이지로 이동하는 솔루션을 설계하고 있습니다. 기본 웹 사이트의 DNS 레코드는 도메인이 ALB (애플리케이션 로드 밸런서) 를 가리키는 Amazon Route 53에서 호스팅됩니다.솔루션 설계자가 변경 사항 및 인프라 오버헤드를 최소화하면서 회사의 요구 사항을 충족하기 위해 사용합니까?\nA. Route 53 별칭 레코드를 원본 중 하나로 사용하는 Amazon CloudFront 배포에 가리킨 다음 배포에 대한 사용자 지정 오류 페이지를 생성합니다. B. Route 53 액티브-패시브 페일오버 구성 설정 Route 53 상태 확인으로 ALB 엔드포인트가 비정상이라고 판단될 때 Amazon S3 버킷 내에 호스팅되는 정적 오류 페이지로 트래픽을 직접 지정 C. 지연 시간 기반 라우팅 정책을 사용하도록 Route 53 레코드 업데이트 Amazon S3 버킷 내에서 호스팅되는 백업 정적 오류 페이지를 레코드에 추가하여 트래픽이 응답성이 가장 높은 엔드포인트로 전송되도록 합니다. D. ALB와 정적 오류 페이지를 엔드포인트로 호스팅하는 Amazon EC2 인스턴스를 사용하여 Route 53 액티브-액티브 구성을 설정합니다. Route 53는 ALB에 대한 상태 확인이 실패할 경우에만 인스턴스에 요청을 보냅니다. #\rAnswer\r...\rAnswer: B\r#\rQ60\r#\r회사의 애플리케이션이 Amazon EC2 인스턴스에서 실행되고 있으며, 재해 발생 시 솔루션 설계자가 리소스를 두 번째 지역에도 배포할 수 있도록 해야 하는 재해 발생 시 솔루션 설계자가 이를 달성하기 위해 수행해야 하는 작업 조합에는 어떤 것이 있습니까?(두 개 선택)\nA. EC2 인스턴스에서 볼륨을 분리하여 Amazon S3에 복사합니다. B. 새 리전의 Amazon 머신 이미지 (AMI) 에서 새 EC2 인스턴스 시작 C. 새 리전에서 새 EC2 인스턴스를 시작하고 Amazon S3에서 새 인스턴스로 볼륨을 복사합니다. D. EC2 인스턴스의 Amazon 머신 이미지 (AMI) 를 복사하고 대상에 대해 다른 리전을 지정합니다. E. Amazon S3에서 Amazon EBS (Elastic Block Store) 볼륨을 복사하고 해당 EBS 볼륨을 사용하여 대상 리전에서 EC2 인스턴스를 시작합니다. #\rAnswer\r...\rAnswer: B D\r#\rQ61\r#\r솔루션 설계자는 여러 Amazon EC2 인스턴스가 모든 EC2 인스턴스에서 동시에 액세스할 수 있는 미션 크리티컬 데이터에 사용되는 공통 데이터 소스에 액세스할 수 있는 네트워크를 설계해야 합니다. 솔루션은 확장성이 뛰어나고 구현하기 쉬우며 NFS 프로토콜을 지원해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. Amazon EFS 파일 시스템 생성 각 가용 영역에 마운트 대상을 구성합니다. 각 인스턴스를 적절한 마운트 대상에 연결합니다. B. 추가 EC2 인스턴스를 생성하고 이를 파일 서버로 구성 인스턴스 간의 통신을 허용하는 보안 그룹을 생성하여 추가 인스턴스에 적용합니다. C. 적절한 권한을 가진 Amazon S3 버킷을 생성합니다. AWS IAM에서 S3 버킷에 올바른 권한을 부여하는 역할을 생성합니다. 데이터에 액세스해야 하는 EC2 인스턴스에 역할 연결 D. 적절한 권한을 사용하여 Amazon EBS 볼륨 생성 역할 생성 AWS IAM에서 EBS 볼륨에 올바른 권한을 부여하는 데이터에 액세스해야 하는 EC2 인스턴스에 역할을 연결합니다. #\rAnswer\r...\rAnswer: A\r#\rQ62\r#\r회사가 AWS CloudTrail 로그를 활성화하여 각 개발자 계정의 Amazon S3 버킷에 로그 파일을 전송했습니다. 이 회사는 관리 및 감사 검토를 간소화하기 위해 중앙 AWS 계정을 만들었습니다. 내부 감사자는 CloudTrail 로그에 액세스해야 하지만 모든 개발자 계정 사용자에 대해 액세스를 제한해야 합니다. 솔루션은 안전하고 최적화되어야 합니다. 솔루션 설계자는 이러한 요구 사항을 어떻게 충족해야 합니까?\nA. 로그 파일을 중앙 계정에 복사하도록 각 개발자 계정에 AWS Lambda 함수를 구성합니다. 감사자의 중앙 계정에서 IAM 역할을 생성합니다.버킷에 대한 읽기 전용 권한을 제공하는 IAM 정책을 연결합니다. B. 각 개발자 계정에서 CloudTrail을 구성하여 로그 파일을 중앙 계정의 S3 버킷으로 전송합니다. 감사자의 중앙 계정에서 IAM 사용자를 생성합니다. 버킷에 대한 모든 권한을 제공하는 IAM 정책을 연결합니다. C. 각 개발자 계정에서 CloudTrail을 구성하여 로그 파일을 중앙 계정의 S3 버킷으로 전송합니다. 감사자의 중앙 계정에서 IAM 역할을 생성합니다.버킷에 대한 읽기 전용 권한을 제공하는 IAM 정책을 연결합니다. D. 각 개발자 계정의 S3 버킷에서 로그 파일을 복사하도록 중앙 계정에 AWS Lambda 함수를 구성합니다. 감사자의 중앙 계정에서 IAM 사용자를 생성합니다.버킷에 대한 모든 권한을 제공하는 IAM 정책을 연결합니다. #\rAnswer\r...\rAnswer: C\r#\rQ63\r#\r솔루션 설계자는 Microsoft에서 네트워크 파일 공유를 실행하는 레거시 문서 관리 응용 프로그램을 최적화하기 위해 노력하고 있습니다. 최고 정보 책임자는 온프레미스 스토리지를 AWS로 이동하여 온프레미스 데이터 센터 공간을 줄이고 스토리지를 최소화하고자 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?\nA. AWS 스토리지 게이트웨이 파일 게이트웨이를 설정합니다. B. Amazon EFS (Elastic File System) 를 설정합니다. C. AWS 스토리지 게이트웨이를 볼륨 게이트웨이로 설정합니다. D. Amazon Elastic Block Store (Amazon EBS) 볼륨을 설정합니다. #\rAnswer\r...\rAnswer: A\r#\rQ64\r#\r회사는 AWS로 마이그레이션하려는 143TB의 MySQL 데이터베이스를 보유하고 있습니다.이 계획은 앞으로 플랫폼으로 Amazon Aurora MySQL을 사용하는 것입니다.이 회사는 Amazon VPC에 100Mbps AWS Direct Connect 연결을 보유하고 있습니다. 회사의 요구 사항을 충족하고 최소한의 시간이 소요되는 솔루션은 무엇입니까?\nA. Amazon S3용 게이트웨이 엔드포인트 사용 데이터를 Amazon S3로 마이그레이션 데이터를 Aurora로 가져오기 B. Direct Connect 링크를 500Mbps로 업그레이드합니다. Amazon S3로 데이터 복사 데이터를 Aurora로 가져오기 C. AWS Snowmobile을 주문하고 데이터베이스 백업을 복사합니다. AWS가 데이터를 Amazon S3로 가져오도록 합니다. 백업을 Aurora로 가져옵니다. D. 50TB AWS Snowball 디바이스 4개를 주문하고 데이터베이스 백업을 해당 디바이스에 복사합니다.AWS에서 데이터를 Amazon S3로 가져오도록 합니다. 데이터를 Aurora로 가져옵니다. #\rAnswer\r...\rAnswer: D\r#\rQ65\r#\r한 회사는 단일 AWS 리전 데이터 보안에서 온프레미스 데이터 센터에서 AWS 클라우드로 회계 시스템을 마이그레이션하려고 하며 불변의 감사 로그가 가장 우선순위입니다. 회사는 규정 준수 감사를 위해 모든 AWS 활동을 모니터링해야 합니다. 이 회사는 감사 로그를 활성화했습니다 AWS CloudTrail이 이러한 요구 사항을 충족하는지 확인하려고 하지만 솔루션 설계자가 CloudTrail을 보호하기 위해 어떤 조치를 취해야 합니까?(두 개를 선택합니다.)\nA. CloudTrail 로그 파일 유효성 검사 활성화 B. CloudTrail 처리 라이브러리 설치 C. CloudTrail에서 인사이트 이벤트 로깅 활성화 D. 온-프레미스 리소스에서 사용자 지정 로깅 사용 E. CloudTrail이 AWS KMS 관리형 암호화 키 (SSE-KMS) 와 함께 서버 측 암호화를 사용하도록 구성되었는지 여부를 모니터링하는 AWS 구성 규칙을 생성합니다. #\rAnswer\r...\rAnswer: C E\r#\rQ66\r#\rAWS Lambda에서 튜닝하는 애플리케이션에는 타사 서비스에 액세스하려면 API 키가 필요합니다. 키는 Lambda 기능에 대한 감사 액세스만으로 안전하게 저장되어야 합니다. 키를 저장하는 가장 안전한 방법은 무엇입니까?\nA. Amazon S3의 객체입니다. B. AWS System Manager Parameter Store의 보안 문자열. C. Lambda 함수에 연결된 Amazon EBS 볼륨의 파일 내부 D. Amazon EFS에 저장된 비밀 파일 내부 #\rAnswer\r...\rAnswer: B\r#\rQ67\r#\r회사는 파일 끝에 도달한 온-프레미스 볼륨 백업 솔루션을 보유하고 있습니다.이 회사는 새로운 백업 솔루션의 일부로 AWS를 사용하고자 하며, AWS에서 백업되는 동안 데이터에 대한 로컬 액세스를 유지하려고 합니다.이 회사는 데이터가 AWS에서 백업되는지 확인하려고 합니다. 회사는 자동으로 안전하게 양도했습니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. AWS Snowball을 사용하여 온프레미스 솔루션에서 Amazon S3로 데이터를 마이그레이션합니다. 데이터에 대한 액세스를 제공하기 위해 Snowball S3 엔드포인트를 마운트하도록 온프레미스 시스템을 구성합니다. B. AWS Snowball Edge를 사용하여 온프레미스 솔루션에서 Amazon S3로 데이터를 마이그레이션합니다.Snowball Edge 파일 인터페이스를 사용하여 온-프레미스 시스템에 데이터에 대한 로컬 액세스 권한을 제공합니다. C. AWS Storage Gateway를 사용하고 캐시된 볼륨 게이트웨이 구성 온프레미스에서 Storage Gateway 소프트웨어 어플라이언스를 실행하고 로컬로 캐시할 데이터의 비율을 구성합니다. 게이트웨이 스토리지 볼륨을 마운트하여 데이터에 대한 로컬 액세스를 제공합니다. D. AWS 스토리지 게이트웨이를 사용하고 저장된 볼륨 게이트웨이를 구성합니다. 온프레미스에서 Storage Gateway 소프트웨어 어플라이언스를 실행하고 게이트웨이 스토리지 볼륨을 온프레미스 스토리지에 매핑합니다. 게이트웨이 스토리지 볼륨을 마운트하여 데이터에 대한 로컬 액세스를 제공합니다. #\rAnswer\r...\rAnswer: C\r#\rQ68\r#\r회사는 수백만 명의 사용자로부터 총 1TB의 데이터를 수신합니다.이 회사는 규정 및 감사 요구 사항을 준수하기 위해 최소 5 년 동안 사용 데이터를 저장해야 합니다. 어떤 스토리지 솔루션이 비용면에서 가장 효과적입니까?\nA. Amazon S3 Standard에 데이터를 저장합니다.1년 후에 S3 Glacier Deep Archive로 데이터를 이전하도록 수명 주기 규칙을 설정합니다. 5년 후에 데이터를 삭제하도록 재활용 규칙을 설정합니다. B. Amazon S3 One Zone Standard Infrequent Access (S3 One Zone-IA) 에 데이터를 저장합니다.1년 후 데이터를 S3 Glacier로 이전하도록 수명 주기 규칙 설정 5년 후에 데이터를 삭제하도록 수명 주기 규칙을 설정합니다. C. Amazon S3 표준에 데이터 저장 1년 후 수명 주기 규칙을 통해 데이터를 S3 표준 액세스 (S3 Standardd-IA) 로 전환하도록 수명 주기 규칙을 설정합니다. D. Amazon S3 표준에 데이터 저장 1년 후에 데이터를 S3 One Zone Infrequent Access (S3 One Zone-IA) 로 이전하도록 수명 주기 규칙을 설정합니다. 5년 후에 데이터를 삭제하도록 수명 주기 규칙을 설정합니다. #\rAnswer\r...\rAnswer: A\r#\rQ69\r#\r회사의 웹 사이트에서 트랜잭션 데이터 스토리지에 Amazon RDS MySQL 다중 AZ DB 인스턴스를 사용하고 있습니다. 내부 배치 처리를 위해 데이터를 가져오도록 이 DB 인스턴스를 쿼리하는 다른 내부 시스템이 있습니다. RDS DB 인스턴스의 속도가 크게 느려지므로 내부 시스템이 데이터를 가져올 수 없습니다. 이 웹 사이트의 읽기 및 쓰기 성능에 영향을 미치고 사용자가 느린 응답 시간을 경험합니다. 웹 사이트의 성능을 향상시킬 수있는 솔루션은 무엇입니까?\nA. MySQL 데이터베이스 대신 RDS PostgreSQL DB 인스턴스를 사용합니다. B. 웹 사이트에 대한 쿼리 응답을 캐시하려면 Amazon ElastiCache를 사용합니다. C. 현재 RDS MySQL 멀티.az DB 인스턴스에 가용 영역을 추가합니다. D. RDS DB 인스턴스에 읽기 전용 복제본을 추가하고 읽기 전용 복제본을 쿼리하도록 내부 시스템을 구성합니다. #\rAnswer\r...\rAnswer: D\r#\rQ70\r#\r회사가 온-프레미스에서 상태 레코드를 관리하고 있습니다. 회사는 이러한 레코드를 무기한 보관하고, 저장된 레코드에 대한 수정 사항을 비활성화하고, 모든 레벨에서 액세스를 세부적으로 감사해야 합니다. CTO (최고 기술 책임자) 는 이미 수백만 개의 레코드가 있고 현재 인프라의 공간이 부족하기 때문에 우려하고 있습니다. CTO는 솔루션 설계자에게 기존 데이터를 이동하고 향후 레코드를 지원할 솔루션을 설계하도록 요청했습니다. 솔루션 설계자는 이러한 요구 사항을 충족 할 것을 권장합니까?\nA. AWS DataSync를 사용하여 기존 데이터를 AWS로 이동합니다. Amazon S3를 사용하여 기존 데이터 및 새 데이터 저장 Amazon S3 객체 잠금을 활성화하고 데이터 이벤트와 함께 AWS CloudTrail을 활성화합니다. B. AWS 스토리지 게이트웨이를 사용하여 기존 데이터를 AWS로 이동 Amazon S3를 사용하여 기존 데이터와 새 데이터를 저장합니다.Amazon S3 객체 잠금을 활성화하고 관리 이벤트로 AWS CloudTrail을 활성화합니다. C. AWS DataAsync를 사용하여 기존 데이터를 AWS로 이동 Amazon S3를 사용하여 기존 데이터 및 새 데이터 저장 Amazon S3 객체 잠금을 활성화하고 관리 이벤트로 AWS CloudTrail을 활성화합니다. D. AWS 스토리지 게이트웨이를 사용하여 기존 데이터를 AWS로 이동 Amazon Elastic Block Store (Amazon EBS) 를 사용하여 기존 데이터와 새 데이터 저장 Amazon S3 객체 잠금 활성화 및 Amazon S3 서버 액세스 로깅 활성화 #\rAnswer\r...\rAnswer: A\r#\rQ71\r#\r회사는 AWS 클라우드에서 멀티 티어 퍼블릭 웹 애플리케이션을 호스팅합니다. 이 웹 애플리케이션은 Amazon EC2 인스턴스에서 실행되며 데이터베이스는 Amazon RDS에서 실행됩니다. 이 회사는 다가오는 휴일 주말 동안 판매량이 크게 증가할 것으로 예상됩니다. 솔루션 설계자는 웹 애플리케이션의 성능을 세부적으로 분석할 솔루션을 구축해야 합니다. 솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. Amazon Redshift로 Amazon CloudWatch 로그 보내기 Amazon QuickSight 사용 추가 분석 수행 B. 모든 EC2 인스턴스에 대한 세부 모니터링 활성화 Amazon CloudWatch 메트릭을 사용하여 추가 분석 수행 C. Amazon CloudWatch 로그에서 EC2 로그를 가져오는 AWS Lambda 함수 생성 Amazon CloudWatch 메트릭을 사용하여 추가 분석 수행 D. Amazon S3로 EC2 로그 보내기 Amazon Redshift를 사용하여 S3 버킷에서 로그를 가져와 Amazon QuickSight를 통해 추가 분석을 위해 원시 데이터를 처리합니다. #\rAnswer\r...\rAnswer: B\r#\rQ72\r#\r회사는 데이터를 수신합니다 (다른 소스 및 이 데이터를 사용하기 위해 여러 응용 프로그램을 구현합니다. 주말에만 실행되는 짧은 실행 작업이 많이 있습니다. 데이터는 주말 전체가 아닌 일괄 처리로 도착합니다. 이 회사는 트랜잭션 순서를 유지하면서 이 데이터를 수집하고 처리할 수 있는 AWS 환경을 필요로 합니다.가장 비용 효율적인 방식으로 이러한 요구 사항을 충족하는 AWS 서비스 조합은 무엇입니까?\nA. AWS Lambda를 사용한 Amazon Kinesis Data Streams B. Amazon EC2 자동 크기 조정을 사용하는 Amazon Kinesis Data Streams C. AWS Lambda를 통한 Amazon SQS (단순 대기열 서비스) D. Amazon EC2 자동 크기 조정을 지원하는 Amazon SQS (단순 대기열 서비스) #\rAnswer\r...\rAnswer: A\r#\rQ73\r#\r온프레미스 애플리케이션을 실행하는 회사가 탄력성과 가용성을 높이기 위해 애플리케이션을 AWS로 마이그레이션하고 있습니다.현재 아키텍처에서는 읽기 작업이 많은 Microsoft SQL Server 데이터베이스를 사용합니다. 이 회사는 대체 데이터베이스 옵션을 살펴보고 필요한 경우 데이터베이스 엔진을 마이그레이션하려고 합니다. 개발 팀은 4시간마다 프로덕션 데이터베이스의 전체 복사본을 만들어 테스트 데이터베이스를 채웁니다. 이 기간 동안 사용자는 대기 시간을 경험합니다. 솔루션 설계자는 대체 데이터베이스로 무엇을 권장해야합니까?\nA. 다중 AZ Aurora 복제본과 함께 Amazon Aurora를 사용하고 테스트 데이터베이스의 경우 mysqldump에서 복원합니다. B. 다중 AZ Aurora 복제본과 함께 Amazon Aurora를 사용하고 테스트 데이터베이스용으로 Amazon RDS에서 스냅샷을 복원합니다. C. MySQL용 Amazon RDS를 다중 AZ 배포 및 읽기 전용 복제본과 함께 사용하고 테스트 데이터베이스에 대기 인스턴스를 사용합니다. D. 다중 AZ 배포 및 읽기 전용 복제본과 함께 SQL Server용 Amazon RDS를 사용하고 테스트 데이터베이스용으로 RDS에서 스냅샷을 복원합니다. #\rAnswer\r...\rAnswer: D\r#\rQ74\r#\r비용 탐색기에 프로덕션 계정의 애플리케이션 서버에 연결된 Amazon EBS (Elastic Block Store) 볼륨에 대해 예상보다 높은 요금이 표시됩니다. Amazon EBS의 변경 사항 중 상당 부분은 프로비저닝된 IOPS SSD (io1) 볼륨 유형으로 생성된 볼륨에서 발생한 것입니다.비용이 이 애플리케이션의 최우선 과제입니다. 애플리케이션 다운타임을 초래하지 않고 EBS 비용을 분석하고 줄이기 위해 사용자가 수행해야 하는 단계는 무엇입니까?(두 개 선택)\nA. Amazon EC2 수정 NstanceAttribute 작업을 사용하여 애플리케이션 서버 인스턴스에서 EBS 최적화를 활성화합니다. B. Amazon CloudWatch GetMetricData 작업을 사용하여 각 볼륨의 읽기 쓰기 작업과 읽기/쓰기 바이트를 평가합니다. C. Amazon EC2 수정 작업을 사용하여 사용률이 낮은 101 볼륨의 크기를 줄입니다. D. Amazon EC2 ModifyVolume 작업을 사용하여 사용률이 낮은 io1 볼륨의 볼륨 유형을 범용 SSD (gp2) 로 변경합니다. E. Amazon S3 PutBucket정책 작업을 사용하여 기존 볼륨 스냅샷을 Amazon S3 Glacier로 마이그레이션 #\rAnswer\r...\rAnswer: A D\r#\rQ75\r#\r회사가 애플리케이션 로드 밸런서 뒤에 있는 Amazon EC2 인스턴스에서 웹 서비스를 실행합니다. 인스턴스는 두 개의 가용 영역에 걸쳐 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. 회사는 필요한 SLA (서비스 수준 계약) 를 충족하기 위해 항상 최소 4개의 인스턴스가 필요합니다. 가용 영역에 장애가 발생할 경우 회사는 어떻게 SLA를 준수할 수 있습니까?\nA. 휴지 기간이 짧은 대상 추적 조정 정책 추가 B. 더 큰 인스턴스 유형을 사용하도록 Auto Scaling 그룹 시작 구성을 변경합니다. C. 세 개의 가용 영역에서 6개의 서버를 사용하도록 Auto Scaling 그룹 변경 D. 두 가용 영역에서 8개의 서버를 사용하도록 Auto Scaling 그룹 변경 #\rAnswer\r...\rAnswer: D\r#\rQ76\r#\r회사는 느슨하게 결합되도록 강력하게 결합된 애플리케이션을 재설계하고 있습니다. 이전에는 애플리케이션이 요청/응답 패턴을 사용하여 계층 간에 통신했습니다.이 회사는 디커플링 요구 사항을 달성하기 위해 Amazon SQS (단순 대기열 서비스) 를 사용할 계획입니다.초기 디자인에는 요청에 대한 큐와 응답에 대한 큐가 하나 포함되어 있습니다. 그러나 이 방법은 응용 프로그램이 확장됨에 따라 모든 메시지를 처리하지 않습니다.솔루션 설계자는이 문제를 해결하기 위해 무엇을해야합니까?\nA. SQS 대기열의 수신 메시지 API 작업에서 배달 못 한 편지 대기열을 구성합니다. B. FIFO 큐를 구성하고 메시지 중복 제거 ID 및 메시지 그룹 ID를 사용합니다. C. 각 응답 메시지를 수신할 임시 대기열 클라이언트를 사용하여 임시 대기열을 만듭니다. D. 각 생산자의 시작 시 각 요청과 응답에 대한 대기열을 만들고 상관 관계 ID 메시지 속성을 사용합니다. #\rAnswer\r...\rAnswer: B\r#\rQ77\r#\r한 회사에서 단일 VPC의 여러 가용 영역에 분산된 여러 Amazon EC2 인스턴스에서 미디어 스토어를 운영하고 있습니다.이 회사는 모든 EC2 인스턴스 간에 데이터를 공유할 수 있는 고성능 솔루션을 원하며, 데이터를 VPC 내에만 보관하기를 원합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. Amazon S3 버킷을 생성하고 각 인스턴스의 애플리케이션에서 서비스 API를 호출합니다. B. Amazon S3 버킷을 생성하고 마운트된 볼륨으로 액세스하도록 모든 인스턴스를 구성합니다. C. Amazon EBS (Elastic Block Store) 볼륨을 구성하고 모든 인스턴스에 마운트합니다. D. Amazon EFS (Elastic 파일 시스템) 파일 시스템을 구성하고 모든 인스턴스에 마운트합니다. #\rAnswer\r...\rAnswer: D\r#\rQ78\r#\r웹 애플리케이션은 애플리케이션 로드 밸런서 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 애플리케이션을 통해 사용자는 과거 기상 데이터에 대한 사용자 지정 보고서를 생성할 수 있습니다.보고서를 생성하는 데 최대 5분이 걸릴 수 있습니다. 이러한 장기 실행 요청은 사용 가능한 수신 연결을 많이 사용하므로 시스템이 다른 사용자에게 응답하지 않게 만드는 솔루션 설계자가 시스템을 보다 빠르게 반응하게 하려면 어떻게 해야 합니까?\nA. AWS Lambda와 함께 Amazon SOS를 사용하여 보고서 생성 B. 애플리케이션 로드 밸런서의 유휴 시간 제한을 5분 으로 늘립니다. C. 클라이언트 쪽 응용 프로그램 코드를 업데이트하여 요청 제한 시간을 5분으로 늘립니다. D. Amazon S3에 보고서를 게시하고 Amazon CloudFront를 사용하여 사용자에게 다운로드합니다. #\rAnswer\r...\rAnswer: A\r#\rQ79\r#\r회사는 매달 200GB의 데이터를 Amazon S3에 저장합니다.회사는 지난 달의 각 판매 지역에서 판매되는 품목 수를 결정하기 위해 매월 말에 이 데이터에 대한 분석을 수행해야 합니다. 회사에서 사용할 수 있는 가장 비용 효율적인 분석 전략은 무엇입니까?\nA. Amazon ES (Elastic 검색 서비스) 클러스터를 생성합니다.Amazon ES에서 데이터를 쿼리합니다. Kibana를 사용하여 데이터를 시각화합니다. B. AWS 글루 데이터 카탈로그에 테이블을 생성합니다. Amazon Athena를 사용하여 Amazon S3의 데이터를 쿼리합니다.Amazon QuickSight의 데이터 시각화 C. Amazon EMR 클러스터 생성 Amazon EMR을 사용하여 데이터를 쿼리하고 결과를 Amazon S3에 저장하여 Amazon QuickSight에 데이터를 시각화합니다. D. Amazon Redshift 클러스터를 생성합니다.Amazon Redshift에서 데이터를 쿼리하고 결과를 Amazon S3에 업로드합니다.Amazon QuickSight에서 데이터를 시각화합니다. #\rAnswer\r...\rAnswer: B\r#\rQ80\r#\r솔루션 설계자는 미션 크리티컬 웹 애플리케이션을 설계하고 있습니다. 애플리케이션 로드 밸런서 뒤에 있는 Amazon EC2 인스턴스와 관계형 데이터베이스로 구성됩니다. 데이터베이스는 가용성이 높고 내결함성이 있어야 합니다. 이러한 요구 사항을 충족하는 데이터베이스 구현은 무엇입니까?(두 개를 선택합니다.)\nA. Amazon Redshift B. Amazon DynamoDB C. MySQL용 Amazon RDS D. MySQL 호환 Amazon Aurora 다중 AZ E. SQL Server Standard Edition Multi-AZ 용 Amazon RDS #\rAnswer\r...\rAnswer: D E\r#\rQ81\r#\r회사는 AWS에서 멀티 티어 웹 애플리케이션을 실행하고 있습니다. 애플리케이션은 Amazon Aurora MySQL에서 데이터베이스 계층을 실행합니다. 애플리케이션 및 데이터베이스 계층이 us-east-1 리전 A 에 있습니다. Aurora DB 클러스터를 정기적으로 모니터링하는 데이터베이스 관리자는 간헐적으로 읽기 트래픽이 증가하면 읽기 복제본의 CPU 사용률이 높아져 애플리케이션의 읽기 지연 시간이 늘어납니다. 솔루션 설계자가 읽기 확장 성을 향상시키기 위해 무엇을합니까?\nA. Aurora DB 클러스터 재부팅 B. 리전 간 읽기 전용 복제본 생성 C. 읽기 전용 복제본의 인스턴스 클래스 증가 D. 읽기 전용 복제본에 대한 Aurora 자동 크기 조정 구성 #\rAnswer\r...\rAnswer: D\r#\rQ82\r#\r회사가 소프트웨어 엔지니어링에 사용되는 AWS 계정을 보유하고 있습니다.AWS 계정은 한 쌍의 AWS Direct Connect 연결을 통해 회사의 온프레미스 데이터 센터에 액세스할 수 있습니다. VPC가 아닌 모든 트래픽은 가상 프라이빗 게이트웨이로 라우팅됩니다.개발 팀이 최근 콘솔을 통해 AWS Lambada 함수를 만들었습니다.개발 팀은 이 기능이 회사 데이터 센터의 프라이빗 서브넷에서 실행되는 데이터베이스에 액세스할 수 있도록 허용해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 적절한 보안 그룹과 함께 VPC에서 실행되도록 Lambda 함수를 구성합니다. B. AWS에서 데이터 센터로의 VPN 연결을 설정합니다.VPN을 통해 Lambda 함수에서 트래픽 라우팅 C. Lambda 함수가 Direct Connect을 통해 온프레미스 데이터 센터에 액세스할 수 있도록 VPC의 라우팅 테이블을 업데이트합니다. D. Elastic IP 주소를 생성합니다.Elastic 네트워크 인터페이스 없이 Elastic IP 주소를 통해 트래픽을 전송하도록 Lambda 함수를 구성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ83\r#\r회사는 Amazon S3 버킷을 데이터 레이크 스토리지 플랫폼으로 사용합니다. S3 버킷에는 여러 팀과 수백 개의 애플리케이션이 무작위로 액세스하는 방대한 양의 데이터가 포함되어 있습니다. 이 회사는 S3 스토리지 비용을 절감하고 자주 액세스하는 객체에 대한 즉각적인 가용성을 제공하고자 합니다.이러한 요구 사항을 충족하는 가장 효율적인 운영 솔루션은 무엇입니까?\nA. S3 수명 주기 규칙을 생성하여 객체를 S3 Intelliginet-Tiering 스토리지 클래스로 전환합니다. B. Amazon S3 Glacier에 객체 저장 S3 사용 애플리케이션에 데이터에 대한 액세스 권한 제공 C. S3 스토리지 클래스 분석의 데이터를 사용하여 S3 수명 주기 규칙을 생성하여 객체를 S3 표준 Standard Infrequent Access {S3 Standard-IA) 스토리지 클래스로 자동 전환합니다. D. 객체를 S3 Standard-infrequent Access (S3 Standard-IA) 스토리지 클래스로 전환 애플리케이션이 객체를 액세스할 때 S3 Standard 스토리지 클래스로 전환하기 위한 AWS Lambda 함수를 생성합니다. #\rAnswer\r...\rAnswer: A\r#\rQ84\r#\r회사는 VPC 내의 데이터베이스와 통신할 웹 애플리케이션을 AWS에서 호스팅하려고 합니다.응용 프로그램의 가용성이 높아야 합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. 로드 밸런서 뒤에 웹 서버를 호스팅할 두 개의 Amazon EC2 인스턴스를 생성한 다음 대규모 인스턴스에 데이터베이스를 배포합니다. B. 웹 서버용 Auto Scaling 그룹을 사용하여 여러 가용 영역에 로드 밸런서를 배포한 다음 여러 가용 영역에 Amazon RDS를 배포합니다. C. 웹 서버용 Auto Scaling 그룹과 함께 퍼블릭 서브넷에 로드 밸런서를 배포한 다음 프라이빗 서브넷의 Amazon EC2 인스턴스에 데이터베이스를 배포합니다. D. Auto Scaling 그룹을 사용하여 두 개의 웹 서버를 배포하고 두 개의 웹 서버를 가리키는 도메인을 구성한 다음 여러 가용 영역에 데이터베이스 아키텍처를 배포합니다. #\rAnswer\r...\rAnswer: C\r#\rQ85\r#\r회사가 3개의 매우 큰 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다. us-east-1 리전의 단일 가용 영역에서 각 EC2 인스턴스에 여러 개의 16TB Amazon Elastic Block Store (Amazon EBS) 볼륨이 연결됩니다. 운영 팀은 일정 기반 Amazon EventBridge (Amazon CloudWatch 이벤트) 규칙에 의해 트리거된 AWS Lambda 스크립트를 사용하여 저녁과 주말에 인스턴스를 중지하고 평일 아침에 인스턴스를 시작합니다. 이 회사는 솔루션을 배포하기 전에 공개 AWS 요금 설명서를 사용하여 하루 10시간 동안 주 5일 동안 이 데이터 웨어하우스 솔루션을 실행하는 데 드는 총 비용을 추정했습니다. 이 새 계정에 대한 월별 비용 탐색기 요금을 살펴보면 전체 요금이 예상치보다 높습니다. 회사가 간과할 가능성이 가장 높은 비용 요소는 무엇입니까?\nA. 인스턴스 간 EC2 데이터 전송 요금이 예상보다 훨씬 높습니다. B. EC2 및 EBS 요금은 대부분의 다른 AWS 리전보다 us-east1에서 더 높습니다. C. 인스턴스를 중지하고 시작하는 Lambda 요금은 예상보다 훨씬 높습니다. D. 밤과 주말에 EBS 스토리지에 대한 요금이 청구됩니다. #\rAnswer\r...\rAnswer: D\r#\rQ86\r#\r환경에는 AZ-a와 AZ-B에는 4개의 인스턴스가 있고 AZ-B에는 3개의 EC2 인스턴스가 있으므로 두 개의 가용 영역에 Auto Scaling 그룹이 있습니다.Auto Scaling 그룹은 기본 종료 정책을 사용합니다. 어떤 인스턴스도 확장 이벤트로부터 보호되지 않습니다.스케일 인 이벤트가 있는 경우 Auto Scaling은 어떻게 처리됩니까?\nA. Auto Scaling은 임의로 종료할 인스턴스를 선택합니다 B. Auto Scaling은 모든 인스턴스의 가장 오래된 시작 구성으로 인스턴스를 종료합니다. C. Auto Scaling은 4개의 EC2 인스턴스가 있는 가용 영역을 선택한 다음 계속 평가합니다. D. Auto Scaling은 모든 인스턴스의 다음 청구 시간이 종료된 상태로 인스턴스를 종료합니다. #\rAnswer\r...\rAnswer: C\r#\rQ87\r#\r회사에서 Amazon EX2 및 Amazon RDS의 사용률이 낮은 인스턴스를 식별하려고 합니다.회사는 사용률이 낮은 모든 인스턴스의 비용과 각 리소스의 사용률 메트릭에 대해 보고해야 합니다. 이 데이터를 제공하는 도구와 서비스의 조합은 무엇입니까?(두 개를 선택합니다.)\nA. 비용 탐색기 B. AWS 비용 및 사용 보고서 C. AWS 예산 D. Amazon CloudWatch E. AWS CloudTrail #\rAnswer\r...\rAnswer: A D\r#\rQ88\r#\r한 회사는 Amazon Route 53가 지시하는 트래픽과 함께 10개 이상의 Amazon EC2 인스턴스를 호스팅하는 웹 애플리케이션을 보유하고 있습니다. 회사에서 응용 프로그램을 탐색하려고 할 때 시간 초과 오류가 발생하는 경우가 있습니다. 네트워킹 팀은 일부 DNS 쿼리가 비정상 인스턴스의 IP 주소를 반환하여 시간 초과 오류가 발생한다는 것을 알게되었습니다. 솔루션 설계자는 이러한 시간 초과 오류를 극복하기 위해 무엇을 구현해야합니까?\nA. Route 53 간단한 선출 정책 레코드 로트 만들기 각 EC2 인스턴스 난로 확인을 각 레코드와 연결 B. 각 EC2 인스턴스에 대한 Route 53 장애 조치 라우팅 정책 레코드 생성 상태 확인을 각 레코드와 연결 C. EC2 인스턴스를 오리진으로 사용하여 Amazon CloudFront 배포 생성 상태 확인을 EC2 인스턴스와 연결합니다. D. EC2 인스턴스 앞에 상태 확인이 있는 애플리케이션 로드 밸런서 (ALB) 생성 Route 53에서 ALB로 라우팅 #\rAnswer\r...\rAnswer: A\r#\rQ89\r#\r퍼블릭 웹 애플리케이션은 프라이빗 서브넷의 Amazon EC2 인스턴스에서 호스팅되는 데이터베이스를 쿼리합니다. 많은 수의 쿼리에 여러 테이블 조인이 포함되며 복잡한 쿼리의 증가로 인해 응용 프로그램 성능이 저하되었습니다. 응용 프로그램 팀은 성능을 향상시키기 위해 업데이트를 수행합니다. 솔루션 설계자는 애플리케이션 팀에 무엇을 추천해야합니까?(두 개를 선택합니다.)\nA. Amazon SQS의 캐시 쿼리 데이터 B. 읽기 전용 복제본을 생성하여 쿼리 오프로드 C. Amazon Athena로 데이터베이스 마이그레이션 D. 데이터를 캐시하기 위해 Amazon DynamoDB Accelerator를 구현합니다. E. Amazon RDS로 데이터베이스 마이그레이션 #\rAnswer\r...\rAnswer: B E\r#\rQ90\r#\rAWS에서 실행되는 애플리케이션을 사용하여 전 세계 구독자에게 콘텐츠를 제공하는 회사. 애플리케이션에는 ALB (애플리케이션 로드 밸런서) 뒤에 있는 프라이빗 서브넷에 여러 Amazon EC2 인스턴스가 있습니다. 최근 저작권 제한이 변경되었기 때문에 CIO (최고 정보 책임자) 는특정 국가에 대한 액세스 어떤 조치가 이러한 요구 사항을 충족합니까?\nA. 차단된 국가에서 들어오는 트래픽을 거부하도록 ALB 보안 그룹을 수정합니다. B. EC2 인스턴스에 대한 보안 그룹을 수정하여 차단된 국가에서 들어오는 트래픽을 거부합니다. C. Amazon CloudFront를 사용하여 애플리케이션을 제공하고 차단된 국가에 대한 액세스를 거부합니다. D. 차단된 국가에서 들어오는 트래픽에 대한 액세스가 거부된 응답을 반환하려면 ALB 수신기 규칙을 사용합니다. #\rAnswer\r...\rAnswer: C\r#\rQ91\r#\r회사는 AWS 클라우드에서 애플리케이션을 호스팅합니다. 이 애플리케이션은 Auto Scaling 그룹의 Elastic 로드 밸런서 뒤에 있는 Amazon EC2 인스턴스에서 Amazon DynamoDB 테이블을 사용하여 실행됩니다. 이 회사는 다운타임을 최소화하면서 다른 AWS 리전에서 애플리케이션을 사용할 수 있는지 확인하고자 합니다. 솔루션 설계자는 최소한의 다운타임으로 이러한 요구 사항을 충족하기 위해 어떻게 해야 합니까?\nA. 재해 복구 영역에 Auto Scaling 그룹 및 로드 밸런서를 생성합니다. DynamoDB 테이블을 전역 테이블로 구성합니다.새 재해 복구 지역의 로드 밸런서를 가리키도록 DNS 장애 조치를 구성합니다. B. AWS 클라우드 형성 템플릿을 생성하여 필요할 때 실행할 EC2 인스턴스, 로드 밸런서 및 DynamoDB 테이블을 생성합니다.새로운 재해 복구 지역의 두꺼비 밸런서를 가리키도록 DNS 장애 조치를 구성합니다. C. AWS CloudFormation 템플릿을 생성하여 EC2 인스턴스와 필요할 때 실행할 로드 밸런서를 생성합니다.DynamoDB 테이블을 전역 테이블로 구성합니다.새 재해 복구 지역의 로드 밸런서를 가리키도록 DNS 장애 조치를 구성합니다. D. 재해 복구 영역에 Auto Scaling 그룹 및 로드 밸런서를 생성합니다.DynamoDB 테이블을 글로벌 테이블로 구성 Amazon CloudWatch 경보를 생성하여 재해 복구 로드 밸런서를 가리키는 Amazon Route 53을 업데이트하는 AWS Lambda 함수를 트리거합니다. #\rAnswer\r...\rAnswer: C\r#\rQ92\r#\r한 회사는 응용 프로그램에서 데이터를 암호화해야 하는 개발자를 지원하기 위해 확장 가능한 키 관리 인프라를 구축하고자 합니다.솔루션 설계자는 운영 부담을 줄이기 위해 무엇을 해야 합니까?\nA. 다중 요소 인증 (MFA) 을 사용하여 암호화 키 보호 B. AWS KMS (키 관리 서비스) 를 사용하여 암호화 키 보호 C. AWS 인증서 관리자 (ACM) 를 사용하여 암호화 키를 생성, 저장 및 할당 D. IAM 정책을 사용하여 암호화 키를 보호할 액세스 권한이 있는 사용자의 범위를 제한합니다. #\rAnswer\r...\rAnswer: B\r#\rQ93\r#\r회사는 Amazon EC2 리눅스 인스턴스에 대한 웹 사이트를 운영합니다.일부 인스턴스는 장애가 발생한 인스턴스의 스왑 공간이 부족하기 때문에 문제 해결 지점을 차지하고 있습니다.운영 팀 책임자는이를 모니터링 할 수있는 솔루션이 필요합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. Amazon CloudWatch 스왑 사용량 측정기준을 구성합니다.CloudWatch의 EC2 지표에서 스왑 사용량 측정기준을 모니터링합니다. B. EC2 메타데이터를 사용하여 정보를 수집한 다음 Amazon CloudWatch SwapUtilizaion 사용자 지정지표에 게시합니다. CloudWatch에서 SwapUsage 지표를 모니터링합니다. C. 인스턴스에 Amazon CloudWatch 에이전트를 설치합니다. 설정된 일정에 따라 적절한 스크립트를 실행합니다. CloudWatch에서 SwapUtilizaion 지표를 모니터링합니다. D. EC2 콘솔에서 세부 모니터링을 활성화합니다.Amazon CloudWatch SwapUtilizaion 사용자 지정 지표를 생성합니다. CloudWatch에서 SwapUtilizaion 지표를 모니터링합니다. #\rAnswer\r...\rAnswer: C\r#\rQ94\r#\r회사는 데이터 과학 팀이 온프레미스와 AWS 클라우드에서 데이터를 분석할 수 있는 스토리지 옵션을 원합니다. 팀은 온프레미스에서 데이터를 사용하고 여러 가용 영역에 걸쳐 Amazon EC2 인스턴스 집합을 사용하여 통계 분석을 실행할 수 있어야 합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. AWS 스토리지 게이트웨이 테이프 게이트웨이를 사용하여 온프레미스 파일을 Amazon S3에 복사합니다. B. AWS 스토리지 게이트웨이 볼륨 게이트웨이를 사용하여 온프레미스 파일을 Amazon S3로 복사합니다. C. AWS 스토리지 게이트웨이 파일 게이트웨이를 사용하여 온프레미스 파일을 Amazon Elastic Block Store (Amazon EBS) 로 복사합니다. D. Amazon EFS (Elastic 파일 시스템) 파일 시스템을 온 프레미스 서버에 연결합니다.파일을 Amazon EFS로 복사합니다. #\rAnswer\r...\rAnswer: B\r#\rQ95\r#\r회사는.NET 애플리케이션 서버 및 마이크로소프트 SQL Server 데이터베이스에 대한 공유 파일 시스템을 배포하려고 합니다.이 솔루션은 기업 Active Directory 도메인에 통합되고, 내구성이 뛰어나고, AWS에서 관리하며, PUT 및 IOPS 수준을 제공할 수 있어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 윈도우 파일 서버용 Amazon FSX 사용 B. Amazon Elastic File System (Amazon EFS) 사용 C. 파일 게이트웨이 모드에서 AWS 스토리지 게이트웨이를 사용합니다. D. 두 가용 영역에서 두 개의 온디맨드 인스턴스에 Windows 파일 서버를 배포합니다. #\rAnswer\r...\rAnswer: A\r#\rQ96\r#\r회사의 웹 애플리케이션은 Amazon RDS PostgreSQL DB 인스턴스를 사용하여 애플리케이션 데이터를 저장합니다. 매월 시작의 금융 폐쇄 기간 동안.회계사는 높은 사용량으로 인해 데이터베이스의 성능에 영향을 미치는 대규모 쿼리를 실행합니다.이 회사는 보고 활동이 웹 애플리케이션에 미치는 영향을 최소화하려고 합니다.솔루션 설계자는 최소한의 노력으로 데이터베이스에 미치는 영향을 줄이기 위해 무엇을해야합니까?\nA. 읽기 전용 복제본을 생성하고 보고 트래픽을 복제본으로 전송합니다. B. 다중 AZ 데이터베이스를 생성하고 보고 트래픽을 예비 복제본으로 전송합니다. C. 리전 간 읽기 전용 복제본을 생성하고 보고 트래픽을 복제본으로 전송합니다. D. Amazon Redshift 데이터베이스를 생성하고 보고 트래픽을 Amazon Redshift 데이터베이스로 직접 전송합니다. #\rAnswer\r...\rAnswer: A\r#\rQ97\r#\r회사는 여러 웹 사이트에서 클릭스트림 데이터를 캡처하고 일괄 처리를 사용하여 분석합니다.데이터는 야간에 Amazon Redshift로 로드되며 비즈니스 분석가가 사용합니다.이 회사는 시기적절한 인사이트를 얻기 위해 거의 실시간 데이터 처리로 전환하려고 합니다.솔루션은 최소한의 노력과 운영 오버헤드로 스트리밍 데이터를 처리해야 합니다.이 솔루션에서 가장 비용 효율적인 AWS 서비스 조합은 무엇입니까?(두 개를 선택합니다.)\nA. Amazon EC2 B. AWS Lambda C. Amazon Kinesis Data Streams D. Amazon Kinesis Data Firehose E. Amazon Kinesis Data Analytics #\rAnswer\r...\rAnswer: C D\r#\rQ98\r#\r회사는 두 개의 Amazon EC2 인스턴스에서 호스팅되는 동적 웹 애플리케이션을 보유하고 있습니다.회사는 SSL 종료를 수행하기 위해 각 인스턴스에 자체 SSL 인증서를 가지고 있습니다.최근 트래픽이 증가했으며 운영 팀은 SSL 암호화 및 암호 해독으로 인해 웹 서버의 컴퓨팅 용량이 최대 한계에 도달한다고 판단했습니다. 솔루션 설계자는 응용 프로그램의 성능을 향상시키기 위해 무엇을해야합니까?\nA. AWS 인증서 관리자 (ACM) 를 사용하여 새 SSL 인증서를 만듭니다.각 인스턴스에 ACM 인증서를 설치합니다. B. Amazon S3 버킷을 생성합니다.SSL 인증서를 S3 버킷으로 마이그레이션합니다.SSL 종료를 위해 버킷을 참조하도록 EC2 인스턴스를 구성합니다. C. 다른 EC2 인스턴스를 프록시 서버로 생성합니다.SSL 인증서를 새 인스턴스로 마이그레이션하고 기존 EC2 인스턴스에 Direct Connect하도록 구성합니다. D. SSL 인증서를 AWS 인증서 관리자 (ACM) 로 가져옵니다.ACM의 SSL 인증서를 사용하는 HTTPS 리스너를 사용하여 애플리케이션 로드 밸런서를 생성합니다. #\rAnswer\r...\rAnswer: D\r#\rQ99\r#\rAWS에서 실행 중인 애플리케이션은 운영 활동에 대한 감사 로그를 생성합니다. 규정 준수 요구 사항 애플리케이션이 5년간 로그를 보관해야 한다는 요구 사항을 어떻게 충족할 수 있습니까?\nA. Amazon S3 버킷에 토그를 저장하고 버킷에서 MFA 삭제를 활성화합니다. B. Amazon EFS (Elastic File System) 볼륨에 토그를 저장하고 볼륨과 함께 네트워크 파일 시스템 버전 4 (NFSv4) 잠금을 사용합니다. C. Amazon S3 Glacier 저장소에 새끼 저장 및 저장소 잠금 정책 정의 D. Amazon Elastic Block Store (Amazon EBS) 볼륨에 로그를 저장하고 매월 스냅샷을 생성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ100\r#\r회사는 IPv6 주소를 사용하는 Amazon EC2 인스턴스에서 호스팅되는 애플리케이션을 보유하고 있습니다.응용 프로그램은 인터넷을 사용하여 다른 외부 응용 프로그램과의 통신을 시작해야 합니다.그러나 회사의 보안 정책에는 외부 서비스가 EC2 인스턴스에 대한 연결을 시작할 수 없다고 명시되어 있습니다.솔루션 설계자가이 문제를 해결하기 위해 무엇을 권장해야합니까?\nA. NAT 게이트웨이를 생성하여 서브넷의 라우팅 테이블의 대상으로 만듭니다. B. 인터넷 게이트웨이를 만들어 서브넷의 라우팅 테이블의 대상으로 만듭니다. C. 가상 프라이빗 게이트웨이를 생성하여 서브넷 라우팅 테이블의 대상으로 지정합니다. D. 송신 전용 인터넷 게이트웨이를 만들어 서브넷 라우팅 테이블의 대상으로 지정합니다. #\rAnswer\r...\rAnswer: D\r#\rQ101\r#\r회사는 AWS에서 새로운 머신 러닝 모델 솔루션을 개발하고 있습니다.이 모델은 시작 시 Amazon S3에서 약 1GB의 모델 데이터를 가져와 메모리로 로드하는 독립 마이크로서비스로 개발되었습니다.사용자는 비동기 API를 통해 모델에 액세스합니다.사용자는 요청 또는 요청 배치를 보내고 결과를 보낼 위치를 지정할 수 있습니다.이 회사는 수백 명의 사용자에게 모델을 제공합니다.모델의 사용 패턴이 불규칙한 경우 일부 모델은 며칠 또는 몇 주 동안 사용되지 않을 수 있습니다. 다른 모델은 한 번에 수천 건의 요청을 일괄 처리받을 수 있습니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. API의 요청은 ALB (애플리케이션 로드 밸런서) 모델로 전송됩니다. ALB에서 호출하는 AWS Lambda 함수로 배포됩니다. B. API의 요청은 Amazon SQS (단순 대기열 서비스) 대기열 모델로 전송됩니다.SQS 이벤트에 의해 트리거되는 AWS Lambda 함수로 모델을 배포하여 Lambda에서 AWS Auto Scaling이 활성화되어 SQS 대기열 크기에 따라 vCPU 수를 늘립니다. C. API의 요청은 모델의 Amazon SQS (단순 대기열 서비스) 대기열로 전송됩니다.모델은 대기열에서 읽는 Amazon ECS (Amazon Elastic Container Service) 서비스로 배포됩니다. AWS App Mesh는 SQS 대기열 크기를 기반으로 ECS 클러스터의 인스턴스를 확장합니다. D. API의 요청은 Amazon SQS (단순 대기열 서비스) 대기열 모델은 Amazon ECS에서 활성화한 AWS Auto Scaling.s 대기열에서 읽는 Amazon ECS (Amazon Elastic Container Service) 서비스로 배포됩니다. 대기열 크기에 따라 서비스의 클러스터와 복사본에 대해 Amazon ECS에서 활성화되었습니다. #\rAnswer\r...\rAnswer: D\r#\rQ102\r#\r회사는 최근 내부 보안 표준을 업데이트했습니다.이제 모든 Amazon S3 버킷과 Amazon EBS (Elastic Block Store) 볼륨이 생성되어 내부 보안 전문가가 주기적으로 교체하는 키로 암호화되도록 해야 합니다.이 회사는 이러한 목표를 달성하기 위해 기본 소프트웨어 기반 AWS 서비스를 찾고 있습니다.솔루션 설계자는 솔루션으로 무엇을 추천해야합니까?\nA. AWS 비밀 관리자를 고객 마스터 키 (CMK) 와 함께 사용하여 마스터 키 자료를 저장하고 정기적으로 새 CMK를 생성하고 AWS 비밀 관리자에서 교체하는 루틴을 적용합니다. B. AWS KMS (고객 마스터 키) 와 함께 AWS KMS (키 관리 서비스) 를 사용하여 마스터 키 자료를 저장하고 라우팅을 적용하여 주기적으로 새 키를 다시 생성하고 AWS KMS에서 교체합니다. C. 고객 마스터 키와 AWS CloudHSM 클러스터를 사용하여 (CMKs) 마스터 키 자료를 저장하고 정기적으로 새 키를 다시 만들고 CloudHSM 클러스터 노드에서 교체 루틴을 적용하는. D. AWS Systems Manager 파라미터 스토어를 고객 마스터 키 (CMK) 키와 함께 사용하여 마스터 키 자료를 저장하고 루틴을 적용하여 주기적으로 새 항목을 다시 생성하고 파라미터 스토어에서 교체합니다. #\rAnswer\r...\rAnswer: B\r#\rQ103\r#\r회사에서 전자 상거래 웹 사이트의 데이터베이스 계층에 대해 프로비저닝된 처리량을 갖춘 Amazon DynamoDB를 사용하고 있습니다. 플래시 판매 중에 고객은 데이터베이스에서 발생하는 많은 수의 트랜잭션을 처리할 수 없는 기간을 경험하게 됩니다.이로 인해 회사가 거래를 잃게 됩니다. 정상적인 기간 동안 데이터베이스가 적절하게 수행됩니다. 회사가 직면한 성능 문제를 해결하는 솔루션은 무엇입니까?\nA. 플래시 판매 중 DynamoDB를 온 디맨드 모드로 전환 B. 빠른 메모리 성능을 위해 DynamoDB Accelerator 구현 C. Amazon Kinesis를 사용하여 처리를 위해 트랜잭션을 DynamoDB에 대기열에 넣습니다. D. Amazon SQS (단순 대기열 서비스) 를 사용하여 DynamoDB에 트랜잭션을 대기열에 넣기 #\rAnswer\r...\rAnswer: A\r#\rQ104\r#\r솔루션 설계자가 최근에 마이그레이션된 워크로드에 대한 보안 검토를 수행하고 있습니다.워크로드는 애플리케이션 로드 밸런서 뒤에 있는 Auto Scaling 그룹의 Amazon EC2 인스턴스로 구성된 웹 애플리케이션입니다.솔루션 설계자는 보안 상태를 개선하고 DDoS 공격이 리소스에 미치는 영향을 최소화해야 합니다. 어떤 솔루션이 가장 효과적입니까?\nA. 비용 기반 규칙을 사용하여 AWS WAF ACL을 구성합니다.애플리케이션 로드 밸런서를 가리키는 Amazon CloudFront 배포를 생성합니다.CloudFront 배포에서 WAF ACL 활성화 B. 식별된 공격을 공통 취약점 풀에 추가하여 잠재적인 DDoS 공격을 포착하는 사용자 지정 AWS Lambda 함수를 생성합니다. 식별된 정보를 사용하여 네트워크 ACL을 수정하여 액세스를 차단합니다. C. VPC 흐름 로그를 활성화한 다음 Amazon S3에 저장합니다.DDoS 공격을 찾는 로그를 구문 분석하는 사용자 지정 AWS Lambda 함수를 생성합니다.네트워크 ACL을 수정하여 식별된 원본 IP 주소를 차단합니다. D. Amazon GuardDuty 활성화 및 검색 결과 구성 10 개의 Amazon GloudWatch 작성됨 Amazon SNS (단순 알림 서비스) 를 트리거하는 DDoS 경고를 위한 클라우드 워치 이벤트로 이벤트 생성 Amazon SNS에서 DDoS 공격을 찾는 로그를 구문 분석하는 사용자 지정 AWS Lambda 함수를 호출하도록 하기 네트워크 수정식별된 원본 IP 주소를 차단하는 ACL #\rAnswer\r...\rAnswer: A\r#\rQ105\r#\r솔루션 설계자는 다가오는 음악 이벤트를위한 웹 사이트를 최적화하고 있습니다. 공연의 비디오는 실시간으로 스트리밍 된 다음 필요에 따라 사용할 수 있습니다. 이벤트는 글로벌 온라인 잠재 고객을 유치 할 것으로 예상됩니다.스트리밍?\nA. Amazon CloudFront B. AWS global Accelerator C. Amazon Route 53 D. Amazon S3 Transfer Acceleration #\rAnswer\r...\rAnswer: A\r#\rQ106\r#\r회사는 온-프레미스 데이터 센터를 통해 정적 웹 사이트를 실행합니다.이 회사는 여러 서버 매트는 트래픽을 모두 처리하고있다, 하지만 바쁜 일에, 서비스가 중단되고 웹 사이트를 사용할 수 없게됩니다.이 회사는 전 세계적으로 자사의 입지를 확장하고 웹 사이트 트래픽을 3배로 늘릴 계획입니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 권장해야합니까?\nA. 웹 사이트 콘텐츠를 Amazon S3로 마이그레이션하고 웹 사이트를 Amazon CloudFront에 호스팅합니다. B. 웹 사이트 콘텐츠를 여러 AWS 리전에서 퍼블릭 Elastic IP 주소를 사용하는 Amazon EC2 인스턴스로 마이그레이션합니다. C. 웹 사이트 콘텐츠를 Amazon EC2 인스턴스로 마이그레이션하고 로드가 증가함에 따라 세로로 확장합니다. D. Amazon Route 53을 사용하여 전 세계에 존재하는 각 AWS 리전에 대해 여러 Amazon CloudFront 배포에 로드를 분산합니다. #\rAnswer\r...\rAnswer: A\r#\rQ107\r#\r회사는 온프레미스 데이터 센터에 소량의 데이터를 Amazon S3에 주기적으로 백업해야 하는 NFS 서버를 보유하고 있습니다.이러한 요구 사항을 충족하며 비용 대비 효과가 가장 높은 솔루션은 무엇입니까?\nA. 온프레미스 서버에서 Amazon S3로 데이터를 복사하도록 AWS Gluy를 설정합니다. B. 온프레미스 서버에 AWS DataSync 에이전트를 설정하고 데이터를 Amazon S3에 동기화합니다. C. SFTP용 AWS 전송을 사용하여 SFTP 동기화를 설정하여 온프레미스에서 Amazon S3로 데이터를 동기화합니다. D. 온프레미스 데이터 센터와 VPC 간에 AWS Direct Connect 연결을 설정하고 데이터를 Amazon S3에 복사합니다. #\rAnswer\r...\rAnswer: C\r#\rQ108\r#\r회사는 사용자의 서비스 사용 데이터를 수집, 처리 및 저장하는 잠재적 솔루션을 조사하고 있습니다. 비즈니스 목표는 회사가 표준 SQL 쿼리를 사용하여 운영 통찰력을 빠르게 수집할 수 있도록 하는 분석 기능을 만드는 것입니다.이 솔루션은 가용성이 높고 데이터 계층에서 원자성, 일관성, 격리 및 내구성 (ACID) 준수를 보장해야 합니다.솔루션 설계자가 권장해야 하는 솔루션은 무엇입니까?\nA. Amazon DynamoDB 트랜잭션 사용 B. 다중 AZ 설계에서 Amazon 해왕성 데이터베이스 생성 C. 다중 AZ 설계에서 완전히 관리되는 MySQL용 Amazon RDS 데이터베이스 사용 D. Amazon EBS 처리량 최적화 HDD (st1) 스토리지를 사용하는 Amazon EC2 인스턴스에 PostgreSQL을 배포합니다. #\rAnswer\r...\rAnswer: C\r#\rQ109\r#\r회사는 AWS에 사용자 디바이스에서 센서 데이터를 수집하는 3계층 환경을 보유하고 있습니다. 트래픽은 NLB (네트워크 로드 밸런서) 를 거쳐 웹 계층의 Amazon EC2 인스턴스로, 마지막으로 데이터베이스를 호출하는 애플리케이션 계층의 EC2 인스턴스로 전달됩니다. 솔루션 설계자는 웹 티어로 전송되는 데이터의 보안을 향상시키기 위해 어떻게 해야 합니까?\nA. TLS 리스너를 구성하고 NLB에 서버 인증서를 추가합니다. B. NLB에서 AWS 쉴드 어드밴스드를 구성하고 AWS WAF를 활성화합니다. C. 로드 밸런서를 애플리케이션 로드 밸런서로 변경하고 AWS WAF를 여기에 연결합니다. D. AWS KMS (키 관리 서비스) 를 사용하여 EC2 인스턴스의 Amazon EBS (Amazon Elastic Block Store) 볼륨 암호화 #\rAnswer\r...\rAnswer: A\r#\rQ110\r#\r회사는 웹 서버, 응용 프로그램 서버 및 데이터베이스 서버로 구성된 3 계층 웹 응용 프로그램을 만들고 있습니다.응용 프로그램은 배달되는 패키지의 GPS 좌표를 추적합니다.응용 프로그램은 0-5 초마다 데이터베이스를 업데이트합니다.추적은 사용자가 패키지 상태를 확인할 수 있도록 가능한 한 빨리 읽어야 합니다.며칠 동안 몇 개의 패키지만 추적될 수 있지만 다른 날에는 수백만 개의 패키지가 추적될 수 있습니다. 추적 ID 고객 ID 및 주문 ID 주문 ID를 통해 추적을 검색할 수 있어야 합니다. 1개월이 넘는 주문은 더 이상 읽지 않습니다. 솔루션 설계자는 최소한의 소유 비용으로 이를 달성하기 위해 무엇을 권장해야합니까?\nA. DynamoDB 테이블에서 Amazon DynamoDB 자동 크기 조정 사용을 사용합니다.1개월보다 오래된 항목에 대한 자동 삭제 스크립트를 예약합니다. B. 글로벌 보조 인덱스와 함께 Amazon DynamoDB를 사용합니다.DynamoDB 테이블과 글로벌 보조 인덱스에서 Auto Scaling을 활성화합니다.DynamoDB 테이블에서 TTL을 활성화합니다. C. 프로비저닝된 IOPS (PIOPS) 가 있는 Amazon RDS 온 디맨드 인스턴스를 사용합니다.PIOPS가 초과되면 알림을 보내도록 Amazon CloudWatch 경보를 활성화합니다.필요에 따라 PIOPS를 늘리거나 줄입니다. D. 프로비저닝된 IOPS (PIOPS) 와 함께 Amazon RDS 예약 인스턴스를 사용합니다.PIOPS가 초과되면 알림을 보내도록 Amazon CloudWatch 경보를 활성화합니다.필요에 따라 PIOPS를 늘리거나 줄입니다. #\rAnswer\r...\rAnswer: B\r#\rQ111\r#\r솔루션 설계자는 웹, 애플리케이션 및 데이터베이스 계층으로 구성된 고가용성 애플리케이션을 설계해야 합니다. HTTPS 콘텐츠 전송은 가능한 한 Edge에 가까워야 하며 배달 시간은 최소화되어야 합니다. 이러한 요구 사항을 충족하고 가장 안전한 솔루션은 무엇입니까?\nA. 여러 개의 중복 Amazon EC2 인스턴스가 포함된 퍼블릭 애플리케이션 로드 밸런서 (ALB) 구성 퍼블릭 서브넷 공개 ALB를 오리진으로 사용하여 HTTPS 콘텐츠를 전송하도록 Amazon CloudFront 구성 B. 프라이빗 서브넷의 Amazon EC2 인스턴스 구성 EC2 인스턴스를 오리진으로 사용하여 HTTPS 콘텐츠를 전송하도록 여러 개의 중복 Amazon CloudFront를 사용하여 퍼블릭 애플리케이션 로드 밸런서를 구성합니다. C. 프라이빗 서브넷에 여러 중복 Amazon EC2 인스턴스가 포함된 퍼블릭 애플리케이션 로드 밸런서 (ALB) 구성 퍼블릭 ALB를 오리진으로 사용하여 HTTPS 콘텐츠를 전송하도록 Amazon CloudFront 구성 D. 퍼블릭 서브넷에 여러 개의 중복 Amazon EC2 인스턴스가 있는 퍼블릭 애플리케이션 로드 밸런서 구성 EC2 인스턴스를 오리진으로 사용하여 HTTPS 콘텐츠를 전송하도록 Amazon CloudFront 구성 #\rAnswer\r...\rAnswer: C\r#\rQ112\r#\r회사는 타사 공급업체를 사용하여 마켓플레이스 분석을 관리하고 있습니다. 공급업체는 회사 계정의 리소스에 대한 제한된 프로그래밍 방식으로 액세스해야 합니다. 적절한 액세스 권한을 부여하기 위해 필요한 모든 정책이 만들어졌습니다. 공급업체에 계정에 대한 가장 안전한 액세스 권한을 제공하는 추가 구성 요소는 무엇입니까?\nA. IAM 사용자를 생성합니다. B. SCP (서비스 제어 정책) 구현 C. 외부 ID가 있는 교차 계정 역할을 사용합니다. D. SSO (단일 사인온) ID 제공자를 구성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ113\r#\r개발 팀은 통합 제품을 만들기 위해 다른 회사와 협력하고 있습니다.다른 회사는 개발 팀의 계정에 포함된 Amazon SQS (단순 대기열 서비스) 대기열에 액세스해야 합니다.다른 회사는 자신의 계정 권한을 포기하지 않고 대기열을 폴링하려고 합니다.솔루션 설계자는 SQS 대기열에 대한 액세스 권한을 어떻게 제공해야 합니까?\nA. SQS 대기열에 대한 다른 회사 액세스 권한을 제공하는 인스턴스 프로필을 생성합니다. B. 다른 회사에서 SQS 대기열에 대한 액세스 권한을 제공하는 IAM 정책을 생성합니다. C. SQS 대기열에 대한 다른 회사 액세스 권한을 제공하는 SQS 액세스 정책을 생성합니다. D. 다른 회사에서 SQS 대기열에 대한 액세스 권한을 제공하는 Amazon SNS (단순 알림 서비스) 액세스 정책을 생성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ114\r#\r한 IAM 사용자가 지난 주 프로덕션 배포 중에 회사 계정에 있는 AWS 리소스의 구성을 몇 가지 변경했습니다. 솔루션 설계자는 몇 가지 보안 그룹 규칙이 원하는 대로 구성되지 않았음을 알게 되었습니다. 솔루션 설계자는 변경을 담당하는 IAM 사용자를 확인하려고 합니다. 솔루션 설계자는 원하는 정보를 찾기 위해 어떤 서비스를 사용해야 합니까?\nA. Amazon GuardDuty B. Amazon Inspector C. AWS CloudTrail D. AWS Config #\rAnswer\r...\rAnswer: A D\r#\rQ115\r#\r회사의 레거시 애플리케이션은 현재 암호화 없이 단일 인스턴스 Amazon RDS MySQL 데이터베이스에 의존하고 있습니다. 새로운 규정 준수 요구 사항으로 인해 이 데이터베이스의 기존 데이터와 새 데이터를 모두 암호화해야 함 이 작업을 수행하려면 어떻게 해야 합니까?\nA. 서버 측 암호화가 활성화된 Amazon S3 버킷 생성 모든 데이터를 Amazon S3로 이동 RDS 인스턴스 삭제 B. 유휴 상태의 암호화가 활성화된 RDS 다중 AZ 모드 활성화 대기 인스턴스로 장애 조치를 수행하여 원래 인스턴스를 삭제합니다. C. RDS 인스턴스의 스냅샷 생성 스냅샷의 암호화된 복사본 생성 암호화된 스냅샷에서 RDS 인스턴스 복원 D. 미사용 시 암호화가 활성화된 RDS 읽기 전용 복제본 생성 읽기 전용 복제본을 마스터로 승격하고 애플리케이션을 새 마스터로 전환하여 이전 RDS 인스턴스를 삭제합니다. #\rAnswer\r...\rAnswer: C\r#\rQ116\r#\r팀은 Amazon 버킷에 업로드되는 새 객체를 감지하는 애플리케이션을 보유하고 있습니다. Amazon DynamoDB 테이블과 PostgreSQL 데이터베이스용 Amazon RDS에 메타데이터를 기록하는 트리거 AWS Lambda 함수를 업로드합니다. 고가용성을 보장하기 위해 팀은 어떤 조치를 취해야 합니까?\nA. 교차 리전 복제를 활성화하여 고가용성 보장 B. 애플리케이션이 배포되는 각 가용 영역에 대해 Lambda 함수를 생성합니다. C. RDS PostgreSQL 데이터베이스에서 다중 AZ를 사용하도록 설정합니다. D. DynamoDB 테이블에 대한 DynamoDB 스트림 생성 #\rAnswer\r...\rAnswer: C\r#\rQ117\r#\r회사가 AWS에 웹 사이트를 배포하고 있습니다.데이터베이스 백엔드는 확장 요구 사항을 지원하기 위해 기본 인스턴스와 5개의 읽기 전용 복제본이 있는 MySQL용 Amazon RDS에서 호스팅됩니다. 읽기 전용 복제본은 사용자 환경을 지원하기 위해 기본 인스턴스보다 1초 이상 지연되지 않아야 합니다. 웹 사이트의 트래픽이 계속 증가함에 따라 복제본은 로드가 가장 높은 기간 동안 더 뒤쳐져 검색 결과가 일치하지 않을 경우 사용자의 불만이 발생합니다 솔루션 설계자는 애플리케이션 코드 또는 운영 요구 사항에 대한 변경을 최소화하면서 가능한 한 복제 지연을 줄여야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 데이터베이스를 Amazon Aurora MySQL로 마이그레이션 MySQL 읽기 전용 복제본을 Aurora 복제본으로 대체하고 Aurora Auto Scaling 활성화 B. 데이터베이스 앞에 Redis 용 Amazon ElastiCache 클러스터 배포 데이터베이스 읽기 엔드포인트를 쿼리하기 전에 캐시를 검사하도록 웹 사이트 수정 C. Amazon RDS에서 Amazon EC2 컴퓨팅 인스턴스에서 실행 중인 MySQL로 데이터베이스를 마이그레이션합니다.모든 복제본 노드에 대해 매우 큰 컴퓨팅 최적화 인스턴스를 선택합니다. D. Amazon DynamoDB로 데이터베이스 마이그레이션 처음에는 온 디맨드 용량 확장을 활성화한 상태에서 필요한 처리량을 지원하기 위해 많은 수의 읽기 용량 단위 (RCU) 를 프로비저닝합니다. #\rAnswer\r...\rAnswer: A\r#\rQ118\r#\r회사는 AWS에서 설문 조사 웹 사이트를 호스팅할 계획입니다. 회사는 예측할 수 없는 트래픽 양을 예상하고 있습니다. 이 트래픽으로 인해 데이터베이스에 대한 비동기 업데이트가 발생합니다. 이 회사는 AWS에서 호스팅되는 데이터베이스에 대한 쓰기가 삭제되지 않도록 하려고 합니다. 회사는 이러한 데이터베이스 요청을 처리하기 위해 어떤 응용 프로그램을 작성해야합니까?\nA. Amazon SNS (단순 알림 서비스) 에 게시하도록 애플리케이션을 구성합니다. SNS 주제에 데이터베이스를 구독하십시오. B. 거짓말 애플리케이션 구성: Amazon SNS (단순 알림 서비스) 주제를 구독하십시오. SNS 주제에 대한 데이터베이스 업데이트를 게시합니다. C. Amazon SOS (단순 대기열 서비스) FIFO 대기열을 사용하여 데이터베이스에 데이터를 쓸 리소스가 있을 때까지 데이터베이스 연결을 대기열에 대기시킵니다. D. Amazon SOS (단순 대기열 서비스) FIFO 대기열을 사용하여 쓰기를 캡처하고 데이터베이스에 쓰기가 수행될 때마다 대기열을 극적으로 만듭니다. #\rAnswer\r...\rAnswer: D\r#\rQ119\r#\r회사는 us-east-1 지역에 개발, 테스트 및 프로덕션이라는 VPC 3개를 보유하고 있습니다. 세 개의 VPC를 온-프레미스 데이터 센터에 연결해야 하며 보안을 유지하고 리소스 공유를 방지하기 위해 분리되도록 설계되었습니다. 솔루션 설계자가 확장 가능하고 안전한 솔루션을 찾아야 하는 경우 솔루션 설계자는 무엇을 권장해야 합니까?\nA. 데이터 센터에 다시 연결할 각 VPC에 대해 AWS Direct Connect 연결 및 VPN 연결을 생성합니다. B. 모든 VPC에서 프로덕션 VPC로의 VPC 피어 생성. 프로덕션 VPC에서 데이터 센터로의 AWS Direct Connect 연결 사용 C. 모든 VPC의 VPN 연결을 프로덕션 VPC의 VPN에 연결합니다.프로덕션 VPC에서 데이터 센터로의 VPN 연결 사용 D. 네트워크 VPC 내에 네트워크라는 새 VPC 생성 AWS Direct Connect 연결이 있는 AWS 전송 게이트웨이 생성 데이터 센터로 다시 연결 다른 모든 VPC를 네트워크 VPC에 연결합니다. #\rAnswer\r...\rAnswer: A\r#\rQ120\r#\r게임 회사는 고가용성 아키텍처를 설계하고 있습니다. 이 응용 프로그램은 수정 된 Linux 커널에서 실행되며 UDP 기반 트래픽 만 지원합니다.이 회사는 최상의 사용자 환경을 제공하기 위해 프런트 엔드 계층이 필요합니다.계층은 지연 시간이 짧고 트래픽을 가장 가까운 엣지 로케이션으로 라우팅하고 애플리케이션 엔드포인트에 입력할 수 있는 고정 IP 주소를 가져야 합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. 애플리케이션 로드 밸런서에 요청을 전달하도록 Amazon Route 53을 구성합니다.AWS 애플리케이션 Auto Scaling의 애플리케이션에 AWS Lambda를 사용합니다. B. 요청을 네트워크 로드 밸런서에 전달하도록 Amazon CloudFront를 구성합니다.AWS 애플리케이션 Auto Scaling 그룹의 애플리케이션에 AWS Lambda를 사용합니다. C. 요청을 네트워크 로드 밸런서로 전달하도록 AWS Global Accelerator를 구성합니다.EC2 Auto Scaling 그룹의 애플리케이션에 Amazon EC2 인스턴스를 사용합니다. D. 요청을 애플리케이션 로드 밸런서로 전달하도록 Amazon API 게이트웨이를 구성합니다.EC2 Auto Scaling 그룹의 애플리케이션에 Amazon EC2 인스턴스를 사용합니다. #\rAnswer\r...\rAnswer: C\r#\rQ121\r#\r회사에서 Amazon S3에 많은 수의 이미지를 저장할 웹 애플리케이션을 만들고 있습니다. 사용자는 다양한 기간 동안 이미지에 액세스할 수 있습니다.회사는 다음을 원합니다.\n모든 이미지 유지 검색 비용이 발생하지 않습니다. 최소한의 관리 오버헤드가 있습니다. 검색 시간에 영향을 주지 않고 이미지를 사용할 수 있습니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? A. S3 Intelliginet 계층화 구현 B. S3 스토리지 클래스 분석 구현 C. S3 수명 주기 정책을 구현하여 데이터를 S3 표준 Standard Infrequent Access (S3 표준-IA) 로 이동합니다. D. S3 단일 영역 Standard Infrequent Access (S3 원 영역- IA) 로 데이터를 이동하는 S3 수명 주기 정책을 구현합니다. #\rAnswer\r...\rAnswer: A\r#\rQ122\r#\r회사는 임시 트랜잭션 데이터를 생성하는 Amazon EC2 인스턴스에 애플리케이션을 구축하고 있습니다. 애플리케이션에서 구성 가능하고 일관된 IOPS를 제공할 수 있는 데이터 스토리지에 액세스해야 하는 솔루션 설계자는 무엇을 권장합니까?\nA. 처리량에 최적화된 HDD (st1) 루트 볼륨과 콜드 HDD (세트) 데이터 볼륨으로 EC2 인스턴스 프로비저닝 B. 루트 및 데이터 볼륨으로 사용할 처리량에 최적화된 HDD (st1) 볼륨으로 EC2 인스턴스를 프로비저닝합니다. C. 범용 SSD (gp2\u0026gt; 루트 볼륨 및 프로비저닝된 IOPS SSD (io1) 데이터 볼륨으로 EC2 인스턴스 프로비저닝 D. 범용 SSD (gp2) 루트 볼륨으로 EC2 인스턴스 프로비저닝 데이터를 Amazon S3 버킷에 저장하도록 애플리케이션을 구성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ123\r#\r회사는 일반 트래픽 중에 Amazon EC2 인스턴스가 4개 이상 필요한 애플리케이션을 사용하고 있으며 로드가 가장 많을 때는 EC2 인스턴스를 최대 12개까지 확장해야 합니다.애플리케이션은 비즈니스에 매우 중요하며 가용성이 높아야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. Auto Scaling 그룹에 EC2 인스턴스 배포 가용 영역 A에 2개, 가용 영역 B에 2개를 설정하고 최대값은 M으로 설정합니다. B. Auto Scaling 그룹에 EC2 인스턴스 배포 가용 영역 A에 4개를 모두 포함하면서 최소값은 4로, 최대 값은 12개로 설정합니다. C. Auto Scaling 그룹에 EC2 인스턴스 배포 가용 영역 A에서 4개, 가용 영역 B에 4개, 가용 영역 B에 4개 설정 D. Auto Scaling 그룹에 EC2 인스턴스 배포 가용 영역 A에서 최소 8개, 최대 값은 12개로 설정합니다. #\rAnswer\r...\rAnswer: C\r#\rQ124\r#\r회사는 이전에 데이터 웨어하우스 솔루션을 AWS로 마이그레이션했습니다.이 회사는 또한 AWS 다이렉트 커넥트 연결을 가지고 있습니다. 기업 사무실 사용자는 시각화 도구를 사용하여 데이터 웨어하우스를 쿼리합니다. 데이터 웨어하우스에서 반환되는 쿼리의 평균 크기는 50MB이고 시각화 도구에서 보낸 각 웹 페이지는 약 500KB입니다.데이터 웨어하우스에 의해 반환된 결과 집합은 캐시되지 않습니다. 회사에 가장 낮은 데이터 전송 송신 비용을 제공하는 솔루션은 무엇입니까?\nA. 구내 시각화 도구를 호스팅하고 인터넷을 통해 직접 데이터 웨어하우스를 쿼리합니다.- B. 시각화 도구를 데이터 웨어하우스와 동일한 AWS 리전에서 호스팅합니다.인터넷을 통해 액세스 할 수 있습니다. C. 온-프레미스에서 시각화 도구를 호스팅하고 동일한 AWS 리전의 위치에 있는 Direct Connect 연결을 통해 직접 데이터 웨어하우스를 쿼리합니다. D. 시각화 도구를 데이터 웨어하우스와 동일한 AWS 리전에서 호스팅하고 동일한 리전의 위치에 있는 Direct Connect 연결을 통해 액세스합니다. #\rAnswer\r...\rAnswer: D\r#\rQ125\r#\r회사가 온프레미스 인프라에서 AWS 클라우드로 마이그레이션 중입니다. 회사의 애플리케이션 중 하나는 DFSR (분산 파일 시스템 복제) 을 사용하여 데이터를 동기화 상태로 유지하는 Windows 파일 서버 팜에 파일을 저장합니다. 솔루션 설계자는 파일 서버 팜을 교체해야 하는 서비스솔루션 설계자가 사용합니까?\nA. Amazon EFS B. Amazon FSX C. Amazon S3 D. AWS 스토리지 게이트웨이 #\rAnswer\r...\rAnswer: B\r#\rQ126\r#\r회사는 AWS에서 새로운 웹 애플리케이션을 구축할 계획입니다.이 회사는 기대 예측 가능한 트래픽 올해의 대부분과 경우에 매우 높은 트래픽.웹 응용 프로그램은 최소한의 대기 시간으로 가용성과 내결함성이 있어야합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 권장해야합니까?\nA. Amazon Route 53 라우팅 정책을 사용하여 각각 하나의 Amazon EC2 인스턴스가 있는 두 개의 AWS 리전으로 요청을 배포합니다. B. Auto Scaling 그룹에서 Amazon EC2 인스턴스를 여러 가용 영역에 걸쳐 애플리케이션 로드 밸런서와 함께 사용합니다. C. 여러 가용 영역에 걸쳐 애플리케이션 로드 밸런서가 있는 클러스터 배치 그룹에서 Amazon EC2 인스턴스를 사용합니다. D. 클러스터 배치 그룹에서 Amazon EC2 인스턴스를 사용하고 새 Auto Scaling 그룹 내에 클러스터 배치 그룹을 포함합니다. #\rAnswer\r...\rAnswer: B\r#\rQ127\r#\r회사가 AWS에 데이터 레이크 배포를 준비하고 있습니다.솔루션 설계자는 저장 데이터의 암호화 전략을 정의해야 합니다. Amazon S3 회사의 보안 정책은\n키는 90일마다 회전해야 합니다. 주요 사용자와 주요 관리자 간의 엄격한 업무 분리를 구현해야 합니다. 감사 키 사용이 가능해야 함 솔루션 설계자는 무엇을 추천해야합니까? A. 고객 관리형 고객 마스터 키 (CMK) 가 포함된 AWS KMS 관리형 키 (SSE-KMS) 를 사용한 서버 측 암호화 B. AWS 관리형 고객 마스터 키 (CMK) 를 사용한 AWS KMS 관리형 키 (SSE-KMS) 를 사용한 서버 측 암호화 C. Amazon S3 관리형 키를 사용한 서버 측 암호화 (SSE-S3) 및 고객 관리형 고객 마스터 키 (CMK) D. AWS 관리형 고객 마스터 키 (CMK) 를 사용한 Amazon S3 관리 키 (SSE-S3) 를 사용한 서버 측 암호화 #\rAnswer\r...\rAnswer: B\r#\rQ128\r#\r웹 애플리케이션이 AWS 클라우드에 배포됨 웹 계층과 데이터베이스 계층을 포함하는 2계층 아키텍처로 구성됩니다. 웹 서버는 크로스 사이트 스크립팅 (XSS) 공격에 취약합니다. 솔루션 설계자가 취약점을 해결하기 위해 어떻게 해야 합니까?\nA. 클래식 로드 밸런서 생성 웹 계층을 로드 밸런서 뒤에 배치하고 AWS WAF를 활성화합니다. B. 네트워크 로드 밸런서 생성 웹 계층을 로드 밸런서 뒤에 배치하고 AWS WAF를 활성화합니다. C. 애플리케이션 로드 밸런서 생성 웹 계층을 로드 밸런서 뒤에 배치하고 AWS WAF를 활성화합니다. D. 애플리케이션 로드 밸런서 생성 웹 계층을 로드 밸런서 뒤에 배치하고 AWS Shield 표준을 사용합니다. #\rAnswer\r...\rAnswer: C\r#\rQ129\r#\r응용 프로그램은 공급업체가 실행하는 서비스를 호출합니다.공급 업체는 통화 수를 기준으로 요금을 부과합니다.재무 부서는 청구 명세서를 검증하기 위해 서비스에 걸린 통화 수를 알아야 합니다. 솔루션 설계자는 애플리케이션을 변경하지 않고도 통화 수를 안정적으로 저장할 수 있는 시스템을 어떻게 설계할 수 있습니까?\nA. 인터넷 게이트웨이를 통해 서비스 호출 B. Amazon SQS (단순 대기열 서비스) 대기열을 사용하여 서비스에서 애플리케이션을 분리합니다. C. 서비스에 대한 호출을 계산하는 사용자 지정 Amazon CloudWatch 측정치를 게시합니다. D. VPC 피어링 연결을 통해 서비스를 호출합니다. #\rAnswer\r...\rAnswer: C\r#\rQ130\r#\r금융 회사는 미국 동부 1 리전에서 프로덕션 AWS 환경을 운영하고 Amazon EBS (Elastic Block Store) 스냅샷을 사용하여 인스턴스를 백업합니다.규정 준수 요구 사항을 충족하려면 모든 중요 데이터의 보조 복제본을 기본 위치에서 최소 160.9km 떨어진 곳에 보관해야 합니다. 이 요구 사항을 충족하는 가장 비용 효율적인 방법은 무엇입니까?\nA. EBS 스냅샷을 us-east-1의 다른 가용 영역으로 복제합니다. B. EBS 스냅샷을 us-east-2에 복제합니다. C. EBS 스냅샷을 us-west-1로 복제합니다. D. EBS 스냅샷을 us-west-2에 복제 #\rAnswer\r...\rAnswer: B\r#\rQ131\r#\r회사는 인기있는 웹 애플리케이션을 호스팅합니다.웹 애플리케이션은 프라이빗 VPC 서브넷에서 실행 중인 데이터베이스에 연결합니다.웹 서버는 SSL 연결을 사용하는 고객만 액세스할 수 있어야 합니다. MySQL용 Amazon RDS 데이터베이스 서비스는 웹 서버에서만 액세스할 수 있습니다.솔루션 설계자는 애플리케이션에 영향을 주지 않고 요구 사항을 충족하도록 솔루션을 어떻게 설계해야 합니까?\nA. 웹 서버의 서브넷에 네트워크 ACL을 생성하고 HTTPS 인바운드 및 MySQL 아웃바운드를 허용합니다.데이터베이스와 웹 서버를 모두 동일한 서브넷에 배치합니다. B. 웹 서버용 보안 그룹에서 HTTPS 포트를 열고 소스를 0.0.0.0/0으로 설정합니다.데이터베이스 보안 그룹에서 MySQL 포트를 열고 MySQL 인스턴스에 연결합니다. 소스를 웹 서버 보안 그룹으로 설정합니다. C. 웹 서버의 서브넷에 네트워크 ACL을 생성하고, HTTP를 허용하고, 인바운드를 허용하고, 소스를 0.0.0.0/0.데이터베이스 서브넷에 네트워크 ACL을 생성하면 웹 서버에 대한 MySQL 포트를 인바운드 허용하고 모든 아웃바운드 트래픽을 거부할 수 있습니다. D. 웹 서버의 보안 그룹에서 MySQL 포트를 열고 소스를 0.0.0.0/0으로 설정합니다.데이터베이스 보안 그룹에서 HTTPS 포트를 열고 MySQL 인스턴스에 연결합니다.소스를 웹 서버 보안 그룹으로 설정합니다. #\rAnswer\r...\rAnswer: B\r#\rQ132\r#\r회사의 보안 정책에 따라 AWS 계정의 대체 AWS API 활동이 정기적인 감사에 기록되어야 합니다.이 회사는 AWS 조직을 사용하여 현재 및 미래의 모든 AWS 계정에서 AWS CloudTrail을 활성화해야 합니다. 어떤 솔루션이 가장 안전합니까?\nA. 조직의 루트에서 CloudTrail만 사용하도록 허용하는 SCP (서비스 제어 정책) 를 정의하고 연결합니다. B. 필요에 따라 조직의 마스터 계정에 IAM 그룹 생성 사용자가 CloudTrail을 비활성화할 수 없도록 하는 IAM 정책을 정의하고 그룹에 연결합니다. C. 계정을 OU (조직 구성 단위) 로 구성 조직의 루트에서 사용자가 CloudTrail을 사용하지 않도록 설정하는 SCP (서비스 제어 정책) 를 정의하고 연결합니다. D. 조직의 루트 아래에 있는 모든 기존 계정 추가 사용자가 CloudTrail을 사용하지 않도록 설정하는 모든 계정에 SCP (서비스 제어 정책) 를 정의하고 연결합니다. #\rAnswer\r...\rAnswer: D\r#\rQ133\r#\r회사는 여행 발권 웹 응용 프로그램을 보유하고 있습니다.이 애플리케이션은 북미의 단일 데이터 센터에서 실행되는 데이터베이스를 기반으로 합니다.이 회사는 글로벌 사용자 기반을 제공하기 위해 응용 프로그램을 확장하려고 합니다.회사는 애플리케이션을 여러 AWS 리전으로 표시해야 합니다.예약 데이터베이스 업데이트의 평균 지연 시간은 1초 미만이어야 합니다.이 회사는 여러 지역에 웹 플랫폼을 별도로 배포하려고 합니다.그러나 회사는 전 세계적으로 일관된 단일 기본 예약 데이터베이스를 유지 관리해야 합니다. 솔루션 설계자가 이러한 요구 사항을 충족하기 위해 어떤 솔루션을 권장해야 합니까?\nA. Amazon DynamoDB를 사용하도록 애플리케이션을 변환합니다.센터 예약 테이블에는 글로벌 테이블을 사용합니다. 각 지역별 배포에서 올바른 지역별 엔드 포인트를 사용합니다. B. 데이터베이스를 Amazon Aurora MySQL 데이터베이스로 마이그레이션합니다.각 리전에서 Aurora 읽기 전용 복제본을 배포합니다.각 지역 배포에서 올바른 지역 엔드 포인트를 사용하여 데이터베이스에 액세스합니다. C. 데이터베이스를 MySQL용 Amazon RDS 데이터베이스로 마이그레이션합니다.각 리전에서 MySQL 읽기 전용 복제본을 배포합니다.데이터베이스에 대한 액세스를 위해 각 지역 배포에서 올바른 지역별 엔드 포인트를 사용합니다. D. 애플리케이션을 Amazon Aurora 서버 없는 데이터베이스로 마이그레이션합니다.데이터베이스의 인스턴스를 각 지역에 배포합니다.각 지역 배포에서 올바른 지역 엔드 포인트를 사용하여 데이터베이스에 액세스합니다.AWS Lambda 함수를 사용하여 각 리전에서 이벤트 스트림을 처리하여 데이터베이스를 동기화합니다. #\rAnswer\r...\rAnswer: A\r#\rQ134 그룹에는 Amazon S3 버킷을 나열하고 해당 버킷에서 객체를 삭제할 권한이 필요합니다.관리자는 버킷에 대한 액세스 권한을 제공하기 위해 다음 IAM 정책을 생성하고 해당 정책을 그룹에 적용했습니다.그룹은 버킷의 객체를 삭제할 수 없습니다.더 컴퍼니는 최소 권한 액세스 규칙을 따릅니다.\r#\rA. 옵션 B. 옵션 B C. 옵션 C D. 옵션 D #\rAnswer\r...\rAnswer: A\r#\rQ135\r#\r회사는 데이터웨어 하우스에 대한 Amazon 레드 시프트를 사용합니다.이 회사는 구성 요소에 고장이 발생할 경우 데이터에 대한 높은 내구성을 보장하고자 합니다.솔루션 설계자는 무엇을 추천해야합니까?\nA. 동시성 좌석을 활성화합니다. B. 교차 리전 스냅샷을 활성화합니다. C. 데이터 보존 기간을 늘립니다. D. 다중 AZ에서 Amazon Redshift를 배포합니다. #\rAnswer\r...\rAnswer: B\r#\rQ136\r#\r개발 팀은 범용 Amazon RDS (또는 성능 인사이트가 활성화된 MySQL DB 인스턴스) 에 대해 월별 리소스 집약적 테스트를 실행합니다.테스트는 한 달에 한 번 48시간 동안 지속되며 데이터베이스를 사용하는 유일한 프로세스입니다.팀은 DB 인스턴스의 컴퓨팅 및 메모리 속성을 줄이지 않고 테스트 실행 비용을 절감하고자 합니다. 어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까?\nA. 테스트가 완료되면 DB 인스턴스 중지 필요한 경우 DB 인스턴스를 다시 시작합니다. B. Auto Scaling 정책을 DB 인스턴스와 함께 사용하여 테스트가 완료되면 자동으로 확장 C. 테스트가 완료되면 스냅샷 생성 DB 인스턴스를 종료하고 필요한 경우 스냅샷을 복원합니다. D. 테스트가 완료되면 DB 인스턴스를 저용량 인스턴스로 수정 필요한 경우 DB 인스턴스를 다시 수정 #\rAnswer\r...\rAnswer: C\r#\rQ137\r#\r한 회사가 다른 지역에 자사 환경의 격리된 백업을 만들었습니다.응용 프로그램이 웜 대기 모드에서 실행 되 고 응용 프로그램 로드 밸런서 (ALB) 앞에 있습니다.현재 장애 조치 프로세스는 수동이며 다른 지역의 보조 ALB를 가리키도록 DNS 별칭 레코드를 업데이트해야 합니다. 페일오버 프로세스를 자동화하기 위해 솔루션 설계자가 수행해야 하는 작업은 무엇입니까?\nA. ALB 상태 확인을 활성화합니다. B. Amazon Route 53 상태 확인을 활성화합니다. C. Amazon Route 53에서 ALB 엔드포인트를 가리키는 CNAME 레코드를 생성합니다. D. Amazon Route 53에서 내부 BIND DNS 서버를 가리키는 조건부 전달 규칙을 생성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ138\r#\r회사는 Amazon RDS 데이터베이스에 대한 우려가 있습니다.워크로드는 예측할 수 없으며, 새로운 사용자 등록의 주기적인 홍수로 인해 회사의 스토리지가 부족할 수 있습니다.데이터베이스는 300GB의 저장소가 있는 범용 인스턴스에서 실행됩니다.솔루션 설계자는 회사에 무엇을 추천해야합니까?\nA. RDS 스토리지 자동 크기 조정을 활성화합니다. B. 수직 인스턴스 배율 조정을 예약합니다. C. 스토리지 최적화 인스턴스 유형으로 변경하고 데이터베이스를 세로로 확장합니다. D. 스토리지 공간이 부족할 때 RDS 스토리지를 1GiB 증가하도록 AWS Lambda 함수를 구성합니다. #\rAnswer\r...\rAnswer: D\r#\rQ139\r#\r한 회사에서 재무 검토를 위해 AWS 비용을 모니터링하려고 합니다.클라우드 운영 팀은 AWS 조직 마스터 계정의 아키텍처를 설계하여 모든 구성원 계정에 대해 AWS 비용 및 사용 보고서를 쿼리합니다.팀은 한 달에 한 번이 쿼리를 실행하고 청구서에 대한 자세한 분석을 제공해야 합니다. 이러한 요구 사항을 충족하는 가장 확장 가능하고 비용 효율적인 솔루션은 무엇입니까?\nA. 마스터 계정에서 비용 및 사용량 보고서를 활성화합니다.Amazon Kinesis 사용 Amazon EMR 토르 분석에 보고서를 제공합니다. B. 마스터 계정에서 비용 및 사용량 보고서를 활성화합니다.분석을 위해 Amazon S3에 Amazon Athena를 사용하여 보고서를 전송합니다. C. 멤버 계정에 대해 비용 및 사용량 보고서를 활성화합니다.Amazon S3에 보고서를 전송하여 분석을 위해 Amazon Redshift를 사용합니다. D. 멤버 계정에 대해 비용 및 사용량 보고서를 활성화합니다.보고서를 Amazon Kinesis로 전송하여 분석을 위해 Amazon QuickSight 사용 #\rAnswer\r...\rAnswer: B\r#\rQ140\r#\r솔루션 설계자가 사용자의 요청을 수신하는 Amazon API Gateway를 사용하여 새 API를 설계하고 있습니다. 요청 볼륨은 매우 다양하며 단일 요청을 수신하지 않고 몇 시간이 경과할 수 있습니다. 데이터 처리는 비동기적으로 수행되지만 몇 초 내에 완료되어야 합니다.요청 후 솔루션 설계자가 가장 낮은 비용으로 요구 사항을 제공하기 위해 API를 호출해야하는 컴퓨팅 서비스는 무엇입니까?\nA. AWS 글루 작업 B. AWS Lambda 함수 C. Amazon EKS (Elastic Kubernetes 서비스) 에서 호스팅되는 컨테이너화된 서비스 D. Amazon EC2와 함께 Amazon ECS에서 호스팅되는 컨테이너화된 서비스 #\rAnswer\r...\rAnswer: B\r#\rQ141\r#\r회사는 3계층 웹 애플리케이션을 온프레미스에서 AWS 클라우드로 마이그레이션하기로 결정합니다.새 데이터베이스는 스토리지 용량을 동적으로 확장하고 테이블 조인을 수행할 수 있어야 합니다. 이러한 요구 사항을 충족하는 AWS 서비스는 무엇입니까?\nA. Amazon Aurora B. SQL서버용 Amazon RDS C. Amazon DynamoDB 스트림 D. 온 디맨드 Amazon DynamoDB #\rAnswer\r...\rAnswer: A\r#\rQ142\r#\r솔루션 설계자가 새 AWS 계정을 생성했으며 AWS 계정 루트 사용자 액세스를 보호해야 합니다. 어떤 작업 조합이 이를 수행할 수 있습니까?(두 개를 선택합니다.)\nA. 루트 사용자가 강력한 암호를 사용하는지 확인합니다. B. 루트 사용자에게 다중 요소 인증을 활성화합니다. C. 루트 사용자 액세스 키를 암호화된 Amazon S3 버킷에 저장 D. root 사용자를 관리 권한이 포함된 그룹에 추가합니다. E. 인라인 정책 문서를 사용하여 루트 사용자에게 필요한 사용 권한 적용 #\rAnswer\r...\rAnswer: A B\r#\rQ143\r#\r한 회사가 데이터 스토리지에 Amazon DynamoDB 테이블을 사용할 계획입니다.이 회사는 비용 최적화에 대해 우려하고 있습니다.이 테이블은 저녁에는 대부분의 아침에 사용되지 않으며 읽기 및 쓰기 트래픽은 예측할 수 없는 경우가 많습니다. 트래픽 급증이 발생하면 매우 빠르게 발생합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. 온 디맨드 용량 모드에서 DynamoDB 테이블을 생성합니다. B. 글로벌 보조 인덱스가 있는 DynamoDB 테이블 생성 C. 프로비저닝된 용량과 Auto Scaling을 사용하여 DynamoDB 테이블을 생성합니다. D. 프로비저닝된 용량 모드에서 DynamoDB 테이블을 생성하고 글로벌 테이블로 구성합니다. #\rAnswer\r...\rAnswer: A\r#\rQ144\r#\r솔루션 설계자는 고가용성 접속 호스트 아키텍처를 구축해야 합니다.솔루션은 단일 AWS 리전 내에서 복원력이 있어야 하며 유지 관리를 위해 최소한의 노력만 하면 됩니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?\nA. UDP 수신기가 있는 Auto Scaling 그룹에서 지원하는 네트워크 로드 밸런서를 생성합니다. B. 스팟 집합이 지원하는 네트워크 로드 밸런서를 생성하여 파티션 배치 그룹에 인스턴스가 있는 그룹에 인스턴스를 생성합니다. C. 서로 다른 가용 영역에 있는 기존 기능을 대상으로 지원하는 네트워크 로드 밸런서를 만듭니다. D. 여러 가용 영역에 있는 인스턴스를 대상으로 사용하여 Auto Scaling을 지원하는 네트워크 로드 밸런서를 생성합니다. #\rAnswer\r...\rAnswer: D\r#\rQ145\r#\rAmazon EC2 관리자가 여러 사용자를 포함하는 IAM 그룹과 연결된 다음 정책을 생성했습니다.\n정책의 효과는 무엇입니까?\nA. 사용자는 us-east-1을 제외한 모든 AWS 리전에서 EC2 인스턴스를 종료할 수 있습니다. B. 사용자는 us-east-1 리전 C에서 IP 주소가 10.100. 1001 인 EC2 인스턴스를 종료할 수 있습니다. - C. 사용자는 사용자의 소스 IP가 10.100.100.254인 경우 us-east-1 리전에서 EC2 인스턴스를 종료할 수 있습니다. D. 사용자의 소스 IP가 10.100.100인 경우 사용자는 us-east-1 리전에서 EC2 인스턴스를 종료할 수 없습니다. #\rAnswer\r...\rAnswer: C\r#\rQ146\r#\r회사 많은 양의 데이터를 저장할 새 응용 프로그램을 만들고 있습니다.데이터는 매시간 분석되며 여러 가용 영역에 배포된 여러 Amazon EC2 Linux 인스턴스에 의해 수정됩니다. 향후 6개월 동안 필요한 스토리지 공간이 계속 늘어날 것입니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 스토리지 솔루션을 권장해야 합니까?\nA. Amazon S3 Glacier에 데이터를 저장하여 애플리케이션 인스턴스에 대한 액세스를 허용하도록 S3 Glacier 저장소 정책을 업데이트합니다. B. Amazon EBS (Elastic Block Store) 볼륨에 데이터를 저장합니다. EBS 볼륨을 애플리케이션 인스턴스에 마운트합니다. C. Amazon EFS (Elastic 파일 시스템) 파일 시스템에 데이터를 저장합니다.애플리케이션 인스턴스에 파일 시스템 마운트 D. 애플리케이션 인스턴스 간에 공유되는 Amazon Elastic 블록 스토어 (Amazon ESS) 프로비저닝된 IOPS 볼륨에 데이터 저장 #\rAnswer\r...\rAnswer: C\r#\rQ147\r#\r솔루션 설계자가 회사의 온프레미스 Linux 서버 및 애플리케이션과 함께 사용할 수 있는 AWS 파일 스토리지 솔루션을 조사하고 있습니다. 이 회사는 회사의 VPC와 온프레미스 네트워크 간에 기존 VPN 연결이 설정되어 있습니다.솔루션 설계자가 사용해야 하는 AWS 서비스는 무엇입니까?(두 개 선택)\nA. AWS 백업 B. AWS 데이터비동기 C. AWS Snowball Edge D. AWS 스토리지 게이트웨이 E. Amazon Elastic File System (Amazon EFS) #\rAnswer\r...\rAnswer: A E\r#\rQ148\r#\r회사는 글로벌 사용자가 여러 AWS 지역에 배포된 애플리케이션에 액세스하여 퍼블릭 고정 IP 주소를 노출합니다.인터넷을 통해 응용 프로그램에 액세스 할 때 사용자는 성능이 저하됩니다. 솔루션 설계자는 인터넷 대기 시간을 줄이기 위해 무엇을 권장해야합니까?\nA. AWS Global Accelerator를 설정하고 엔드포인트를 추가합니다. B. 여러 리전에서 AWS 다이렉트 커넥트 위치를 설정합니다. C. 애플리케이션에 액세스하기 위해 Amazon CloudFront 배포를 설정합니다. D. 트래픽을 라우팅하기 위해 Amazon Route 53 지리적 근접 라우팅 정책을 설정합니다. #\rAnswer\r...\rAnswer: A\r#\rQ149\r#\r회사는 Amazon S3 버킷을 사용하여 정적 이미지를 저장하는 웹 사이트를 설계하고 있습니다.이 회사는 지연 시간과 비용을 모두 줄이면서 이후의 레일 요청에 테이스터 응답 시간을 갖기를 원합니다.솔루션 설계자가 권장하는 서비스 구성은 무엇입니까?\nA. Amazon S3 앞에 NAT 서버를 배포합니다. B. Amazon S3 앞에 Amazon CloudFront를 배포합니다. C. Amazon S3 앞에 네트워크 로드 밸런서를 배포합니다. D. Auto Scaling을 구성하여 웹 사이트의 용량을 자동으로 조정합니다. #\rAnswer\r...\rAnswer: B\r#\rQ150\r#\r회사는 전자 상거래 웹 사이트를위한 다중 계층 응용 프로그램을 만들었습니다.이 웹 사이트는 퍼블릭 서브넷에 상주하는 애플리케이션 로드 밸런서, 퍼블릭 서브넷의 웹 계층, 프라이빗 서브넷의 Amazon EC2 인스턴스에서 호스팅되는 MySQL 클러스터를 사용합니다.MySQL 데이터베이스는 타사 공급자가 인터넷에서 호스팅하는 제품 카탈로그 및 가격 정보를 검색해야 합니다.솔루션 설계자는 운영 오버헤드를 늘리지 않고 보안을 극대화하는 전략을 고안해야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?\nA. VPC에 NAT 인스턴스를 배포합니다.NAT 인스턴스를 통해 모든 인터넷 기반 트래픽을 라우팅합니다. B. 퍼블릭 서브넷에 NAT 게이트웨이를 배포합니다.모든 인터넷 바운드 트래픽을 NAT 게이트웨이로 전송하도록 프라이빗 서브넷 라우팅 테이블을 수정합니다. C. 인터넷 게이트웨이를 구성하고 VPC에 연결합니다.인터넷 바운드 트래픽을 인터넷 게이트웨이로 전송하도록 프라이빗 서브넷 라우팅 테이블을 수정합니다. D. 가상 프라이빗 게이트웨이를 구성하여 VPC에 연결합니다.프라이빗 서브넷 라우팅 테이블을 수정하여 인터넷 바운드 트래픽을 가상 프라이빗 게이트웨이로 향하게 합니다. #\rAnswer\r...\rAnswer: B\r#\rQ151\r#\r애플리케이션이 Amazon RDS MySQL DB 인스턴스를 사용합니다.RDS 데이터베이스의 디스크 공간이 부족해지고 있습니다. 한 솔루션 설계자가 가동 중지 시간 없이 디스크 공간을 늘리려고 합니다. 어떤 솔루션이 최소한의 노력으로 이러한 요구 사항을 충족합니까?\nA. RDS에서 스토리지 자동 크기 조정을 활성화합니다. B. RDS 데이터베이스 인스턴스 크기 늘리기 C. RDS 데이터베이스 인스턴스 스토리지 유형을 프로비저닝된 IOPS로 변경합니다. D. RDS 데이터베이스 백업, 스토리지 용량 증가, 데이터베이스 복원 및 이전 인스턴스 중지 #\rAnswer\r...\rAnswer: A\r#\rQ152\r#\r회사에서 Amazon Aurora를 실행하는 Amazon RDS DB 인스턴스를 배포할 계획입니다. 이 회사는 백업 보존 정책 요구 사항이 90일이면 솔루션 설계자가 권장해야 하는 솔루션은 무엇입니까?\nA. RDS DB 인스턴스를 만들 때 백업 보존 기간을 90일로 설정합니다. B. 90일 후에 삭제하도록 수명 주기 정책이 설정된 사용자 관리 Amazon S3 버킷에 자동 스냅샷을 복사하도록 RDS를 구성합니다. C. 보존 기간이 90일로 설정된 RDS 데이터베이스의 일일 스냅샷을 수행할 AWS 백업 계획 생성 AWS 백업 작업을 생성하여 매일 백업 계획 실행을 예약합니다. D. Amazon CloudWatch 이벤트와 함께 매일 예약된 이벤트를 사용하여 RDS 자동 스냅샷 삭제 스냅샷 사본을 만드는 사용자 지정 AWS Lambda 함수를 실행합니다. 이 기능은 90일이 넘은 스냅샷을 삭제합니다. #\rAnswer\r...\rAnswer: C\r#\rQ153\r#\r회사의 클라우드 운영 팀은 리소스 문제 해결을 표준화하려고 합니다.이 회사는 AWS 조직의 조직 내 모든 구성원 계정에 대한 표준 거버넌스 평가 및 교정 세트를 제공하려고 합니다. 회사에서 최소한의 운영 노력으로 이러한 요구 사항을 충족하기 위해 어떤 자체 관리형 AWS 서비스를 사용할 수 있습니까?\nA. AWS 보안 허브 규정 준수 표준 B. AWS 구성 준수 팩 C. AWS CloudTrail D. AWS 신뢰할 수 있는 #\rAnswer\r...\rAnswer: A\r#\rQ154\r#\r회사가 회사의 Amazon SQS (단순 대기열 서비스) 대기열에 대한 쓰기 액세스가 필요한 외부 공급업체와 협력하고 있습니다.공급업체에 자체 AWS 계정이 있습니다.솔루션 설계자가 최소한의 권한 액세스를 구현하기 위해 무엇을해야합니까?\nA. SQS 대기열의 권한 정책을 업데이트하여 공급업체의 AWS 계정에 대한 쓰기 액세스 권한을 부여합니다. B. SQS 대기열에 대한 쓰기 권한이 있는 IAM 사용자를 생성하고 IAM 사용자의 자격 증명을 공유합니다. C. 공급업체의 AWS 계정에서 SQS 대기열에 대한 쓰기 액세스 권한을 제공하도록 AWS 리소스 액세스 관리자를 업데이트합니다. D. 모든 SQS 대기열에 액세스할 수 있는 교차 계정 역할을 생성하고 해당 역할에 대한 신뢰 문서에서 공급업체의 AWS 계정을 사용합니다. #\rAnswer\r...\rAnswer: A\r#\rQ155\r#\r게임 회사는 레이어 4의 사용자와 통신하는 멀티플레이어 게임을 위해 단일 가용 영역에 여러 Amazon EC2 인스턴스를 보유하고 있습니다.CTO (최고 기술 책임자) 는 높은 가용성과 비용 효율적인 아키텍처를 만들고자 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?(두 개를 선택합니다.)\nA. EC2 인스턴스 수 늘리기 B. EC2 인스턴스 수 감소 C. EC2 인스턴스 앞에 네트워크 로드 밸런서를 구성합니다. D. EC2 인스턴스 앞에 애플리케이션 로드 밸런서 구성 E. 여러 가용 영역의 인스턴스를 자동으로 추가 또는 제거하도록 Auto Scaling 그룹 구성 #\rAnswer\r...\rAnswer: C E\r#\rQ156\r#\r회사는 이전 뉴스 영상을 통해 AWS에 비디오 아카이브를 저장할 수 있는 솔루션을 찾고 있습니다.이 회사는 비용을 최소화해야 하며 이러한 파일을 복구할 필요가 거의 없습니다.파일이 필요한 경우 최대 5 분 안에 파일을 사용할 수 있어야 합니다. 가장 비용 효율적인 솔루션이란 무엇입니까?\nA. 비디오 아카이브를 Amazon S3 Glacier에 저장하고 빠른 검색을 사용합니다. B. 비디오 아카이브를 Amazon S3 Glacier에 저장하고 표준 검색을 사용합니다. C. 비디오 아카이브를 Amazon S3 표준 Standard Infrequent Access (S3 표준-IA) 에 저장합니다. D. 비디오 아카이브를 Amazon S3 One Zone Standard Infrequent Access (S3 원 영역-IA) 에 저장합니다. #\rAnswer\r...\rAnswer: A\r#\rQ157\r#\r회사의 거의 실시간에 가까운 스트리밍 애플리케이션이 AWS에서 실행 중입니다. (데이터는 데이터에서 작업을 실행하고 완료하는 데 30분 소요. 대량의 수신 데이터로 인해 워크로드의 지연 시간이 자주 발생합니다. 솔루션 설계자는 확장 가능하고 서버를 사용하지 않는 솔루션을 설계해야 합니다.성능을 향상시키기 위해 솔루션 설계자가 수행해야 할 단계 조합은 무엇입니까?(두 개 선택)\nA. Amazon Kinesis Data Firehose를 사용하여 데이터 수집 B. AWS 단계 함수와 함께 AWS Lambda를 사용하여 데이터 처리 C. AWS 데이터베이스 마이그레이션 서비스 (AWS DMS) 를 사용하여 데이터 수집 D. Auto Scaling 그룹의 Amazon EC2 인스턴스를 사용하여 데이터 처리 E. AWS Fargate와 Amazon Elastic 컨테이너 서비스 (Amazon ECS) 를 사용하여 데이터를 처리합니다. #\rAnswer\r...\rAnswer: A E\r#\rQ158\r#\r웹 애플리케이션은 순시간 처리를 지원하기 위해 주문 데이터를 Amazon S3에 유지해야 합니다.솔루션 설계자는 확장 가능하고 내결함성이 있는 아키텍처를 만들어야 합니다.이러한 요구 사항을 충족하는 솔루션은 무엇입니까?(두 개 선택)\nA. 주문 이벤트를 Amazon DynamoDB 테이블에 기록합니다.DynamoDB 스트림을 사용하여 페이로드를 구문 분석하고 Amazon S3에 데이터를 쓰는 AWS Lambda 함수를 트리거합니다. B. 주문 이벤트를 Amazon SQS (단순 대기열 서비스) 대기열에 기록합니다.대기열을 사용하여 페이로드를 파싱하고 Amazon S3에 데이터를 쓰는 AWS Lambda 함수를 트리거합니다. C. Amazon SNS (단순 알림 서비스) 주제에 주문 이벤트를 작성합니다.SNS 주제를 사용하여 페이로드를 구문 분석하고 Amazon S3에 데이터를 쓰는 AWS Lambda 함수를 트리거합니다. D. 주문 이벤트를 Amazon SQS (단순 대기열 서비스) 대기열에 기록합니다.Amazon 이벤트 브리지 (Amazon CloudWatch 이벤트) 규칙을 사용하여 페이로드를 구문 분석하고 Amazon S3에 데이터를 쓰는 AWS Lambda 함수를 트리거합니다. E. Amazon SNS (단순 알림 서비스) 주제에 주문 이벤트 작성 Amazon 이벤트 브리지 (Amazon CloudWatch 이벤트) 규칙을 사용하여 페이로드를 구문 분석하고 데이터를 Amazon S3에 쓰는 AWS Lambda 함수를 트리거합니다. #\rAnswer\r...\rAnswer: A C\r#\rQ159\r#\rAWS에서 웹 애플리케이션을 호스팅하는 회사는 모든 Amazon EC2 인스턴스를 보장하고자 합니다.Amazon RDS DB 인스턴스와 Amazon Redshift 클러스터는 태그로 구성됩니다.이 회사는 이 수표를 구성하고 운영하기 위한 노력을 최소화하려고 합니다.이를 달성하기 위해 솔루션 설계자는 무엇을해야합니까?\nA. AWS Config 규칙을 사용하여 속성 태그가 지정되지 않은 리소스를 정의하고 검색합니다. B. 원가 탐색기를 사용하여 올바르게 태그가 지정되지 않은 자원을 표시할 수 있습니다. C. 적절한 태그 할당을 위해 모든 리소스를 검사하는 API 호출을 작성합니다.EC2 인스턴스에서 정기적으로 코드를 실행합니다. D. 적절한 태그 할당을 위해 모든 리소스를 검사하는 API 호출을 작성합니다.Amazon CloudWatch를 통해 AWS Lambda 함수를 예약하여 주기적으로 코드를 실행합니다. #\rAnswer\r...\rAnswer: A\r#\rQ160\r#\r회사는 고객이 웹 사이트에 사진을 업로드 할 수있는 모바일 앱을 설계합니다.앱에는 다중 요소 인증 (MFA) 을 사용한 보안 로그인이 필요합니다.이 회사는 초기를 제한하고 싶어합니다. 빌드 시간 및 솔루션 유지 관리 솔루션 설계자가 이러한 요구 사항을 충족하기 위해 권장해야 하는 솔루션은 무엇입니까?\nA. SMS 기반 MFA와 함께 Amazon Cognito ID를 사용합니다. B. 모든 사용자에 대해 MFA를 요구하도록 IAM 정책을 편집합니다. C. MFA가 필요한 기업 Active Directory에 대해 IAM을 통합 D. Amazon API 게이트웨이를 사용하고 사진에 서버 측 암호화 (SSE) 필요 #\rAnswer\r...\rAnswer: A\r#\rQ161\r#\r솔루션 설계자는 암호화되지 않은 EBS 스냅샷에서 복원된 모든 Amazon Elastic Block Store (Amazon EBS) 볼륨이 암호화되도록 해야 하는 경우 솔루션 설계자가 이를 수행하려면 어떻게 해야 합니까?\nA. AWS 리전에서 EBS 암호화를 기본적으로 활성화합니다. B. 특정 볼륨에 대해 기본적으로 EBS 암호화를 활성화합니다. C. 새 볼륨을 생성하고 암호화에 사용할 대칭 고객 마스터 키 (CMK) 를 지정합니다. D. 새 볼륨을 생성하고 암호화에 사용할 비대칭 고객 마스터 키 (CMK) 를 지정합니다. #\rAnswer\r...\rAnswer: A\r#\rQ162\r#\r응용 프로그램에는 몇 년 동안 개발 환경 (DEV) 및 프로덕션 환경 (PROD) 이 필요합니다.DEV 인스턴스는 일반 업무 시간 동안 매일 10시간 동안 실행되며 PROD 인스턴스는 매일 24시간 실행됩니다.솔루션 설계자는 비용을 최소화하기 위해 컴퓨팅 인스턴스 구매 전략을 결정해야 합니다. 가장 비용 효율적인 솔루션은 무엇입니까?\nA. 스팟 인스턴스를 사용하는 DEV 및 온 디맨드 인스턴스를 사용하는 PROD B. 온 디맨드 인스턴스를 사용하는 DEV 및 스팟 인스턴스가 있는 PROD C. 예약 인스턴스를 사용하는 DEV 및 예약 인스턴스를 사용하는 PROD D. 온디맨드 인스턴스를 사용하는 DEV 및 예약된 예약 인스턴스가 있는 PROD #\rAnswer\r...\rAnswer: A\r#\rQ163\r#\r회사의 재무 애플리케이션은 월별 보고서를 Amazon S3 버킷에 저장합니다.재무 담당 부사장은 이러한 보고서에 대한 모든 액세스 권한을 기록하고 로그 파일에 대한 수정 사항을 탐지하도록 요구했습니다. 솔루션 설계자가 이러한 요구 사항을 충족하기 위해 어떤 조치를 취할 수 있습니까?\nA. 데이터 읽기 및 쓰기 이벤트와 로그 파일 유효성 검사 옵션이 활성화된 보고서를 보관하는 버킷에서 S3 서버 액세스 로깅을 사용합니다. B. 읽기 및 쓰기 관리 이벤트와 로그 파일 유효성 검사 옵션이 활성화된 보고서를 보관하는 버킷에서 S3 서버 액세스 로깅을 사용합니다. C. AWS CloudTrail을 사용하여 새 트레일을 만듭니다.보고서를 저장하는 S3 버킷에 데이터 읽기 및 쓰기 이벤트를 기록하도록 추적 구성 이러한 이벤트를 새 버킷에 기록하고 로그 파일 유효성 검사를 활성화합니다. D. AWS CloudTrail을 사용하여 새 트레일을 생성합니다.보고서를 보관하는 S3 버킷에 읽기 및 쓰기 관리 이벤트를 기록하도록 추적을 구성합니다.이러한 이벤트를 새 버킷에 기록하고 로그 파일 유효성 검사를 활성화합니다. #\rAnswer\r...\rAnswer: C\r#\rQ164\r#\r솔루션 설계자는 AWS 클라우드를 사용하여 하이브리드 애플리케이션을 설계하고 있습니다.온프레미스 데이터 센터와 AWS 간의 네트워크는 AWS Direct Connect (DX) 연결을 사용합니다.AWS와 온프레미스 데이터 센터 간의 애플리케이션 연결은 복원력이 뛰어나야 합니다.이러한 요구 사항을 충족하려면 어떤 DX 구성을 구현해야 합니까?\nA. 위에 VPN을 사용하여 DX 연결을 구성합니다. B. 여러 DX 위치에서 DX 연결을 구성합니다. C. 가장 신뢰할 수 있는 DX 파트너를 사용하여 DX 연결을 구성합니다. D. DX 연결 위에 여러 가상 인터페이스를 구성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ165\r#\r회사는 데이터 센터의 NAS (Network Attached Storage) 에 저장된 700TB의 백업 데이터를 보유하고 있습니다. 이 백업 데이터는 규정 요구 사항이 드물기 때문에 액세스할 수 있어야 하며 7년 동안 보존해야 합니다.이 회사는 데이터 센터에서 AWS로 이 백업 데이터를 마이그레이션하기로 결정했습니다.마이그레이션은 1개월 이내에 완료되어야 합니다. 회사는 공용 인터넷 연결에 500Mbps의 전용 대역폭을 보유하고 있어 데이터 전송에 사용할 수 있습니다.가장 낮은 비용으로 데이터를 마이그레이션하고 저장하려면 솔루션 설계자가 수행해야 하는 작업은 무엇입니까?\nA. AWS Snowball 디바이스를 주문하여 데이터를 전송합니다.수명 주기 정책을 사용하여 파일을 Amazon S3 Glacier 딥 아카이브로 전환 B. 데이터 센터와 Amazon VPC 간에 VPN 연결 배포 AWS CLI를 사용하여 온프레미스에서 Amazon S3 Glacier로 데이터를 복사합니다. C. 500Mbps AWS Direct Connect 연결을 프로비저닝하고 데이터를 Amazon S3로 전송합니다.수명 주기 정책을 사용하여 파일을 Amazon S3 Glacier 딥 아카이브로 전환합니다. D. AWS DataSync를 사용하여 데이터를 전송하고 온프레미스에 DataSync 에이전트 배포 DataSync 작업을 사용하여 Amazon S3 Glacier의 온 프레미스 NAS 스토리지에서 파일을 복사합니다. #\rAnswer\r...\rAnswer: A\r#\rQ166\r#\r회사는 AWS의 컨테이너를 사용하여 웹 애플리케이션을 구축하고 있습니다.회사는 웹 응용 프로그램의 세 인스턴스를 항상 실행해야합니다.애플리케이션은 수요 증가에 맞춰 확장할 수 있어야 합니다. 관리는 비용에 매우 민감하지만 응용 프로그램의 가용성이 높아야 한다는 데 동의합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. Fargate 시작 유형을 사용하여 Amazon ECS (Amazon 탄력적 컨테이너 서비스) 클러스터를 생성합니다.웹 응용 프로그램에 대한 작업 정의를 생성합니다.원하는 세 가지 작업 수를 사용하여 ECS 서비스를 만듭니다. B. 하나의 가용 영역에 3개의 컨테이너 인스턴스가 있는 Amazon EC2 시작 유형을 사용하여 Amazon ECS (Amazon Elastic Container Service) 클러스터를 생성합니다.웹 응용 프로그램에 대한 작업 정의를 생성합니다. 각 컨테이너 인스턴스에 대해 하나의 작업을 배치합니다. C. 3개의 가용 영역에 있는 하나의 컨테이너 인스턴스와 함께 Fargate 시작 유형을 사용하여 Amazon ECS (Amazon Elastic Container Service) 클러스터를 생성합니다.웹 응용 프로그램에 대한 작업 정의를 생성합니다.원하는 세 가지 작업 수를 사용하여 ECS 서비스를 만듭니다. D. 두 개의 다른 가용 영역에 있는 하나의 컨테이너 인스턴스와 함께 Amazon EC2 시작 유형을 사용하여 Amazon ECS (Amazon Elastic Container Service) 클러스터를 생성합니다.웹 응용 프로그램에 대한 작업 정의를 생성합니다.하나의 컨테이너 인스턴스에 두 개의 작업을 배치하고 나머지 컨테이너 인스턴스에 하나의 작업을 배치합니다. #\rAnswer\r...\rAnswer: A\r#\rQ167\r#\r비즈니스 애플리케이션은 Amazon EC2에서 호스팅되며 암호화된 객체 스토리지에 Amazon S3를 사용합니다.최고 정보 보안 책임자는 두 서비스 간의 애플리케이션 트래픽이 공용 인터넷을 통과하지 않도록 지시했습니다. 솔루션 설계자는 규정 준수 요구 사항을 충족하기 위해 어떤 기능을 사용해야 합니까?\nA. AWS 키 관리 서비스 (AWS KMS) B. VPC 엔드 C. 프라이빗 서브넷 D. 가상 프라이빗 게이트웨이 #\rAnswer\r...\rAnswer: B\r#\rQ168\r#\r한 회사는 많은 Amazon EC2 인스턴스를 사용하여 이를 완료하는 매우 동적인 일괄 처리 작업을 보유하고 있습니다. 이 작업은 본질적으로 무국적이며 부정적인 영향없이 언제든지 시작 및 중지 할 수 있으며 일반적으로 완료하는 데 60 분 이상 걸립니다. 이 회사는 솔루션 설계자에게 작업의 요구 사항을 충족하는 확장 가능하고 비용 효율적인 솔루션을 설계하도록 요청했습니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. EC2 스팟 인스턴스 구현 B. EC2 예약 인스턴스 구매 C. EC2 온 디맨드 인스턴스 구현 D. AWS Lambda에서 처리 구현 #\rAnswer\r...\rAnswer: A\r#\rQ169\r#\r전자 상거래 웹 사이트의 제품 관리자가 다음 달에 새로운 제품 라인을 출시합니다.웹 사이트를 호스팅하는 애플리케이션은 로드 밸런서 뒤에 있는 Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행됩니다.테스트가 수행되었으며 출시 시 최대 부하가 추정되었습니다.응용 프로그램에 대한 트래픽은 출시 후 처음 몇 주 이내에 점진적으로 감소 할 것으로 예상됩니다.이 워크로드는 시작 중에 확장될 것으로 예상되는 유일한 워크로드입니다.시작 시 애플리케이션이 확장될 때 적절한 용량을 확보하기 위해 가장 비용 효율적인 단계는 무엇입니까?(두 개를 선택합니다.)\nA. 영역 범위의 예약 인스턴스 (RI) 를 구매하여 용량을 예약하고 컴퓨팅 할인을 받을 수 있습니다. 그런 다음 출시 후 리스를 취소합니다. B. AWS에 문의하여 AWS 리전에서 가장 많은 사용자에게 가까운 하드웨어를 예약합니다. C. 계정에서 EC2 서비스 할당량을 확인하고 시작 시 예상 부하보다 값이 낮으면 증가를 요청합니다. D. 예약된 인스턴스를 구매하여 시작 용량을 예약하고 최대 용량 시간 동안 일일 일정에 따라 실행합니다. #\rAnswer\r...\rAnswer: A D\r#\rQ170\r#\r회사는 사진 용 클라우드 스토리지를 구축하고 애플리케이션을 공유하고 있습니다.사용자는 자신의 컴퓨터와 휴대 전화에서 사진을 업로드 할 수 있습니다. 사진은 업로드, 대부분은 처음 40-90 일 동안 자주 공유 및 다운로드됩니다.사진은 일반적으로 90일 후에 덜 자주 액세스되지만 일부 사진은 높은 액세스 속도를 유지합니다.애플리케이션은 처음에 Amazon S3 Standard A 솔루션 설계자가 사용자 경험이나 데이터 내구성을 저하시키지 않으면서 애플리케이션의 운영 비용을 절감해야 하는 사진을 Amazon S3 Standard A 에 저장합니다. 솔루션 설계자는 이러한 요구 사항을 가장 비용 효율적으로 충족하기 위해 어떤 전략을 사용해야 합니까?\nA. S3 Intelliginet 계층화로 객체를 즉시 전환하는 S3 수명 주기 규칙을 정의합니다. B. 90일 후에 S3 표준에서 S3 Glacier로 객체를 전환하는 S3 수명 주기 규칙을 정의합니다. C. 65일 후에 S3 표준에서 S3 표준 Standard Infrequent Access (S3 표준-IA) 로 객체를 전환하는 S3 수명 주기 규칙을 정의합니다. D. 90일 후에 S3 표준에서 S3 1영역 자주 사용되지 않는 액세스 (S3 One Zone-IA) 로 객체를 전환하는 S3 수명 주기 규칙을 정의합니다. #\rAnswer\r...\rAnswer: A\r#\rQ171\r#\r회사는 사용자 데이터를 AWS에 저장합니다.데이터는 업무 시간 동안 최대 사용량에 따라 지속적으로 사용됩니다. 액세스 패턴은 다양하며 일부 데이터는 한 번에 몇 달 동안 사용되지 않습니다.솔루션 설계자는 고가용성을 유지하면서 최고 수준의 내구성을 유지하는 비용 효율적인 솔루션을 선택해야 합니다. 이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까?\nA. Amazon S3 표준 B. Amazon S3 Intelliginet 계층화 C. Amazon S3 Glacier 딥 아카이브 D. Amazon S3 One Zone 드문 액세스 (자체 One Zone-IA) #\rAnswer\r...\rAnswer: B\r#\rQ172\r#\r회사의 도메인 네임 레코드를 호스팅하는 DNS 공급자가 AWS에서 실행되는 웹 사이트의 서비스 중단을 야기하는 중단을 겪고 있습니다. 회사는 복원력이 뛰어난 관리형 DNS 서비스로 마이그레이션해야 하며 AWS에서 서비스를 실행하기를 원합니다.솔루션 설계자는 DNS 호스팅 서비스를 신속하게 마이그레이션하기 위해 무엇을해야합니까?\nA. 도메인 이름에 대한 Amazon Route 53 퍼블릭 호스팅 영역을 생성합니다.이전 공급자가 호스팅하는 도메인 레코드가 포함된 영역 파일을 가져옵니다. B. 도메인 이름에 대한 Amazon Route 53 프라이빗 호스팅 영역 생성 이전 공급자가 호스팅하는 도메인 레코드가 포함된 영역 파일을 가져옵니다. C. AWS에서 단순 AD 디렉토리를 생성합니다.도메인 레코드에 대해 DNS 공급자와 Microsoft Active Directory용 AWS 디렉터리 서비스 간의 영역 전송을 활성화합니다. D. VPC에 Amazon Route 53 확인자 인바운드 엔드포인트 생성 공급자의 DNS가 DNS 쿼리를 전달할 IP 주소를 지정합니다. 다음 주소로 도메인에 대한 DNS 쿼리를 인바운드 엔드포인트에 지정된 IP 주소로 전달하도록 공급자의 DNS를 구성합니다. #\rAnswer\r...\rAnswer: A\r#\rQ173\r#\r솔루션 설계자는 개발자에게 AWS 조직을 통해 개별 AWS 계정을 제공하는 동시에 표준 보안 제어를 유지하려는 기업을 위한 보안 솔루션을 설계하고 있습니다. 개별 개발자는 자신의 AWS 계정 루트 사용자 수준 액세스 권한을 갖게 되므로 계정을 사용하는 경우 솔루션 설계자는 새 개발자 계정에 적용되는 필수 AWS CloudTrail 구성이 수정되지 않는지 확인하려고 합니다. 이러한 요구 사항을 충족하는 작업은 무엇입니까?\nA. CloudTrail에 대한 변경을 금지하는 IAM 정책을 생성하고 이를 루트 사용자에게 연결합니다. B. 조직 추적 옵션이 활성화된 개발자 계정 내에서 CloudTrail에 새 추적을 만듭니다. C. CloudTrail에 대한 변경을 금지하는 SCP (서비스 제어 정책) 를 생성하고 개발자 계정에 연결합니다. D. 마스터 계정의 ARN (Amazon 리소스 이름) 에서만 변경할 수 있는 정책 조건을 사용하여 CloudTrail에 대한 서비스 연결 역할을 생성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ174\r#\r솔루션 설계자는 Amazon Linux를 기반으로 고성능 컴퓨팅 (HPC) 환경을 위한 스토리지를 설계하고 있습니다.워크로드는 공유 스토리지와 대용량 컴퓨팅을 필요로 하는 많은 양의 엔지니어링 도면을 저장하고 처리합니다. 어떤 스토리지 옵션이 최적의 솔루션일까요?\nA. Amazon Elastic 파일 시스템 (Amazon EFS) B. 러스트리를 위한 Amazon FSX C. Amazon EC2 인스턴스 스토어 D. Amazon EBS 프로비저닝된 IOPS SSD (io1) #\rAnswer\r...\rAnswer: B\r#\rQ175\r#\r회사는 미디어 공유 애플리케이션을 구축하고 있으며 스토리지에 Amazon S3를 사용하기로 결정합니다.미디어 파일이 업로드되면 회사는 썸네일을 만들고, 이미지에서 객체를 식별하고, 비디오를 표준 형식과 해상도로 트랜스코딩하고, 메타데이터를 추출하여 Amazon DynamoDB 테이블에 저장하는 다단계 프로세스를 시작합니다.메타데이터는 검색 및 탐색에 사용됩니다. 트래픽 양은 가변적입니다. 솔루션은 불필요한 비용 없이 부하의 급증을 처리할 수 있도록 확장할 수 있어야 합니다. 솔루션 설계자는 이 워크로드를 지원하기 위해 무엇을 권장해야 합니까?\nA. Amazon S3에 콘텐츠를 업로드하는 데 사용되는 웹 사이트 또는 모바일 앱에 프로세스 구축 객체가 업로드될 때 필요한 데이터를 DynamoDB 테이블에 저장합니다. B. 객체가 S3 버킷에 저장되어 있을 때 AWS 단계 함수 트리거 단계 함수가 객체를 처리하는 데 필요한 단계를 수행하도록 한 다음 메타데이터를 DynamoDB 테이블에 씁니다. C. 객체가 S3 버킷에 저장될 때 AWS Lambda 함수 트리거 Lambda 함수가 AWS Batch를 시작하여 객체 처리 단계를 수행합니다. 완료되면 객체 데이터를 DynamoDB 테이블에 배치 D. Amazon S3에 객체를 업로드할 때 DynamoDB 테이블에 초기 항목을 저장하도록 AWS Lambda 함수를 트리거합니다.Auto Scaling 그룹의 Amazon EC2 인스턴스에서 실행 중인 프로그램을 사용하여 프로세스 취소를 위해 인덱스를 폴링하려면 프로그램을 사용하여 처리를 수행합니다. #\rAnswer\r...\rAnswer: C\r#\rQ176\r#\r한 회사에서 1년 동안 Amazon EC2 부분 선결제 예약 인스턴스를 구입했습니다.한 솔루션 설계자가 일일 유효 비용이 가능한 모든 할인을 통해 얼마인지 분석하려고 합니다.올바른 값을 얻으려면 솔루션 설계자가 비용 탐색기의 고급 옵션에서 선택해야하는 뷰는 무엇입니까?\nA. 순 상각 원가 표시 B. 혼합되지 않은 순 원가 표시 C. 상각 비용 표시 D. 혼합 비용 표시 #\rAnswer\r...\rAnswer: C\r#\rQ177\r#\r회사의 웹 애플리케이션이 애플리케이션 로드 밸런서 뒤에 있는 Amazon EC2 인스턴스에서 실행되고 있습니다.회사는 최근에 정책을 변경했으며 이제는 특정 국가에서만 응용 프로그램에 액세스해야합니다. 이 요구 사항을 충족하는 구성은 무엇입니까?\nA. EC2 인스턴스에 대한 보안 그룹을 구성합니다. B. 애플리케이션 로드 밸런서에서 보안 그룹을 구성합니다. C. VPC의 애플리케이션 로드 밸런서에 AWS WAF를 구성합니다. D. EC2 인스턴스가 포함된 서브넷에 대한 네트워크 ACL을 구성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ178\r#\r데이터 과학 팀은 야간 로그 처리를 위한 스토리지가 필요합니다.로그의 크기와 수는 알 수 없으며 24 시간 동안 지속됩니다. 가장 비용 효율적인 솔루션은 무엇입니까?\nA. Amazon S3 Glacier B. Amazon S3 표준 C. Amazon S3 Intelliginet 계층화 D. Amazon S3 One Zone Standard Infrequent Access {S3 One Zone-IA) #\rAnswer\r...\rAnswer: B\r#\rQ179\r#\r한 회사에서 1PB 온프레미스 이미지 리포지토리를 AWS로 마이그레이션하려고 합니다.이미지는 서버리스 웹 응용 프로그램에서 사용됩니다. 저장소에 저장된 이미지는 거의 액세스되지 않지만 즉시 사용할 수 있어야합니다.또한 이미지는 저장 시 암호화해야 하며 실수로 삭제되지 않도록 보호해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 클라이언트 측 암호화를 구현하고 이미지를 Amazon S3 Glacier 저장소에 저장하여 실수로 삭제되지 않도록 저장소 잠금을 설정합니다. B. S3 표준 Standard Infrequent Access (S3 Standard-IA) 스토리지 클래스의 Amazon S3 버킷에 이미지 저장 버전 관리 사용: 기본 암호화 및 MFA 삭제 S3 버킷에 사용 C. Windows용 Amazon FSX 파일 서버 파일 공유에 이미지 저장 AWS KMS (키 관리 서비스) 고객 마스터 키 (CMK) 를 사용하여 파일 공유의 이미지를 암호화하도록 Amazon FSx 파일 공유 구성 실수로 삭제되는 것을 방지하기 위해 이미지에 NTFS 사용 권한 집합 사용 D. 자주 액세스하지 않는 스토리지 클래스의 Amazon EFS (Elastic File System) 파일 공유에 이미지를 저장합니다.실수로 삭제되지 않도록 파일 공유에 있는 이미지를 암호화하기 위해 AWS KMS (키 관리 서비스) 고객 마스터 키 (CMK) 를 사용하도록 EFS 파일 공유를 구성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ180\r#\r회사가 Linux 기반 웹 서버 그룹을 AWS로 마이그레이션하고 있습니다. 웹 서버는 일부 콘텐츠를 위해 공유 파일 저장소의 파일에 액세스해야 합니다. 마이그레이션 날짜를 충족하기 위해 최소한의 변경을 수행할 수 있습니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떻게 해야 합니까?\nA. 웹 서버에 액세스할 수 있는 Amazon S3 표준 버킷을 생성합니다. B. Amazon S3 버킷을 오리진으로 사용하여 Amazon CloudFront 배포를 구성합니다. C. Amazon EFS (Elastic 파일 시스템) 볼륨을 생성하여 모든 웹 서버 D에 마운트합니다. Amazon EBS (Elastic Block Store) 프로비저닝된 IOPS SSD (io1) 볼륨을 구성하고 모든 웹 서버에 마운트합니다. #\rAnswer\r...\rAnswer: C\r#\rQ181\r#\r솔루션 설계자가 매일 한 번 실행되며 완료하는 데 최대 2시간이 걸릴 수 있는 데이터 처리 작업을 만들고 있습니다. 작업이 중단되면 처음부터 다시 시작해야 합니다. 솔루션 설계자는 이 문제를 가장 비용 효율적인 방식으로 어떻게 해결해야 합니까?\nA. cron 작업에 의해 트리거되는 Amazon EC2 예약 인스턴스에서 로컬로 실행되는 스크립트를 생성합니다. B. Amazon 이벤트 브리지 (Amazon CloudWatch 이벤트} 예약 이벤트에 의해 트리거되는 AWS Lambda 함수 생성 C. Amazon EventBridge (Amazon CloudWatch 이벤트) 예약 이벤트에 의해 트리거된 Amazon 탄력적 컨테이너 서비스 (Amazon ECS) Fargate 작업을 사용합니다. D. Amazon EventBridge (Amazon CloudWatch 이벤트) 예약 이벤트에 의해 트리거된 Amazon EC2에서 실행되는 Amazon 탄력적 컨테이너 서비스 (Amazon ECS) 작업을 사용합니다. #\rAnswer\r...\rAnswer: C\r#\rQ182\r#\r전자 상거래 웹 사이트에서 웹 애플리케이션을 Amazon 탄력적 컨테이너 서비스로 배포하고 있습니다. (Amazon ECS) 컨테이너 인스턴스는 애플리케이션 로드 밸런서 (ALB) 뒤에 있습니다.활동이 많은 기간에는 웹 사이트 속도가 느려지고 가용성이 감소합니다.솔루션 설계자는 Amazon CloudWatch 경보를 사용하여 가용성 문제가 발생할 때마다 알림을 수신하여 리소스를 확장할 수 있습니다.회사 경영진은 이러한 이벤트에 자동으로 응답하는 솔루션을 원합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. ALB에 시간 초과가 있을 때 ECS 서비스를 확장하도록 AWS Auto Scaling을 설정하여 CPU 또는 메모리 예약이 너무 높을 때 ECS 클러스터를 확장하도록 AWS Auto Scaling을 설정합니다. B. ALB CPU 사용률이 너무 높을 때 ECS 서비스를 확장하도록 AWS Auto Scaling을 설정합니다.CPU 또는 메모리 예약이 너무 많을 때 ECS 클러스터를 확장하도록 AWS Auto Scaling을 설정합니다. C. 서비스의 CPU 사용률이 너무 높을 때 ECS 서비스를 확장하기 위해 AWS Auto Scaling을 업.CPU 또는 메모리 예약이 너무 많을 때 ECS 클러스터를 확장하도록 AWS Auto Scaling을 설정합니다. D. ALB 대상 그룹 CPU 사용률이 너무 높으면 ECS 서비스를 확장하도록 AWS Auto Scaling을 설정합니다.CPU 또는 메모리 예약이 너무 많을 때 ECS 클러스터를 확장하도록 AWS Auto Scaling을 설정합니다. #\rAnswer\r...\rAnswer: C\r#\rQ183\r#\r한 회사는 최근 Amazon Aurora를 글로벌 전자 상거래 애플리케이션의 데이터 저장소로 사용하기 시작했습니다. 대규모 보고서를 실행하면 개발자는 전자 상거래 응용 프로그램의 성능이 저하되고 있다고 보고합니다.Amazon CloudWatch에서 지표를 검토한 후, 솔루션 설계자는 월별 보고서가 실행될 때 ReadLOP 및 CPU 사용률 지표가 급증하고 있음을 확인합니다. 가장 비용 효율적인 솔루션이란 무엇입니까?\nA. 월별 보고를 Amazon Redshift로 마이그레이션합니다. B. 월별 보고를 Aurora 복제본으로 마이그레이션합니다. C. Aurora 데이터베이스를 더 큰 인스턴스 클래스로 마이그레이션합니다. D. Aurora 인스턴스에서 프로비저닝된 IOPS를 늘립니다. #\rAnswer\r...\rAnswer: D\r#\rQ184\r#\r온라인 사진 애플리케이션을 통해 사용자가 사진을 업로드하고 이미지 편집 작업을 수행할 수 있습니다. 애플리케이션은 무료 및 유료 사용자가 제출한 사진이 처리되기 전에 무료 사용자가 제출한 사진이 Amazon S3에 업로드되고 작업 정보가 Amazon으로 전송됩니다.SQS. 솔루션 설계자가 권장해야 하는 구성은 무엇입니까?\nA. SQS FIFO 대기열 하나 사용 유료 사진이 먼저 처리되도록 먼저 우선 순위를 할당합니다. B. 두 개의 SQS FIFO 대기열 사용: 하나는 유료이고 다른 하나는 무료 대기열은 짧은 폴링을 사용하도록 설정하고 유료 대기열은 긴 폴링을 사용하도록 설정합니다. C. 두 개의 SQS 표준 대기열 하나는 유료 및 무료 Amazon EC2 인스턴스 구성을 사용하여 무료 대기열보다 유료 대기열에 대한 폴링의 우선 순위를 지정합니다. D. SQS 표준 대기열 하나를 사용합니다.유료 사진의 가시성 제한 시간을 0으로 설정 Amazon EC2 인스턴스를 구성하여 가시성 설정의 우선 순위를 지정하여 유료 사진이 먼저 처리되도록 합니다. #\rAnswer\r...\rAnswer: C\r#\rQ185\r#\r솔루션 설계자는 Windows 사용자의 가정에 적합한 탄력적인 솔루션을 설계해야 합니다. 디렉토리에 저장됩니다.이 솔루션은 회사의 Active Directory를 기반으로 내결함성, 파일 레벨 백업/복구, 액세스 제어 기능을 제공해야 합니다. 이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까?\nA. 사용자의 홈 디렉토리를 저장하도록 Amazon S3를 구성합니다.액티브 디렉터리에 Amazon S3를 가입합니다. B. Windows용 Amazon FSX를 사용하여 다중 AZ 파일 시스템을 구성하면 Amazon FSX를 액티브 디렉터리에 가입할 수 있습니다. C. 사용자의 홈 디렉터리에 대해 Amazon EFS (Elastic 파일 시스템) 를 구성합니다.액티브 디렉토리를 사용하여 AWS 싱글 사인온을 구성합니다. D. 사용자의 홈 디렉토리를 저장하도록 Amazon EBS (Elastic Block Store) 구성 Active Directory를 사용하여 AWS 싱글 사인온 구성 #\rAnswer\r...\rAnswer: B\r#\rQ186\r#\r회사가 AWS 클라우드에서 퍼블릭 웹 애플리케이션을 시작할 준비를 하고 있습니다. 아키텍처는 Elastic 로드 밸런서 (ELB) 뒤에 있는 VPC 내의 Amazon EC2 인스턴스로 구성됩니다.타사 서비스는 DNS에 사용됩니다.회사의 솔루션 설계자는 대규모 DDoS 공격을 탐지하고 방어하기 위한 솔루션을 추천해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 계정에서 Amazon GuardDuty 활성화 B. EC2 인스턴스에서 Amazon 검사기 활성화 C. AWS 쉴드를 활성화하고 Amazon Route 53을 할당합니다. D. AWS 쉴드 어드밴스드를 활성화하고 ELB를 할당합니다. #\rAnswer\r...\rAnswer: D\r#\rQ187\r#\r회사는 온-프레미스에서 정적 웹 사이트를 호스팅하고 웹 사이트를 AWS로 마이그레이션하려고 합니다. 전 세계 사용자를 위해 웹 사이트를 최대한 빨리 로드해야 합니다. 또한 가장 비용 효율적인 솔루션을 원합니다.\nA. 웹 사이트 콘텐츠를 Amazon S3 버킷에 복사 정적 웹 페이지 콘텐츠를 제공하도록 버킷 구성 S3 버킷을 여러 AWS 리전으로 복제 B. 웹 사이트 콘텐츠를 Amazon S3 버킷에 복사 정적 웹 페이지 콘텐츠를 제공하도록 버킷 구성 S3 버킷을 오리진으로 사용하여 Amazon CloudFront를 구성 C. 웹 사이트 콘텐츠를 Apache HTTP 서버를 실행하는 Amazon EBS 지원 Amazon EC2 인스턴스로 복사하여 Amazon Route 53 지리적 위치 라우팅 정책을 구성하여 가장 가까운 오리진을 선택합니다. D. 여러 AWS 지역에서 Apache HTTP 서버를 실행하는 여러 Amazon EBS 지원 Amazon EC2 인스턴스로 웹 사이트 콘텐츠 복사 가장 가까운 오리진을 선택하도록 Amazon CloudFront 지리적 위치 라우팅 정책 구성 #\rAnswer\r...\rAnswer: B\r#\rQ188\r#\r미디어 회사는 시스템을 AWS 클라우드로 이전할 가능성을 평가하고 있습니다.이 회사는 비디오 처리를 위해 가능한 최대 I/O 성능을 갖춘 최소 10TB의 스토리지가 필요합니다. 미디어 컨텐츠 저장을 위한 300TB의 내구성이 뛰어난 스토리지와 더 이상 사용되지 않는 아카이브 미디어에 대한 요구 사항을 충족하기 위해 900TB의 스토리지가 필요합니다.솔루션 설계자가 이러한 요구 사항을 충족하기 위해 권장해야 하는 서비스 세트는 무엇입니까?\nA. 최대 성능을 제공하는 Amazon EBS, 내구성 있는 데이터 스토리지용 Amazon S3, 아카이브 스토리지용 Amazon S3 Glacier B. 성능 극대화를 위한 Amazon EBS내구성 있는 데이터 스토리지를 위한 Amazon EFS 및 보관 스토리지용 Amazon S3 Glacier C. 성능 극대화를 위한 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 스토리지용 Amazon EFS, 아카이브 스토리지용 Amazon S3 D. 성능 극대화를 위한 Amazon EC2 인스턴스 스토어, 내구성 있는 데이터 스토리지용 Amazon S3, 보관 스토리지용 Amazon S3 Glacier #\rAnswer\r...\rAnswer: D\r#\rQ189\r#\r회사에서 Amazon S3 버킷에 파일을 업로드하는 데 사용되는 애플리케이션을 호스팅하고 나면 파일이 처리되어 메타데이터를 추출합니다. 이 작업은 5초 미만입니다.업로드의 볼륨과 빈도는 매시간 몇 개의 파일에서 수백 개의 동시 업로드에 이르기까지 베인됩니다.이 회사는 솔루션 설계자에게 이러한 요구 사항을 충족하는 비용 효율적인 아키텍처를 설계하도록 요청했습니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. S3 API 호출을 기록하도록 AWS CloudTrail 추적 구성 AWS AppSync를 사용하여 파일 처리 B. 파일을 처리하기 위해 AWS Lambda 함수를 호출하도록 S3 버킷 내에 객체 생성 이벤트 알림을 구성합니다. C. 데이터를 처리하고 Amazon S3로 전송하도록 Amazon Kinesis Data Streams 구성 파일을 처리하기 위해 AWS Lambda 함수를 호출합니다. D. Amazon S3에 업로드된 파일을 처리하도록 Amazon SNS (단순 알림 서비스) 주제를 구성합니다.AWS Lambda 함수를 호출하여 파일을 처리합니다. #\rAnswer\r...\rAnswer: B\r#\rQ190\r#\r솔루션 설계자가 모놀리식 애플리케이션을 두 개의 마이크로 서비스로 구성된 느슨하게 결합된 애플리케이션으로 재설계하고 있습니다. 마이크로서비스 A와 마이크로서비스 B 마이크로서비스 A는 마이크로서비스 B가 사용할 수 있도록 Amazon SOS (단순 대기열 서비스) 대기열에 메시지를 배치합니다.를 사용하여 4번 재시도한 후 메시지를 처리하려면 대기열에서 메시지를 제거하고 추가 조사를 위해 저장해야 합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?\nA. SQS 데드 레터 큐 만들기 마이크로서비스 B는 메시지를 4번 수신하여 처리하지 못한 후 실패한 메시지를 해당 대기열에 추가합니다. B. SQS 배달 못한 편지 대기열 생성 메시지를 네 번 받은 후 배달 못한 편지 대기열에 메시지를 전달하도록 기본 SQS 대기열을 구성합니다. C. 실패한 메시지에 대한 SQS 대기열을 생성합니다. 마이크로서비스 A는 마이크로서비스 B가 메시지를 4번 수신하고 처리하지 못한 후 실패한 메시지를 해당 대기열에 추가합니다. D. 실패한 메시지에 대한 SQS 대기열을 생성합니다.원본 메시지가 네 번 수신된 후 기본 SQS 대기열에서 메시지를 가져오도록 실패한 메시지에 대한 SQS 대기열을 구성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ191\r#\r한 회사는 해당 애플리케이션을 위한 스토리지 솔루션을 찾고 있습니다.솔루션은 가용성과 확장성이 뛰어나야 합니다. 또한 솔루션은 파일 시스템으로 작동하고, AWS의 여러 Linux 인스턴스에서 기본 프로토콜을 통해 마운트할 수 있어야 하며, 최소 크기 요구 사항이 없어야 합니다.이 회사는 온프레미스 네트워크에서 VPC로 액세스할 수 있도록 사이트 간 VPN을 설정했습니다. 이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까?\nA. Amazon FSX 다중 AZ 배포 B. Amazon Elastic Block Store (Amazon EBS) 다중 연결 볼륨 C. 여러 마운트 대상이 있는 Amazon EFS (Elastic 파일 시스템) D. 단일 마운트 대상과 여러 액세스 포인트가 있는 Amazon EFS (Elastic 파일 시스템) #\rAnswer\r...\rAnswer: C\r#\rQ192\r#\r온라인 쇼핑 애플리케이션이 Amazon RDS 다중 AZ DB 인스턴스에 액세스합니다.데이터베이스 성능이 응용 프로그램의 속도를 저하시킵니다.차세대 인스턴스 유형으로 업그레이드한 후에는 성능이 크게 향상되지 않았습니다. 분석에 따르면 약 700 IOPS가 지속되고 일반적인 쿼리가 장기간 실행되며 메모리 사용률이 높습니다. 솔루션 설계자가 이러한 문제를 해결하기 위해 권장해야 하는 응용 프로그램 변경은 무엇입니까?\nA. RDS 인스턴스를 Amazon Redshift 클러스터로 마이그레이션하고 매주 가비지 수집을 활성화합니다. B. 장기 실행 쿼리를 새로운 Multi AZ RDS 데이터베이스로 분리하고 애플리케이션을 수정하여 필요한 데이터베이스를 쿼리합니다. C. 2노드 Amazon ElastiCache 클러스터를 배포하고 애플리케이션을 수정하여 먼저 클러스터를 쿼리하고 필요한 경우에만 데이터베이스를 쿼리합니다. D. 일반적인 쿼리에 대한 Amazon SQS (단순 대기열 서비스) FIFO 대기열을 생성하고 먼저 쿼리하고 필요한 경우에만 데이터베이스를 쿼리합니다. #\rAnswer\r...\rAnswer: C\r#\rQ193\r#\r한 회사는 사용자 데이터를 캡처하고 향후 분석을 위해 저장하는 식품 주문 애플리케이션을 구축했습니다.애플리케이션의 정적 프런트 엔드가 Amazon EC에 배포됩니까?인스턴스로 이동합니다.프런트 엔드 애플리케이션은 별도의 EC2 인스턴스에서 실행되는 백엔드 애플리케이션으로 요청을 전송합니다.그런 다음 백엔드 애플리케이션은 Amazon RDS에 데이터를 저장합니다. 솔루션 설계자는 아키텍처를 분리하고 확장 가능하게하기 위해 무엇을해야합니까?\nA. Amazon S3를 사용하여 프런트 엔드 애플리케이션을 제공합니다. 프런트 엔드 애플리케이션은 Amazon EC2로 백엔드 애플리케이션을 실행하도록 요청을 보냅니다.백엔드 애플리케이션이 Amazon RDS에서 데이터를 처리하고 저장합니다. B. Amazon S3를 사용하여 프런트 엔드 애플리케이션을 제공하고 Amazon SNS (단순 알림 서비스) 주제에 요청을 작성합니다.HTTP/HTTPS 엔드포인트에 Amazon EC2 인스턴스를 구독 (주제, Amazon RDS에 데이터 처리 및 저장 C. EC2 인스턴스를 사용하여 프런트 엔드를 처리하고 Amazon SOS 대기열에 요청 쓰기 백엔드 인스턴스를 Auto Scaling 그룹에 배치하고 대기열 깊이에 따라 확장하여 Amazon RDS에서 데이터를 처리 및 저장합니다. D. Amazon S3를 사용하여 정적 프런트 엔드 애플리케이션을 제공하고 요청 전송 Amazon SQS 대기열에 요청을 쓰는 Amazon API Gateway를 통해 백엔드 인스턴스를 Auto Scaling 그룹에 배치하고 대기열 깊이에 따라 확장하여 Amazon RDS에서 데이터를 처리 및 저장합니다. #\rAnswer\r...\rAnswer: D\r#\rQ194\r#\r회사가 Amazon EC2 인스턴스에서 실행되는 API 기반 재고 보고 애플리케이션을 보유하고 있습니다. 애플리케이션은 Amazon DynamoDB 테이블에 정보를 저장합니다. 회사의 유통 센터에는 배송 라벨을 인쇄하기 전에 재고를 업데이트하기 위해 API를 호출하는 온프레미스 배송 애플리케이션이 있습니다.회사는 응용 프로그램 중단을 매일 여러 번 경험해 왔으며 이로 인해 트랜잭션이 손실되었습니다.솔루션 설계자는 애플리케이션 복원력을 향상시키기 위해 무엇을 권장해야 합니까?\nA. 전달 응용 프로그램을 수정하여 로컬 데이터베이스에 씁니다. B. AWS Lambda를 사용하여 서버를 사용하지 않고 실행하도록 애플리케이션 API 수정 C. EC2 인벤토리 애플리케이션 API를 호출하도록 Amazon API 게이트웨이를 구성합니다. D. Amazon SQS (단순 대기열 서비스) 를 사용하여 재고 업데이트를 전송하도록 애플리케이션을 수정합니다. #\rAnswer\r...\rAnswer: D\r#\rQ195\r#\r온라인 소매 업체는 매주 금요일에 발생하는 일련의 플래시 판매를 보유하고 있습니다. 판매 트래픽은 판매 중에만 증가하고 플랫폼은 증가 된 부하를 처리합니다.플랫폼은 3 계층 응용 프로그램입니다.웹 티어는 애플리케이션 로드 밸런서 뒤의 Amazon EC2 인스턴스에서 실행됩니다.Amazon CloudFront는 웹 서버 로드를 줄이는 데 사용되지만 동적 콘텐츠에 대한 많은 요청은 웹 서버로 이동해야 합니다. 성능이나 안정성에 영향을 주지 않고 비용을 절감하기 위해 웹 계층에서 수행해야 하는 작업은 무엇입니까?\nA. T 시리즈 인스턴스 사용 B. 예약된 예약 인스턴스를 구매합니다. C. Amazon Elastic캐시 구현 D. 스팟 인스턴스를 사용 #\rAnswer\r...\rAnswer: B\r#\rQ196\r#\r회사는 온프레미스 애플리케이션을 Amazon EC2 인스턴스로 이전하고 있습니다.그러나 컴퓨팅 요구 사항의 변동으로 인해 EC2 인스턴스는 항상 특정 가용 영역에서 오전 8시에서 오후 5시 사이에 사용할 준비가 되어 있어야 합니다. 회사에서 애플리케이션을 실행하기 위해 어떤 EC2 인스턴스를 선택해야 합니까?\nA. 예약 예약 I 인스턴스 B. 온 디맨드 C. 스팟 집합의 일부인 스팟 인스턴스 D. Auto Scaling 그룹의 EC2 인스턴스 #\rAnswer\r...\rAnswer: A\r#\rQ197\r#\r3 계층 웹 애플리케이션은 고객의 주문을 처리합니다.웹 티어는 애플리케이션 로드 밸런서 뒤에 있는 Amazon EC2 인스턴스로 구성되며, Amazon SQS를 사용하여 웹 티어에서 분리된 세 개의 EC2 인스턴스로 이루어진 중간 계층과 Amazon DynamoDB 백엔드로 구성됩니다.피크 시간대에 사이트를 사용하여 주문을 제출하는 고객은 처리 시간이 길어서 확인을 받기 위해 평소보다 훨씬 오래 기다려야 합니다.솔루션 설계자는 이러한 처리 시간을 줄여야 합니다. 이 작업을 수행하는 데 가장 효과적인 작업은 무엇입니까?\nA. SQS 대기열을 Amazon Kinesis Data Firehose로 교체합니다. B. DynamoDB 백엔드 계층 앞에 있는 Redis용 Amazon ElastiCache를 사용하십시오. C. Amazon CloudFront 배포를 추가하여 웹 티어에 대한 응답을 캐시합니다. D. Amazon EC2 Auto Scaling을 사용하여 SOS 대기열 깊이에 따라 중간 계층 인스턴스를 확장할 수 있습니다. #\rAnswer\r...\rAnswer: D\r#\rQ198\r#\r한 회사는 계층적 디렉터리 구조를 사용하는 애플리케이션이 있는 VPC에서 여러 Amazon EC2 Linux 인스턴스를 실행합니다.애플리케이션이 공유 스토리지에 신속하고 동시에 읽고 쓸 필요가 있는 경우 이를 달성할 수 있는 방법은 무엇입니까?\nA. Amazon EFS 파일 시스템을 생성하고 각 EC2 인스턴스에서 마운트합니다. B. Amazon S3 버킷을 생성하고 VPC의 모든 EC2 인스턴스에서 액세스를 허용합니다. C. Amazon EBS 프로비저닝된 IOPS SSD (io1) 볼륨에 파일 시스템을 생성합니다.볼륨을 모든 EC2 인스턴스에 연결합니다. D. 각 EC2 인스턴스에 연결된 Amazon EBS 볼륨에 파일 시스템을 생성합니다.여러 EC2 인스턴스에서 Amazon EBS 볼륨을 동기화합니다. #\rAnswer\r...\rAnswer: A\r#\rQ199\r#\r마케팅 회사가 통계 분석을 위해 Amazon S3 버킷에 CSV 파일을 저장하고 있습니다. Amazon EC2 인스턴스의 애플리케이션은 S3 버킷에 저장된 CSV 데이터를 효율적으로 처리할 수 있는 권한이 필요합니다. EC2 인스턴스에 S3 버킷에 대한 액세스 권한을 가장 안전하게 부여하는 작업은 무엇입니까?\nA. S3 버킷에 리소스 기반 정책 연결 B. S3 버킷에 대한 특정 권한을 가진 애플리케이션에 대한 IAM 사용자를 생성합니다. C. IAM 역할을 EC2 인스턴스 프로필에 최소 권한 권한과 연결 D. API 호출에 사용할 인스턴스의 애플리케이션을 위해 EC2 인스턴스에 AWS 자격 증명을 직접 저장합니다. #\rAnswer\r...\rAnswer: C\r#\rQ200\r#\r한 회사에서 온프레미스 데이터 세트의 보조 사본에 Amazon S3를 사용하려고 합니다.회사는 이 사본에 액세스할 필요가 거의 없습니다.스토리지 솔루션의 비용은 최소화되어야 합니다. 이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까?\nA. S3 표준 B. S3 Intelliginet 계층화 C. S3 표준 Standard Infrequent Access (S3 표준-IA) D. S3 One Zone Standard Infrequent Access (S3 One Zone-IA) #\rAnswer\r...\rAnswer: D\r#\rQ201\r#\r회사는 AWS에서 실행되는 인기 있는 게임 플랫폼을 보유하고 있습니다.지연 시간은 사용자 경험에 영향을 미치고 일부 플레이어에게 부당한 이점을 제공할 수 있기 때문에 지연 시간에 민감합니다. 애플리케이션은 애플리케이션 로드 밸런서 (ALB) 뒤에 구성된 Auto Scaling 그룹의 일부인 Amazon EC2 인스턴스에서 실행되는 모든 AWS 지역에 배포됩니다.솔루션 설계자는 애플리케이션의 상태를 모니터링하고 트래픽을 정상 엔드 포인트로 리디렉션하는 메커니즘을 구현해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. AWS 글로벌 Accelerator에서 Accelerator 구성 애플리케이션이 수신하는 포트의 수신기를 추가하고 각 리전의 리전 엔드포인트에 연결 ALB를 엔드포인트로 추가 B. Amazon CloudFront 배포를 생성하고 ALB를 오리진 서버로 지정합니다.오리진 캐시 헤더를 사용하도록 캐시 동작 구성 AWS Lambda 함수를 사용하여 트래픽 최적화 C. Amazon CloudFront 배포를 생성하고 Amazon S3를 오리진 서버로 지정합니다.원본 캐시 헤더를 사용하도록 캐시 동작을 구성합니다.AWS Lambda 함수를 사용하여 트래픽 D. 애플리케이션의 데이터 저장소로 사용할 Amazon DynamoDB 데이터베이스 구성 애플리케이션 데이터를 호스팅하는 DynamoDB의 인 메모리 캐시 역할을 하도록 DynamoDB Accelerator (DAX) 클러스터를 만듭니다. #\rAnswer\r...\rAnswer: A\r#\rQ202\r#\r대기업의 관리자가 회사의 AWS 계정에 대한 암호화폐와 관련된 공격을 모니터링하고 방지하려고 합니다. 관리자가 공격으로부터 회사를 보호하기 위해 어떤 AWS 서비스를 사용할 수 있습니까?\nA. Amazon Cognito B. Amazon GuardDuty C. Amazon Inspector D. Amazon Macie #\rAnswer\r...\rAnswer: B\r#\rQ203\r#\r솔루션 설계자는 개발자가 웹 서버에 SSH 연결을 허용해야합니다. 요구 사항은 다음과 같습니다.\n회사 네트워크에서 시작된 사용자만 액세스할 수 있도록 제한합니다. 웹 서버는 인터넷에서 직접 SSH 액세스를 할 수 없습니다. 웹 서버는 프라이빗 서브넷에 상주합니다. 설계자는 이러한 요구 사항을 충족하기 위해 어떤 단계 조합을 완료해야 합니까?(두 개를 선택합니다.) A. 회사 디렉토리에 대해 사용자를 인증하는 접속 호스트 생성 B. 회사 네트워크의 트래픽만 허용하는 보안 그룹 규칙이 있는 접속 호스트를 생성합니다. C. 관련 권한이 있는 접속 호스트에 IAM 역할 연결 D. 접속 호스트에서 SSH 트래픽을 허용하도록 웹 서버의 보안 그룹을 구성합니다. E. 인바운드 네트워크 ACL에서 회사 네트워크의 모든 SSH 트래픽을 거부합니다. #\rAnswer\r...\rAnswer: B D\r#\rQ204\r#\r한 회사에서 AWS CloudTrail 로그가 각 개발자 계정의 Amazon S3 버킷에 로그 파일을 전송하도록 활성화했습니다.이 회사는 관리 및 감사 검토를 간소화하기 위해 중앙 AWS 계정을 만들었습니다. 내부 감사자는 CloudTrail 로그에 액세스해야 하지만 모든 개발자 계정 사용자에 대한 액세스를 제한해야 합니다. 솔루션은 안전하고 최적화되어야 합니다. 솔루션 설계자는 이러한 요구 사항을 어떻게 충족해야 합니까?\nA. 각 개발자 계정에서 로그 파일을 중앙 계정에 복사하도록 AWS Lambda 함수를 구성합니다.감사자의 중앙 계정에 IAM 역할을 생성합니다. 버킷에 대한 읽기 전용 권한을 제공하는 IAM 정책을 연결합니다. B. tog 파일을 중앙 계정의 S3 버킷으로 전송하도록 각 개발자 계정에서 CloudTrail을 구성합니다.감사자의 중앙 계정에서 IAM 사용자를 생성합니다.버킷에 대한 모든 권한을 제공하는 IAM 정책을 연결합니다. C. 각 개발자 계정에서 CloudTrail을 구성하여 중앙 계정의 S3 버킷에 로그 파일을 전송하도록 구성감사자의 중앙 계정에 IAM 역할 만들기 버킷에 읽기 전용 권한을 제공하는 La\u0026rsquo;.L 정책을 연결합니다. D. 중앙 계정의 AWS Lambda 함수를 구성하여 각 개발자 계정의 S3 버킷에서 로그 파일을 복사하도록 구성감사자의 중앙 계정에 IAM 사용자 만들기 버킷에 대한 모든 권한을 제공하는 IAM 정책을 연결합니다. #\rAnswer\r...\rAnswer: C\r#\rQ205\r#\r한 회사가 최근 메시지 처리 시스템을 AWS로 마이그레이션했습니다.시스템은 Amazon EC2 인스턴스에서 실행 중인 ActiveMQ 대기열로 메시지를 수신합니다.메시지는 Amazon EC2에서 실행되는 소비자 애플리케이션에 의해 처리됩니다. 소비자 애플리케이션은 메시지를 처리하고 Amazon EC2에서 실행 중인 MySQL 데이터베이스에 결과를 기록합니다.이 회사는 운영 복잡성이 낮고 이 애플리케이션의 가용성을 높여야 합니다. 어떤 아키텍처가 최고 수준의 가용성을 제공합니까?\nA. 다른 가용 영역에 보조 ActiveMQ 서버 추가 다른 가용 영역에 소비자 EC2 인스턴스 추가 MySQL 데이터베이스를 다른 가용 영역으로 복제합니다. B. 두 가용 영역에 걸쳐 구성된 활성/대기 브로커와 함께 Amazon MQ 사용 다른 가용 영역에 소비자 EC2 인스턴스를 추가합니다.MySQL 데이터베이스를 다른 가용 영역으로 복제 C. 두 가용 영역에 걸쳐 구성된 활성/대기 브로커와 함께 Amazon MQ를 사용합니다.다른 가용 영역에 소비자 EC2 인스턴스를 추가합니다.다중 AZ가 활성화된 MySQL용 Amazon RDS 사용 D. 두 가용 영역에 구성된 활성/대기 브로커와 함께 Amazon MQ 사용 두 가용 영역에서 소비자 EC2 인스턴스에 대한 Auto Scaling 그룹 추가 다중 AZ가 활성화된 MySQL용 Amazon RDS를 사용합니다. #\rAnswer\r...\rAnswer: D\r#\rQ206\r#\r회사는 인스턴스 간 지연 시간을 최소화해야 하는 다중 인스턴스 애플리케이션을 AWS 내에 배포하고 있습니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. 클러스터 배치 그룹과 함께 Auto Scaling 그룹을 사용합니다. B. 동일한 AWS 리전에 단일 가용 영역이 있는 Auto Scaling 그룹을 사용합니다. C. 동일한 AWS 리전에 여러 가용 영역이 있는 Auto Scaling 그룹을 사용합니다. D. 여러 Amazon EC2 전용 호스트와 함께 네트워크 로드 밸런서를 대상으로 사용하십시오. #\rAnswer\r...\rAnswer: A\r#\rQ207\r#\r미디어 스트리밍 회사는 실시간 데이터를 수집하여 디스크에 최적화된 데이터베이스 시스템에 저장합니다. 이 회사는 예상 처리량을 얻지 못하고 있으며 데이터 복제를 통해 더 빠른 성능을 발휘하고 고가용성을 제공하는 인메모리 데이터베이스 스토리지 솔루션을 원합니다.솔루션 설계자가 권장해야하는 데이터베이스는 무엇입니까?\nA. MySQL용 Amazon RDS B. PostgreSQL용 Amazon RDS C. 레디스를 위한 Amazon ElastiCache D. 멤캐쉬를 위한 Amazon ElastiCache #\rAnswer\r...\rAnswer: C\r#\rQ208\r#\r회사는 Amazon S3를 사용하여 사용자가 업로드한 이미지를 저장할 계획입니다.Amazon S3에 저장된 이미지는 암호화해야 합니다.이 회사는 키를 관리하고 회전하는 데 시간을 할애하고 싶지 않지만 해당 키에 액세스할 수 있는 사용자를 제어하려고 합니다.솔루션 설계자가이를 수행하기 위해 무엇을 사용해야합니까?\nA. S3 버킷에 저장된 키를 사용한 서버 측 암호화 B. 고객 제공 키를 사용한 서버 측 암호화 (SSE-C) C. Amazon S3 관리형 키를 사용한 서버 측 암호화 (SSE-S3) D. AWS KMS 관리형 키를 사용한 서버 측 암호화 (SSE-KMS) #\rAnswer\r...\rAnswer: D\r#\rQ209\r#\r회사는 온프레미스 서버에서 AWS로 10Gbps AWS Direct Connect 연결을 보유하고 있습니다.연결을 사용하는 워크로드는 매우 중요합니다.이 회사는 현재 연결 대역폭을 최소한으로 유지하는 최대 복원력을 갖춘 재해 복구 전략을 요구합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. 다른 AWS 리전에서 새 Direct Connect 연결을 설정합니다. B. 다른 AWS 리전에서 새 AWS 관리형 VPN 연결을 설정합니다. C. 두 개의 새 Direct Connect 연결을 설정합니다. 하나는 현재 AWS 리전에 있고 다른 하나는 다른 지역에 있습니다. D. 두 개의 새로운 AWS 관리형 VPN 연결을 설정합니다. 하나는 현재 AWS 리전에 있고 다른 하나는 다른 지역에 있습니다. #\rAnswer\r...\rAnswer: C\r#\rQ210\r#\r회사의 웹 사이트가 공개적으로 제품을 판매하는 데 사용됩니다. 이 사이트는 애플리케이션 로드 밸런서 (ALB) 뒤에 있는 Auto Scaling 그룹에서 Amazon EC2 인스턴스에서 실행됩니다. 또한 Amazon CloudFront 배포가 있으며 AWS WAF는 SQL 주입 공격으로부터 보호하기 위해 사용되고 있습니다.CloudFront 배포 최근 보안 로그를 검토한 결과 웹 사이트에 액세스하지 못하도록 차단해야 하는 외부 악성 IP가 발견되었습니다. 솔루션 설계자는 애플리케이션을 보호하기 위해 어떻게 해야 합니까?\nA. CloudFront 배포에서 네트워크 ACL을 수정하여 악성 IP 주소에 대한 거부 규칙을 추가합니다. B. 악의적인 IP 주소를 차단하기 위해 IP 일치 조건을 추가하도록 AWS WAF의 구성을 수정합니다. C. ALB 뒤의 대상 그룹에서 EC2 인스턴스에 대한 네트워크 ACL을 수정하여 악성 IP 주소를 거부합니다. D. ALB 뒤의 대상 그룹에서 EC2 인스턴스에 대한 보안 그룹을 수정하여 악성 IP 주소를 거부합니다. #\rAnswer\r...\rAnswer: B\r#\rQ211\r#\r회사는 산발적인 사용 패턴을 가진 웹 애플리케이션을 보유하고 있습니다.매월 초에 사용량이 많고, 매주 시작에는 보통 사용량이 많으며, 주중에는 예측할 수 없는 사용량이 있습니다.응용 프로그램은 웹 서버와 데이터 센터 내에서 실행되는 MySQL 데이터베이스 서버로 구성됩니다.이 회사는 애플리케이션을 AWS 클라우드로 이전하고자 하며, 데이터베이스를 수정할 필요가 없는 비용 효율적인 데이터베이스 플랫폼을 선택해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. Amazon DynamoDB B. MySQL용 Amazon RDS C. MySQL 호환 Amazon Aurora 서버리스 D. Amazon EC2에 Auto Scaling 그룹에 배포된 MySQL #\rAnswer\r...\rAnswer: C\r#\rQ212\r#\r회사가 AWS에서 온라인 트랜잭션 처리 (OLTP) 워크로드를 실행하고 있습니다.이 워크로드는 다중 AZ 배포에서 암호화되지 않은 Amazon RDS DB 인스턴스를 사용합니다.매일 데이터베이스 스냅숏은 이 인스턴스에서 가져옵니다. 솔루션 설계자는 데이터베이스와 스냅샷이 항상 암호화되도록 하기 위해 무엇을해야합니까?\nA. 최신 DB 스냅샷의 사본을 암호화합니다.암호화된 스냅샷을 복원하여 기존 DB 인스턴스를 교체합니다. B. 암호화된 Amazon Elastic 블록 스토어 (Amazon EBS) 볼륨을 새로 생성하고 스냅샷을 복사합니다.DB 인스턴스에서 암호화를 활성화합니다. C. 스냅샷을 복사하고 AWS KMS (키 관리 서비스) 를 사용하여 암호화를 활성화합니다.암호화된 스냅샷을 기존 DB 인스턴스로 복원합니다. D. 스냅샷을 AWS KMS (키 관리 서비스) 관리형 키 (SSE-KMS) 를 사용하여 서버 측 암호화를 사용하여 암호화된 Amazon S3 버킷에 복사합니다. #\rAnswer\r...\rAnswer: A\r#\rQ213\r#\r회사는 자연 재해의 영향을 받는 지역에 본사를 두고 있기 때문에 데이터 센터 공급자로부터 일관되지 않은 서비스를 받습니다.이 회사는 AWS 클라우드로 완전히 마이그레이션할 준비가 되어 있지 않지만 온프레미스 데이터 센터에 장애가 발생할 경우 AWS에서 장애 환경을 원합니다. 이 회사는 외부 공급업체에 연결하는 웹 서버를 운영합니다.AWS와 온프레미스에서 사용할 수 있는 데이터는 동일해야 합니다. 솔루션 설계자가 다운타임이 가장 적은 솔루션을 권장해야 합니까?\nA. Amazon Route 53 장애 조치 레코드를 구성합니다.Auto Scaling 그룹의 애플리케이션 로드 밸런서 뒤에 있는 Amazon EC2 인스턴스에서 애플리케이션 서버를 실행합니다.Amazon S3에 데이터를 백업하기 위해 저장된 볼륨으로 AWS 스토리지 게이트웨이를 설정합니다. B. Amazon Route 53 장애 조치 레코드를 구성합니다.스크립트에서 AWS CloudFormation 템플릿을 실행하여 애플리케이션 로드 밸런서 뒤에 Amazon EC2 인스턴스를 생성합니다.Amazon S3에 데이터를 백업하기 위해 저장된 볼륨으로 AWS 스토리지 게이트웨이를 설정합니다. C. Amazon Route 53 장애 조치 레코드를 구성합니다.VPC와 데이터 센터 간에 AWS Direct Connect 연결을 설정합니다.Amazon EC2에서 Auto Scaling 그룹에서 애플리케이션 서버를 실행합니다.AWS Lambda 함수를 실행하여 AWS CloudFormation 템플릿을 실행하여 애플리케이션 로드 밸런서를 생성합니다. D. Amazon Route 53 장애 조치 레코드를 구성합니다.AWS Lambda 함수를 실행하여 AWS CloudFormation 템플릿을 실행하여 두 개의 Amazon EC2 인스턴스를 시작합니다.Amazon S3에 데이터를 백업하기 위해 저장된 볼륨으로 AWS 스토리지 게이트웨이를 설정합니다.VPC와 데이터 센터 간에 AWS Direct Connect 연결을 설정합니다. #\rAnswer\r...\rAnswer: D\r#\rQ214\r#\r회사가 고객에게 3계층 웹 애플리케이션을 제공합니다. 각 고객은 애플리케이션이 배포되는 AWS 계정을 보유하고 있으며, 이러한 계정은 AWS 조직에 속한 회사 조직의 구성원입니다. 해당 고객의 AWS 계정 및 애플리케이션을 보호하기 위해 회사가 이를 모니터링하려는 고객의 AWS 계정 및 애플리케이션을 보호합니다.비정상적이고 예기치 않은 행동 이 회사는 고객 VPC 흐름 로그를 분석하고 모니터링해야 합니다.AWS CloudTrail 로그 및 DNS 로그 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떻게 해야 합니까?\nA. 조직의 계정을 모든 계정에서 AWS Shield 마스터 계정 방패 및 방패 활성화 로그로 지정하고, 계정을 Shield 마스터 계정에 가입하도록 초대합니다. 실드 마스터 계정 검색 결과 분석 B. 조직의 계정을 Amazon GuardDuty 마스터 계정으로 지정합니다. 모든 계정에서 GuardDuty 활성화하고 GuardDuty 마스터 계정에 가입하도록 계정을 초대합니다. GuardDuty 마스터 계정의 GuardDuty 검색 결과 분석 C. 조직의 계정을 AWS WAF 마스터 계정으로 지정 모든 계정에서 AWS WAF 및 AWS WAF 로그를 활성화하고 AWS WAF 마스터 계정에 가입하도록 계정을 초대합니다. AWS WAF 마스터 계정에서 AWS WAF 로그 분석 D. 조직의 계정을 AWS 리소스 액세스 관리자 (AWS RAM) 마스터 계정으로 지정 모든 계정에서 AWS RAM을 활성화하고 AWS RAM 마스터 계정에 가입하도록 계정을 초대합니다. AWS RAM 마스터 계정의 AWS RAM 로그 분석 #\rAnswer\r...\rAnswer: B\r#\rQ215\r#\r회사에서 온프레미스 애플리케이션을 AWS로 마이그레이션할 준비를 하고 있습니다. 애플리케이션은 애플리케이션 서버와 Microsoft SQL Server 데이터베이스로 구성됩니다. SQL Server 기능은 애플리케이션의 NET 코드에서 사용되기 때문에 데이터베이스를 다른 엔진으로 마이그레이션할 수 없습니다.이 회사는 운영 및 관리 오버헤드를 최소화하면서 가능한 최고의 가용성을 달성하고자 하는 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. 다중 AZ 배포에서 Amazon EC2에 SQL 서버 설치 B. 다중 AZ 배포에서 SQL Server용 Amazon RDS로 데이터를 마이그레이션합니다. C. 다중 AZ 복제본을 사용하여 SQL Server용 Amazon RDS에 데이터베이스를 배포합니다. D. 리전 간 다중 AZ 배포에서 SQL Server용 Amazon RDS로 데이터 마이그레이션 #\rAnswer\r...\rAnswer: B\r#\rQ216\r#\r애플리케이션이 여러 가용 영역에 걸쳐 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 애플리케이션 로드 밸런서 뒤에 있는 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. EC2 인스턴스의 CPU 사용률이 40% 에 가까울 때 애플리케이션이 최상의 성능을 발휘합니다. 솔루션 설계자는그룹의 모든 인스턴스에서 원하는 성능을 유지할 수 있습니까?\nA. 단순 조정 정책을 사용하여 Auto Scaling 그룹의 크기를 동적으로 조정합니다. B. 대상 추적 정책을 사용하여 Auto Scaling 그룹을 동적으로 조정 C. AWS Lambda 함수를 사용하여 원하는 Auto Scaling 그룹 용량을 업데이트합니다. D. 예약된 배율 조정 작업을 사용하여 Auto Scaling 그룹의 배율 조정 및 축소 #\rAnswer\r...\rAnswer: B\r#\rQ217\r#\r회사의 주문 처리 서비스는 MySQL 데이터베이스를 사용합니다.데이터베이스는 많은 수의 동시 쿼리 및 트랜잭션을 지원해야 합니다. 개발자가 데이터베이스 패치 적용 및 튜닝에 시간을 소비하고 있습니다. 이로 인해 신제품 기능 출시 지연이 발생합니다. 회사는 클라우드 기반 서비스를 사용하여 이러한 새로운 문제를 해결하려고 합니다.개발자가 코드를 거의 또는 전혀 변경하지 않고 데이터베이스를 마이그레이션하고 성능을 최적화해야합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 서비스를 사용해야 합니까?\nA. Amazon Aurora B. Amazon DynamoDB C. Amazon ElastiCache D. Amazon EC2의 MySQL #\rAnswer\r...\rAnswer: A\r#\rQ218\r#\r한 회사에서 AWS 리전을 온프레미스 인프라의 재해 복구 위치로 사용하려고 합니다.이 회사는 10TB의 기존 데이터를 보유하고 있으며, 온프레미스 데이터 센터에는 1Gbps의 인터넷 연결이 있습니다.솔루션 설계자는 회사가 암호화되지 않은 채널을 사용하여 데이터를 전송하지 않고 72시간 내에 AWS에 기존 데이터를 보유할 수 있도록 솔루션을 찾아야 합니다. 솔루션 설계자는 어떤 솔루션을 선택해야합니까?\nA. FTP를 사용하여 초기 10TB의 데이터를 AWS로 전송합니다. B. AWS Snowball을 사용하여 초기 10TB의 데이터를 AWS로 보냅니다. C. Amazon VPC와 회사의 데이터 센터 간에 VPN 연결을 설정합니다. D. Amazon VPC와 회사의 데이터 센터 간에 AWS Direct Connect 연결을 설정합니다. #\rAnswer\r...\rAnswer: C\r#\rQ219\r#\r솔루션 설계자는 Windows IIS (인터넷 정보 서비스) 웹 애플리케이션을 AWS로 마이그레이션해야 합니다.응용 프로그램은 현재 사용자의 온-프레미스 NAS (네트워크 연결 저장소) 에서 호스팅되는 파일 공유를 사용합니다. 아키텍처 된 솔루션은 IIS 웹 서버 마이그레이션을 제안했습니다. 약속중인 필로 공유로 대체하는 것이 가장 탄력적이고 내구성이 있습니까?\nA. 파일 공유를 Amazon RDS로 마이그레이션합니다. B. 파일 공유를 AWS 스토리지 게이트웨이로 마이그레이션 C. 파일 공유를 Windows 파일 서버용 Amazon FSx로 마이그레이션합니다. D. 파일 공유를 Amazon EFS (Elastic File System) 로 마이그레이션 #\rAnswer\r...\rAnswer: C\r#\rQ220 한 회사는 여러 부서에 대해 여러 AWS 계정을 보유하고 있습니다.한 부서에서 Amazon S3 버킷을 다른 모든 부서와 공유하려고 합니다.최소한의 노력이 필요한 솔루션은 무엇입니까?\r#\rA. 버킷에 대해 교차 계정 S3 복제 활성화 B. 버킷에 미리 서명된 URL을 만들어 다른 부서와 공유합니다. C. 다른 부서에 대한 교차 계정 액세스를 허용하도록 S3 버킷 정책 설정 D. 각 부서에 대해 IAM 사용자를 생성하고 읽기 전용 IAM 정책을 구성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ221\r#\r회사는 Amazon API 게이트웨이와 AWS Lambda를 사용하는 공개적으로 액세스 가능한 서버를 사용하지 않는 애플리케이션을 운영하고 있습니다.봇넷의 사기성 요청으로 인해 최근 애플리케이션 트래픽이 급증했습니다. 권한 없는 사용자의 요청을 차단하려면 솔루션 설계자가 수행해야 하는 단계는 무엇입니까?(두 개를 선택합니다.)\nA. 정품 사용자에게만 공유되는 API 키를 사용하여 사용 계획을 만듭니다. B. Lambda 함수 내에 로직을 통합하여 사기성 주소의 요청을 무시합니다. C. AWS WAF 규칙을 구현하여 악성 요청을 대상으로 지정하고 이를 필터링하는 작업을 트리거합니다. D. 기존 공용 API를 전용 API로 변환합니다.DNS 레코드를 업데이트하여 사용자를 새 API 엔드 포인트로 리디렉션합니다. E. API에 액세스하려는 각 사용자에 대해 IAM 역할을 생성합니다.사용자는 API 호출을 할 때 역할을 맡게 됩니다. #\rAnswer\r...\rAnswer: A C\r#\rQ222\r#\r회사는 AWS에서 멀티 티어 애플리케이션을 호스팅합니다. 규정 준수, 거버넌스, 감사 및 보안을 위해 회사는 AWS 리소스의 구성 변경을 추적하고 이러한 리소스에 대한 API 호출 기록을 기록해야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떻게 해야 합니까?\nA. AWS CloudTrail을 사용하여 구성 변경 사항을 추적하고 AWS Config를 사용하여 API 호출 기록 B. AWS Config를 사용하여 구성 변경 사항을 추적하고 AWS CloudTrail을 사용하여 API 호출 기록 C. AWS 구성을 사용하여 구성 변경 사항을 추적하고 Amazon CloudWatch를 사용하여 API 호출 기록 D. AWS CloudTrail을 사용하여 구성 변경을 추적하고 Amazon CloudWatch를 사용하여 API 호출을 기록하십시오. #\rAnswer\r...\rAnswer: B\r#\rQ223\r#\r회사는 Amazon Elastic Block Store (Amazon EBS) 가 지원하는 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다.인스턴스는 매일 12시간 동안 사용할 수 있어야 합니다.회사는 애플리케이션에 필요한 창 밖에서 인스턴스를 사용할 수 없게 함으로써 비용을 절감하고자 합니다. 그러나 인스턴스를 사용할 수 없을 때마다 인스턴스 메모리 내용을 보존해야 합니다. 솔루션 설계자는 이 요구 사항을 충족해야 합니까?\nA. 애플리케이션의 가용성 창 밖에서 인스턴스를 중지합니다.필요한 경우 인스턴스를 다시 시작합니다. B. Hibernate는 애플리케이션의 가용성 창을 벗어나는 인스턴스를 묶습니다.필요한 경우 인스턴스를 다시 시작합니다. C. Auto Scaling을 사용하여 애플리케이션의 가용성 창 밖에서 인스턴스를 축소할 수 있습니다.필요한 경우 인스턴스를 확장합니다. D. 애플리케이션의 가용성 창 밖에서 인스턴스 종료 필요한 경우 사전 구성된 Amazon 머신 이미지 (AMI) 를 사용하여 인스턴스를 시작합니다. #\rAnswer\r...\rAnswer: B\r#\rQ224\r#\r회사가 애플리케이션 로드 밸런서를 사용하여 세 개의 AWS 리전에서 애플리케이션을 배포하고 있습니다. Amazon Route 53는 이러한 리전 간에 트래픽을 분산하는 데 사용됩니다.솔루션 설계자가 가장 우수한 성능을 제공하기 위해 어떤 Route 53 구성을 사용해야 합니까?\nA. 지연 시간 정책을 사용하여 A 레코드를 만듭니다. B. 지리적 위치 정책을 사용하여 A 레코드를 만듭니다. C. 장애 조치 정책을 사용하여 CNAME 레코드를 만듭니다. D. 지리적 근접성 정책을 사용하여 CNAME 레코드를 만듭니다. #\rAnswer\r...\rAnswer: A\r#\rQ225\r#\r회사 AWS에서 전자 상거래 웹 사이트를 시작합니다.이 웹 사이트는 Amazon Aurora MySQL의 다중 AZ 배포에서 MySQL 데이터베이스를 포함하는 3계층 아키텍처를 기반으로 구축되었습니다.웹 사이트 애플리케이션은 가용성이 높아야 하며 처음에는 세 개의 가용 영역이 있는 AWS 리전에서 시작됩니다.응용 프로그램은 응용 프로그램 경험의 로드를 설명하는 메트릭을 생성합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 예약된 조정을 통해 ALB 뒤에 Amazon EC2 Auto Scaling을 사용하여 애플리케이션 로드 밸런서 (ALB) 구성 B. 간단한 조정 정책을 사용하여 ALB 뒤에 애플리케이션 로드 밸런서 (ALB) 및 Amazon EC2 Auto Scaling을 구성합니다. C. NLB (네트워크 로드 밸런서) 를 구성하고 NLB 뒤에서 Amazon EC2 Auto Scaling을 사용하여 스팟 집합을 시작합니다. D. 대상 추적 조정 정책을 사용하여 ALB 뒤에 애플리케이션 로드 밸런서 (ALB) 및 Amazon EC2 Auto Scaling을 구성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ226\r#\r회사의 동적 웹 사이트는 미국의 온-프레미스 서버를 사용하여 호스팅됩니다.이 회사는 유럽에서 제품을 출시하고 새로운 유럽 사용자를 위해 사이트 로딩 시간을 최적화하고자 합니다.사이트의 백엔드는 미국에 남아 있어야 합니다.이 제품은 며칠 내에 출시되고 있으며 즉각적인 솔루션이 필요합니다. 솔루션 설계자는 무엇을 권장해야합니까?\nA. us-east-1에서 Amazon EC2 인스턴스를 시작하고 사이트를 해당 인스턴스로 마이그레이션합니다. B. 웹 사이트를 Amazon S3로 이동 리전 간 교차 리전 복제 사용 C. 온프레미스 서버를 가리키는 사용자 지정 오리진과 함께 Amazon CloudFront 사용 D. 온프레미스 서버를 가리키는 Amazon Route 53 지리적 근접 라우팅 정책 사용 #\rAnswer\r...\rAnswer: C\r#\rQ227\r#\r회사의 패키지 응용 프로그램은 사용자 요청에 응답하여 일회용 텍스트 파일을 동적으로 생성하고 반환합니다.이 회사는 배포를 위해 Amazon CloudFront를 사용하고 있지만 향후 데이터 전송 비용을 절감하고자 합니다.회사는 응용 프로그램의 소스 코드를 수정합니다. 솔루션 설계자는 비용을 절감하기 위해 무엇을 해야 합니까?\nA. Lambda 감지를 사용하여 파일을 사용자에게 보낼 때 압축합니다. B. Amazon S3 Transfer Acceleration을 활성화하여 응답 시간을 줄입니다. C. CloudFront 배포에서 캐싱을 활성화하여 생성된 파일을 Edge에 저장합니다. D. Amazon S3 멀티파트 업로드를 사용하여 파일을 사용자에게 반환하기 전에 Amazon S3로 이동합니다. #\rAnswer\r...\rAnswer: A\r#\rQ228\r#\r제품에 대한 수요가 증가함에 따라 회사가 성장하고 있습니다. 트래픽이 급증할 때 회사의 기존 구매 응용 프로그램이 느립니다. 응용 프로그램은 동기 트랜잭션을 사용하는 모 놀리 식 3 계층 응용 프로그램이며 때로는 응용 프로그램 계층 솔루션에 병목 현상을 볼 수 있습니다. 설계자는 트래픽 폭증을 고려하면서 필요한 애플리케이션 응답 시간을 충족할 수 있는 솔루션을 설계해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 더 큰 Amazon EC2 인스턴스 크기를 사용하여 애플리케이션 인스턴스를 세로로 확장합니다. B. AWS에 Oracle RAC를 도입하여 애플리케이션의 지속성 계층을 수평으로 확장 C. Auto Scaling 그룹과 애플리케이션 로드 밸런서를 사용하여 웹 및 애플리케이션 계층을 수평으로 확장 D. 비동기 AWS Lambda 호출과 함께 Amazon SQS (단순 대기열 서비스) 를 사용하여 애플리케이션과 데이터 계층을 분리합니다. #\rAnswer\r...\rAnswer: C\r#\rQ229\r#\r회사는 웹 소켓을 사용하는 온-프레미스 서버 목록에서 실행되는 라이브 채팅 응용 프로그램을 보유하고 있습니다.이 회사는 애플리케이션을 AWS 애플리케이션 트래픽으로 마이그레이션하려고 합니다. 그리고 향후 급격한 급증으로 인해 트래픽이 더 많아질 것으로 예상합니다.이 회사는 서버 유지 관리나 고급 용량 계획 없이 확장성이 뛰어난 솔루션을 원하십니까? 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. Amazon API 게이트웨이 및 AWS Lambda를 Amazon DynamoDB 테이블과 함께 데이터 저장소로 사용 프로비저닝된 용량에 대한 DynamoDB 테이블 구성 B. Amazon API 게이트웨이 및 AWS Lambda를 Amazon DynamoDB 테이블과 함께 데이터 저장소로 사용 온 디맨드 용량에 대한 DynaiwDB 테이블 구성 C. Amazon DynamoDB 테이블을 데이터 저장소로 사용하여 Auto Scaling 그룹의 애플리케이션 로드 밸런서 뒤에서 Amazon EC2 인스턴스 실행 온 디맨드 용량에 맞게 DynamoDB 테이블 구성 D. Amazon DynamoDB 테이블을 데이터 저장소로 사용하여 Auto Scaling 그룹의 네트워크 로드 밸런서 뒤에서 Amazon EC2 인스턴스를 실행합니다. 프로비저닝된 용량을 위한 DynamoDB 테이블 구성 #\rAnswer\r...\rAnswer: B\r#\rQ230\r#\r회사는 단일 가용 영역의 MySQL용 Amazon RDS DB 인스턴스에 저장된 온라인 광고 비즈니스용 대규모 데이터 세트를 보유하고 있습니다.이 회사는 프로덕션 DB 인스턴스에 대한 쓰기 작업에 영향을 주지 않고 비즈니스 보고 쿼리를 실행하기를 원합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. RDS 읽기 전용 복제본을 배포하여 비즈니스 보고 쿼리를 처리합니다. B. DB 인스턴스를 Elastic 로드 밸런서 뒤에 배치하여 수평으로 스케일아웃 C. 쓰기 작업 및 쿼리를 처리할 수 있도록 DB 인스턴스를 더 큰 인스턴스 유형으로 확장합니다. D. DB 인스턴스를 여러 가용 영역에 배포하여 비즈니스 보고 쿼리를 처리합니다. #\rAnswer\r...\rAnswer: A\r#\rQ231\r#\r예측 프로세스에서는 Amazon S3 버킷에 저장된 교육된 모델에 액세스해야 합니다.이 프로세스는 이미지를 처리하고 예측하는 데 몇 초가 걸립니다.이 프로세스는 지나치게 리소스를 많이 사용하지 않고 특수 하드웨어가 필요하지 않으며 실행하는 데 512MB 미만의 메모리가 필요합니다. 이 사용 사례에 가장 효과적인 컴퓨팅 솔루션은 무엇입니까?\nA. Amazon 탄력적 컨테이너 서비스 (Amazon ECS) B. Amazon EC2 스팟 인스턴스 C. AWS Lambda 함수 D. AWS Elastic Beanstalk(Beanstalk) #\rAnswer\r...\rAnswer: C\r#\rQ232\r#\r회사가 AWS에서 확장 가능한 웹 애플리케이션을 호스팅하려고 합니다.응용 프로그램은 세계의 다른 지리적 지역의 사용자가 액세스 할 수 있습니다.응용 프로그램 사용자는 최대 기가 바이트의 고유 한 데이터를 다운로드하고 업로드 할 수 있습니다.개발 팀은 업로드 및 다운로드 대기 시간을 최소화하고 성능을 극대화할 수 있는 비용 효율적인 솔루션을 원합니다.이를 달성하기 위해 솔루션 설계자는 무엇을해야합니까?\nA. Amazon S3를 Transfer Acceleration과 함께 사용하여 애플리케이션을 호스팅합니다. B. CacheControl 헤더와 함께 Amazon S3를 사용하여 애플리케이션을 호스팅합니다. C. Amazon EC2와 Amazon CloudFront를 사용하여 애플리케이션을 호스팅합니다. D. Amazon EC2를 사용하여 자동 크기 조정 및 Amazon ElastiCache를 사용하여 애플리케이션을 호스팅합니다. #\rAnswer\r...\rAnswer: C\r#\rQ233\r#\r한 회사에서 재해 발생 시 복구하기 위해 데이터를 AWS로 복제하려고 합니다.현재 시스템 관리자가 NFS 공유에 데이터를 복제하는 스크립트를 보유하고 있습니다. 개별 백업 파일은 애플리케이션 관리자가 처리 오류를 처리하려면 짧은 지연 시간으로 액세스해야 합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 권장해야합니까?\nA. 온 프레미스 NFS 공유 대신 Amazon S3 버킷에 데이터를 복사하도록 스크립트를 수정합니다. - B. 온프레미스 NFS 공유 대신 Amazon S3 Glacier 아카이브로 데이터를 복사하도록 스크립트를 수정하십시오. C. 온 프레미스 NFS 공유 대신 Amazon EFS (Elastic 파일 시스템) 볼륨으로 데이터를 복사하도록 스크립트를 수정합니다. D. 온 프레미스 NFS 공유 대신 파일 게이트웨이용 AWS 스토리지 게이트웨이 가상 어플라이언스로 데이터를 복사하도록 스크립트를 수정합니다. #\rAnswer\r...\rAnswer: D\r#\rQ234\r#\r회사는 6개의 Aurora 복제본이 포함된 Amazon Aurora MySQL DB 클러스터에서 운영 워크로드를 실행합니다.이 회사는 부서 중 한 곳의 실제와 가까운 보고 쿼리를 Aurora Replicas에 자동으로 배포하기를 원합니다.이 세 개의 복제본은 나머지 DB 클러스터와 다른 컴퓨팅 및 메모리 사양을 가지고 있습니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. 워크로드에 대한 사용자 지정 엔드 포인트 만들기 및 사용 B. 3 노드 클러스터 클론을 생성하고 읽기 장치 엔드포인트 사용 C. 선택한 세 노드에 대해 인스턴스 엔드 포인트 중 하나를 사용합니다. D. 읽기 전용 워크로드를 자동으로 분산하려면 읽기 전용 엔드포인트를 사용합니다. #\rAnswer\r...\rAnswer: B\r#\rQ235\r#\r회사가 웹 포털을 배포하고 있습니다. 회사는 응용 프로그램의 웹 부분만 공개적으로 액세스 할 수 있는지 확인하려고합니다. 이를 위해 VPC는 2개의 퍼블릭 서브넷과 2개의 프라이빗 서브넷으로 설계되었습니다.애플리케이션은 Auto Scaling 그룹의 여러 Amazon EC2 인스턴스에서 실행됩니다. SSL 종료는 EC2 인스턴스에서 오프로드되어야 합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. 퍼블릭 서브넷에서 네트워크 로드 밸런서를 구성합니다.프라이빗 서브넷에서 Auto Scaling 그룹을 구성하고 이를 애플리케이션 로드 밸런서와 연결합니다. B. 퍼블릭 서브넷에서 네트워크 로드 밸런서를 구성합니다.퍼블릭 서브넷에서 Auto Scaling 그룹을 구성하고 이를 애플리케이션 로드 밸런서와 연결 C. 퍼블릭 서브넷에서 애플리케이션 로드 밸런서를 구성합니다.프라이빗 서브넷에서 Auto Scaling 그룹을 구성하고 이를 애플리케이션 로드 밸런서와 연결합니다. D. 프라이빗 서브넷에서 애플리케이션 로드 밸런서를 구성합니다.프라이빗 서브넷에서 Auto Scaling 그룹을 구성하고 이를 애플리케이션 로드 밸런서와 연결합니다. #\rAnswer\r...\rAnswer: C\r#\rQ236\r#\r온프레미스에서 웹 애플리케이션을 운영하는 회사는 AWS에서 새로운 버전의 애플리케이션을 시작할 준비를 하고 있습니다.회사는 URL 쿼리 문자열을 기반으로 AWS에서 호스팅하는 애플리케이션이나 온프레미스 호스팅 애플리케이션으로 요청을 라우팅해야 합니다.온프레미스 애플리케이션은 인터넷에서 사용할 수 없으며 Amazon VPC와 회사의 데이터 센터 간에 VPN 연결이 설정됩니다. 이 회사는 이번 출시에 애플리케이션 로드 밸런서 (ALB) 를 사용하려고 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 두 개의 ALB를 사용합니다. 하나는 온프레미스용이고 다른 하나는 AWS 리소스용입니다.각 ALB의 각 대상 그룹에 호스트를 추가합니다.URL 쿼리 문자열을 기반으로 Amazon Route 53로 라우팅합니다. B. 두 개의 ALB를 사용합니다. 하나는 온프레미스와 AWS 리소스용입니다.각 ALB의 대상 그룹에 호스트를 추가합니다.URL 쿼리 문자열을 기반으로 EC2 인스턴스에 소프트웨어 라우터를 만듭니다. C. AWS 리소스용과 온프레미스에 하나씩 두 개의 대상 그룹이 있는 ALB 하나를 사용합니다.ALB의 각 대상 그룹에 호스트를 추가합니다.URL 쿼리 문자열을 기반으로 리스너 규칙을 구성합니다. D. 두 개의 AWS Auto Scaling 그룹과 함께 ALB 하나를 사용합니다. 하나는 AWS 리소스용이고 다른 하나는 온프레미스용입니다.각 Auto Scaling 그룹에 호스트를 추가합니다.URL 쿼리 문자열을 기반으로 Amazon Route 53로 라우팅합니다. #\rAnswer\r...\rAnswer: C\r#\rQ237\r#\r솔루션 설계자가 애플리케이션에 대한 새 Amazon CloudFront 배포를 생성하고 있습니다. 사용자가 제출한 정보 중 일부는 민감합니다. 애플리케이션은 HTTPS를 사용하지만 또 다른 보안 계층이 필요합니다. 중요한 정보는 전체 애플리케이션 스택에서 보호되어야 하며 정보에 대한 액세스는 특정 애플리케이션으로 제한되어야 합니다. 솔루션 설계자는 어떤 조치를 취해야 합니까?\nA. CloudFront 서명된 URL 구성 B. CloudFront 서명된 쿠키를 구성합니다. C. CloudFronl 필드 수준 암호화 프로파일을 구성합니다. D. CloudFront를 구성하고 최종 사용자 프로토콜 포키에 대해 원본 프로토콜 정책 설정을 HTTPS 전용으로 설정 #\rAnswer\r...\rAnswer: C\r#\rQ238\r#\r회사에서 뉴스 콘텐츠를 호스팅하는 멀티 티어 웹 애플리케이션을 실행합니다. 애플리케이션은 애플리케이션 로드 밸런서 뒤의 Amazon EC2 인스턴스에서 실행됩니다.인스턴스는 여러 가용 영역에서 EC2 Auto Scaling 그룹에서 실행되며 Amazon Aurora 데이터베이스를 사용합니다.솔루션 설계자는 정기적인 요청 속도 증가에 대해 응용 프로그램의 탄력성을 높여야 합니다.솔루션 설계자는 어떤 아키텍처를 구현해야합니까?(두 개 선택)\nA. AWS 쉴드를 추가합니다. B. Aurora 복제본 추가 C. AWS Direct Connect 추가 D. AWS Global Accelerator 추가 E. 애플리케이션 로드 밸런서 앞에 Amazon CloudFront 배포를 추가합니다. #\rAnswer\r...\rAnswer: B E\r#\rQ239\r#\r회사는 Amazon DynamoDB에 기반을 둔 데이터 저장소가 있는 모바일 채팅 애플리케이션을 보유하고 있습니다.사용자는 가능한 한 적은 지연 시간으로 새 메시지를 읽기를 원합니다.솔루션 설계자는 최소한의 애플리케이션 변경이 필요한 최적의 솔루션을 설계해야 합니다. 솔루션 설계자는 어떤 방법을 선택해야합니까?\nA. 새 메시지 테이블에 대해 Amazon DynamoDB Accelerator (DAX) 를 구성합니다.DAX 엔드 포인트를 사용하도록 코드를 업데이트합니다. B. DynamoDB 읽기 전용 복제본을 추가하여 증가된 읽기 로드를 처리합니다.읽기 전용 복제본의 읽기 엔드 포인트를 가리키도록 애플리케이션을 업데이트합니다. C. DynamoDB의 새 메시지 테이블에 대한 읽기 용량 단위 수를 두 배로 늘립니다.기존 DynamoDB 엔드포인트를 계속 사용합니다. D. 애플리케이션 스택에 레디스용 Amazon ElastiCache 캐시를 추가합니다.DynamoDB 대신 Redis 캐시 엔드포인트를 가리키도록 애플리케이션을 업데이트합니다. #\rAnswer\r...\rAnswer: A\r#\rQ240\r#\r회사는 최근 새로운 유형의 인터넷 연결 센서를 출시했습니다.이 회사는 매초마다 많은 양의 데이터를 중앙 위치로 스트리밍하도록 설계된 수천 개의 센서를 판매할 것으로 기대하고 있습니다.솔루션 설계자는 엔지니어링 팀이 밀리초의 응답성으로 거의 실시간으로 데이터를 분석할 수 있도록 데이터를 수집 및 저장하는 솔루션을 설계해야 합니다.솔루션 설계자는 어떤 솔루션을 권장해야합니까?\nA. Amazon SQS 대기열을 사용하여 데이터를 수집할 수 있습니다.AWS Lambda 함수를 사용하여 데이터를 소비한 다음 Amazon Redshift에 데이터를 저장합니다. B. Amazon SOS 대기열을 사용하여 데이터를 수집할 수 있습니다.Amazon DynamoDB에 데이터를 저장하는 AWS Lambda 함수를 사용하여 데이터를 사용합니다. C. Amazon Kinesis Data Streams을 사용하여 데이터를 수집할 수 있습니다.AWS Lambda 함수를 사용하여 데이터를 소비한 다음 Amazon Redshift에 데이터를 저장합니다. D. Amazon Kinesis Data Streams을 사용하여 데이터를 수집하십시오.Amazon DynamoDB에 데이터를 저장하는 AWS Lambda 함수를 사용하여 데이터를 사용합니다. #\rAnswer\r...\rAnswer: D\r#\rQ241\r#\r회사가 새 AWS 계정을 설립했습니다.계정이 새로 프로비저닝되고 기본 설정이 변경되지 않았습니다.이 회사는 AWS 계정 루트 사용자의 보안에 대해 우려하고 있습니다. 루트 사용자를 보호하기 위해 수행해야 할 작업은 무엇입니까?\nA. 일일 관리 작업을 위한 IAM 사용자 생성 루트 사용자를 비활성화합니다. B. 일일 관리 작업을 위한 IAM 사용자 생성 루트 사용자에 대해 다중 요소 인증을 활성화합니다. C. 루트 사용자에 대한 액세스 키를 생성합니다.AWS 관리 콘솔 대신 일일 관리 작업에 액세스 키를 사용합니다. D. 가장 선임 솔루션 설계자에게 루트 사용자 자격 증명을 제공합니다.솔루션 설계자가 일일 관리 작업에 루트 사용자를 사용하도록 합니다. #\rAnswer\r...\rAnswer: B\r#\rQ242\r#\r회사는 Amazon RDS 데이터베이스 규정 준수 규정에 따라 Amazon EC2에서 매우 민감한 애플리케이션을 실행하고 있습니다. 모든 개인 식별 정보 (Pll) 를 암호화해야 합니다. 솔루션 설계자가 이 요구 사항을 충족하도록 권장해야 하는 솔루션은인프라에 대한 변경 사항”\nA. AWS 인증서 관리자를 배포하여 인증서 생성 인증서를 사용하여 데이터베이스 볼륨을 암호화합니다. B. AWS CloudHSM을 배포합니다. 암호화 키를 생성하고 고객 마스터 키 (CMK) 를 사용하여 데이터베이스 볼륨을 암호화합니다. C. AWS 키 관리 서비스 고객 마스터 키 (AWS KMS CMK) 를 사용하여 SSL 암호화를 구성하여 데이터베이스 볼륨을 암호화합니다. D. AWS KMS (키 관리 서비스) 키로 Amazon Elastic Block Store {Amazon EBS) 암호화 및 Amazon RDS 암호화를 구성하여 인스턴스 및 데이터베이스 볼륨을 암호화합니다. #\rAnswer\r...\rAnswer: D\r#\rQ243\r#\r회사가 Amazon EFS (Elastic 파일 시스템) 를 사용하여 데이터를 저장하는 애플리케이션을 보유하고 있습니다.파일의 크기는 1GB 이상이며 생성 후 처음 며칠 동안만 액세스되는 경우가 많습니다. 애플리케이션 데이터는 Linux 서버 클러스터에서 공유됩니다.이 회사는 애플리케이션에 대한 스토리지 비용을 절감하고자 하는 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떻게 해야 합니까?\nA. Amazon FSX를 구현하고 각 서버에 네트워크 드라이브를 마운트합니다. B. Amazon EFS에서 요금을 이동하여 각 Amazon EC2 인스턴스에 로컬로 저장합니다. C. 7일 후에 파일을 EFS 드물게 액세스 (IA) 스웨지 클래스로 이동하도록 수명 주기 정책을 구성합니다. D. S3 수명 주기 정책이 활성화된 상태로 파일을 Amazon S3로 이동합니다.S3 버킷 마운트를 지원하도록 애플리케이션을 다시 작성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ244\r#\r회사는 타사 공급업체로부터 거의 실시간으로 데이터를 수신할 수 있는 REST 기반 인터페이스를 갖춘 애플리케이션을 보유하고 있습니다. 수신되면 애플리케이션은 추가 분석을 위해 데이터를 처리하고 저장합니다.애플리케이션이 Amazon EC2 인스턴스에서 실행 중입니다.타사 공급 업체는 응용 프로그램에 데이터를 보낼 때 많은 503 서비스 사용할 수 없음 오류를 받았습니다.데이터 볼륨이 급증하면 컴퓨팅 용량이 최대 한계에 도달하여 응용 프로그램에서 모든 요청을 처리할 수 없습니다. 솔루션 설계자가 확장성이 뛰어난 솔루션을 제공하기 위해 어떤 디자인을 추천해야 합니까?\nA. Amazon Kinesis Data Streams을 사용하여 데이터 수집 AWS Lambda 함수를 사용하여 데이터를 처리합니다. B. 기존 애플리케이션 위에 Amazon API 게이트웨이를 사용합니다.타사 공급업체에 대한 할당량 Iimit 사용 계획을 생성합니다. C. Amazon SNS (단순 알림 서비스) 를 사용하여 데이터 수집 EC2 인스턴스를 애플리케이션 로드 밸런서 뒤에 있는 Auto Scaling 그룹에 넣습니다. D. 응용 프로그램을 컨테이너로 다시 패키지합니다.EC2 시작 유형을 Auto Scaling 그룹과 함께 사용하여 Amazon ECS (Amazon Elastic Container Service) 를 사용하여 애플리케이션을 배포합니다. #\rAnswer\r...\rAnswer: A\r#\rQ245\r#\r한 회사는 분기별로 액세스하는 데이터에 대한 데이터 저장 비용을 최적화하려고 합니다.이 회사는 높은 처리량, 짧은 지연 시간 및 신속한 액세스를 필요로 합니다. 필요한 경우 솔루션 설계자가 권장해야 하는 Amazon S3 스토리지 클래스는 무엇입니까?\nA. Amazon S3 Glacier (S3 Glacier) B. Amazon S3 표준 (S3 표준) C. Amazon S3 Intelliginet 계층화 (S3 Intelliginet 계층화) D. Amazon S3 표준 Standard Infrequent Access(Standard-Infrequent) (S3 표준-IA) #\rAnswer\r...\rAnswer: D\r#\rQ246\r#\rAmazon S3 버킷에 업로드된 모든 객체가 암호화되도록 솔루션 설계자는 어떻게 해야 합니까?\nA. putObject에 s3 x-amz-acl 헤더 세트가 없는 경우 거부하도록 버킷 정책을 업데이트합니다. B. putObject에 s3 x-amz-acl 헤더가 비공개로 설정되어 있지 않은 경우 거부하도록 버킷 정책을 업데이트합니다. C. putObject에 aws SecureTransport 헤더가 true로 설정되어 있지 않은 경우 거부하도록 버킷 정책을 업데이트합니다. D. PutObject에 x-amz-server-side-encryption 헤더 세트가 없는 경우 거부하도록 버킷 정책을 업데이트합니다. #\rAnswer\r...\rAnswer: D\r#\rQ247\r#\r미디어 회사는 비디오 콘텐츠를 Amazon EBS (Elastic Block Store) 볼륨에 저장합니다.특정 비디오 파일이 인기를 얻었으며 전 세계 많은 수의 사용자가이 콘텐츠에 액세스하고 있습니다.이로 인해 비용이 증가했습니다.사용자 접근성에 영향을 주지 않으면서 비용을 절감할 수 있는 조치는 무엇입니까?\nA. EBS 볼륨을 프로비저닝된 IOPS (PIOPS) 로 변경합니다. B. 비디오를 Amazon S3 버킷에 저장하고 Amazon CloudFront 배포를 생성합니다. C. 비디오를 여러 개의 작은 세그먼트로 분할하여 사용자가 요청된 비디오 세그먼트로만 라우팅되도록 합니다. D. 각 리전에서 Amazon S3 버킷을 지우고 사용자가 가장 가까운 S3 버킷으로 라우팅되도록 비디오를 업로드합니다. #\rAnswer\r...\rAnswer: B\r#\rQ248\r#\r솔루션 설계자는 무엇을 권장해야합니까?\nA. 보조 리전의 Amazon EC2에 MySQL 설치 B. 교차 리전 복제본을 사용하여 데이터베이스를 Amazon Aurora로 마이그레이션 C. 보조 리전에 MySQL용 다른 RDS 읽기 전용 복제본 생성 D. Amazon ElastiCache를 구현하여 데이터베이스 쿼리 성능 향상 #\rAnswer\r...\rAnswer: B\r#\rQ249\r#\r한 회사는 최근 미국 동부 1 리전의 두 가용 영역에 2 계층 애플리케이션을 배포했습니다.웹서버는 퍼블릭 서브넷에 배포되는 동안 데이터베이스는 프라이빗 서브넷에 배포됩니다.인터넷 게이트웨이가 VPC에 연결되어 있습니다.애플리케이션 및 데이터베이스는 Amazon EC2 인스턴스에서 실행됩니다.데이터베이스 서버는 인터넷에서 패치에 액세스할 수 없습니다.솔루션 설계자는 최소한의 운영 오버헤드로 데이터베이스 보안을 유지하는 솔루션을 설계해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 각 가용 영역의 퍼블릭 서브넷 내에 NAT 게이트웨이를 배포하고 이를 Elastic IP 주소와 연결합니다.프라이빗 서브넷의 라우팅 테이블을 업데이트하여 기본 경로로 사용합니다. B. 각 가용 영역의 프라이빗 서브넷 내에 NAT 게이트웨이를 배포하고 이를 Elastic IP 주소와 연결합니다.프라이빗 서브넷의 라우팅 테이블을 업데이트하여 기본 경로로 사용합니다. C. 각 가용 영역의 퍼블릭 서브넷 내에 두 개의 NAT 인스턴스를 배포하고 이를 Elastic IP 주소와 연결합니다.프라이빗 서브넷의 라우팅 테이블을 업데이트하여 기본 경로로 사용합니다. D. 각 가용 영역의 프라이빗 서브넷 내에 두 개의 NAT 인스턴스를 배포하고 이를 Elastic IP 주소와 연결합니다.프라이빗 서브넷의 라우팅 테이블을 업데이트하여 기본 경로로 사용합니다. #\rAnswer\r...\rAnswer: A\r#\rQ250\r#\r솔루션 설계자가 Amazon API 게이트웨이 뒤에 새로운 서비스를 설계하고 있습니다. 서비스에 대한 요청 패턴은 예측할 수 없으며 0 요청에서 초당 500 이상으로 갑자기 변경 될 수 있습니다. 백엔드 데이터베이스에서 유지해야 하는 데이터의 총 크기는 현재예측할 수 없는 미래 성장 간단한 키-값 요청을 사용하여 데이터를 쿼리할 수 있는 AWS 서비스 조합은 이러한 요구 사항을 충족합니까?(두 개 선택)\nA. AWS Fargate B. AWS Lambda C. Amazon DynamoDB D. Amazon EC2 Auto Scaling E. MySQL 호환 Amazon Aurora #\rAnswer\r...\rAnswer: B C\r#\rQ251\r#\r솔루션 설계자는 Amazon S3를 사용하여 새로운 디지털 미디어 애 미디어 파일은 가용 영역 손실에 대한 복원력이 있어야 합니다. 일부 파일은 자주 액세스되지만 다른 파일은 예측할 수 없는 패턴으로 거의 액세스되지 않습니다.솔루션 설계자는 미디어 파일을 저장하고 검색하는 비용을 최소화해야 합니다. 이러한 요구 사항을 충족하는 스토리지 옵션은 무엇입니까?\nA. S3 표준 B. S3 Intelliginet 계층화 C. S3 표준 드물게 액세스 {S3 표준-IA) D. S3 One Zone Standard Infrequent Access (S3 One Zone-IA) #\rAnswer\r...\rAnswer: B\r#\rQ252\r#\r회사의 애플리케이션이 Elastic 로드 밸런서 뒤에 있는 Auto Scaling 그룹 내의 Amazon EC2 인스턴스에서 실행 중이며, 애플리케이션의 내역에 따라 매년 휴가 기간 동안 트래픽이 급증할 것으로 예상됩니다.솔루션 설계자는 Auto Scaling 그룹이 사전 예방적으로 용량을 늘리고 애플리케이션 사용자에게 미치는 성능에 미치는 영향을 최소화할 수 있도록 전략을 설계해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. CPU 사용률이 90% 를 초과할 때 EC2 인스턴스를 확장하려면 Amazon CloudWatch 경보를 생성합니다. B. 예약된 반복 작업을 생성하여 예상 최대 수요 기간 전에 Auto Scaling 그룹을 확장합니다. C. 최대 수요 기간 동안 Auto Scaling 그룹에서 EC2 인스턴스의 최소 및 최대 수를 늘립니다. D. 자동 크기 조정: EC2_instance_Launch 이벤트가 있을 때 경고를 보내도록 Amazon SNS (단순 알림 서비스) 알림을 구성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ253\r#\r솔루션 설계자는 새로운 워크로드를 배포하기 전에 회사의 기존 IAM 정책을 분석하고 업데이트해야 합니다.솔루션 설계자는 다음 정책을 작성했습니다.\n이 정책의 순 효과는 무엇입니까?\nA. 다중 요소 인증 (MFA) 이 활성화된 경우 s3 PutObject를 제외한 모든 작업이 사용자에게 허용됩니다. B. 다중 요소 인증 (MFA) 이 활성화되지 않은 경우 s3 PutObject를 제외한 모든 작업을 수행할 수 있습니다. C. 다중 요소 인증 (MFA) 이 활성화된 경우 s3; putObject를 제외한 모든 작업은 사용자가 거부됩니다. D. 다중 요소 인증 (MFA) 이 활성화되지 않은 경우 S3:putObject를 제외한 모든 작업이 거부됩니다. #\rAnswer\r...\rAnswer: D\r#\rQ254\r#\r회사는 Amazon EC2 인스턴스 및 온프레미스 가상화 서버에서 외부 웹 사이트를 실행해야 합니다. AWS 환경은 데이터 센터에 1GB의 AWS Direct Connect 연결이 있습니다.응용 프로그램에 변경되지 않는 IP 주소가 있습니다.오류가 발생하는 경우 온프레미스 및 AWS 서버는 동일한 IP 주소를 유지하면서 스스로를 다시 시작할 수 있습니다. 일부 웹 사이트 사용자는 공급업체를 허용 목록에 추가해야 하므로 솔루션에 고정 IP 주소가 있어야 합니다. 이분할 트래픽.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. 온프레미스 및 AWS IP 주소를 가리키는 규칙이 포함된 Amazon Route 53 해결 프로그램을 배포합니다. B. AWS에 네트워크 로드 밸런서를 배포합니다.온프레미스 및 AWS IP 주소에 대한 대상 그룹을 생성합니다. C. AWS에 애플리케이션 로드 밸런서 배포 대상 그룹에 온 프레미스 및 AWS IP 주소를 등록합니다. D. Amazon API 게이트웨이를 배포하여 요청 헤더에 따라 온 프레미스 및 AWS IP 주소로 트래픽을 보냅니다. #\rAnswer\r...\rAnswer: A\r#\rQ255\r#\r회사가 AWS Lambda 함수를 호출하는 애플리케이션을 보유하고 있습니다. 최근 코드 검토에서 소스 코드에 저장된 데이터베이스 자격 증명을 찾았습니다. 데이터베이스 자격 증명은 Lambda 소스 코드에서 제거해야 합니다. 그런 다음 자격 증명은 진행 중인 보안 정책 요구 사항을 충족하기 위한 기준 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 권장해야 합니까?\nA. AWS CloudHSM에 암호 저장 Lambda 함수를 키 ID가 지정된 CloudHSM에서 암호를 검색할 수 있는 역할과 연결합니다. B. AWS 비밀 관리자에 암호를 저장합니다. Lambda 함수를 보안 ID가 지정된 경우 보안 관리자에서 암호를 검색할 수 있는 역할과 연결합니다. C. Lambda 함수와 연결된 환경 변수로 데이터베이스 암호 이동 실행 시 환경 변수에서 암호 검색 D. AWS KMS (키 관리 서비스) 에 암호 저장 Lambda 함수를 키 ID가 지정된 AWS KMS에서 암호를 검색할 수 있는 역할과 연결합니다. #\rAnswer\r...\rAnswer: B\r#\rQ256\r#\r애플리케이션이 Amazon EC2 인스턴스에서 실행 중이며 워크로드를 실행할 때 지연 시간이 밀리초여야 합니다.응용 프로그램은 파일 시스템에 많은 작은 읽기 및 쓰기를 수행하지만 파일 시스템 자체는 작습니다. 솔루션 설계자가 EC2 인스턴스에 연결해야 하는 Amazon EBS (Elastic Block Store) 볼륨 유형은 무엇입니까?\nA. 콜드 HDD (sc1) B. 범용 SSD (gp2) C. 프로비저닝된 IOPS SSD (IO1) D. 처리량 최적화 HDD (st1) #\rAnswer\r...\rAnswer: C\r#\rQ257\r#\r전자 상거래 회사는 사용자 트래픽의 증가를 경험하고 있습니다.이 회사의 스토어는 Amazon EC2 인스턴스에 웹 티어와 별도의 데이터베이스 계층으로 구성된 2 계층 애플리케이션으로 배포됩니다. 트래픽이 증가함에 따라, 이 아키텍처는 사용자에게 시기적절한 마케팅 및 주문 확인 이메일을 보내는 데 상당한 지연을 초래하고 있음을 알립니다.이 회사는 복잡한 이메일 전송 문제를 해결하는 데 소요되는 시간을 줄이고 운영 오버헤드를 최소화하고자 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떻게 해야 합니까?\nA. 이메일 처리 전용 EC2 인스턴스를 사용하여 별도의 애플리케이션 계층을 생성합니다. B. Amazon SES (단순 이메일 서비스) C를 통해 이메일을 보내도록 웹 인스턴스 구성 C. Amazon SNS (단순 알림 서비스) 를 통해 이메일을 보내도록 웹 인스턴스를 구성합니다. D. 이메일 처리 전용 EC2 인스턴스를 사용하여 별도의 애플리케이션 계층을 생성합니다.인스턴스를 Auto Scaling 그룹에 배치합니다. #\rAnswer\r...\rAnswer: B\r#\rQ258\r#\r솔루션 설계자가 AWS에 배포되는 새 애플리케이션을 위한 클라우드 아키텍처를 설계하고 있습니다. 프로세스는 처리할 작업 수에 따라 필요에 따라 애플리케이션 노드를 추가 및 제거하는 동시에 병렬로 실행되어야 합니다. 프로세서 애플리케이션은 상태 비저장됨 솔루션 설계자는응용 프로그램이 느슨하게 결합되고 작업 항목이 내구성이 있는지 확인합니다. 저장 솔루션 설계자는 어떤 디자인을 사용해야합니까?\nA. 처리해야 할 작업을 전송하려면 Amazon SNS 주제를 생성합니다. 프로세서 애플리케이션으로 구성된 Amazon 머신 이미지 (AMI) 생성 시작 구성을 사용하여 AMI를 사용하는 시작 구성 생성 Auto Scaling 그룹 생성 Auto Scaling 그룹의 조정 정책을CPU 사용량에 따라 노드 추가 및 제거 B. 처리해야 할 작업을 보관할 Amazon SQS 대기열 생성 프로세서 애플리케이션으로 구성된 Amazon 머신 이미지 (AMI) 생성 시작 구성을 사용하여 AMI를 사용하는 시작 구성 생성 Auto Scaling 그룹 생성 Auto Scaling 그룹의 조정 정책을네트워크 사용량에 따라 노드 추가 및 제거 C. 처리해야 할 작업을 보관할 Amazon SQS 대기열 생성 프로세서 애플리케이션으로 구성된 Amazon 머신 이미지 (AMI) 생성 시작 템플릿을 사용하여 AMI를 사용하는 시작 템플릿 생성 Auto Scaling 그룹 생성 추가할 Auto Scaling 그룹에 대한 조정 정책 설정SQS 대기열의 항목 수에 따라 노드 제거 D. 처리해야 할 작업을 전송하려면 Amazon SNS 주제를 생성합니다. 프로세서 애플리케이션으로 구성된 Amazon 머신 이미지 (AMI) 생성 시작 템플릿을 사용하여 AMI를 사용하는 시작 템플릿 생성 Auto Scaling 그룹 생성 추가할 Auto Scaling 그룹의 조정 정책 설정는 SNS 주제에 게시된 메시지 수에 따라 노드를 제거합니다. #\rAnswer\r...\rAnswer: C\r#\rQ259\r#\r회사는 Amazon S3 버킷 내에 정적 웹 사이트를 호스팅합니다.솔루션 설계자는 실수로 삭제한 경우 데이터를 복구할 수 있도록 해야 합니다. 이 작업을 수행하는 작업은 무엇입니까?\nA. Amazon S3 버전 관리 활성화 B. Amazon S3 Intelliginet 계층화를 활성화합니다. C. Amazon S3 수명 주기 정책 활성화 D. Amazon S3 교차 리전 복제를 활성화합니다. #\rAnswer\r...\rAnswer: A\r#\rQ260\r#\r회사가 VPC의 프라이빗 서브넷 내의 Amazon EC2 인스턴스에서 실행되는 애플리케이션을 보유하고 있습니다. 인스턴스는 동일한 AWS 리전에 있는 Amazon S3 버킷의 데이터에 액세스합니다.VPC에는 S3 버킷에 액세스할 수 있는 퍼블릭 서브넷에 NAT 게이트웨이가 포함되어 있습니다. 회사는 보안이나 중복성을 손상시키지 않고 NAT 게이트웨이를 교체하여 비용을 절감하려고 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. NAT 게이트웨이를 NAT 인스턴스로 바꿉니다. B. NAT 게이트웨이를 인터넷 게이트웨이로 교체합니다. C. NAT 게이트웨이를 게이트웨이 VPC 엔드포인트로 교체 D. NAT 게이트웨이를 AWS Direct Connect 연결로 교체 #\rAnswer\r...\rAnswer: C\r#\rQ261\r#\r회사는 서비스를 사용하여 2 계층 전자 상거래 웹 사이트를 운영하고 있습니다.현재 설계자는 프라이빗 서브넷의 Amazon EC2 인스턴스로 트래픽을 전송하는 게시 연결 Elastic 로드 밸런서를 사용합니다.정적 콘텐츠는 EC2 인스턴스에서 호스팅되며 동적 콘텐츠는 MYSQL 데이터베이스에서 검색됩니다.응용 프로그램이 미국에서 실행 중입니다.이 회사는 최근 유럽과 호주의 사용자에게 판매를 시작했습니다.솔루션 설계자는 해외 사용자가 향상된 검색 환경을 제공할 수 있도록 솔루션을 설계해야 합니다. 가장 비용 효율적인 솔루션은 무엇입니까?\nA. Amazon S3에 전체 웹 사이트를 호스팅합니다. B. Amazon CloudFront 및 Amazon S3를 사용하여 정적 이미지를 호스팅합니다. C. 퍼블릭 로드 밸런서 및 EC2 인스턴스 수 증가 D. 유럽 및 Austraila의 AWS 리전에 2계층 웹 사이트를 배포합니다. #\rAnswer\r...\rAnswer: B\r#\rQ262\r#\r솔루션 설계자는 비즈니스 사용자가 Amazon S3에 객체를 업로드할 수 있는 애플리케이션을 설계하고 있습니다. 이 솔루션은 물체의 내구성을 극대화해야 합니다.또한 객체는 언제든지 어떤 시간 동안 쉽게 사용할 수 있어야 합니다.사용자는 객체를 업로드한 후 처음 30일 이내에 객체에 자주 액세스하지만 사용자는 30일 이상 지난 객체에 액세스할 가능성이 훨씬 적습니다.이러한 요구 사항을 가장 경제적으로 충족하는 솔루션은 무엇입니까?\nA. S3 수명 주기 규칙과 함께 모든 객체를 S3 표준에 저장하여 30일 후에 객체를 S3 Giacier로 전환합니다. B. 모든 객체를 S3 수명 주기 규칙과 함께 S3 표준에 저장하여 객체를 30일 후에 S3 Standard-infrequent Access (S3 표준-IA) 로 전환합니다. C. 모든 객체를 S3 수명 주기 규칙과 함께 S3 표준에 저장하여 30일 후에 객체를 S3 영역 드물게 액세스 (S3 영역-IA) 로 전환합니다. D. S3 수명 주기 규칙과 함께 모든 객체를 S3 Intelliginet 계층화 에 저장하여 객체를 S3 Standard-infrequent Access (S3 표준-IA) 로 전환합니다. #\rAnswer\r...\rAnswer: D\r#\rQ263\r#\r회사는 매월 초에 판매 보고서를 작성해야합니다.보고 프로세스는 매월 첫 번째 날에 20개의 Amazon EC2 인스턴스를 시작합니다.이 프로세스는 7 일 동안 실행되며 중단 될 수 없습니다.이 회사는 비용을 최소화하려고 합니다. 회사는 어떤 가격 모델을 선택해야합니까?\nA. 예약 인스턴스 B. 스팟 블록 인스턴스 C. 온 디맨드 D. 예약된 예약 인스턴스 #\rAnswer\r...\rAnswer: D\r#\rQ264\r#\rAWS로 이전할 때 애플리케이션의 성능을 향상시킬 수 있는 솔루션은 무엇입니까?\nA. 프로비저닝된 용량이 있는 Amazon DynamoDB 테이블로 데이터를 가져옵니다.보고서를 위해 DynamoDB를 사용하도록 애플리케이션을 리팩터링합니다. B. 컴퓨팅 최적화 Amazon EC2 인스턴스에서 데이터베이스 생성 컴퓨팅 리소스가 온프레미스 데이터베이스를 초과하는지 확인 C. 여러 읽기 전용 복제본이 포함된 Amazon Aurora MySQL 다중 AZ DB 클러스터를 생성합니다.읽기 장치 엔드 포인트 tor 보고서를 사용하도록 응용 프로그램을 구성합니다. D. Amazon Aurora MySQL 다중 AZ DB 클러스터 생성 클러스터의 백업 인스턴스를 보고서의 엔드포인트로 사용하도록 애플리케이션을 구성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ265\r#\r회사는 보험 견적을 처리하는 AWS를 사용하여 웹 애플리케이션을 설계하고 있습니다. 사용자가 애플리케이션에서 견적을 요청할 것입니다. 견적 유형으로 구분해야 합니다. 이러한 요구 사항을 충족하는 솔루션”\nA. 인용 유형에 따라 여러 Amazon Kinesis Data Streams 생성 적절한 Data Streams으로 메시지를 보내도록 웹 애플리케이션 구성 Kinesis 클라이언트 라이브러리 (Kinesis 클라이언트 라이브러리) 를 사용하여 자체 Data Streams에서 메시지를 풀하도록 애플리케이션 서버의 각 백엔드 그룹 구성 B. 여러 Amazon 단순 알림 서비스 {Amazon SNS) 주제를 생성하고 견적 유형에 따라 자체 SNS 주제에 Amazon SQS 대기열을 등록합니다.SNS 주제 대기열에 메시지를 게시하도록 웹 애플리케이션 구성 자체 SQS 대기열을 작동하도록 각 백엔드 애플리케이션 서버 구성 C. 단일 Amazon 단순 알림 서비스 {Amazon SNS) 주제를 생성하고 Amazon SQS 대기열을 SNS 주제로 구독하여 견적 유형에 따라 적절한 SQS 대기열에 메시지를 게시하도록 SNS 메시지 필터링을 구성합니다.자체 SQS 대기열을 작동하도록 각 백엔드 애플리케이션 서버를 구성합니다. D. 견적 유형에 따라 여러 Amazon Kinesis Data Firehose 전송 스트림을 생성하여 Amazon Elasticsearch 서비스 {Amazon ES) 클러스터로 Data Streams을 전달합니다.적절한 전송 스트림으로 메시지를 보내도록 웹 애플리케이션 구성 Amazon ES에서 메시지를 검색하고 그에 따라 처리하도록 애플리케이션 서버의 각 백엔드 그룹 구성 #\rAnswer\r...\rAnswer: C\r#\rQ266\r#\r한 회사에서 여러 AWS 리전에서 애플리케이션 로드 밸런서 (ALB) 를 사용합니다.ALB는 일년 내내 스파이크 및 드롭할 수 있는 일관되지 않은 트래픽을 수신합니다. 회사의 네트워킹 팀은 연결을 활성화하려면 온-프레미스 방화벽에 있는 ALB의 IP 주소를 허용해야 합니다.구성 변경을 최소화하면서 확장성이 가장 뛰어난 솔루션은 무엇입니까?\nA. AWS Lambda 스크립트를 작성하여 여러 지역의 ALB의 IP 주소를 가져오도록 온프레미스 방화벽 규칙을 업데이트하여 ALB의 IP 주소를 허용합니다. B. 서로 다른 지역의 모든 ALB를 NLB (네트워크 로드 밸런서) 로 마이그레이션 온프레미스 방화벽 규칙을 업데이트하여 모든 NLB의 Elastic IP 주소를 허용합니다. C. AWS 글로벌 Accelerator 시작 여러 지역의 ALB를 Accelerator에 등록합니다.Accelerator와 연결된 고정 IP 주소를 허용하도록 온-프레미스 방화벽의 규칙을 업데이트합니다. D. 한 리전에서 NLB (네트워크 부하 분산 장치) 시작 NLB를 사용하여 ALB m 다른 지역의 프라이빗 IP 주소를 등록하여 NLB에 연결된 Elastic IP 주소를 허용하도록 온-프레미스 방화벽 규칙을 업데이트합니다. #\rAnswer\r...\rAnswer: C\r#\rQ267\r#\r한 회사에서 온프레미스 네트워크 연결 스토리지 (NAS) 를 AWS로 이전하려고 합니다.더 회사는 VPC 내의 모든 Linux 인스턴스에서 데이터를 사용할 수 있도록 하고 데이터 저장소에 액세스하는 모든 인스턴스에서 변경 사항이 자동으로 동기화되도록 합니다.대부분의 데이터는 매우 드물게 액세스되며 일부 파일은 여러 사용자가 동시에 액세스할 수 있습니다.이러한 요구 사항을 충족하고 가장 비용 효율적인 솔루션은 무엇입니까?\nA. 데이터가 포함된 Amazon Elastic Block Store (Amazon EBS) 스냅샷을 생성합니다.VPC 내의 사용자와 공유합니다. B. 적절한 일수가 지난 후 데이터를 S3 표준 액세스 횟수 (S3 Standard-IA) 로 전환하도록 설정된 수명 주기 정책이 있는 Amazon S3 버킷을 생성합니다. C. VPC 내에 Amazon EFS (Elastic 파일 시스템) 파일 시스템을 생성합니다.처리량 모드를 프로비저닝으로 설정하고 동시 사용을 지원하는 데 필요한 IOPS 양으로 설정합니다. D. VPC 내에 Amazon EFS (Elastic 파일 시스템) 파일 시스템을 생성합니다.적절한 기간 (일) 후에 데이터를 EFS 자주 액세스 (EFS IA) 로 전환하도록 수명 주기 정책을 설정합니다. #\rAnswer\r...\rAnswer: D\r#\rQ268\r#\r회사가 Amazon RDS의 데이터베이스에 목록을 저장하는 자동차 판매 웹 사이트를 보유하고 있습니다. 자동차가 판매되면 웹 사이트에서 리스팅을 제거하고 데이터를 여러 대상 시스템으로 전송해야 합니다. 솔루션 설계자는 어떤 디자인을 추천해야합니까?\nA. Amazon RDS의 데이터베이스가 업데이트될 때 트리거되는 AWS Lambda 함수를 생성하여 대상이 소비할 Amazon SOS (단순 대기열 서비스) 대기열로 정보를 전송합니다. B. Amazon RDS의 데이터베이스가 업데이트되어 타겟이 사용할 Amazon SQS (단순 대기열 서비스) FIFO 대기열로 정보를 전송할 때 트리거되는 AWS Lambda 함수를 생성합니다. C. RDS 이벤트 알림을 구독하고 Amazon SQS (단순 알림 서비스) 큐를 여러 Amazon SNS (단순 알림 서비스) 주제로 전송하여 AWS Lambda 함수를 사용하여 대상 업데이트 D. RDS 이벤트 알림을 구독하고 Amazon SNS (단순 알림 서비스) 주제를 여러 Amazon SQS (Amazon SQS) 대기열로 전송하여 AWS Lambda 함수를 사용하여 대상 업데이트 #\rAnswer\r...\rAnswer: D\r#\rQ269\r#\r회사가 두 개의 프라이빗 서브넷에서 Amazon ECS (Amazon Elastic Container Service) 에서 실행되는 이미지 처리 워크로드를 보유하고 있습니다.각 프라이빗 서브넷은 인터넷 액세스에 NAT 인스턴스를 사용합니다.모든 이미지는 Amazon S3 버킷에 저장됩니다. 이 회사는 Amazon ECS와 Amazon S3 간의 데이터 전송 비용에 대해 우려하고 있습니다. 솔루션 설계자는 비용을 절감하기 위해 무엇을해야합니까?\nA. NAT 인스턴스를 교체하도록 NAT 게이트웨이를 구성합니다. B. Amazon S3로 향하는 트래픽에 대한 게이트웨이 엔드포인트를 구성합니다. C. Amazon S3로 향하는 트래픽에 대한 인터페이스 엔드포인트 구성 D. 이미지를 저장하는 S3 버킷에 대해 Amazon CloudFront를 구성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ270\r#\r회사에서 Amazon EC2 인스턴스에서 분석 소프트웨어를 실행합니다. 소프트웨어가 작업을 수락합니다. Amazon S3에 업로드된 데이터를 처리하도록 사용자의 요청 중 일부 제출된 데이터가 처리되지 않는다고 보고함 Amazon CloudWatch에서 EC2 인스턴스의 CPU 사용률이 일관되게 유지됨을 알 수 있음 100% 회사는 시스템 성능을 향상시키고 사용자 부하에 따라 시스템을 확장하고자 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?\nA. 인스턴스 복사본 생성 모든 인스턴스를 애플리케이션 로드 밸런서 뒤에 배치 B. Amazon S3용 S3 VPC 엔드포인트 생성 엔드포인트를 참조하도록 소프트웨어를 업데이트합니다. C. EC2 인스턴스 중지 인스턴스 유형을 더 강력한 CPU와 더 많은 메모리를 가진 인스턴스 유형으로 수정 인스턴스를 다시 시작합니다. D. 수신 요청을 Amazon SQS (단순 대기열 서비스) 로 라우팅 대기열 크기에 따라 EC2 Auto Scaling 그룹 구성 대기열에서 읽도록 소프트웨어 업데이트 #\rAnswer\r...\rAnswer: A\r#\rQ271\r#\r회사에서 Amazon EC2 인스턴스에서 단일 계층 아키텍처를 사용하는 레거시 애플리케이션을 실행합니다. 디스크 I/O가 낮습니다. 업무 시간 동안 약간의 스파이크가 발생하는 경우가 있습니다.이 회사는 매일 오후 8시부터 오전 8시까지 인스턴스를 중지해야 합니다. 이 워크로드에 가장 적합한 스토리지 옵션은 무엇입니까?\nA. Amazon EC2 인스턴스 스토리지 B. Amazon EBS 범용 SSD (gp2) 스토리지 C. Amazon S3 D. Amazon EBS 프로비저닝된 IOPS SSD (io2) 스토리지 #\rAnswer\r...\rAnswer: B\r#\rQ272\r#\r보안 팀이 팀의 모든 AWS 계정에서 특정 서비스 또는 작업에 대한 액세스를 제한하려고 합니다.모든 계정은 AWS 조직의 대규모 조직에 속합니다. 솔루션은 확장 가능해야 하며 권한을 유지할 수 있는 단일 지점이 있어야 합니다.이를 달성하기 위해 솔루션 설계자는 무엇을해야합니까?\nA. 서비스 또는 작업에 대한 액세스 권한을 제공하는 ACL을 생성합니다. B. 보안 그룹을 생성하여 계정을 허용하고 사용자 그룹에 연결합니다. C. 각 계정에 교차 계정 역할을 생성하여 서비스 또는 작업에 대한 액세스를 거부합니다. D. 루트 조직 구성 단위에 서비스 제어 정책을 만들어 서비스 또는 작업에 대한 액세스를 거부합니다. #\rAnswer\r...\rAnswer: D\r#\rQ273\r#\r솔루션 설계자는 타사 데이터베이스 서버를 실행하기 위한 아키텍처를 설계하고 있습니다.메모리 집약적이고 운영 체제 내의 vCPU 코어 수에 따라 비용이 증가하는 CPU 기반 라이선스 모델이 있습니다.솔루션 설계자는메모리를 사용하여 데이터베이스 소프트웨어를 실행할 수 있지만 선택한 인스턴스에는 많은 수의 vCPU가 있습니다.솔루션 설계자는 vCPU의 활용도가 낮지 않고 비용을 최소화해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 적절한 수의 vCPU를 사용하여 더 작은 EC2 인스턴스를 선택하고 시작합니다. B. 인스턴스 시작 중에 선택한 EC2 인스턴스에서 CPU 코어와 스레드를 구성합니다. C. 새 EC2 인스턴스를 생성하고 인스턴스 세부 정보를 구성할 때 멀티스레딩이 활성화되어 있는지 확인하십시오. D. 새 용량 예약을 생성하고 적절한 인스턴스 유형을 선택합니다.이 새로운 용량 예약으로 인스턴스를 시작합니다. #\rAnswer\r...\rAnswer: A\r#\rQ274\r#\r이 회사는 필요한 인프라를 수동으로 프로비저닝하여 새로운 웹 사이트의 인프라를 프로토타이핑하고 있습니다.이 인프라에는 Auto Scaling 그룹, 애플리케이션 로드 밸런서 및 Amazon RDS 데이터베이스가 포함됩니다.구성이 완전히 검증되면 기능 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 권장해야 하며, 기업은 두 가용 영역 모두에서 개발 및 프로덕션을 위해 인프라를 즉시 배포할 수 있습니다.”\nA. AWS Systems Manager를 사용하여 프로토타입 인프라를 두 가용 영역에서 복제하고 프로비저닝합니다. B. 프로토타입 인프라를 가이드로 사용하여 인프라를 템플릿으로 정의 AWS CloudFormation을 사용하여 인프라 배포 C. AWS Config를 사용하여 프로토타입 인프라에 사용된 리소스 인벤토리 AWS Config를 사용하여 프로토타입 인프라를 두 개의 가용 영역에 배포합니다. D. 프로토타입 인프라에 대한 자동 참조와 함께 AWS Elastic Beanstalk를 사용하여 두 가용 영역에 자동으로 배포되도록 새 환경을 구성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ275\r#\r회사는 Amazon RDS에서 MySQL용 데이터베이스를 개발했습니다. 지원 팀의 증가로 인해 DB 인스턴스의 느린 읽기 속도를 보고하고 읽기 전용 복제본을 추가하는 것이 좋습니다. 이 변경 사항을 구현하기 전에 솔루션 설계자가 수행해야 하는 작업 조합은 무엇입니까?(두 개를 선택합니다.)\nA. RDS 마스터에서 binlog 복제를 사용하도록 설정합니다. B. 원본 DB 인스턴스의 장애 조치 우선 순위를 선택합니다. C. 원본 DB 인스턴스에서 장기 실행 트랜잭션을 완료할 수 있습니다. D. 글로벌 테이블을 생성하고 테이블을 사용할 수 있는 AWS 리전을 지정합니다. E. 백업 보존 기간을 0 이외의 값으로 설정하여 소스 인스턴스에서 자동 백업을 활성화합니다. #\rAnswer\r...\rAnswer: C E\r#\rQ276\r#\r전자 상거래 회사는 Amazon RDS 기반 웹 애플리케이션의 성능 저하를 발견했습니다. 성능 저하는 비즈니스 분석가가 트리거한 읽기 전용 SQL 쿼리 수가 증가한 것입니다.솔루션 설계자는 기존 웹 응용 프로그램에 대한 최소한의 변경으로 문제를 해결해야합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. 데이터를 Amazon DynamoDB로 내보내고 비즈니스 분석가가 쿼리를 실행하도록 합니다. B. 데이터를 Amazon ElastiCache로 로드하고 비즈니스 분석가가 쿼리를 실행하도록 합니다. C. 기본 데이터베이스의 읽기 전용 복제본을 생성하고 비즈니스 분석가에게 쿼리를 실행합니다. D. Amazon Redshift 클러스터에 데이터를 복사하고 비즈니스 분석가가 쿼리를 실행하도록 합니다. #\rAnswer\r...\rAnswer: C\r#\rQ277\r#\r회사는 최근 프라이빗 서브넷에서 Amazon EC2에서 Linux 기반 애플리케이션 인스턴스를 시작하고 VPC의 퍼블릭 서브넷에 있는 Amazon EC2 인스턴스에서 Linux 기반 접속 호스트를 시작했습니다.솔루션 설계자는 온-프레미스 네트워크에서 회사의 인터넷 연결을 통해 접속 호스트 및 응용 프로그램 서버에 연결해야 합니다.솔루션 설계자는 모든 EC2 인스턴스의 보안 그룹이 해당 액세스를 허용하는지 확인해야 합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 단계를 조합해야 합니까?(두 개 선택)\nA. 접속 호스트의 현재 보안 그룹을 애플리케이션 인스턴스로부터의 인바운드 액세스만 허용하는 보안 그룹으로 바꿉니다. B. 접속 호스트의 현재 보안 그룹을 회사의 내부 IP 범위에서 인바운드 액세스만 허용하는 보안 그룹으로 교체합니다. C. 접속 호스트의 현재 보안 그룹을 회사의 외부 IP 범위에서 인바운드 액세스만 허용하는 보안 그룹으로 바꿉니다. D. 애플리케이션 인스턴스의 현재 보안 그룹을 접속 호스트의 프라이빗 IP 주소에서만 인바운드 SSH 액세스를 허용하는 보안 그룹으로 바꿉니다. #\rAnswer\r...\rAnswer: A C\r#\rQ278\r#\r솔루션 설계자는 VPC 내의 IPv6 리소스를 사용하여 원격 API 서버에 액세스해야 하는 VPC를 인터넷에서 직접 액세스해서는 안 됩니다. 이것이 어떻게 이루어져야합니까?\nA. NAT 게이트웨이를 사용하고 보안 그룹을 사용하여 공용 액세스를 거부합니다. B. 송신 전용 인터넷 게이트웨이를 연결하고 라우팅 테이블을 업데이트합니다. C. NAT 게이트웨이를 사용하고 라우팅 테이블을 업데이트합니다. D. 인터넷 게이트웨이를 연결하고 보안 그룹을 사용하여 공용 액세스 거부 #\rAnswer\r...\rAnswer: B\r#\rQ279\r#\r개발 팀이 AWS Lambda 함수를 사용하는 이벤트 기반 애플리케이션을 만들고 있습니다.파일이 Amazon S3 버킷에 추가될 때 이벤트가 생성됩니다.개발 팀은 현재 Amazon S3의 이벤트 대상으로 구성된 Amazon SNS (단순 알림 서비스) 를 보유하고 있습니다. 확장 가능한 이유는 솔루션 설계자가 Amazon S3의 이벤트를 처리하기 위해 무엇을해야합니까?\nA. 이벤트가 Lambda에서 실행되기 전에 Amazon ECS (탄력적 컨테이너 서비스) 에서 이벤트를 처리하는 SNS 구독을 생성합니다. B. 이벤트가 Lambda에서 실행되기 전에 Amazon EKS (탄력적 Kubermetes 서비스) 에서 이벤트를 처리하는 SNS 구독을 생성합니다. C. AWS 서버 마이그레이션 서비스 (AWS SQS) 로 이벤트를 전송하는 SNS 구독에서 생성합니다. Lambda 함수를 트리거하도록 SQS 대기열을 구성합니다. D. 이벤트를 AWS 서버 마이그레이션 서비스 (AWS SMS) 로 전송하는 SNS 구독을 생성합니다.SMS 이벤트에서 폴링하도록 Lambda 함수 구성 #\rAnswer\r...\rAnswer: C\r#\rQ280\r#\r솔루션 설계자는 사용자를 위해 수백 개의 기계 학습 모델을 호스팅해야 하는 기업을 위해 클라우드 아키텍처를 설계하고 있습니다.시작하는 동안 모델은 Amazon S3에서 메모리로 최대 10GB의 데이터를 로드해야 하지만 디스크 액세스는 필요하지 않습니다.대부분의 모델은 산발적으로 사용되지만 사용자는 모든 모델이 높은 가용성과 낮은 대기 시간으로 액세스 할 수 있기를 기대합니다. 요구 사항을 충족하고 가장 비용 효율적인 솔루션은 무엇입니까?\nA. 각 모델에 대해 Amazon API 게이트웨이 뒤에 AWS Lambda 함수로 모델을 배포합니다. B. 각 모델에 대한 애플리케이션 로드 밸런서 뒤에 Amazon ECS (Amazon Elastic Container Service) 서비스로 모델을 배포합니다. C. 하나의 경로가 각 모델에 해당하는 경로 기반 라우팅이 있는 단일 Amazon API 게이트웨이 뒤에 AWS Lambda 함수로 모델을 배포합니다. D. 경로 기반 라우팅이 있는 단일 애플리케이션 로드 밸런서 뒤에 Amazon ECS (Amazon Elastic Container Service) 서비스로 모델을 배포합니다. 여기서 하나의 경로가 각 모델에 해당합니다. #\rAnswer\r...\rAnswer: C\r#\rQ281\r#\r회사는 이벤트 데이터를 생성하는 서비스를 보유하고 있습니다.이 회사는 이벤트 데이터를 수신할 때 AWS를 사용하여 처리하려고 합니다.데이터는 처리 과정에서 유지되어야 하는 특정 순서로 작성됩니다. 회사는 운영 오버헤드를 최소화하는 솔루션을 구현하고자 합니다. 솔루션 설계자는 어떻게 이것을 달성해야합니까”\nA. 메시지를 보관할 Amazon SOS (단순 대기열 서비스) FIFO 대기열을 생성합니다.대기열의 메시지를 처리하도록 AWS Lambda 함수를 설정합니다. B. Amazon SNS (단순 알림 서비스) 주제를 생성하여 처리할 페이로드가 포함된 알림을 전송합니다.AWS Lambda 함수를 구독자로 구성 C. Amazon SOS (단순 대기열 서비스) 표준 대기열 생성 메시지를 보관하기 위한 AWS Lambda 함수 설정: 대기열의 메시지를 독립적으로 처리합니다. D. Amazon SNS (단순 알림 서비스) 주제를 생성하여 Amazon SQS (Amazon 단순 대기열 서비스) 대기열을 구독자로 구성하는 페이로드가 포함된 알림을 전송합니다. #\rAnswer\r...\rAnswer: A\r#\rQ282\r#\r회사는 등록된 상위 도메인에서 여러 사업부의 여러 웹 사이트를 호스팅하고 있습니다.이러한 웹 사이트에 액세스하는 사용자는 하위 도메인을 기반으로 적절한 백엔드 Amazon EC2 인스턴스로 라우팅됩니다.웹 사이트는 정적 웹 페이지, 이미지 및 PHP와 자바 스크립트와 같은 서버 측 스크립트를 호스팅합니다. 일부 웹 사이트는 업무의 처음 2시간 동안 피크 액세스를 경험하며 나머지 시간에는 지속적인 사용량을 경험합니다.솔루션 설계자는 비용을 낮추면서 이러한 트래픽 패턴에 맞게 용량을 자동으로 조정하는 솔루션을 설계해야 합니다.이러한 요구 사항을 충족하는 AWS 서비스 또는 기능의 조합은 무엇입니까?(두 개를 선택합니다.)\nA. AWS 배치 B. 네트워크 로드 밸런서 C. 애플리케이션 로드 밸런서 D. Amazon EC2 Auto Scaling E. Amazon S3 웹 사이트 호스팅 #\rAnswer\r...\rAnswer: C D\r#\rQ283\r#\r미디어 회사는 웹 사이트에서 사용자의 클릭을 추적하고 분석을 수행하여 실시간에 가까운 권장 사항을 제공하는 애플리케이션을 보유하고 있습니다.애플리케이션에는 웹 사이트에서 데이터를 수신하고 Amazon RDS DB 인스턴스로 데이터를 전송하는 Amazon EC2 인스턴스가 있습니다. 또 다른 EC2 인스턴스 집합은 데이터베이스의 변경 사항을 지속적으로 확인하고 SQL 쿼리를 실행하여 권장 사항을 제공하는 애플리케이션 부분을 호스팅합니다.관리에서 인프라를 분리하기 위한 재설계를 요청했습니다. 솔루션은 Data Analytics가가 데이터만 분석하기 위해 SQL을 작성하는지 확인해야 합니다 배포 중 손실될 수 있는 데이터가 없습니다. 솔루션 설계자는 무엇을 권장해야 합니까?\nA. Amazon Kinesis Data Streams을 사용하여 웹 사이트에서 데이터를 캡처합니다. Kinesis Data Firehose는 Amazon S3에 데이터를 보존하고 Amazon Athena는 데이터를 쿼리합니다. B. Amazon Kinesis Data Streams을 사용하여 웹 사이트에서 데이터를 캡처합니다.Kinesis Data Analytics을 사용하여 데이터를 쿼리하고 Kinesis Data Firehose는 Amazon S3에 데이터를 유지합니다. C. Amazon SQS (단순 대기열 서비스) 를 사용하여 웹 사이트에서 데이터를 캡처하고, EC2 인스턴스를 유지하며, Auto Scaling 그룹 구성에서 더 큰 인스턴스 유형으로 변경합니다. D. Amazon SNS (단순 알림 서비스) 를 사용하여 웹 사이트에서 데이터를 수신하고 쿼리를 실행하는 AWS Lambda 함수로 메시지를 프록시하고 데이터를 유지하는 Amazon RDS를 Amazon Aurora 서버를 사용하지 않고 데이터를 보존합니다. #\rAnswer\r...\rAnswer: A\r#\rQ284\r#\r회사는 온프레미스 LDAP 디렉토리 서비스를 사용하여 AWS 관리 콘솔에서 사용자를 인증해야 합니다.디렉터리 서비스가 보안 어설션 마크업 언어 (SAML) 와 호환되지 않습니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. AWS와 온프레미스 LDAP 간에 AWS 싱글 사인온 활성화 B. IAM 정책 매트를 생성하여 AWS 자격 증명을 사용하고 정책을 LDAP에 통합합니다. C. LDAP 자격 증명이 업데이트될 때마다 IAM 자격 증명을 순환하는 프로세스를 설정합니다. D. AWS STS (보안 토큰 서비스) 를 사용하여 단수명 자격 증명을 얻는 프로세스 매트의 온프레미스 사용자 지정 자격 증명 브로커 애플리케이션 개발 #\rAnswer\r...\rAnswer: A\r#\rQ285\r#\r기업이 기존 워크로드를 AWS 클라우드로 이전하고 있습니다.워크로드 파일은 처음 생성될 때 Amazon EC2 인스턴스를 통해 공유, 추가 및 자주 액세스됩니다. 파일은 나이가 들어감에 따라 때때로 액세스됩니다. 솔루션 설계자는 무엇을 권장합니까?\nA. Amazon Elastic 블록 스토어 (Amazon EBS) 데이터 볼륨이 연결된 Amazon EC2 인스턴스를 사용하여 데이터 저장 B. AWS 스토리지 게이트웨이 볼륨 게이트웨이를 사용하여 데이터를 저장하고 거의 액세스하지 않는 데이터를 Amazon S3 스토리지로 내보냅니다. C. 거의 액세스하지 않는 데이터에 대해 수명 주기 관리가 활성화된 Amazon EFS (Elastic 파일 시스템) 를 사용하여 데이터 저장 D. S3 수명 주기 정책이 활성화된 Amazon S3를 사용하여 데이터를 저장하여 S3 표준 액세스 빈도가 낮은 액세스 (S3 표준-IA) 로 데이터를 이동합니다. #\rAnswer\r...\rAnswer: D\r#\rQ286\r#\r회사는 사용 중인 두 개의 NAT 인스턴스가 더 이상 회사 애플리케이션에 필요한 트래픽을 지원할 수 없다고 우려하고 있습니다.한 솔루션 설계자가 고가용성 내결함성이 있고 자동으로 확장 가능한 솔루션을 구현하려고 합니다. 솔루션 설계자가 권장하는 사항은 무엇입니까?\nA. 두 개의 NAT 인스턴스를 제거하고 동일한 가용 영역에서 두 개의 NAT 게이트웨이로 교체합니다. B. 서로 다른 가용 영역에 있는 NAT 인스턴스에 대해 네트워크 로드 밸런서와 함께 Auto Scaling 그룹을 사용합니다. C. 두 개의 NAT 인스턴스를 제거하고 서로 다른 가용 영역에 있는 두 개의 NAT 게이트웨이로 교체합니다. D. 두 NAT 인스턴스를 서로 다른 가용 영역에 있는 스팟 인스턴스로 바꾸고 네트워크 로드 밸런서를 배포합니다. #\rAnswer\r...\rAnswer: C\r#\rQ287\r#\r회사는 날씨 데이터를 온라인으로 사용자에게 판매 할 수있는 맞춤형 웹 응용 프로그램을 보유하고 있습니다.이 회사는 Amazon DynamoDB를 사용하여 데이터를 저장하고 새로운 날씨 이벤트가 기록될 때마다 내부 팀 4명의 관리자에게 알림을 보내는 새 서비스를 구축하려고 합니다. 회사는 이 새로운 서비스가 현재 애플리케이션의 성능에 영향을 미치지 않기를 원합니다.설계자는 최소한의 운영 오버 헤드로 이러한 요구 사항을 충족해야합니까?\nA. DynamoDB 트랜잭션을 사용하여 테이블에 새 이벤트 데이터를 기록하여 내부 팀에 알릴 트랜잭션을 구성합니다. B. 현재 애플리케이션에서 Amazon SNS (단순 알림 서비스) 주제에 메시지를 게시하도록 합니다.각 팀이 하나의 주제를 구독하도록 합니다. C. 테이블에서 Amazon DynamoDB 스트림 활성화 트리거를 사용하여 팀이 구독할 수 있는 단일 Amazon SNS (단순 알림 서비스) 주제에 쓰기 D. 각 레코드에 사용자 지정 속성을 추가하여 새 항목에 대해 매분마다 테이블을 스캔하는 cron 작업을 작성하고 팀이 구독할 수 있는 Amazon SQS (단순 대기열 서비스) 대기열에 알립니다. #\rAnswer\r...\rAnswer: C\r#\rQ288\r#\r사용자가 Amazon EC2 인스턴스에 연결된 IAM 역할을 나열하려고 합니다. 사용자는 EC2 인스턴스에 대한 로그인 액세스 권한이 있지만 IAM 권한이 없는 경우 솔루션 설계자가 이 정보를 검색하려면 어떻게 해야 합니까?\nA. 다음 EC2 명령 컬을 실행합니다. http://169.254.169.254/latest/meta-data/iam/info B. 다음 EC2 명령 컬 실행 http://169.254.169.254/latest-/user-data/iam/info C. 다음 EC2 명령을 실행합니다. http://169.254.169.254/latest/dynamic/instance-idencity/ D. 다음 AWS CLI 명령을 실행합니다. 인스턴스-프로파일-이름 예제-인스턴스-프로파일-이름 예제LNSTANCE프로파일 #\rAnswer\r...\rAnswer: A\r#\rQ289\r#\r회사가 Amazon Aurora에서 데이터베이스를 운영하고 있습니다.데이터베이스가 매일 저녁 유휴 상태입니다. 데이터베이스에 대해 광범위한 읽기를 수행하는 응용 프로그램에서 사용자 트래픽이 급증하는 아침 시간 동안 성능 문제가 발생합니다. 이러한 피크 기간 동안 응용 프로그램은 데이터베이스에서 읽을 때 시간 초과 오류를 수신합니다. 회사는 전용운영 팀을 운영하고 있으며 성능 문제를 해결하기 위해 자동화된 솔루션이 필요하십니까? 솔루션 설계자가 데이터베이스의 증가 된 읽기 부하에 맞게 자동으로 조정하려면 어떤 조치를 취해야 합니까?(두 개 선택)\nA. 데이터베이스를 Aurora 서버를 사용하지 않는 데이터베이스로 마이그레이션합니다. B. Aurora 데이터베이스의 인스턴스 크기 늘리기 C. Aurora 복제본을 사용하여 Aurora 자동 크기 조정 구성 D. 데이터베이스를 Aurora 다중 마스터 클러스터로 마이그레이션 E. MySQL 다중 AZ 배포용 Amazon RDS로 데이터베이스 마이그레이션 #\rAnswer\r...\rAnswer: A C\r#\rQ290\r#\r회사는 프라이빗 서브넷에서 실행되는 Amazon EC2 인스턴스를 보유하고 있으며, 이 인스턴스는 퍼블릭 웹 사이트에 액세스하여 패치 및 업데이트를 다운로드해야 합니다.이 회사는 외부 웹 사이트에서 EC2 인스턴스 IP 주소를 확인하거나 연결을 시작하지 못하도록 합니다. 솔루션 설계자는 어떻게 이러한 목표를 달성 할 수 있습니까?\nA. 프라이빗 서브넷과 퍼블릭 사이트가 배포된 네트워크 간에 사이트 간 VPN 연결을 만듭니다. B. 퍼블릭 서브넷에 NAT 게이트웨이 생성 NAI 게이트웨이를 통해 프라이빗 서브넷에서 아웃바운드 트래픽 라우팅 C. 배포된 EC2 인스턴스가 퍼블릭 웹 사이트의 IP 주소 범위에서만 액세스할 수 있는 프라이빗 서브넷에 대한 네트워크 ACL을 생성합니다. D. 공용 웹 사이트의 IP 주소 범위에서만 연결을 허용하는 보안 그룹을 만듭니다.보안 그룹을 EC2 인스턴스에 연결합니다. #\rAnswer\r...\rAnswer: B\r#\rQ291\r#\r회사에서 Amazon S3 게이트웨이 엔드포인트가 신뢰할 수 있는 버킷에 대한 트래픽만 허용하도록 요구하고 있습니다. 이 요구 사항을 충족하려면 솔루션 설계자가 어떤 방법을 구현해야 합니까?\nA. 회사의 신뢰할 수 있는 VPC의 트래픽만 허용하는 각 회사의 신뢰할 수 있는 S3 버킷에 대한 버킷 정책을 생성합니다. B. 회사의 S3 게이트웨이 엔드포인트 ID로부터의 트래픽만 허용하는 회사의 신뢰할 수 있는 각 S3 버킷에 대한 버킷 정책을 생성합니다. C. 회사의 신뢰할 수 있는 VPC 이외의 VPC로부터의 액세스를 차단하는 각 S3 게이트웨이 엔드포인트에 대해 S3 엔드포인트 정책을 생성합니다. D. 신뢰할 수 있는 S3 버킷의 Amazon 리소스 이름 (ARN) 에 대한 액세스를 제공하는 각 회사의 S3 게이트웨이 엔드포인트에 대한 S3 엔드포인트 정책을 생성합니다. #\rAnswer\r...\rAnswer: D\r#\rQ292\r#\r회사는 AWS에서 제품 정보 웹 페이지를 호스팅합니다.기존 솔루션은 Auto Scaling 그룹의 애플리케이션 로드 밸런서 뒤에 있는 여러 Amazon C2 인스턴스를 사용합니다.또한 이 웹 사이트는 사용자 지정 DNS 이름을 사용하며 전용 SSL 인증서를 통해서만 HTTPS와 통신합니다.이 회사는 신제품 출시를 계획하고 있으며 전 세계 사용자가 새 웹 사이트에서 최상의 경험을 제공하는지 확인하고자합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. Amazon CloudFront를 사용하도록 애플리케이션을 다시 설계합니다. B. AWS Elastic Beanstalk를 사용하도록 애플리케이션을 다시 디자인합니다. C. 네트워크 로드 밸런서를 사용하도록 응용 프로그램을 다시 디자인합니다. D. Amazon S3 정적 웹 사이트 호스팅을 사용하도록 애플리케이션을 다시 디자인합니다. #\rAnswer\r...\rAnswer: A\r#\rQ293\r#\r회사는 Amazon S3 버킷을 사용하여 웹 사이트의 정적 이미지를 저장합니다.회사는 권한이 있는 사용자만 Amazon S3 객체에 액세스할 수 있도록 권한을 구성했습니다.데이터 손실을 방지하려면 솔루션 설계자가 수행해야 하는 작업은 무엇입니까?(두 개를 선택합니다.)\nA. S3 버킷에서 버전 관리를 활성화합니다. B. S3 버킷에 대한 액세스 로깅 활성화 C. S3 버킷에서 서버 측 암호화를 활성화합니다. D. 객체를 Amazon S3 Glacier로 전환하도록 S3 수명 주기 규칙을 구성합니다. E. MFA Delete를 사용하여 다중 요소 인증을 요구하여 객체 삭제 #\rAnswer\r...\rAnswer: A E\r#\rQ294\r#\r회사는 퍼블릭 서브넷과 프라이빗 서브넷에서 실행되는 2계층 애플리케이션 아키텍처를 보유하고 있습니다. 웹 애플리케이션을 실행하는 Amazon EC2 인스턴스는 퍼블릭 서브넷에 있고 데이터베이스는 프라이빗 서브넷에서 실행됩니다. 웹 애플리케이션 인스턴스와 데이터베이스는 단일 가용 영역 (AZ) 에서 실행되고 있습니다. 이 아키텍처에 고가용성을 제공하기 위해 솔루션 설계자가 수행해야 하는 단계 조합은 무엇입니까?(두 개를 선택합니다.)\nA. 고가용성을 위해 동일한 AZ에 새로운 퍼블릭 및 프라이빗 서브넷을 생성합니다. B. 여러 AZ에 걸쳐 있는 Amazon EC2 Auto Scaling 그룹 및 애플리케이션 로드 밸런서 생성 C. 애플리케이션 로드 밸런서 뒤에 있는 Auto Scaling 그룹에 기존 웹 애플리케이션 인스턴스 추가 D. 새 AZ에서 새 퍼블릭 및 프라이빗 서브넷 생성 하나의 AZ에서 Amazon EC2를 사용하여 데이터베이스 생성 E. 동일한 VPC에 새 퍼블릭 및 프라이빗 서브넷을 각각 새 AZ에서 생성합니다. 데이터베이스를 Amazon RDS 다중 AZ 배포로 마이그레이션합니다. #\rAnswer\r...\rAnswer: B E\r#\rQ295\r#\r데이터베이스는 읽기 수준이 매우 동적인 Amazon RDS MySQL 5.6 다중 AZ DB 인스턴스에 있습니다. 애플리케이션 개발자는 보조 AWS 리전에서 읽기 성능을 테스트할 때 상당한 속도 저하를 경험하게 됩니다.개발자는 읽기 복제 지연 시간을 1초 미만으로 제공하는 솔루션을 원합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. (보조 리전) 의 Amazon EC2에 MySQL을 설치합니다. B. 교차 리전 복제본을 사용하여 데이터베이스를 Amazon Aurora로 마이그레이션합니다. C. 보조 복제본에 MySQL용 다른 RDS를 생성합니다. D. Amazon ElastiCache를 구현하여 데이터베이스 쿼리 성능을 향상시킵니다. #\rAnswer\r...\rAnswer: B\r#\rQ296\r#\r한 회사가 재무 위험 모델링을 위해 AWS에서 고성능 컴퓨팅 (HPC) 인프라를 사용하고자 합니다.회사의 HPC 워크로드는 Linux에서 실행됩니다. 각 HPC 워크플로는 수백 개의 Amazon EC2 스팟 인스턴스에서 실행되며 수명이 짧으며 궁극적으로 수천 개의 출력 파일을 생성하여 분석과 장기적인 향후 사용을 위해 영구 스토리지에 저장됩니다.온프레미스 데이터를 장기 영구 스토리지로 복사하여 모든 EC2 인스턴스에서 데이터를 처리할 수 있도록 합니다.또한 이 솔루션은 데이터 세트 및 출력 파일을 읽고 쓸 수 있는 영구 스토리지와 통합된 고성능 파일 시스템이어야 합니다. 이러한 요구 사항을 충족하는 AWS 서비스 조합은 무엇입니까?\nA. Amazon S3와 통합된 러스트리용 Amazon FSX B. Amazon S3와 통합된 Windows 파일 서버용 Amazon FSX C. Amazon S3 Glacier가 Amazon Elastic Block Store (Amazon EBS) 와 통합됨 D. Amazon EBS (Elastic Block Store) 범용 SSD (gp2) 볼륨과 통합된 VPC 엔드포인트가 있는 Amazon S3 버킷 #\rAnswer\r...\rAnswer: A\r#\rQ297\r#\r회사는 수백 개의 AWS 계정에 걸쳐 있는 미국 동부 지역의 여러 VPC를 연결해야 합니다.회사의 네트워킹 팀은 클라우드 네트워크를 관리하기 위한 자체 AWS 계정을 보유하고 있습니다.VPC를 연결하기 위한 가장 효율적인 솔루션은 무엇입니까?\nA. 각 VPC 간에 VPC 피어링 연결을 설정합니다.연결된 각 서브넷의 라우팅 테이블을 업데이트합니다. B. 내부를 통해 각 VPC에 연결된 각 VPC의 NAT 게이트웨이와 내부 게이트웨이를 구성합니다. C. 네트워킹 팀의 AWS 계정에서 AWS 전송 게이트웨이를 생성합니다.각 VPC에서 정적 경로를 구성합니다. D. 각 VPC에 VPN 게이트웨이를 배포합니다.네트워킹 팀의 AWS 계정에서 전송 VPC를 생성하여 각 VPC에 연결할 수 있도록 구성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ298\r#\r회사는 웹 사이트에서 검색 가능한 항목 저장소를 유지 관리합니다. 타이 데이터는 MySQL용 Amazon RDS용 데이터베이스 테이블에 저장됩니다. 이 데이터베이스에는 2TB의 범용 SSD (gp2) 스토리지가 있습니다.회사의 웹 사이트를 통해 매일 수백만 건의 데이터가 업데이트되고 있습니다. 회사는 일부 작업에 10초 이상 걸리고 있으며 데이터베이스 저장소 성능이 병목 현상임을 확인했습니다. 어떤 솔루션이 성능 문제를 해결합니까?\nA. 스토리지 유형을 프로비저닝된 IOPS SSD (io1) 로 변경합니다. B. 인스턴스를 메모리에 최적화된 인스턴스 클래스로 변경 C. 인스턴스를 버스트 가능한 성능 DB 인스턴스 클래스로 변경 D. MySQL 네이티브 비동기 복제를 사용하여 다중 AZ RDS 읽기 전용 복제본 활성화 #\rAnswer\r...\rAnswer: A\r#\rQ299\r#\r회사는 다지역 재해 복구 RPO (복구 시점 목표) 가 1초이고 RTO (복구 시간 목표) 가 1분인 관계형 데이터베이스를 구현해야 합니다. 이를 달성할 수 있는 AWS 솔루션은 무엇입니까?\nA. Amazon Aurora 글로벌 데이터베이스 B. Amazon DynamoDB 글로벌 테이블입니다. C. 다중 AZ가 활성화된 MySQL용 Amazon RDS. D. 교차 리전 스냅샷 사본이 있는 MySQL용 Amazon RDS #\rAnswer\r...\rAnswer: A\r#\rQ300\r#\r솔루션 설계자는 VPC에 있는 Amazon EC2 인스턴스에서 Amazon DynamoDB에 대한 API 호출이 인터넷을 통과하지 않도록 해야 합니다. 이를 위해 솔루션 설계자는 어떻게 해야 합니까?(두 개 선택)\nA. 엔드포인트에 대한 라우팅 테이블 항목 생성 B. DynamoDB용 게이트웨이 엔드포인트 생성 C. 엔드포인트를 사용하는 새 DynamoDB 테이블을 생성합니다.s D. VPC의 각 서브넷에서 엔드포인트에 대한 ENI를 생성합니다. E. 기본 보안 그룹에 보안 그룹 항목을 생성하여 액세스 권한을 제공합니다. #\rAnswer\r...\rAnswer: A B\r#\rQ301\r#\r회사는 동일한 AWS 지역에 위치한 Amazon S3 버킷에서 사진을 자주 업로드하고 다운로드해야 하는 사진 처리 애플리케이션을 운영하고 있습니다. 솔루션 설계자는 데이터 전송 요금의 비용이 증가하고 이러한 비용을 줄이기 위한 솔루션을 구현해야 합니다.솔루션 설계자가 이러한 요구 사항을 충족합니까?\nA. Amazon API 게이트웨이를 퍼블릭 서브넷에 배포하고 라우팅 테이블을 조정하여 이를 통해 S3 호출을 라우팅합니다. B. 퍼블릭 서브넷에 NAT 게이트웨이를 배포하고 S3 버킷에 대한 액세스를 허용하는 엔드 포인트 정책을 연결합니다. C. 애플리케이션을 퍼블릭 서브넷에 배포하고 인터넷 게이트웨이를 통해 라우팅하여 S3 버킷에 액세스할 수 있도록 허용 D. S3 VPC 게이트웨이 엔드포인트를 VPC에 배포하고 S3 버킷에 대한 액세스를 허용하는 엔드포인트 정책을 연결합니다. #\rAnswer\r...\rAnswer: B\r#\rQ302\r#\r한 회사에서 기존 방화벽의 가용성을 개선하려고 합니다.VPC에서 호스팅되는 애플리케이션의 규정 준수 요구 사항을 충족하기 위해 회사의 보안 팀은 Amazon EC2 인스턴스에서 실행되는 독점 방화벽을 사용하고 있습니다. 모든 인터넷 트래픽은 기본 방화벽을 통과합니다.기본 방화벽이 다운되면 팀은 다른 가용 영역에서 실행되는 보조 방화벽을 사용하도록 VPC 라우팅 테이블을 수동으로 변경합니다.솔루션 설계자가 방화벽의 가용성을 향상시키기 위해 어떤 전략을 사용해야 합니까?(두 개를 선택합니다.)\nA. EC2 게이트웨이 엔드포인트 생성 방화벽이 호스팅되는 VPC에서 B. 방화벽이 호스팅되는 VPC에서 EC2 인터페이스 엔드포인트를 생성합니다. C. 전용 방화벽을 실행하는 EC2 인스턴스에서 향상된 네트워킹 활성화 D. VPC에 예약된 AWS Lambda 함수를 배포하여 기본 방화벽을 모니터링하고 장애 발생 시 보조 방화벽을 사용하도록 라우팅 테이블을 변경합니다. E. Amazon 이벤트 브리지 (Amazon 클라우드워치 이벤트) 에서 방화벽 인스턴스 상태를 모니터링합니다.감지된 실패 시 기본 방화벽을 다시 시작하도록 이벤트 규칙을 트리거합니다. #\rAnswer\r...\rAnswer: D E\r#\rQ303\r#\r회사는 가상화된 컴퓨팅 리소스 없이 소규모 데이터클로짓 내의 지사에서 애플리케이션을 실행합니다.애플리케이션 데이터는 NFS 볼륨에 저장됩니다.규정 준수 표준을 준수하려면 NFS 볼륨의 오프사이트 백업을 매일 수행해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 온프레미스에 AWS 스토리지 게이트웨이 파일 게이트웨이를 설치하여 Amazon S3에 데이터를 복제합니다.- B. 온프레미스에 AWS 스토리지 게이트웨이 파일 게이트웨이 하드웨어 어플라이언스를 설치하여 Amazon S3에 데이터를 복제합니다. C. 온프레미스에 저장된 볼륨이 있는 AWS 스토리지 게이트웨이 볼륨 게이트웨이를 설치하여 Amazon S3에 데이터를 복제합니다. D. 온프레미스에 캐시된 볼륨이 있는 AWS 스토리지 게이트웨이 볼륨 게이트웨이를 설치하여 Amazon S3에 데이터를 복제합니다. #\rAnswer\r...\rAnswer: B\r#\rQ304\r#\r소프트웨어 공급업체는 많은 AWS 사용자가 활용할 새로운 SaaS (서비스형 소프트웨어) 솔루션을 배포하고 있습니다.서비스는 네트워크 로드 밸런서 뒤의 VPC에서 호스팅됩니다.소프트웨어 공급업체는 관리 오버헤드가 적고 공용 인터넷에 서비스를 노출시키지 않고 사용자에게 이 서비스에 대한 액세스를 제공하려고 합니다. 솔루션 설계자는 이 목표를 달성하기 위해 무엇을해야합니까?\nA. 각 사용자의 VPC에서 소프트웨어 벤더의 VPC로의 피어링 VPC 연결을 생성합니다. B. 소프트웨어 벤더의 AWS 계정에 전송 VPC를 배포합니다.각 사용자 계정으로 VPN 연결 만들기 C. VPC의 서비스를 AWS 프라이버트링크 엔드포인트와 연결합니다.사용자가 엔드포인트를 구독하도록 합니다. D. 소프트웨어 벤더의 AWS 계정에 전송 VPC를 배포합니다.각 사용자 계정에 AWS Direct Connect 연결을 생성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ305\r#\r회사는 여러 AWS 리전에 걸쳐 여러 Amazon EC2 인스턴스를 사용하여 AWS에서 웹 애플리케이션을 호스팅하려고 합니다. 애플리케이션 콘텐츠는 각 지리적 지역에 따라 다르므로 클라이언트 요청은 해당 클라이언트 리전의 콘텐츠를 호스팅하는 서버로 라우팅되어야 합니다.이를 달성하기 위해 솔루션 설계자는 무엇을해야합니까?\nA. 지연 시간 라우팅 정책을 사용하여 Amazon Route 53을 구성합니다. B. 가중치 기반 라우팅 정책을 사용하여 Amazon Route 53을 구성합니다. C. 지리적 위치 라우팅 정책을 사용하여 Amazon Route 53 구성 D. 다중 값 응답 라우팅 정책을 사용하여 Amazon Route 53 구성 #\rAnswer\r...\rAnswer: C\r#\rQ306\r#\r회사가 Elastic IP 주소를 사용하는 퍼블릭 서브넷의 Amazon EC2 인스턴스에서 실행되는 웹 서버를 보유하고 있습니다. 기본 보안 그룹은 EC2 인스턴스에 할당됩니다.모든 트래픽을 차단하도록 기본 네트워크 ACL이 수정되었습니다.솔루션 설계자는 포트 443의 모든 곳에서 웹 서버에 액세스 할 수 있도록해야합니다. 어떤 단계 조합이이 작업을 수행 할 수 있습니까?(두 개를 선택합니다.)\nA. 소스 0.0.0.0/0에서 TCP 포트 443을 허용하는 규칙을 사용하여 보안 그룹을 생성합니다. B. TCP 포트 443을 대상 0.0.0.0/0으로 허용하는 규칙을 사용하여 보안 그룹을 생성합니다. C. 소스 0.0.0.0/0에서 TCP 포트 443을 허용하도록 네트워크 ACL을 업데이트합니다. D. 소스 0.0.0.0/0에서 대상 0.0.0.0/0까지 인바운드/아웃바운드 TCP 포트 443을 허용하도록 네트워크 ACL을 업데이트합니다. E. 소스 0.0.0 0/0에서 인바운드 TCP 포트 443을 허용하고 아웃바운드 TCP 포트 32768-65535에서 대상 0.0.0.0/0으로 허용하도록 네트워크 ACL을 업데이트합니다. #\rAnswer\r...\rAnswer: A E\r#\rQ307\r#\r솔루션 설계자가 정책1과 정책2의 두 IAM 정책을 만들었습니다.두 정책 모두 IAM 그룹에 연결됩니다.\n클라우드 엔지니어가 IAM 사용자로 IAM 그룹에 추가됩니다.클라우드 엔지니어가 수행할 수 있는 작업은 무엇입니까?\nA. IAM 사용자 삭제 B. 디렉토리 삭제 C. Amazon EC2 인스턴스 삭제 D. Amazon 클라우드워치 로그에서 로그 삭제 #\rAnswer\r...\rAnswer: C\r#\rQ308\r#\r한 회사는 Auto Scaling 그룹의 여러 Amazon EC2 인스턴스에 다중 계층 애플리케이션을 배포하고 있습니다. Oracle용 Amazon RDS는 Oracle 전용 PUSQL 함수를 사용하는 애플리케이션” 데이터 계층입니다.애플리케이션에 대한 트래픽이 꾸준히 증가하고 있습니다. 이로 인해 EC2 인스턴스가 i RDS 인스턴스에 과부하가 걸려 스토리지가 부족하게 됩니다.Auto Scaling 그룹에는 조정 메트릭이 없으며 최소 정상 인스턴스 수만 정의합니다.회사는 수평을 맞추기 전에 트래픽이 꾸준하지만 예측할 수 없는 속도로 계속 증가할 것이라고 예측합니다.증가하는 트래픽에 맞게 시스템이 자동으로 확장되도록 솔루션 설계자가 수행해야 하는 작업은 무엇입니까?(두 개 선택)\nA. Oracle용 RDS에서 스토리지 Auto Scaling을 구성합니다. B. 데이터베이스를 Amazon Aurora로 마이그레이션하여 Auto Scaling 스토리지를 사용합니다. C. 사용 가능한 스토리지 공간이 부족할 경우 Oracle용 RDS 인스턴스에서 경보를 구성합니다. D. 평균 CPU를 배율 조정 메트릭으로 사용하도록 Auto Scaling 그룹을 구성합니다. E. 사용 가능한 평균 메모리를 배율 조정 메트릭으로 사용하도록 Auto Scaling 그룹을 구성합니다. #\rAnswer\r...\rAnswer: A C\r#\rQ309\r#\r회사는 수많은 애플리케이션이 공유하는 Amazon S3 버킷의 데이터 레이크를 관리합니다.S3 버킷에는 각 애플리케이션에 대한 접두사가 있는 고유한 폴더가 포함되어 있습니다.회사는 각 응용 프로그램을 특정 폴더로 제한하고 각 폴더의 객체를 보다 세부적으로 제어하려고 합니다. 최소한의 노력으로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 각 애플리케이션에 대한 전용 S3 액세스 포인트 및 액세스 포인트 정책을 생성합니다. B. S3 버킷의 각 객체에 대한 ACL 권한을 설정하려면 ANS3 일괄 작업 작업을 생성합니다. C. S3 버킷의 특정 폴더를 기반으로 각 애플리케이션에 대한 액세스 권한을 부여하려면 3 S3 버킷 정책을 업데이트합니다. D. S3 버킷의 객체를 각 애플리케이션의 새 S3 버킷에 복제 접두사로 복제 규칙을 만듭니다. #\rAnswer\r...\rAnswer: B\r#\rQ310\r#\r회사는 Auto Scaling 그룹의 클라이언트와 서버 간의 통신에 UDP를 사용하는 실시간 멀티플라이어 게임을 개발하고 있습니다. 낮에는 수요 스파이크가 예상되므로 게임 서버 플랫폼이 적절하게 조정되어야 합니다.개발자는 게이머 점수 및 기타 비관계형 데이터를 개입 없이 확장할 수 있는 데이터베이스 솔루션에 저장하려고 합니다. 솔루션 설계자가 권장해야 하는 솔루션은 무엇입니까?\nA. 트래픽 배포에는 Amazon Route 53을 사용하고 데이터 스토리지에는 Amazon Aurora 서버리스 서버를 사용합니다. B. 트래픽 배포에는 네트워크 로드 밸런서를 사용하고 데이터 스토리지에는 Amazon DynamoDB를 온디맨드 방식으로 사용합니다. C. 트래픽 분배에는 네트워크 로드 밸런서를 사용하고 데이터 스토리지에는 Amazon Aura Global을 사용합니다. D. 트래픽 배포에는 애플리케이션 로드 밸런서를 사용하고 데이터 스토리지에는 Amazon DynamoDB 글로벌 테이블을 사용합니다. #\rAnswer\r...\rAnswer: B\r#\rQ311\r#\r회사에서 웹 애플리케이션을 AWS로 마이그레이션하려고 합니다.레거시 웹 응용 프로그램은 웹 계층, 응용 프로그램 계층 및 MySQL 데이터베이스로 구성됩니다.다시 설계된 응용 프로그램은 관리 팀이 인스턴스 또는 클러스터를 관리할 필요가 없는 기술로 구성되어야 합니다.솔루션 설계자는 전체 아키텍처에 어떤 서비스 조합을 포함해야 합니까?(두 개 선택)\nA. Amazon Aurora 서버리스 B. Amazon EC2 스팟 인스턴스 C. Amazon Elastic 검색 서비스 (Amazon ES) D. MySQL용 Amazon RDS E. AWS Fargate #\rAnswer\r...\rAnswer: A E\r#\rQ312\r#\r한 회사는 Amazon EC2 인스턴스에 Auto Scaling 그룹에서 실행되는 여러 애플리케이션을 보유하고 있습니다.회사 정책에 따라 연결된 Amazon EBS (Elastic Block Store) 볼륨의 데이터가 보존되어야 합니다. 성능에 영향을 주지 않고 이러한 요구 사항을 충족하는 작업은 무엇입니까?\nA. Amazon EC2 인스턴스에서 종료 보호를 활성화합니다. B. Amazon EBS 볼륨에 대한 삭제 종료 속성을 비활성화합니다. C. Amazon EC2 사용자 데이터를 사용하여 루트 볼륨에 대한 동기화 작업을 설정합니다. D. 루트 볼륨의 소스를 가리키도록 Auto Scaling 상태 확인을 변경합니다. #\rAnswer\r...\rAnswer: B\r#\rQ313\r#\rAWS에서 호스팅되는 애플리케이션에 성능 문제가 발생하고 있으며, 애플리케이션 공급업체는 추가 문제를 해결하기 위해 로그 파일 분석을 수행하려고 합니다.로그 파일은 Amazon S3에 저장되며 크기는 10GB입니다.응용 프로그램 소유자는 제한된 시간 동안 공급업체에서 로그 파일을 사용할 수 있도록 합니다. 이 작업을 수행하는 가장 안전한 방법은 무엇입니까?\nA. S3 객체에 대한 공개 읽기를 활성화하고 공급업체에 대한 링크를 제공합니다. B. Amazon WorkDocs에 파일을 업로드하고 공급업체와 공개 링크를 공유합니다. C. 미리 서명된 URL을 생성하고 공급업체가 로그 파일을 다운로드하도록 합니다. D. S3 버킷 및 애플리케이션에 대한 액세스 권한을 제공할 공급업체에 대한 IAM 사용자를 생성합니다.다단계 인증을 적용합니다. #\rAnswer\r...\rAnswer: C\r#\rQ314\r#\r한 회사에서 주말에 Amazon EC2 인스턴스 클러스터를 운영합니다.비용은 감소하지만 0으로 떨어지지 않습니다. 어떤 자원이 여전히 비용을 발생시킬 수 있습니까?(두 개를 선택합니다.)\nA. 탄력적 IP 주소 B. 데이터 전송 C. 지역별 데이터 전송 D. Amazon Elastic Block Store (Amazon EBS) 볼륨 E. AWS Auto Scaling #\rAnswer\r...\rAnswer: A E\r#\rQ315\r#\r솔루션 설계자는 AWS 클라우드에서 고성능 컴퓨팅 (HPC) 워크로드를 호스팅해야 합니다. 워크로드는 수백 개의 Amazon EC2 인스턴스에서 실행되며 대규모 데이터 세트의 분산 처리를 위해서는 공유 파일 시스템에 대한 병렬 액세스가 필요합니다.데이터 세트는 여러 인스턴스에서 동시에 액세스할 수 있습니다.워크로드는 1ms 이내에 액세스 대기 시간이 필요합니다.처리가 완료되면 엔지니어는 수동 후처리를 위해 데이터셋에 액세스해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. Amazon EFS (Elastic File System) 를 공유 파일 시스템으로 사용 Amazon EFS에서 데이터 세트에 액세스합니다. B. 공유 파일 시스템으로 사용할 Amazon S3 버킷 마운트 S3 버킷에서 직접 사후 처리 수행 C. Lustre용 Amazon FSX를 공유 파일 시스템으로 사용합니다.사후 처리를 위해 파일 시스템을 Amazon S3 버킷에 연결합니다. D. Amazon S3 버킷을 공유하도록 AWS 리소스 액세스 관리자를 구성하여 처리 및 사후 처리를 위해 모든 인스턴스에 마운트할 수 있습니다. #\rAnswer\r...\rAnswer: C\r#\rQ316\r#\rManagement는 IPv6이 활성화된 모든 AWS VPC를 배포하기로 결정했습니다. 잠시 후 솔루션 설계자가 새 인스턴스를 시작하려고 시도하고 서브넷에 사용 가능한 IP 주소 공간이 부족하다는 오류 메시지가 표시됩니다. 이 문제를 해결하기 위해 솔루션 설계자는 어떻게 해야 합니까?\nA. VPC 생성 중에 IPv6만 사용되었는지 확인합니다. B. 범위가 더 넓은 새 IPv4 서브넷을 생성한 다음 인스턴스 시작 C. 범위가 더 넓은 새 IPv6 전용 서브넷을 생성한 다음 인스턴스 시작 D. IPv4 서브넷을 사용하지 않도록 설정하고 모든 인스턴스를 IPv6으로 마이그레이션 완료되면 인스턴스를 시작합니다. #\rAnswer\r...\rAnswer: B\r#\rQ317\r#\r신입 직원이 배포 엔지니어로 회사에 합류했습니다.배포 엔지니어는 AWS CloudFormation 템플릿을 사용하여 여러 AWS 리소스를 생성합니다.솔루션 설계자는 배포 엔지니어가 작업 활동을 수행하기를 원합니다. 최소 권한의 원칙을 따릅니다. 이 목표를 달성하기 위해 솔루션 설계자가 취해야 하는 조치의 조합은 무엇입니까?(두 개를 선택합니다.)\nA. 배포 엔지니어가 AWS CloudFormation 스택 작업을 수행하기 위해 AWS 계정 루프 사용자 자격 증명을 사용하도록 합니다. B. 배포 엔지니어를 위한 새 IAM 사용자를 생성하고 PowerUsers IAM 정책이 연결된 그룹에 IAM 사용자를 추가합니다. C. 배포 엔지니어를 위한 새 IAM 사용자를 생성하고 관리/액세스 IAM 정책이 연결된 그룹에 IAM 사용자를 추가합니다. D. 배포 엔지니어를 위한 새 IAM 사용자를 생성하고 AWS CloudFormation 작업만 허용하는 IAM 정책이 있는 그룹에 IAM 사용자를 추가합니다. E. 배포 엔지니어가 AWS CloudFormation 스택에 특정한 권한을 명시적으로 정의하고 다이얼 IAM 역할을 사용하여 스택을 시작할 수 있도록 IAM 역할을 생성합니다. #\rAnswer\r...\rAnswer: D E\r#\rQ318\r#\r회사의 운영 팀은 버킷 내에 새 객체가 생성될 때 Amazon SQS 대기열에 알리도록 구성된 기존 Amazon S3 버킷을 보유하고 있습니다.또한 개발 팀은 새 객체가 만들어질 때 이벤트를 받기를 원합니다.기존 운영 팀 워크플로는 그대로 유지되어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 다른 SQS 대기열 생성 버킷의 S3 이벤트를 업데이트하여 새 객체가 생성될 때 새 대기열도 업데이트합니다. B. Amazon S3만 대기열에 액세스할 수 있도록 허용하는 새 SQS 대기열을 생성합니다. Amazon S3 업데이트는 새 객체가 생성될 때 이 대기열을 업데이트합니다. C. 업데이트에 대한 Amazon SNS 주제 및 SQS 대기열을 생성합니다.버킷을 업데이트하여 새 주제로 이벤트를 보냅니다.Amazon SNS를 폴링하도록 두 대기열을 모두 업데이트합니다. D. 버킷 업데이트를 위한 Amazon SNS 주제 및 SQS 대기열을 생성합니다.버킷을 업데이트하여 주제의 두 대기열에 대한 구독 추가를 새 주제로 이벤트를 보냅니다. #\rAnswer\r...\rAnswer: D\r#\rQ319\r#\r주최자는 일일 보고서를 온라인 정적 HTML 페이지로 만들려고 합니다. 페이지에 전 세계 사용자로부터 수백만 건의 조회수가 생성될 것으로 예상됩니다. 파일은 Amazon S3 버킷에 저장됩니다. 솔루션 설계자는 효율적이고 효과적인 솔루션을 설계하라는 요청을 받았습니다.솔루션 설계자가 이것을 달성하기 위해 취해야합니까?\nA. 파일에 대해 미리 서명된 URL 생성 B. 모든 리전에 교차 리전 복제 사용 C. Amazon Route 53의 지리적 근접 기능 사용 D. S3 버킷을 오리진으로 사용하여 Amazon CloudFront 사용 #\rAnswer\r...\rAnswer: D\r#\rQ320\r#\r회사는 애플리케이션 로드 밸런서 (ALB) 뒤에 있는 Amazon EC2 인스턴스 집합에서 다국어 웹 사이트를 제공합니다. 이 아키텍처는 현재 us-west- 지역에서 실행 중이지만 전 세계 다른 지역에 있는 사용자에게는 요청 지연 시간이 높습니다. 웹 사이트는 요청을 처리해야 합니다.사용자의 위치에 관계없이 신속하고 효율적으로 그러나 회사는 여러 지역에서 기존 아키텍처를 재생성하기를 원하지 않습니다. 솔루션 설계자는 어떻게 이것을 수행해야합니까?\nA. 기존 아키텍처를 Amazon S3 버킷에서 제공하는 웹 사이트로 교체합니다.S3 버킷을 오리진으로 사용하여 Amazon CloudFront 배포를 구성합니다. B. ALB를 오리진으로 사용하여 Amazon CloudFront 배포를 구성합니다.Accept-Language 요청 헤더에 따라 캐시만 사용하도록 캐시 동작 설정 설정 C. ALB를 통합으로 사용하여 Amazon API 게이트웨이를 설정합니다.HTTP 통합 유형을 사용하도록 API 게이트웨이 구성 API 캐시를 사용하도록 API 게이트웨이 스테이지 설정 D. 각 추가 리전에서 EC2 인스턴스를 시작하고 해당 지역의 캐시 서버로 작동하도록 NGINX를 구성합니다. 모든 인스턴스와 ALB를 지리적 위치 라우팅 정책이 있는 Amazon Route 53 레코드 세트 뒤에 배치합니다. #\rAnswer\r...\rAnswer: B\r#\rQ321\r#\rAWS에서 실행되는 애플리케이션은 데이터베이스에 Amazon Aurora 다중 AZ 배포를 사용합니다. 성능 메트릭을 평가할 때 솔루션 설계자는 데이터베이스 읽기가 높은 I/O를 유발하고 데이터베이스에 대한 쓰기 요청 지연 시간을 추가하는 것을 발견했습니다.읽기 요청을 쓰기 요청과 분리 하시겠습니까?\nA. Amazon Aurora 데이터베이스에서 읽기-스루 캐싱 활성화 B. 다중 AZ 대기 인스턴스에서 읽도록 애플리케이션을 업데이트합니다. C. 읽기 전용 복제본을 생성하고 적절한 엔드포인트를 사용하도록 애플리케이션 수정 D. 두 번째 Amazon Aurora 데이터베이스를 생성하여 기본 데이터베이스에 읽기 전용 복제본으로 연결합니다. #\rAnswer\r...\rAnswer: C\r#\rQ322\r#\r한 회사가 서로 다른 AWS 리전의 두 VPC에 있는 Amazon EC2 인스턴스에서 호스팅되는 애플리케이션을 보유하고 있습니다. 서로 통신하기 위해 인스턴스는 연결을 위해 인터넷을 사용합니다.보안 팀은 인터넷을 통해 인스턴스 간의 통신이 이루어지지 않도록 보장하고자 합니다. 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?”\nA. NAT 게이트웨이를 생성하고 EC2 인스턴스 서브넷의 라우팅 테이블을 업데이트합니다. B. VPC 엔드포인트를 생성하고 EC2 인스턴스 서브넷의 라우팅 테이블을 업데이트합니다. C. VPN 연결을 생성하고 EC2 인스턴스 서브넷의 라우팅 테이블을 업데이트합니다. D. VPC 피어링 연결을 생성하고 EC2 인스턴스의 서브넷의 라우팅 테이블을 업데이트합니다. #\rAnswer\r...\rAnswer: D\r#\rQ323\r#\r회사는 타사에서 실시한 AWS 보안 검토를 통과하지 못합니다.검토에 따르면 회사 방법 중 일부는 공용 인터넷을 통해 Amazon EMR에 액세스하는 것을 알 수 있습니다.이 회사는 보안을 강화하기 위해 어떤 단계를 조합해야 합니까?(두 개를 선택합니다.)\nA. Amazon EMR API에 대한 VPC 피어링 연결을 설정합니다. B. VPC 엔드포인트를 설정하여 Amazon EMR API에 연결합니다. C. NAT 게이트웨이를 설정하여 Amazon EMR API에 연결합니다. D. Amazon FMR API에 연결하는 데 사용할 IAM 역할을 설정합니다. E. 액세스 키를 저장하도록 AWS 비밀 관리자로 각 개발자를 설정합니다. #\rAnswer\r...\rAnswer: A D\r#\rQ324\r#\r의료 회사는 매우 민감한 환자 기록을 저장합니다.규정 준수를 위해서는 여러 복제본을 여러 위치에 저장해야 합니다. 각 레코드는 7년 동안 저장되어야 합니다.회사는 서비스 수준 계약 (SLA) 을 체결하여 정부 기관에 첫 30일 동안 즉시 기록을 제공한 다음 그 후 요청 4 시간. 솔루션 설계자는 무엇을 추천해야합니까?\nA. 교차 리전 복제를 활성화한 상태에서 Amazon S3 사용 30일 후 수명 주기 정책을 사용하여 데이터를 Amazon S3 Glacier로 이전합니다. B. CORS (원본 간 리소스 공유) 가 활성화된 상태에서 Amazon S3를 사용합니다.30일 후 수명 주기 정책을 사용하여 데이터를 Amazon S3 Glacier로 이전합니다. C. 교차 리전 복제를 활성화한 상태로 Amazon S3 사용 30일 후 수명 주기 정책을 사용하여 데이터를 Amazon S3 Glacier Deep Acuier로 이전합니다. D. 원본 간 리소스 공유 (GORS) 가 활성화된 상태로 Amazon S3 사용 30일 후 수명 주기 정책을 사용하여 데이터를 Amazon S3 Glacier 딥 아카이브로 이전합니다. #\rAnswer\r...\rAnswer: A\r#\rQ325\r#\r회사는 사용자에게 항목 가격을 기준으로 세금 계산에 대한 조회를 자동화하는 API를 제공합니다. 이 회사는 휴가 기간 동안 응답 시간이 느려지는 경우에만 많은 문의 사항을 경험합니다.솔루션 설계자는 확장 가능하고 탄력적인 솔루션을 설계해야 합니다. 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?\nA. Amazon EC2 인스턴스에서 호스팅되는 API를 제공합니다.EC2 인스턴스는 API 요청이 이루어질 때 필요한 계산을 수행합니다. B. 항목 이름을 허용하는 Amazon API 게이트웨이를 사용하여 REST API를 설계합니다. API 게이트웨이는 세금 계산을 위해 항목 이름을 AWS Lambda로 전달합니다. C. 두 개의 Amazon EC2 인스턴스가 있는 애플리케이션 로드 밸런서를 생성합니다.EC2 인스턴스는 수신된 항목 이름에 대한 세금을 계산합니다. D. Amazon API 게이트웨이를 사용하여 REST API를 설계합니다. Amazon API 게이트웨이는 세금 계산을 위해 항목 이름을 수락하고 EC2 인스턴스로 전달합니다. #\rAnswer\r...\rAnswer: B\r#\rQ326\r#\r엔터테인먼트 회사에서 Amazon DynamoDB를 사용하여 미디어 메타데이터를 저장하고 있습니다.응용 프로그램은 읽기 집약적이며 지연이 발생합니다.이 회사는 추가적인 운영 오버헤드를 처리할 인력이 없으며 애플리케이션을 재구성하지 않고도 DynamoDB의 성능 효율성을 개선해야 합니다. 솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 권장해야합니까?\nA. 레디스에 Amazon ElastiCache 사용 B. Amazon DynamoDB 가속화 (DAX) 사용 C. DynamoDB 글로벌 테이블을 사용하여 데이터 복제 D. 자동 검색이 활성화된 상태에서 멤캐쉬에 Amazon ElastiCache를 사용합니다. #\rAnswer\r...\rAnswer: B\r#\rQ327\r#\r한 회사가 웹 사이트에서 Amazon CloudFront를 사용하고 있습니다.이 회사는 CloudFront 배포에 대한 로깅을 활성화했으며 로그는 회사의 Amazon S3 버킷 중 하나에 저장됩니다.이 회사는 로그에 대한 고급 분석을 수행하고 시각화를 구축해야합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. Amazon Athena의 표준 SQL 쿼리를 사용하여 S3 버킷의 CloudFront 로그를 분석합니다.AWS Glual로 결과를 시각화합니다. B. Amazon Athena의 표준 SQL 쿼리를 사용하여 S3 버킷의 CloudFront 로그를 분석합니다. Amazon QuickSight 결과를 시각화합니다. C. Amazon DynamoDB의 표준 쿼리를 사용하여 S3 버킷의 Cloudfront 로그를 분석합니다. AWS Glual로 결과를 시각화합니다. D. Amazon DynamoDB의 표준 SQL 쿼리를 사용하여 S3 버킷의 CloudFront 로그를 분석합니다.Amazon QuickSight (QuickSight) 로 결과를 시각화 #\rAnswer\r...\rAnswer: D\r#\rQ328\r#\r한 회사에서 레거시 애플리케이션을 AWS로 마이그레이션할 계획입니다.애플리케이션은 현재 NFS를 사용하여 애플리케이션 데이터를 저장하기 위해 온프레미스 스토리지 솔루션과 통신합니다.NFS 이외의 다른 통신 프로토콜을 사용하도록 응용 프로그램을 수정할 수 없습니다.마이그레이션 후 솔루션 설계자가 사용하도록 권장해야 하는 스토리지 솔루션은 무엇입니까?\nA. AWS 데이터비동기 B. Amazon Elastic Block Store (Amazon EBS) C. Amazon Elastic 파일 시스템 (Amazon EFS) D. Amazon EMR 파일 시스템 (Amazon EMRFS) #\rAnswer\r...\rAnswer: C\r#\rQ329\r#\r최근에 생성 된 시작은 3 계층 웹 응용 프로그램을 만들었습니다.프런트 엔드에는 정적 콘텐츠가 있습니다.응용 프로그램 계층은 마이크로 서비스를 기반으로합니다.사용자 데이터는 짧은 대기 시간으로 액세스해야하는 JSON 문서로 저장됩니다.회사는 첫 해에 정기적 인 트래픽이 낮을 것으로 예상하며 매달 새로운 기능을 홍보할 때 트래픽이 최고조로 증가할 것으로 예상합니다.스타트업 팀은 운영 오버헤드 비용을 최소화해야 합니다. 이 작업을 수행하기 위해 솔루션 설계자는 무엇을 권장해야합니까?\nA. Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드 저장 및 서비스 애플리케이션 계층에 AWS Elastic Beanstalk를 사용합니다.Amazon DynamoDB를 사용하여 사용자 데이터를 저장합니다. B. Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드를 저장하고 제공합니다.애플리케이션 계층에 Amazon Elastic Kubernetes 서비스 (Amazon EKS) 를 사용합니다.Amazon DynamoDB를 사용하여 사용자 데이터를 저장합니다. C. Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드를 저장하고 제공합니다.애플리케이션 계층에 Amazon API 게이트웨이 및 AWS Lambda 함수 사용 Amazon DynamoDB를 사용하여 사용자 데이터를 저장합니다. D. Amazon S3 정적 웹 사이트 호스팅을 사용하여 프런트 엔드를 저장하고 제공합니다.애플리케이션 계층에 Amazon API 게이트웨이 및 AWS Lambda 함수를 사용합니다.Amazon RDS를 읽기 전용 복제본과 함께 사용하여 사용자 데이터를 저장합니다. #\rAnswer\r...\rAnswer: C\r#\rQ330\r#\r한 회사에서 3계층 애플리케이션을 VPC로 마이그레이션한 내용을 검토하고 있습니다.보안 팀은 태국어로 애플리케이션 계층 간의 Amazon EC2 보안 그룹 수신 및 송신 규칙에 최소 권한 원칙이 적용되지 않는다는 것을 발견합니다.솔루션 설계자는이 문제를 해결하기 위해 무엇을해야합니까?\nA. 인스턴스 ID를 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다. B. 보안 그룹 ID를 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다. C. VPC CIDR 블록을 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다. D. 서브넷 CIDR 블록을 소스 또는 대상으로 사용하여 보안 그룹 규칙을 생성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ331\r#\r회사가 Amazon Linux EC2 인스턴스 그룹에서 애플리케이션을 실행합니다. 애플리케이션이 표준 API 호출을 사용하여 로그 파일을 작성합니다. 규정 준수를 위해 모든 로그 파일은 무기한 보존되어야 하며 모든 파일에 동시에 액세스해야 하는 보고 도구를 통해 분석됩니다.솔루션 설계자가 가장 비용 효율적인 솔루션을 제공하기 위해 사용합니까?\nA. Amazon EBS B. Amazon EFS C. Amazon EC2 인스턴스 스토어 D. Amazon S3 #\rAnswer\r...\rAnswer: D\r#\rQ332\r#\r회사는 Amazon EC2 인스턴스의 사용이 증가함에 따라 Amazon EDS (Elastic Block Store) 스토리지 비용이 예상보다 빠르게 증가한다는 사실을 알게 되었습니다.비용 절감에 도움이 되는 EBS 관리 방식은 무엇입니까?(두 개를 선택합니다.)\nA. EBS 볼륨을 EC2 인스턴스 스토어로 변환합니다. B. 지속성 요구 사항이 달리 명시되지 않는 한 DetetionOn 종료 속성이 모든 EBS 볼륨에 대해 true로 설정되도록 모니터링하고 적용합니다. C. 지속적인 비즈니스 요구 사항을 충족하고 있는 EBS 볼륨에 대한 EC2 인스턴스 절약 플랜을 구매합니다. D. 활성 사용되지 않는 보존에 필요한 EBS 볼륨의 경우 스냅샷을 생성하고 인스턴스 및 볼륨을 종료합니다. E. 기존 EBS 볼륨을 EBS 프로비저닝된 IOPS SSD (io1) 로 변환합니다. #\rAnswer\r...\rAnswer: B D\r#\rQ333\r#\r회사는 테이프 백업 솔루션을 사용하여 주요 애플리케이션 데이터를 오프사이트에 저장하고 있습니다. 일일 데이터 볼륨은 약 50TB 입니다. 회사는 규정 준수를 위해 7년 동안 백업을 보존해야 합니다. 백업은 거의 액세스하지 않으며 백업을 복원해야 하는 경우 일반적으로 1주일의 통지가 표시됩니다.회사는 이제 테이프 관리에 따른 스토리지 비용과 운영 부담을 줄이기 위한 클라우드 기반 옵션을 고려하고 있습니다. 또한 테이프 백업을 클라우드로의 전환 (ROM 테이프 백업이 중단을 최소화하는지 확인하려고 합니다. 어떤 스토리지 솔루션이 가장 비용 효율적입니까?\nA. Amazon 스토리지 게이트웨이를 사용하여 Amazon Glacier 딥 아카이브에 백업 B. AWS Snowball Edge를 사용하여 백업을 Amazon S3 Glacier와 직접 통합합니다. C. 백업 데이터를 Amazon S3에 복사하고 데이터를 Amazon S3 Glacier로 이동하는 수명 주기 정책을 생성합니다. D. Amazon 스토리지 게이트웨이를 사용하여 Amazon S3에 백업하고 수명 주기 정책을 생성하여 백업을 Amazon S3 Glacier로 이전합니다. #\rAnswer\r...\rAnswer: A\r#\rQ334\r#\r회사가 AWS Lambda 함수를 사용하여 Amazon S3에서 파일을 다운로드하고 해독하는 애플리케이션 워크플로를 보유하고 있습니다. 이러한 파일은 AWS KMS CMK (고객 마스터 키) 를 사용하여 암호화됩니다. 솔루션 설계자는 필요한 권한이올바르게 설정 합니다. 어떤 행동의 조합이 이것을 달성합니까?(두 개를 선택합니다.)\nA. kms.decrypt 권한을 Lambda 함수의 리소스 정책에 연결합니다. B. KMS 키 정책에서 Lambda IAM 역할에 대한 암호 해독 권한을 부여합니다. C. KMS 키 정책에서 Lambda 리소스 정책에 대한 암호 해독 권한을 부여합니다. D. kms:암호 해독 권한을 사용하여 새 IAM 정책을 생성하고 정책을 Lambda 함수에 연결합니다. E. kms 암호 해독 권한을 사용하여 새 IAM 역할을 생성하고 실행 역할을 Lambda 함수에 연결합니다. #\rAnswer\r...\rAnswer: B E\r#\rQ335\r#\r회사가 Amazon DynamoDB 데이터베이스에 대한 읽기 및 쓰기에 의존하는 웹 사이트를 구축하고 있습니다.웹사이트와 관련된 트래픽은 평일의 업무 시간 동안 예측할 수 있을 정도로 최고조이며, 하룻밤 및 주말에는 감소하고 있습니다.솔루션 설계자는 부하를 처리할 수 있는 비용 효율적인 솔루션을 설계해야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?\nA. DynamoDB Accelerator (DAX) 를 활성화하여 데이터를 캐시합니다. B. DynamoDB 데이터베이스에 대해 다중 AZ 복제를 활성화합니다. C. 테이블을 생성할 때 DynamoDB 자동 크기 조정을 활성화합니다. D. 테이블을 생성할 때 DynamoDB 온 디맨드 용량 할당을 활성화합니다. #\rAnswer\r...\rAnswer: C\r#\rQ336\r#\r솔루션 설계자가 여러 Amazon EC2 인스턴스에 분산 데이터베이스를 배포합니다. 데이터베이스는 모든 데이터를 여러 인스턴스에 저장하므로 인스턴스 손실을 견딜 수 있습니다. 데이터베이스에는 초당 수백만 개의 트랜잭션을 지원하기 위해 지연 시간과 처리량이 있는 블록 스토리지가 필요합니다.서버 솔루션 설계자는 어떤 스토리지 솔루션을 사용해야 합니까?\nA. Amazon EBS B. Amazon EC2 인스턴스 스토어 C. Amazon EFS D. Amazon S3 #\rAnswer\r...\rAnswer: B\r#\rQ337\r#\r솔루션 설계자는 대량의 데이터의 일괄 처리를 처리하는 응용 프로그램을 만들고 있습니다.입력 데이터는 Amazon S3에 보관되며 출력 데이터는 다른 S3 버킷에 저장됩니다.처리를 위해 애플리케이션은 네트워크를 통해 여러 Amazon EC2 인스턴스 간에 데이터를 전송합니다. 전체 데이터 전송 비용을 줄이기 위해 솔루션 설계자는 어떻게 해야 합니까?\nA. 모든 EC2 인스턴스를 Auto Scaling 그룹에 배치합니다. B. 모든 EC2 인스턴스를 동일한 AWS 리전에 배치합니다. C. 모든 EC2 인스턴스를 동일한 가용 영역에 배치합니다. D. 모든 EC2 인스턴스를 여러 가용 영역의 프라이빗 서브넷에 배치합니다. #\rAnswer\r...\rAnswer: C\r#\rQ338\r#\r회사는 모든 이메일이 7년 동안 외부에 보관 및 보관되어야 한다는 규정 요건을 준수해야 합니다.관리자가 온-프레미스에서 압축된 이메일 파일을 만들었으며 관리형 서비스가 파일을 AWS 스토리지로 전송하기를 원합니다.솔루션 설계자가 권장해야 하는 관리 서비스는 무엇입니까?\nA. Amazon Elastic 파일 시스템 (Amazon EPS) B. Amazon S3 Glacier C. AWS 백업 D. AWS 스토리지 게이트웨이 #\rAnswer\r...\rAnswer: D\r#\rQ339\r#\r회사에서 Amazon S3 A 규정 준수 요구 사항에 데이터를 저장해야 하는 경우 객체에 변경 사항이 있는 객체의 이전 상태를 보존해야 합니다. 또한 5년보다 오래된 파일에 액세스해서는 안 되지만 감사를 위해 아카이브해야 하는 솔루션은 무엇입니까?건축가는 가장 비용 효율적이라고 권장합니까?\nA. 거버넌스 모드에서 객체 수준 버전 관리 및 S3 객체 잠금 사용 B. 규정 준수 모드에서 객체 수준 버전 관리 및 S3 객체 잠금 활성화 C. 객체 수준 버전 관리 사용 수명 주기 정책을 사용하여 5년보다 오래된 데이터를 S3 Glacier Deep Archive로 이동할 수 있습니다. D. 객체 수준 버전 관리 사용 수명 주기 정책을 사용하여 5년보다 오래된 데이터를 S3 표준 Standard Infrequent Access (S3 Standard-IA) 로 이동할 수 있습니다. #\rAnswer\r...\rAnswer: C\r#\rQ340\r#\r회사에는 수신 메시지를 수신하는 응용 프로그램이 있습니다.이러한 메시지는 수십 개의 다른 응용 프로그램 및 마이크로 서비스에서 빠르게 소비됩니다.메시지 수는 크게 달라지며 때로는 초당 100.000까지 급증하는 경우가 있습니다. 회사는 솔루션을 분리하고 확장성을 높이려고 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. Amazon Kinesis Data Analytics에 메시지 유지 모든 애플리케이션이 메시지를 읽고 처리합니다. B. Amazon EC2 인스턴스에 애플리케이션을 배포합니다. Auto Scaling 그룹은 CPU 메트릭에 따라 EC2 인스턴스 수를 확장합니다. C. 단일 샤드로 Amazon Kinesis Data Streams에 메시지를 기록합니다.모든 응용 프로그램은 스트림에서 읽고 메시지를 처리합니다. D. 하나 이상의 Amazon SQS (단순 대기열 서비스) 구독으로 Amazon SNS (단순 알림 서비스) 주제에 메시지를 게시합니다.그런 다음 모든 응용 프로그램이 대기열의 메시지를 처리합니다. #\rAnswer\r...\rAnswer: D\r#\rQ341\r#\r솔루션 설계자는 ECS 클러스터의 일부인 Amazon EC2 인스턴스에서 실행되는 일련의 Amazon ECS (Amazon Elastic Container Service) 작업 유형을 오케스트레이션하는 솔루션을 설계하고 있습니다.모든 작업의 출력 및 상태 데이터를 저장해야합니다.각 태스크에 의해 출력되는 데이터의 양은 대략 10MB를 사용할 수 있으며 한 번에 수백 개의 작업이 실행될 수 있습니다.이 시스템은 고주파 읽기 및 쓰기를 위해 최적화되어야합니다.이전 출력이 보관되고 삭제되므로 스토리지 크기는 1TB를 초과할 수 없습니다.솔루션 설계자가 권장해야 하는 스토리지 솔루션은 무엇입니까?\nA. 모든 ECS 클러스터 인스턴스에서 액세스할 수 있는 Amazon DynamoDB 테이블입니다. B. 프로비저닝된 처리량 모드의 Amazon EFS (Elastic File System) C. 버스트 처리량 모드를 사용하는 Amazon EFS (Elastic 파일 시스템) 파일 시스템입니다. D. ECS 클러스터 인스턴스에 마운트된 Amazon EBS (Elastic Block Store) 볼륨 #\rAnswer\r...\rAnswer: B\r#\rQ342\r#\r회사는 새로운 모바일 앱을 개발하고 있습니다.회사는 사이트 간 스크립팅 또는 SQL 주입과 같은 일반적인 애플리케이션 수준 공격으로부터 ALB (Application Load Balanacer) 를 보호하기 위해 적절한 트래픽 필터링을 구현해야 합니다.이 회사는 최소한의 인프라 및 운영 인력을 보유하고 있습니다.이 회사는 AWS 환경에 대한 서버 관리, 업데이트 및 보안에 대한 책임의 몫을 줄여야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 권장해야합니까?\nA. AWS WAF 규칙을 구성하고 이를 ALB와 연결합니다. B. 퍼블릭 호스팅이 활성화된 Amazon S3를 사용하여 애플리케이션을 배포합니다. C. AWS 쉴드 어드밴스드 배포 및 ALB 보호 리소스 추가 D. 타사 방화벽을 실행하는 Amazon EC2 인스턴스로 트래픽을 전달하는 새 ALB를 생성합니다. 그러면 해당 트래픽이 현재 ALB로 전달됩니다. #\rAnswer\r...\rAnswer: D\r#\rQ343\r#\r북미 지역에 시설을 갖춘 회사.유럽과 아시아는 글로벌 공급망 및 제조 프로세스를 최적화하기 위해 새로운 분산 애플리케이션을 설계하고 있습니다.한 대륙에 예약된 주문은 두 번째 이하의 모든 지역에서 볼 수 있어야 합니다.데이터베이스는 짧은 RTO (복구 시간 목표) 로 장애 조치를 지원할 수 있어야 합니다. 제조에 영향을 미치지 않도록 하려면 애플리케이션의 가동 시간이 중요합니다. 솔루션 설계자는 무엇을 권장합니까?\nA. Amazon DynamoDB 글로벌 테이블 사용 B. Amazon Aurora 글로벌 데이터베이스 사용 C. 리전 간 읽기 전용 복제본과 함께 MySQL용 Amazon RDS 사용 D. 리전 간 읽기 전용 복제본과 함께 PostgreSQL용 Amazon RDS 사용 #\rAnswer\r...\rAnswer: A\r#\rQ344\r#\r회사는 가장 최근의 청구서에서 Amazon EC2 비용의 증가를 관찰하고 있습니다.결제 팀은 두 EC2 인스턴스에 대해 인스턴스 유형의 원치 않는 수직 확장을 확인합니다.솔루션 설계자는 지난 2개월의 EC2 비용을 비교한 그래프를 만들고 수직 확장의 근본 원인을 식별하기 위해 심층 분석을 수행해야 합니다. 솔루션 설계자는 최소 운영 오버 헤드로 정보를 어떻게 생성해야합니까?\nA. AWS 예산을 사용하여 예산 보고서를 생성하고 인스턴스 유형에 따라 비용을 비교합니다. B. Cost Explorer의 세분화된 필터링 기능을 사용하여 인스턴스 유형에 따라 EC2 비용을 심층적으로 분석할 수 있습니다. C. AWS 결제 및 비용 관리 대시보드의 그래프를 사용하여 최소 2개월 동안의 인스턴스 유형을 기준으로 EC2 비용을 비교합니다. D. AWS 비용 및 사용 보고서를 사용하여 보고서를 생성하여 Amazon S3 버킷으로 전송합니다.Amazon QuickSight Amazon S3를 소스로 사용하여 인스턴스 유형을 기반으로 대화형 그래프를 생성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ345\r#\r회사에서 Amazon S3를 사용하여 다양한 파일 저장 솔루션 설계자는 삭제 후 30일 이내에 삭제된 파일을 즉시 복원할 수 있는 기능을 설계해야 합니다. 가장 비용 효율적인 솔루션입니까?\nA. 객체를 Amazon S3 Glacier로 이동하고 30일 후에 삭제하는 수명 주기 정책을 생성합니다. B. 교차 리전 복제 활성화 AWS Lambda 함수를 사용하여 30일마다 복제본 버킷을 비웁니다. C. 버전 관리를 활성화하고 30일 후에 만료된 버전을 제거하는 수명 주기 정책을 생성합니다. D. Lambda 함수를 사용하여 버전 관리 및 MFA 삭제 활성화 30일 이상 된 객체에서 MFA 삭제 제거 #\rAnswer\r...\rAnswer: A\r#\rQ346\r#\r회사가 애플리케이션 로드 밸런서 (ALB) 뒤의 단일 가용 영역에서 Amazon EC2 Auto Scaling 그룹에 있는 6개의 프런트 엔드 웹 서버를 실행하는 다중 계층 애플리케이션을 보유하고 있습니다. 솔루션 설계자는 애플리케이션을 수정하지 않고 가용성이 높은 인프라를 수정해야 합니다.아키텍처는 고가용성을 제공하는 솔루션 설계자가 선택해야합니까?\nA. 두 영역 각각에서 세 개의 인스턴스를 사용하는 Auto Scaling 그룹을 만듭니다. B. Auto Scaling 그룹을 수정하여 두 가용 영역 각각에 대해 세 개의 인스턴스를 사용합니다. C. 다른 리전에서 더 많은 인스턴스를 빠르게 생성하는 데 사용할 수 있는 Auto Scaling 템플릿을 만듭니다. D. Amazon EC2 인스턴스 앞에 있는 ALB를 라운드 로빈 구성으로 변경하여 트래픽을 웹 티어와 밸런싱합니다. #\rAnswer\r...\rAnswer: B\r#\rQ347\r#\r회사는 매일 수백 개의 파일을 생성하는 온-프레미스 비즈니스 응용 프로그램을 보유하고 있습니다.이러한 파일은 SMB 파일 공유에 저장되며 애플리케이션 서버에 대한 지연 시간이 짧아야 합니다. 새로운 회사 정책에 따르면 애플리케이션 생성 파일을 모두 AWS로 복사해야 합니다. 이미 AWS에 VPN 연결이 있습니다. 애플리케이션 개발 팀은 필요한 코드를 작성할 시간이 없습니다.애플리케이션을 AWS로 이동하기 위한 수정 사항 솔루션 설계자가 애플리케이션에서 AWS로 파일을 복사하도록 허용하려면 어떤 서비스를 권장해야 합니까?\nA. Amazon Elastic 파일 시스템 (Amazon EFS) B. 윈도우 파일 서버용 Amazon FSX C. AWS Snowball D. AWS 스토리지 게이트웨이 #\rAnswer\r...\rAnswer: D\r#\rQ348\r#\r회사가 AWS에 프로덕션 포털 애플리케이션을 배포하고 있습니다.데이터베이스 계층에 구조화된 데이터가 있습니다.이 회사는 쉽게 관리할 수 있고 가용성이 뛰어난 솔루션을 필요로 합니다. 이러한 요구 사항을 어떻게 충족할 수 있습니까?\nA. 여러 가용 영역에 걸쳐 Amazon Elastic 블록 스토어 (Amazon EBS) 가 지원하는 여러 Amazon EC2 인스턴스에 데이터베이스를 배포합니다. B. 여러 가용 영역 옵션과 함께 Amazon RDS를 사용 C. Amazon RDS를 단일 가용 영역 옵션과 함께 사용하고 정기적인 데이터베이스 스냅샷을 예약합니다. D. Amazon DynamoDB 사용 #\rAnswer\r...\rAnswer: B\r#\rQ349\r#\r솔루션 설계자는 Amazon EC2 인스턴스 간의 낮은 네트워크 지연 시간과 높은 네트워크 처리량을 요구하는 새로운 애플리케이션을 위한 아키텍처를 설계하고 있습니다.건축 설계에 포함되어야하는 구성 요소는 무엇입니까?\nA. 스팟 인스턴스 유형이 있는 Auto Scaling 그룹입니다. B. 클러스터 배치 전략을 사용하는 배치 그룹입니다. C. 파티션 배치 전략을 사용하는 배치 그룹입니다. D. 온 디맨드 인스턴스 유형이 있는 Auto Scaling 그룹 #\rAnswer\r...\rAnswer: B\r#\rQ350\r#\r고객이 오리건주에 기반을 둔 서비스를 보유하고 있습니다.미국과 파리.프랑스애플리케이션은 오리건주에 있는 Amazon S3 버킷에 데이터를 저장합니다.이 데이터는 자주 업데이트됩니다.초점이동 사무실에서 개체를 검색할 때 응답 시간이 느립니다.파리 사무실의 느린 응답 시간을 해결하기 위해 솔루션 설계자는 무엇을해야합니까?\nA. 파리에 기반을 둔 S3 버킷을 설정하고 오리건 버킷에서 파리 버킷으로의 교차 리전 복제를 활성화합니다. B. 오리건 S3 버킷과 새 Paris S3 버킷 간에 데이터 검색을 로드 밸런싱하는 애플리케이션 로드 밸런서를 생성합니다. C. 오리건주 mm에 있는 버킷을 오리진으로 사용하여 Amazon CloudFront 배포를 생성하고 캐시 동작에 대한 최대 TTL 설정을 0으로 설정합니다. D. 파리에 기반을 둔 S3 버킷을 설정하고 수명 주기 관리 규칙을 사용하여 오리건 버킷에서 파리 버킷으로 데이터를 이전할 수 있습니다. #\rAnswer\r...\rAnswer: A\r#\rQ351\r#\r회사에서 Amazon ECS (Amazon Elastic Container Service) 클러스터에 배포된 새 애플리케이션을 시작하고 있으며 ECS 작업에 Fargate 시작 유형을 사용하고 있습니다.이 회사는 출시 시 애플리케이션에 대한 트래픽이 많을 것으로 예상되므로 CPU 및 메모리 사용량을 모니터링하고 있습니다.그러나 이 회사는 활용도가 감소할 때 비용을 절감하고자 합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. Amazon EC2 Auto Scaling을 사용하여 이전 트래픽 패턴을 기반으로 특정 기간에 확장할 수 있습니다. B. AWS Lambda 함수를 사용하여 Amazon CloudWatch 경보를 트리거하는 지표 위반에 따라 Amazon ECS를 조정합니다. C. ECS 지표 위반으로 인해 Amazon CloudWatch 경보가 트리거되는 경우 간단한 조정 정책과 함께 Amazon EC2 Auto Scaling을 사용하여 확장할 수 있습니다 D. 대상 추적 정책과 함께 AWS 애플리케이션 Auto Scaling을 사용하여 ECS 지표 위반으로 인해 Amazon CloudWatch 경보가 트리거될 때 확장할 수 있습니다 #\rAnswer\r...\rAnswer: D\r#\rQ352\r#\r한 회사가 여러 Amazon EC2 인스턴스에 대한 교육 사이트를 호스팅합니다.더 컴퍼니 사이트의 수십 개의 교육 비디오로 구성된 새로운 코스가 1 주일에 출시 될 때 매우 인기가있을 것으로 예상합니다. 예상되는 서버 부하를 최소화하기 위해 솔루션 설계자는 무엇을해야합니까?\nA. 비디오를 Redis용 Amazon 엘라스티Cache에 저장합니다.Elastic ache API를 사용하여 비디오를 제공하도록 웹 서버 업데이트 B. Amazon EFS (Elastic File System) 에 비디오를 저장 EFS 볼륨을 탑재할 웹 서버에 대한 사용자 데이터 스크립트를 만듭니다. C. Amazon S3 버킷에 동영상 저장 해당 S3 버킷의 원본 액세스 ID (OAI) 를 사용하여 Amazon CloudFlight 배포를 만듭니다. OAI에 대한 Amazon S3 액세스를 제한합니다. D. Amazon S3 버킷에 비디오를 저장합니다.S3 버킷에 액세스할 AWS Storage Gateway 파일 게이트웨이 생성 파일 게이트웨이를 마운트할 웹 서버에 대한 사용자 데이터 스크립트 생성 응답: #\rAnswer\r...\rAnswer: C\r#\rQ353\r#\r회사가 MySQL 데이터베이스를 실행하는 자체 Amazon EC2 인스턴스를 관리합니다. 이 회사는 수요의 증가 또는 감소에 따라 복제 및 확장을 수동으로 관리하고 있습니다. 회사는 필요에 따라 데이터베이스 계층에 컴퓨팅 용량을 추가하거나 제거하는 프로세스를 간소화하는 새로운 솔루션이 필요합니다.솔루션은 또한 향상된 성능을 제공해야합니다, 작업 마녀 솔루션은 이러한 요구 사항을 충족에서 최소한의 노력으로 확장 및 내구성?\nA. 데이터베이스를 Aurora MySQL을 위해 Amazon Aurora 서버리스 서버로 마이그레이션 B. Aurora PostgreSQL을 위해 계층 데이터베이스를 Amazon Aurora 서버리스 서버로 마이그레이션 C. 데이터베이스를 하나의 큰 MySQL 데이터베이스로 결합 더 큰 EC2 인스턴스에서 더 큰 데이터베이스 실행 D. 데이터베이스 계층에 대한 EC2 Auto Scaling 그룹 생성 기존 데이터베이스를 새 환경으로 마이그레이션합니다. #\rAnswer\r...\rAnswer: A\r#\rQ354\r#\r애플리케이션이 Amazon EC2 인스턴스에서 실행 중입니다. 애플리케이션에 필요한 중요한 정보는 Amazon S3 버킷에 저장됩니다. 버킷을 인터넷 액세스로부터 보호해야 하며 VPC 내의 서비스만 버킷에 액세스할 수 있습니다.이 작업을 수행하기 위해 솔루션을 아카이브해야 하는 작업 조합” (두 개 선택)\nA. Amazon S3용 VPC 엔드포인트를 생성합니다. B. 버킷에서 서버 액세스 로깅 활성화 C. 버킷 정책을 적용하여 S3 엔드포인트에 대한 액세스를 제한합니다. D. 중요한 정보가 있는 버킷에 S3 ACL을 추가합니다. E. IAM 정책을 사용하여 특정 버킷을 사용하도록 사용자를 제한합니다. #\rAnswer\r...\rAnswer: A C\r#\rQ355\r#\r제품 팀이 대량의 데이터를 저장할 새 애플리케이션을 만들고 있습니다. 데이터는 여러 Amazon EC2 Linux 인스턴스에 의해 시간당 분석되고 수정됩니다. 애플리케이션 팀은 필요한 공간이 향후 6개월 동안 계속 증가할 것이라고 믿고 있습니다.솔루션 설계자가 이러한 요구를 지원하기 위해 취하는?\nA. Amazon EBS 볼륨에 데이터 저장 애플리케이션 인스턴스에 EBS 볼륨을 마운트합니다. B. Amazon EFS 파일 시스템에 데이터 저장 애플리케이션 인스턴스에 파일 시스템을 마운트합니다. C. Amazon S3 Glacier에 데이터 저장 애플리케이션 인스턴스에 대한 액세스를 허용하도록 저장소 정책을 업데이트합니다. D. Amazon S3 표준 Standard Infrequent Access (S3 Standard-IA) 에 데이터 저장 애플리케이션 인스턴스에 대한 액세스를 허용하도록 버킷 정책을 업데이트합니다. #\rAnswer\r...\rAnswer: B\r#\rQ356\r#\r한 회사가 온프레미스에서 AWS로 MySQL 데이터베이스를 마이그레이션하려고 합니다.이 회사는 최근 비즈니스에 큰 영향을 미치는 데이터베이스 중단을 경험했습니다.이러한 상황이 다시 발생하지 않도록 하기 위해 이 회사는 데이터 손실을 최소화하고 모든 트랜잭션을 최소 두 개의 노드에 저장하는 신뢰할 수 있는 AWS의 데이터베이스 솔루션을 원합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 3개의 가용 영역에 있는 3개의 노드로 동기식 복제가 가능한 Amazon RDS DB 인스턴스를 생성합니다. B. 다중 AZ 기능이 활성화된 Amazon RDS MySQL DB 인스턴스를 생성하여 데이터를 동기적으로 복제합니다. C. Amazon RDS MySQL DB 인스턴스를 생성한 다음 별도의 AWS 리전에 데이터를 동기적으로 복제하는 읽기 전용 복제본을 생성합니다. D. MySQL 엔진이 설치된 Amazon EC2 인스턴스를 생성하여 AWS Lambda 함수를 트리거하여 데이터를 Amazon RDS MySQL DB 인스턴스에 동기적으로 복제합니다. #\rAnswer\r...\rAnswer: B\r#\rQ357\r#\r회사는 사용자가 업로드한 문서를 Amazon EBS 볼륨에 저장하는 단일 Amazon EC2 인스턴스를 사용하여 AWS에서 웹 애플리케이션을 호스팅하고 있습니다. 확장성 및 가용성 향상을 위해 이 회사는 아키텍처를 복제하고 다른 가용 영역에 두 번째 EC2 인스턴스와 EBS 볼륨을 만들었습니다. 둘 다 애플리케이션 로드 밸런서 뒤에 배치 이 변경을 완료한 후 사용자는 웹 사이트를 새로 고칠 때마다 문서 또는 다른 문서의 하위 집합을 볼 수 있다고 보고했지만 모든 문서를 동시에 사용할 수 없도록 솔루션 설계자는 사용자가 모든 문서를 한 번에 볼 수 있도록 제안해야 하는 것은 무엇입니까?\nA. 두 EBS 볼륨에 모든 문서가 포함되도록 데이터를 복사합니다. B. 사용자를 문서와 함께 서버로 안내하도록 애플리케이션 로드 밸런서를 구성합니다. C. 두 EBS 볼륨에서 Amazon EFS로 데이터 복사 애플리케이션을 수정하여 새 문서를 Amazon EFS에 저장하십시오. D. 두 서버 모두에 요청을 보내도록 애플리케이션 로드 밸런서 구성 올바른 서버에서 각 문서 반환 #\rAnswer\r...\rAnswer: C\r#\rQ358\r#\r회사가 데이터 센터를 재배치 중이며 2주 이내에 50TB의 데이터를 AWS로 안전하게 전송하고자 합니다. 기존 데이터 센터는 AWS에 사이트 간 VPN 연결을 통해 90% 의 활용도가 있습니다.솔루션 설계자가 이러한 요구 사항을 충족하기 위해 어떤 AWS 서비스를 사용해야 합니까?\nA. VPC 엔드포인트가 있는 AWS 데이터비동기 B. AWS Direct Connect C. AWS Snowball 엣지 스토리지 최적화 D. AWS 스토리지 게이트웨이 #\rAnswer\r...\rAnswer: C\r#\rQ359\r#\r한 회사에서 여러 프로덕션 애플리케이션을 호스팅하는 애플리케이션 중 하나는 Amazon EC2 AWS Lambda Amazon RDS Amazon 단순 알림 서비스 (Amazon SNS\u0026gt;. 및 Amazon SQS (단순 대기열 서비스) 의 리소스로 구성됩니다. 모든 회사 리소스에는 태그 이름이“응용 프로그램” 및 각 응용 프로그램에 해당하는 값 솔루션 설계자는 태그가 지정된 모든 구성 요소를 식별할 수 있는 가장 빠른 솔루션을 제공해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족하는지”\nA. AWS CloudTrail을 사용하여 애플리케이션 태그와 함께 리소스 목록 생성 B. AWS CLI를 사용하여 모든 리전의 각 서비스를 쿼리하여 태그가 지정된 구성 요소를 보고합니다. C. Amazon CloudWatch 로그 통찰력에서 쿼리를 실행하여 애플리케이션 태그가 있는 구성 요소에 대해 보고합니다. D. AWS 리소스 그룹 태그 편집기로 쿼리를 실행하여 애플리케이션 태그와 함께 전역적으로 리소스에 대해 보고합니다. #\rAnswer\r...\rAnswer: D\r#\rQ360\r#\r회사에서 Amazon EC2에서 전자 상거래 애플리케이션을 실행하고 있습니다. 애플리케이션은 최소 10개의 인스턴스가 필요한 상태 비저장 웹 티어와 애플리케이션 사용을 지원하기 위해 최대 250개의 인스턴스로 구성됩니다. 애플리케이션에는 시간의 50개의 인스턴스가 필요합니다.비용을 최소화하시겠습니까?\nA. 250개의 인스턴스를 구매하기 위해 예약 인스턴스 구매 B. 예약 인스턴스를 구매하여 80개의 인스턴스를 커버하려면 스팟 인스턴스를 사용하여 나머지 인스턴스를 커버합니다. C. 온디맨드 인스턴스를 구입하여 40개의 인스턴스를 커버하는 스팟 인스턴스를 사용하여 나머지 인스턴스를 커버합니다. D. 50개의 인스턴스를 커버하기 위해 예약 인스턴스 구매 온 디맨드 및 스팟 인스턴스를 사용하여 나머지 인스턴스를 커버합니다. #\rAnswer\r...\rAnswer: D\r#\rQ361\r#\r한 회사가 VMware의 온프레미스에서 호스팅되는 40대의 서버를 AWS 클라우드로 마이그레이션할 계획입니다.마이그레이션 프로세스는 다운타임을 최소화하면서 구현되어야 합니다.또한 이 회사는 컷오버 날짜 전에 서버를 테스트하려고 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 온프레미스 환경에 AWS DataSync 에이전트를 배포합니다.DataSync를 사용하여 서버를 마이그레이션합니다. B. RJ45를 통해 온프레미스 네트워크에 연결된 AWS Snowball 디바이스를 배포합니다.Snowball을 사용하여 서버를 마이그레이션합니다. C. AWS 데이터베이스 마이그레이션 서비스 (AWS DMS) 복제 인스턴스를 AWS에 배포합니다.AWS DMS를 사용하여 서버를 마이그레이션합니다. D. 온프레미스 환경에 AWS 서버 마이그레이션 서비스 (AWS SMS) 커넥터를 배포합니다.AWS SMS를 사용하여 서버를 마이그레이션합니다. #\rAnswer\r...\rAnswer: A\r#\rQ362\r#\r회사에 Amazon SQS에 메시지를 게시하는 애플리케이션이 있습니다. 또 다른 애플리케이션이 대기열을 폴링하고 L/O 집약적인 작업으로 메시지를 처리합니다. 회사는 메시지 수신과 응답 사이에 경과할 수 있는 최대 시간을 지정하는 SLA (서비스 수준 계약) 를 보유하고 있습니다.사용자에게 메시지 수가 증가함에 따라 회사는 SLA를 일관되게 충족시키는 데 어려움이 있습니다. 솔루션 설계자는 응용 프로그램의 처리 시간을 개선하고 모든 수준에서로드를 처리 할 수 있도록하기 위해 무엇을해야합니까?\nA. 처리에 사용된 인스턴스에서 Amazon 머신 이미지 (AMI) 생성 인스턴스를 종료하고 더 큰 크기로 바꿉니다. B. 처리에 사용된 인스턴스에서 Amazon 머신 이미지 (AMI) 생성 인스턴스를 종료하고 Amazon EC2 전용 인스턴스로 대체 C. 처리에 사용된 인스턴스에서 Amazon 머신 이미지 (AMI) 생성 시작 구성에서 이 이미지를 사용하여 Auto Scaling 그룹 생성 대상 추적 정책을 사용하여 그룹을 구성하여 총 CPU 사용률을 70% 미만으로 유지합니다. D. 처리에 사용된 인스턴스에서 Amazon 머신 이미지 (AMI) 생성 시작 구성에서 이 이미지를 사용하여 Auto Scaling 그룹 생성 SQS 대기열에서 가장 오래된 메시지의 수명을 기준으로 대상 추적 정책을 사용하여 그룹을 구성합니다. #\rAnswer\r...\rAnswer: D\r#\rQ363\r#\r회사는 Auto Scaling 그룹에서 현재 프로비저닝한 Amazon EC2 인스턴스에 대한 필요성을 재평가해야 합니다.현재 Auto Scaling 그룹은 두 가용 영역에서 최소 2개의 인스턴스와 최대 4개의 인스턴스에 대해 구성됩니다.한 솔루션 설계자가 Amazon CloudWatch 메트릭을 검토한 결과 EC2 인스턴스의 CPU 사용률이 지속적으로 낮다는 사실을 발견했습니다. 애플리케이션 내결함성을 유지하면서 활용도를 극대화하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?\nA. 일부 EC2 인스턴스를 제거하여 나머지 인스턴스의 사용률을 높입니다. B. CPU 사용률이 낮고 인스턴스의 Amazon EBS (Elastic Block Store) 용량을 늘립니다. C. Auto Scaling 그룹 조정 정책을 수정하여 더 높은 CPU 사용률 메트릭을 기반으로 확장 및 축소합니다. D. 더 작은 인스턴스 유형을 사용하는 새 시작 구성을 생성합니다.기존 Auto Scaling 그룹을 업데이트합니다. #\rAnswer\r...\rAnswer: D\r#\rQ364\r#\r회사가 AWS 클라우드에서 멀티 티어 전자 상거래 웹 애플리케이션을 실행하고 있습니다. 웹 애플리케이션은 Amazon EC2 인스턴스에서 실행되고 있습니다.데이터베이스 계층은 프로비저닝된 Amazon Aurora MySQL DB 클러스터에 있으며 다중 AZ 환경에서 작성자 및 판독기가 있습니다.데이터베이스 계층의 새로운 요구 사항은 인스턴스 장애 조치를 통해 지속적인 쓰기 가용성을 달성하기 위해 애플리케이션을 제공하는 것입니다. 솔루션 설계자는 이 새로운 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. 다중 쓰기를 위해 DB 클러스터에 새 AWS 리전을 추가합니다. B. 새 리더 추가 작성기와 동일한 가용 영역에서. C. 데이터베이스 계층을 Aurora 다중 마스터 클러스터로 마이그레이션합니다. D. 병렬 쿼리가 활성화된 상태에서 데이터베이스 계층을 Aurora DB 클러스터로 마이그레이션합니다. #\rAnswer\r...\rAnswer: D\r#\rQ365\r#\r회사는 VPC의 Amazon EC2 인스턴스에서 실행되는 애플리케이션을 보유하고 있습니다.애플리케이션 중 하나는 Amazon S3 API를 호출하여 객체를 저장하고 읽어야 합니다.회사의 보안 정책은 응용 프로그램의 인터넷 바운드 트래픽을 제한합니다.이러한 요구 사항을 충족하고 보안을 유지할 작업은 무엇입니까?\nA. S3 인터페이스 엔드 포인트를 구성합니다. B. S3 게이트웨이 엔드 포인트를 구성합니다. C. 프라이빗 서브넷에 S3 버킷을 생성합니다. D. EC2 인스턴스와 동일한 리전에 S3 버킷을 생성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ366\r#\r솔루션 설계자는 사용자 지정 도메인 이름을 사용하여 사용자가 액세스하는 정적 단일 페이지 응용 프로그램에 대해 대기 시간이 짧은 솔루션을 설계해야 합니다.이 솔루션은 서버를 사용하지 않고 전송 중에 암호화되어야 하며 비용 효율적이어야 합니다. 솔루션 설계자가 사용해야 하는 AWS 서비스와 기능의 조합은 무엇입니까?(두 개를 선택합니다.)\nA. Amazon S3 B. Amazon EC2 C. AWS Fargate D. Amazon CloudFront E. Elastic 로드 밸런서 #\rAnswer\r...\rAnswer: A D\r#\rQ367\r#\r회사에서 Amazon EC2 인스턴스에서 애플리케이션을 실행합니다.응용 프로그램이 배포됩니다. 사설 서브넷은 us-east-1 리전의 세 개의 가용 영역에 있습니다.인스턴스는 인터넷에 연결하여 파일을 다운로드할 수 있어야 합니다. 회사는 지역 전체에서 가용성이 뛰어난 설계를 원합니다. 인터넷 연결에 방해가 되지 않도록 하려면 어떤 솔루션을 구현해야 합니까?\nA. NAT 인스턴스를 각 가용 영역의 프라이빗 서브넷에 배포합니다. B. 각 가용 영역의 퍼블릭 서브넷에 NAT 게이트웨이를 배포합니다. C. 각 가용 영역의 프라이빗 서브넷에 전송 게이트웨이를 배포합니다. D. 각 가용 영역의 퍼블릭 서브넷에 인터넷 게이트웨이를 배포합니다. #\rAnswer\r...\rAnswer: B\r#\rQ368\r#\r회사의 웹 사이트는 초당 50,000 건의 요청을 수신합니다.회사는 웹 사이트 사용자의 탐색 패턴을 분석하기 위해 여러 응용 프로그램을 사용하여 경험을 개인화할 수 있기를 원합니다.솔루션 설계자가 웹 사이트의 페이지 클릭 수를 수집하고 각 사용자에 대해 순차적으로 처리하는 데 어떤 AWS 서비스 또는 기능을 사용해야 합니까?\nA. AWS CloudTrail B. Amazon 단순 대기열 서비스 (Amazon SQS) FIFO 대기열 C. Amazon Kinesis Data Streams D. Amazon SQS (단순 대기열 서비스) 표준 대기열 #\rAnswer\r...\rAnswer: C\r#\rQ369\r#\r한 회사는 애플리케이션의 성능을 향상시키기 위해 온프레미스에서 AWS 클라우드로 다중 계층 애플리케이션을 이전하려고 합니다.응용 프로그램은 RESTful 서비스를 통해 서로 통신하는 응용 프로그램 계층으로 구성됩니다.한 계층이 과부하되면 트랜잭션이 삭제됩니다. 솔루션 설계자는 이러한 문제를 해결하고 응용 프로그램을 현대화하는 솔루션을 설계해야 합니다. 이러한 요구 사항을 충족하고 가장 효율적인 솔루션은 무엇입니까?\nA. Amazon API 게이트웨이를 사용하여 AWS Lambda 함수에 직접 트랜잭션을 애플리케이션 계층으로 사용합니다. Amazon SQS (단순 대기열 서비스) 를 애플리케이션 서비스 간의 통신 계층으로 사용합니다. B. Amazon CloudWatch 메트릭을 사용하여 애플리케이션 성능 기록을 분석하여 성능 장애 발생 시 서버의 최대 사용률을 파악하여 최대 요구 사항을 충족하도록 애플리케이션 서버의 Amazon EC2 인스턴스 크기를 늘립니다. C. Amazon SNS (단순 알림 서비스) 를 사용하여 Auto Scaling 그룹에서 Amazon EC2에서 실행되는 애플리케이션 서버 간 메시지 처리 Amazon CloudWatch를 사용하여 SNS 대기열 길이를 모니터링하고 필요에 따라 확장 및 축소합니다. D. Amazon SQS (단순 대기열 서비스) 를 사용하여 Auto Scaling 그룹에서 Amazon EC2에서 실행되는 애플리케이션 서버 간 메시지 처리 Amazon CloudWatch를 사용하여 SQS 대기열 길이를 모니터링하고 통신 실패가 감지되면 확장할 수 있습니다. #\rAnswer\r...\rAnswer: A\r#\rQ370\r#\r회사에서 Amazon RDS MySQL DB 인스턴스를 사용하기 위해 애플리케이션을 판매하고 있습니다.데이터베이스는 가동 중지 시간을 최소화하면서 가용 영역과 AWS 리전 전반에서 고가용성을 제공하도록 설계되어야 합니다. 솔루션 설계자는 이 요구 사항을 어떻게 충족해야 합니까?\nA. RDS MySQL 다중 AZ DB 인스턴스를 설정합니다.적절한 백업 윈도우를 구성합니다. B. RDS MySQL 다중 AZ DB 인스턴스를 설정합니다.다른 리전에서 읽기 전용 복제본을 구성합니다. C. RDS MySQL 단일 AZ DB 인스턴스를 설정합니다.다른 리전에서 읽기 전용 복제본을 구성합니다. D. RDS MySQL 단일 AZ DB 인스턴스를 설정합니다.자동화된 스냅샷을 하나 이상의 다른 리전으로 복사합니다. #\rAnswer\r...\rAnswer: B\r#\rQ371\r#\r한 회사가 고성능 컴퓨팅 (HPC) 애플리케이션 및 데이터를 온프레미스에서 AWS 클라우드로 마이그레이션하려고 합니다.이 회사는 Hoi 고성능 병렬 스토리지와 함께 온프레미스에서 계층형 스토리지를 사용하여 애플리케이션을 정기적으로 실행하는 동안 애플리케이션을 지원하고, 애플리케이션이 활발히 실행되지 않을 때 더 경제적인 콜드 스토리지를 사용하여 데이터를 보관합니다.솔루션 설계자가 애플리케이션의 스토리지 요구 사항을 지원하기 위해 어떤 솔루션 조합을 권장해야 합니까?(두 개 선택)\nA. 콜드 데이터 스토리지용 Amazon S3 B. 콜드 데이터 스토리지용 Amazon EFS C. 고성능 병렬 스토리지용 Amazon S3 D. 고성능 병렬 스토리지를 위한 Lustre 용 Amazon FSX E. 고성능 병렬 스토리지를 위한 Windows용 Amazon FSX #\rAnswer\r...\rAnswer: A D\r#\rQ372\r#\r회사는 데이터베이스와 같이 Amazon RDS lor MySQL을 사용하는 여러 애플리케이션을 보유하고 있습니다.이 회사는 최근 새로운 사용자 지정 보고 응용 프로그램이 데이터베이스에 대한 쿼리 수를 증가했음을 발견했습니다.이로 인해 성능이 저하됩니다.솔루션 설계자는 최소 양의 응용 프로그램 변경으로이 문제를 어떻게 해결해야합니까?\nA. 다중 AZ를 사용하여 보조 DB 인스턴스 추가 B. Amazon RDS에서 로드 복제본 아나 다중 AZ를 설정합니다. C. Amazon RDS에 예비 복제본 및 다중 AZ 설정 D. Amazon RDS에서 캐싱을 사용하여 전반적인 성능 향상 #\rAnswer\r...\rAnswer: D\r#\rQ373\r#\r회사의 애플리케이션은 ALB (애플리케이션 로드 밸런서) 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 여러 가용 영역에 걸쳐 Amazon EC2 Auto Scaling 그룹에서 실행되는 인스턴스는 매월 첫날 자정에 월말 재무 계산 시 애플리케이션 속도가 훨씬 느려집니다.batch 실행 이로 인해 EC2 인스턴스의 CPU 사용률이 즉시 100% 로 증가하게 됩니다. 애플리케이션을 방해하는 경우 솔루션 설계자가 애플리케이션이 워크로드를 처리하고 가동 중지 시간을 피할 수 있도록 하려면 무엇을 권장해야 합니까?\nA. ALB 앞에 Amazon CloudFront 배포를 구성합니다. B. CPU 사용률을 기반으로 EC2 Auto Scaling 단순 조정 정책 구성 C. 월별 일정에 따라 EC2 Auto Scaling 예약 조정 정책을 구성합니다. D. EC2 인스턴스에서 일부 워크로드를 제거하도록 Amazon ElastiCache를 구성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ374\r#\r회사는 현재 하드웨어 보안 모듈 (HSM) 에 대칭 암호화 키를 저장하고 있습니다.솔루션 설계자는 키 관리를 AWS로 마이그레이션하기 위한 솔루션을 설계해야 합니다.이 솔루션은 키 회전을 허용하고 고객이 제공한 키의 사용을 지원해야 합니다.이러한 요구 사항을 충족하기 위해 주요 자료를 어디에 저장해야 합니까?\nA. Amazon S3 B. AWS 비밀 관리자 C. AWS 시스템 관리자 매개 변수 저장소 D. AWS 키 관리 서비스 (AWS KMS) #\rAnswer\r...\rAnswer: D\r#\rQ375\r#\r회사는 두 개의 AWS 계정을 보유하고 있습니다. 프로덕션 및 개발 계정에는 프로덕션 계정으로 푸시할 준비가 된 코드 변경 사항이 있습니다. 알파 단계에서는 개발 팀의 수석 개발자 2명만 베타 단계에서 프로덕션 계정에 액세스할 수 있으므로 더 많은 개발자가액세스를 사용하여 테스트를 수행 할 수도 있습니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. 각 계정에서 AWS Management Console을 사용하여 두 개의 정책 문서 생성 액세스가 필요한 개발자에게 정책을 할당합니다. B. 개발 계정에서 IAM 역할 만들기 하나의 IAM 역할에 프로덕션 계정에 대한 액세스 권한 부여 개발자가 역할을 수임할 수 있도록 허용 C. Development 계정을 지정하는 신뢰 정책을 사용하여 프로덕션 계정에 IAM 역할을 만듭니다.개발자가 역할을 수임할 수 있도록 허용합니다. D. 프로덕션 계정에서 IAM 그룹을 생성하고 프로덕션 계정을 지정하는 신뢰 정책의 보안 주체로 추가 그룹에 개발자 추가 #\rAnswer\r...\rAnswer: C\r#\rQ376\r#\r회사는 단일 VPC에서 실행되는 전자 상거래 애플리케이션을 보유하고 있습니다.애플리케이션 스택에는 단일 웹 서버와 Amazon RDS 다중 AZ DB 인스턴스가 있습니다. 이 회사는 한 달에 두 번 신제품을 시작합니다.이로 인해 최소 72시간 동안 웹 사이트 트래픽이 약 400% 증가합니다. 제품 출시 기간 동안 사용자는 브라우저에서 응답 시간이 느리고 시간 초과 오류가 자주 발생하고 작동 시간을 최소화하면서 느린 응답 시간과 시간 초과 오류를 완화하기 위해 솔루션 설계자가 수행해야 할 작업오버 헤드?\nA. 웹 서버의 인스턴스 크기를 늘립니다. B. 애플리케이션 로드 밸런서와 웹 서버를 추가합니다. C. Amazon EC2 Auto Scaling 및 애플리케이션 로드 밸런서 추가 D. Amazon ElastiCache 클러스터를 배포하여 자주 액세스하는 데이터를 저장합니다. #\rAnswer\r...\rAnswer: C\r#\rQ377\r#\r회사는 Amazon EC2 인스턴스 집합에서 프로덕션 애플리케이션을 실행합니다. 애플리케이션은 Amazon SQS 대기열에서 데이터를 읽고 메시지를 병렬로 처리합니다.메시지 볼륨을 예측할 수 없으며 간헐적인 트래픽이 있는 경우가 많습니다.이 애플리케이션은 다운타임 없이 메시지를 지속적으로 처리해야 합니다. 어떤 솔루션이 이러한 요구 사항을 가장 경제적으로 충족합니까?\nA. 스팟 인스턴스만 사용하여 필요한 최대 용량 처리 B. 예약 인스턴스만 사용하여 필요한 최대 용량을 처리할 수 있습니다. C. 예약 인스턴스를 기준 용량으로 사용하고 스팟 InstaKes를 사용하여 추가 용량 처리 D. 예약 인스턴스를 기준 용량으로 사용하고 온 디맨드 인스턴스를 사용하여 추가 용량 처리 #\rAnswer\r...\rAnswer: D\r#\rQ378\r#\r한 회사에서 3계층 애플리케이션을 AWS로 마이그레이션하고 있습니다.응용 프로그램에는 MySQL 데이터베이스가 필요합니다.과거에는 응용 프로그램 사용자가 새 항목을 만들 때 응용 프로그램 성능이 저하되었다고 보고했습니다.이러한 성능 문제는 작업 시간 동안 응용 프로그램에서 다른 실시간 보고서를 생성 하는 사용자가 발생 했습니다. AWS로 이전할 때 애플리케이션의 성능을 향상시킬 수 있는 솔루션은 무엇입니까?\nA. 프로비저닝된 용량이 있는 Amazon DynamoDB 테이블로 데이터를 가져옵니다.보고서를 위해 DynamoDB를 사용하도록 애플리케이션을 리팩터링합니다. B. 컴퓨팅 최적화 Amazon EC2 인스턴스에서 데이터베이스를 생성합니다.컴퓨팅 리소스가 온-프레미스 데이터베이스를 초과하는지 확인합니다. C. 여러 읽기 전용 복제본이 포함된 Amazon Aurora MySQL 다중 AZ DB 클러스터를 생성합니다.보고서에 대한 응용 프로그램 판독기 엔드 포인트를 구성합니다. D. Amazon Aurora MySQL 다중 AZ DB 클러스터를 생성합니다.클러스터의 백업 인스턴스를 보고서의 엔드 포인트로 사용하도록 응용 프로그램을 구성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ379\r#\r한 회사에서 느슨하게 결합된 마이크로 서비스 세트로 AWS에서 온라인 마켓플레이스 애플리케이션을 구축하려고 합니다.이 애플리케이션의 경우 고객이 새 주문을 제출하면 두 개의 마이크로 서비스가 이벤트를 동시에 처리해야 합니다.이메일 마이크로 서비스에서 확인 이메일을 보내고 주문 처리 마이크로 서비스는 주문 배송 프로세스를 시작합니다.고객이 주문을 취소하면 OrderCancelation 및 이메일 마이크로 서비스가 동시에 이벤트를 처리해야합니다.한 솔루션 설계자가 Amazon SOS (단순 대기열 서비스) 및 Amazon SNS (단순 알림 서비스) 를 사용하여 마이크로 서비스 간 메시징을 설계하려고 합니다.솔루션 설계자는 솔루션을 어떻게 설계해야합니까?\nA. 단일 SQS 대기열을 생성하고 이 대기열에 주문 이벤트를 게시합니다.이메일.주문 처리 및 주문 취소 마이크로서비스는 대기열의 메시지를 소비할 수 있습니다. B. 각 마이크로 서비스에 대해 세 개의 SNS 주제를 만듭니다.세 가지 주제에 주문 이벤트를 게시합니다.각 이메일을 구독하십시오.주문 처리. 자체 주제로 주문 취소 마이크로 서비스. C. SNS 주제를 만들고 주문 이벤트를 게시합니다.이메일에 대한 3개의 SQS 대기열을 생성합니다.주문 처리. 및 주문 취소 마이크로 서비스.메시지 필터링을 통해 모든 SQS 대기열을 SNS 주제에 가입 D. 두 개의 SQS 대기열을 생성하고 두 대기열에 동시에 주문 이벤트를 게시합니다.하나의 큐는 전자 메일 및 주문 처리 마이크로 서비스에 대한 것입니다.두 번째 대기열은 이메일 및 주문 취소 마이크로서비스에 대한 것입니다. #\rAnswer\r...\rAnswer: D\r#\rQ380\r#\r회사는 민감한 사용자 데이터를 Amazon S3에 저장할 계획입니다.내부 보안 규정 준수 요구 사항은 데이터를 Amazon S3로 전송하기 전에 데이터를 암호화해야 합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 권장해야합니까?\nA. 고객이 제공한 암호화 키를 사용한 서버 측 암호화 B. Amazon S3 관리형 암호화 키를 사용한 클라이언트 측 암호화 C. AWS KMS (키 관리 서비스) 에 저장된 키를 사용한 서버 측 암호화 D. AWS KMS (키 관리 서비스) 에 저장된 마스터 키를 사용한 클라이언트 측 암호화 #\rAnswer\r...\rAnswer: D\r#\rQ381\r#\r솔루션 설계자는 Amazon EC2 인스턴스에서 실행되는 웹 애플리케이션 그룹을 위한 중앙 집중식 로깅 솔루션을 설계해야 합니다.이 솔루션은 예산 제한으로 인해 최소한의 개발 노력이 필요합니다. 건축가는 무엇을 추천해야합니까?\nA. 각 인스턴스에 crontab 작업 스크립트를 생성하여 로그를 Amazon S3로 정기적으로 푸시합니다. B. Amazon EC2 인스턴스에 Amazon CloudWatch 로그 에이전트 설치 및 구성 C. AWS 관리 콘솔에서 Amazon 이벤트 브리지 (Amazon 클라우드워치 이벤트) 를 활성화합니다. D. AWS 클라우드 추적에서 애플리케이션에서 호출한 모든 API 호출을 매핑할 수 있도록 지원 #\rAnswer\r...\rAnswer: B\r#\rQ382\r#\r솔루션스 아키텍트는 사용자가 S3 버킷에 저장된 프리미엄 공유 콘텐츠에 대한 액세스 권한을 구매할 수 있도록 AWS에서 호스팅할 웹 애플리케이션을 설계해야 합니다.결제 시 사용자가 액세스가 거부되기 전에 14일 동안 콘텐츠를 다운로드할 수 있습니다. 다음 중 가장 복잡한 구현은 무엇입니까?\nA. OAI (오리진 액세스 ID) 가 있는 Amazon CloudFront 배포 사용 서명된 URL의 Lambda 디자인 함수를 통해 파일에 액세스할 수 있도록 Amazon S3 오리진을 사용하여 배포를 구성합니다. 14일이 지난 데이터를 제거합니다. B. S3 버킷을 사용하여 파일에 직접 액세스 제공 DynamoDH 테이블에서 구매를 추적하도록 애플리케이션 설계 Amazon DynamoDB에 대한 쿼리를 기반으로 14일이 지난 데이터를 제거하도록 Lambda 함수 구성 C. OAI와 함께 Amazon CloudFront 배포 사용 서명된 URL을 통해 파일에 대한 액세스 권한을 제공하도록 Amazon S3 오리진을 사용하여 배포를 구성합니다. URL에 14일이 만료되도록 애플리케이션을 설계합니다. D. OAI와 함께 Amazon CloudFront 배포 사용 서명된 URL을 통해 파일에 액세스할 수 있도록 Amazon S3 오리진을 사용하여 배포를 구성합니다. URL의 만료 60분을 설정하고 필요에 따라 URL을 다시 생성하도록 애플리케이션을 설계합니다. #\rAnswer\r...\rAnswer: C\r#\rQ383\r#\r회사는 AWS 클라우드에서 애플리케이션을 실행하고 Amazon DynamoDB를 데이터베이스로 사용합니다. 이 회사는 Amazon EC2 인스턴스를 프라이빗 네트워크에 배포하여 데이터베이스의 데이터를 처리합니다. 회사는 두 개의 NAT 인스턴스를 사용하여 DynamoDB에 대한 연결을 제공합니다.회사에서 NAT 인스턴스 폐기를 원합니다. 솔루션 설계자는 DynamoDB에 대한 연결을 제공하고 지속적인 관리가 필요하지 않은 솔루션을 구현해야 합니다.이러한 요구 사항을 충족하는 가장 비용 효율적인 솔루션은 무엇입니까?\nA. DynamoDB에 대한 연결을 제공하기 위한 게이트웨이 VPC 엔드포인트 생성 B. DynamoDB에 대한 연결을 제공하도록 관리형 NAT 게이트웨이를 구성합니다. C. 프라이빗 네트워크와 DynamoDB 간에 AWS Direct Connect 연결 설정 D. 프라이빗 네트워크와 DynamoDB 간에 AWS 프라이버트링크 엔드포인트 서비스를 배포합니다. # Answer\r...\rAnswer: A\r#\rQ384\r#\r애플리케이션을 사용하면 회사 본사의 사용자가 제품 데이터에 액세스할 수 있습니다. 제품 데이터는 Amazon RDS MySQL DB 인스턴스에 저장됩니다.운영 팀은 애플리케이션 성능 저하를 격리했으며 읽기 트래픽과 쓰기 트래픽을 분리하려고 합니다.솔루션 설계자는 애플리케이션의 성능을 신속하게 최적화해야 합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. 기존 데이터베이스를 다중 AZ 배포로 변경 기본 가용 영역에서 읽기 요청 제공 B. 기존 데이터베이스를 다중 AZ 배포로 변경 보조 가용 영역에서 읽기 요청 제공 C. 데이터베이스에 대한 읽기 전용 복제본 생성 컴퓨팅 및 스토리지 리소스의 절반을 원본 데이터베이스로 사용하여 읽기 전용 복제본을 구성합니다. D. 데이터베이스용 읽기 전용 복제본 생성 소스 데이터베이스와 동일한 컴퓨팅 및 스토리지 자원으로 읽기 전용 복제본을 구성합니다. #\rAnswer\r...\rAnswer: D\r#\rQ385\r#\r회사가 AWS로 마이그레이션해야 하는 Microsoft Windows 기반 애플리케이션을 보유하고 있습니다.이 애플리케이션을 사용하려면 여러 Amazon EC2 Windows 인스턴스에 연결된 공유 Windows 파일 시스템을 사용해야 합니다. 이를 달성하기 위해 솔루션 설계자는 무엇을해야합니까?\nA. 각 Windows 인스턴스에 EPS 볼륨을 마운트하는 Amazon EFS를 사용하여 볼륨 구성 B. 볼륨 게이트웨이 모드에서 AWS 스토리지 게이트웨이 구성 볼륨을 각 Windows 인스턴스에 마운트 C. Windows용 Amazon FSX 파일 서버 구성 각 Windows 인스턴스에 Amazon FSX 볼륨을 마운트합니다. D. 필요한 크기로 Amazon EBS 볼륨 구성 각 EC2 인스턴스를 볼륨에 연결 볼륨 내의 파일 시스템을 각 Windows 인스턴스에 마운트 #\rAnswer\r...\rAnswer: C\r#\rQ386\r#\r한 회사가 AWS에서 메시지 기반 주문 처리 애플리케이션을 설계하고 있습니다.응용 프로그램은 많은 서비스로 구성되어 있으며 처리 결과를 여러 소비 서비스에 전달해야합니다.각 서비스 이용 시 최대 5일이 소요될 수 있습니다. 메시지 어떤 프로세스가 이러한 요구 사항을 충족합니까?\nA. 애플리케이션은 처리 결과를 Amazon SNS (단순 알림 서비스) 주제로 보냅니다. 각 소비 서비스는 이 SNS 주제를 구독하고 그 결과를 소비합니다. B. 애플리케이션은 처리 결과를 Amazon SNS (단순 알림 서비스) 주제로 보냅니다. 각 소비 서비스는 해당 SNS 주제에서 직접 메시지를 소비합니다. C. 애플리케이션은 처리 결과를 Amazon SQS (단순 대기열 서비스) 대기열로 전송합니다. 각 소비 서비스는 이 단일 SQS 대기열을 소비하는 AWS Lambda 함수로 실행됩니다. D. 애플리케이션은 처리 결과를 Amazon SNS (단순 알림 서비스) 주제로 보냅니다.각 서비스에 대해 Amazon SQS (단순 대기열 서비스) 대기열이 생성되고 각 대기열은 SNS 주제의 구독자로 구성됩니다. #\rAnswer\r...\rAnswer: C\r#\rQ387\r#\r회사에서 Amazon EC2 인스턴스에서 배치 애플리케이션을 실행하고 있습니다. 이 애플리케이션은 여러 Amazon RDS 데이터베이스가 있는 백엔드로 구성됩니다. 애플리케이션이 데이터베이스에 대해 많은 읽기 횟수를 발생시키고 있습니다. 솔루션 설계자는 고가용성을 보장하면서 데이터베이스 읽기 수를 줄여야 합니다. 솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. Amazon RDS 읽기 전용 복제본을 추가합니다. B. 레디 스에 Amazon ElastiCache 사용 C. Amazon 루트 53 DNS 캐싱 사용 D. 멤캐쉬에 Amazon ElastiCache 사용 #\rAnswer\r...\rAnswer: A\r#\rQ388\r#\r회사는 매일 한 번씩 다양한 출처에서 정형 및 반정형 데이터를 수신합니다.솔루션 설계자는 빅 데이터 처리 프레임워크를 활용하는 솔루션을 설계해야 합니다.SQL 쿼리 및 비즈니스 인텔리전스 도구를 사용하여 데이터에 액세스할 수 있어야 합니다.솔루션 설계자는 가장 고성능 솔루션을 구축하기 위해 무엇을 권장해야합니까?\nA. AWS Glulues를 사용하여 데이터를 처리하고 Amazon S3를 사용하여 데이터 저장 B. Amazon EMR을 사용하여 데이터를 처리하고 Amazon Redshift를 사용하여 데이터를 저장합니다. C. Amazon EC2를 사용하여 데이터를 처리하고 Amazon Elastic 블록 스토어 (Amazon EBS) 를 사용하여 데이터 저장 D. Amazon Kinesis Data Analytics을 사용하여 데이터를 처리하고 Amazon EFS (Elastic 파일 시스템) 를 사용하여 데이터를 저장합니다. #\rAnswer\r...\rAnswer: B\r#\rQ389\r#\r회사의 웹 사이트는 사용자에게 다운로드 가능한 내역 성과 보고서를 제공합니다.이 웹 사이트는 전 세계적으로 회사의 웹 사이트 요구를 충족하기 위해 확장 할 수있는 솔루션이 필요합니다.이 솔루션은 비용 효과적이어야한다, 제한?프로비저닝을 사용하고 가능한 가장 빠른 응답 시간을 제공합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 조합을 권장해야합니까?\nA. Amazon CloudFront 및 Amazon S3 B. AWS Lambda 및 Amazon 디나모 C. Amazon EC2 자동 크기 조정을 지원하는 애플리케이션 로드 밸런서 D. 내부 애플리케이션 로드 밸런싱을 사용하는 Amazon Route 53 #\rAnswer\r...\rAnswer: A\r#\rQ390\r#\r회사는 AWS에 새로 구축된 애플리케이션을 기본 VPC에 배포할 계획입니다. 애플리케이션은 웹 계층과 데이터베이스 계층으로 구성됩니다.웹 서버는 퍼블릭 서브넷에 생성되었으며 MySQL 데이터베이스는 사설 서브넷에 생성되었습니다.모든 서브넷은 기본 네트워크 ACL 설정으로 생성되며, VPC의 기본 보안 그룹은 새 사용자 지정 보안 그룹으로 대체됩니다. 주요 요구 사항은 다음과 같습니다.\n웹 서버는 SSL 연결을 사용하는 사용자만 액세스할 수 있어야 합니다. 데이터베이스는 퍼블릭 서브넷에서만 생성된 웹 계층에서 액세스할 수 있어야 합니다. IP 범위 182.20.0.0/16 서브넷을 주고받는 모든 트래픽은 차단되어야 합니다.이러한 요구 사항을 충족하는 단계 조합은 무엇입니까?(두 개를 선택합니다.) A. 어디서나 송수신하는 MySQL 포트 3306 트래픽에 대한 인바운드 및 아웃바운드 규칙을 사용하여 데이터베이스 서버 보안 그룹 생성 (0 0.0.0/0) B. MySQL 포트 3306에 대한 인바운드 규칙을 사용하여 데이터베이스 서버 보안 그룹을 생성하고 소스를 웹 서버 보안 그룹으로 지정합니다. C. 어디서든 HTTPS 포트 443의 트래픽에 대한 인바운드 허용 규칙 (0.0.0.0/0) 과 IP 범위 182.20.0.0/16에 대한 인바운드 거부 규칙을 사용하여 웹 서버 보안 그룹을 만듭니다. D. 어디서든 HTTPS 포트 443 트래픽에 대한 인바운드 규칙을 사용하여 웹 서버 보안 그룹 생성 (0.0.0.0/0) IP 범위 182 20.00/16에 대한 네트워크 ACL 인바운드 및 아웃바운드 거부 규칙 만들기 E. 어디서든 (0.0.0.0/0) 송수신하는 HTTPS 포트 443의 트래픽에 대한 인바운드 및 아웃바운드 규칙이 포함된 웹 서버 보안 그룹을 생성합니다.IP 범위 182.20.0.0/16에 대한 네트워크 ACL 인바운드 거부 규칙을 만듭니다. #\rAnswer\r...\rAnswer: B D\r#\rQ391\r#\r회사의 웹 사이트는 ALB (애플리케이션 로드 밸런서) 뒤에 있는 Amazon EC2 인스턴스에서 실행됩니다. 웹 사이트에는 동적 콘텐츠와 정적 콘텐츠가 혼합되어 있습니다. 전 세계 사용자들이 웹 사이트의 속도가 느린다고 보고하고 있습니다.\nA. Amazon CloudFront 배포를 생성하고 ALB를 오리진으로 구성한 다음 CloudFront 배포를 가리키도록 Amazon Route 53 레코드를 업데이트합니다. B. ALB에 대한 지연 시간 기반 Amazon Route 53 레코드를 생성한 다음 인스턴스 크기가 더 큰 새 EC2 인스턴스를 시작하고 ALB에 인스턴스를 등록합니다. C. 네브 시작사용자와 가까운 여러 지역에서 동일한 웹 애플리케이션을 호스팅하는 EC2 인스턴스입니다.그런 다음 교차 리전 VPC 피어링으로 동일한 ALB로 인스턴스를 등록합니다. D. 사용자와 가장 가까운 지역의 Amazon S3 버킷에 웹 사이트를 호스팅하고 ALB 및 EC2 인스턴스를 삭제한 다음 Amazon Route 53 레코드를 업데이트하여 S3 버킷을 가리키도록 #\rAnswer\r...\rAnswer: A\r#\rQ392\r#\r회사는 AWS에서 온라인 마켓플레이스 웹 애플리케이션을 운영하고 있습니다.이 응용 프로그램은 피크 시간 동안 수십만 명의 사용자에게 서비스를 제공합니다.이 회사는 수백만 건의 금융 거래에 대한 세부 정보를 다른 여러 내부 애플리케이션과 공유할 수 있는 확장 가능한 실시간에 가까운 솔루션이 필요합니다.또한 트랜잭션은 짧은 대기 시간 검색을 위해 문서 데이터베이스에 저장되기 전에 중요한 데이터를 제거하기 위해 처리해야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 권장해야합니까?\nA. 트랜잭션 데이터를 Amazon DynamoDB에 저장합니다.DynamoDB에서 쓰기 시 모든 트랜잭션에서 중요한 데이터를 제거하도록 규칙을 설정합니다.DynamoDB 스트림을 사용하여 트랜잭션 데이터를 다른 애플리케이션과 공유합니다. B. 트랜잭션 데이터를 Amazon Kinesis Data Firehose로 스트리밍하여 Amazon DynamoDB 및 Amazon S3에 데이터를 저장합니다.AWS Lambda와 Kinesis Data Firehose를 통합하여 중요한 데이터를 제거합니다. 다른 애플리케이션은 Amazon S3에 저장된 데이터를 사용할 수 있습니다. C. 트랜잭션 데이터를 Amazon Kinesis Data Streams으로 스트리밍합니다.AWS Lambda 통합을 사용하여 모든 트랜잭션에서 중요한 데이터를 제거한 다음 트랜잭션 데이터를 Amazon DynamoDB에 저장합니다.다른 애플리케이션은 Kinesis Data Streams에서 트랜잭션 데이터를 사용할 수 있습니다. D. 배치된 트랜잭션 데이터를 Amazon S3에 파일로 저장합니다.Amazon S3에서 파일을 업데이트하기 전에 AWS Lambda를 사용하여 모든 파일을 처리하고 중요한 데이터를 제거합니다.그런 다음 Lambda 함수는 데이터를 Amazon DynamoDB에 저장합니다.다른 애플리케이션은 Amazon S3에 저장된 트랜잭션 파일을 사용할 수 있습니다. #\rAnswer\r...\rAnswer: C\r#\rQ393\r#\r회사는 us-west-2 리전 애플리케이션 tog에 배포된 애플리케이션이 있는 여러 AWS 계정을 보유하고 있으며 각 계정의 Amazon S3 버킷에 저장됩니다.이 회사는 단일 S3 버킷을 사용하는 중앙 집중식 로그 분석가 솔루션을 구축하려고 합니다. 로그는 US-West-2T를 남기지 않아야 하며 회사는 운영 오버헤드를 최소화하고자 합니다. 이러한 요구 사항을 충족하고 가장 비용 효율적인 솔루션은 무엇입니까?\nA. 애플리케이션 S3 버킷 중 하나에서 중앙 집중식 S3 버킷으로 객체를 복사하는 S3 수명 주기 정책을 생성합니다. B. S3 동일 리전 복제를 사용하여 S3 버킷에서 us- west-2의 다른 S3 버킷으로 togs 복제 로그 분석에 이 S3 버킷을 사용합니다. C. 매일 putObject API 작업을 사용하여 버킷의 전체 내용을 us-west-2의 다른 S3 버킷으로 복사하는 스크립트를 작성합니다. 로그 분석에 이 S3 버킷을 사용합니다. D. 이 계정에 로그가 S3 버킷으로 전송될 때마다 트리거되는 AWS Lambda 함수 작성 (s3 ObjectCreate- D. * 이벤트) 로그를 us-west-2의 다른 S3 버킷에 복사합니다. 이 S3 버킷을 로그 분석에 사용합니다. #\rAnswer\r...\rAnswer: A\r#\rQ394\r#\r회사는 온프레미스 환경과 AWS 간에 안전한 연결이 필요합니다.이 연결은 높은 대역폭이 필요하지 않으며 소량의 트래픽을 처리합니다.연결을 신속하게 설정해야합니다. 이러한 유형의 연결을 설정하는 가장 비용 효율적인 방법은 무엇입니까?\nA. 클라이언트 VPN 구현 B. AWS Direct Connect 구현 C. Amazon EC2 상에 접속 호스트를 구현합니다. D. AWS 사이트 간 VPN 연결을 구현합니다. #\rAnswer\r...\rAnswer: D\r#\rQ395\r#\r최근 전 세계적으로 확장 된 회사는 해당 지리적 위치의 사용자가 응용 프로그램에 액세스 할 수 있도록하고자합니다.애플리케이션이 Auto Scaling 그룹의 애플리케이션 로드 밸런서 뒤에 Amazon EC2 인스턴스에 배포됩니다.이 회사는 한 지역의 리소스에서 다른 지역으로의 능력 시프트 트래픽을 필요로합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. Amazon Route 53 지연 시간 라우팅 정책 구성 B. Amazon Route 53 지리적 위치 라우팅 정책 구성 C. Amazon Route 53 지리적 근접 라우팅 정책을 구성합니다. D. Amazon Route 53 다중 값 응답 라우팅 정책 구성 #\rAnswer\r...\rAnswer: C\r#\rQ396\r#\r회사는 스토리지 용량이 부족한 온프레미스 데이터 센터를 보유하고 있습니다.이 회사는 대역폭 비용을 최소화하면서 스토리지 인프라를 AWS로 마이그레이션하고자 합니다. 이 솔루션은 추가 비용 없이 데이터를 즉시 검색할 수 있어야 합니다. 이러한 요구 사항을 어떻게 충족시킬 수 있습니까?\nA. Amazon S3 Glacier 저장소를 배포하고 빠른 검색을 활성화합니다.워크로드에 대해 프로비저닝된 검색 용량 사용 B. 캐시된 볼륨을 사용하여 AWS 스토리지 게이트웨이를 배포합니다.스토리지 게이트웨이를 사용하여 Amazon S3에 데이터를 저장하고 자주 액세스하는 데이터 하위 세트의 복사본을 로컬에 유지합니다. C. 저장된 볼륨을 사용하여 AWS 스토리지 게이트웨이를 배포하여 데이터를 로컬에 저장합니다.스토리지 게이트웨이를 사용하여 데이터의 특정 시점 스냅샷을 Amazon S3에 비동기적으로 백업 D. AWS Direct Connect를 배포하여 온프레미스 데이터 센터에 연결합니다.데이터를 로컬에 저장하도록 AWS 스토리지 게이트웨이를 구성합니다.스토리지 게이트웨이를 사용하여 데이터의 포트트트 타임 스냅샷을 Amazon S3에 비동기적으로 백업합니다. #\rAnswer\r...\rAnswer: B\r#\rQ397\r#\r솔루션 설계자가 새로운 정적 웹 사이트의 배포를 계획하고 있습니다. 이 솔루션은 비용을 최소화하고 99% 이상의 가용성을 제공해야 합니다.이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 버전 관리가 비활성화된 AWS 리전의 Amazon S3 버킷에 애플리케이션을 배포합니다. B. 두 개의 AWS 리전 및 두 개의 가용 영역에서 실행되는 Amazon EC2 인스턴스에 애플리케이션을 배포합니다. C. 버전 관리 및 교차 리전 복제가 활성화된 Amazon S3 버킷에 애플리케이션을 배포합니다. D. 하나의 AWS 리전과 하나의 가용 영역에서 실행되는 Amazon EC2 인스턴스에 애플리케이션을 배포합니다. #\rAnswer\r...\rAnswer: A\r#\rQ398\r#\r솔루션 설계자는 모든 신규 사용자가 IAM 사용자 암호에 대해 특정 복잡성 요구 사항과 필수 교체 기간을 갖기를 원합니다. 이를 위해 솔루션 설계자는 어떻게 해야 합니까?\nA. 전체 AWS 계정에 대한 전체 암호 정책 설정 B. AWS 계정의 각 IAM 사용자에 대한 암호 정책을 설정합니다. C. 타사 공급업체 소프트웨어를 사용하여 암호 요구 사항 설정 D. Create_NewUser 이벤트에 Amazon CloudWatch 규칙을 연결하여 적절한 요구 사항에 따라 암호를 설정합니다. #\rAnswer\r...\rAnswer: B\r#\rQ399\r#\r솔루션 설계자가 새로운 VPC 설계를 만들고 있습니다.로드 밸런서용 퍼블릭 서브넷 2개, 웹 서버용 프라이빗 서브넷 2개, MySQL용 프라이빗 서브넷 2개 등이 있습니다.웹은 HTTPS 만 사용합니다.솔루션 설계자는 이미 포트 443을 0.0 0.0/0에서 허용하는 로드 밸런서에 대한 보안 그룹을 만들었습니다. 회사 정책에 따라 각 리소스의 작업을 수행하는 데 필요한 최소 액세스 권한이 있어야 합니다. 솔루션 설계자가 이러한 요구 사항을 충족하기 위해 어떤 추가 구성 전략을 사용해야 합니까?\nA. 웹 서버보다 멀리 떨어진 보안 그룹을 만들고 포트 443을 0.0.0.070에서 허용합니다.MySQL 역할의 도움을 허용 포트 3306 웹 서버 보안 그룹에서 보안 그룹을 만듭니다. B. 웹 서버에 대한 네트워크 ACL을 생성하고 포트 443을 0.0.0.0/0에서 허용합니다.MySQL 서버용 네트워크 ACL을 생성하고 웹 서버 보안 그룹에서 포트 3306을 허용합니다. C. 웹 서버에 대한 보안 그룹을 생성하고 로드 밸런서에서 포트 443을 허용합니다.MySQL 서버에 대한 보안 그룹을 만들고 웹 하수구 보안 그룹에서 포트 3306을 허용합니다. D. 웹 서버에 대한 네트워크 ACL을 생성하고 웹 밸런서에서 포트 443을 허용합니다.MySQL 서버용 네트워크 ACL을 생성하고 웹 서버 보안 그룹에서 포트 3306을 허용합니다. #\rAnswer\r...\rAnswer: C\r#\rQ400\r#\r회사는 Amazon S3 버킷에 저장된 날씨 센서 데이터를 처리하기 위해 AWS에서 애플리케이션을 실행하고 있습니다.3가지 배치 작업이 매시간 실행되어 S3 버킷의 데이터를 다양한 용도로 처리합니다. 회사는 이벤트 기반 접근 방식을 사용하여 세 개의 애플리케이션을 병렬로 실행하여 전체 처리 시간을 줄이려고 합니다. 솔루션 설계자가 이러한 요구 사항을 충족하려면 어떻게 해야 합니까?\nA. Amazon SQS (단순 대기열 서비스) FIFO 대기열에 대한 새 객체에 대한 S3 이벤트 알림 활성화 처리를 위해 모든 애플리케이션을 대기열로 구독 B. Amazon SQS (단순 대기열 서비스) 표준 대기열에 새 객체에 대한 S3 이벤트 알림 활성화 모든 애플리케이션에 대해 추가 SQS 대기열을 생성하고 모든 애플리케이션을 초기 대기열에 등록하여 처리를 위해 C. 새 객체에 대해 S3 이벤트 알림을 활성화하여 Amazon SQS (단순 대기열 서비스) FIFO 대기열 분리 각 애플리케이션에 대한 추가 SQS 대기열 생성 및 처리를 위해 각 대기열을 초기 주제에 구독 D. Amazon SNS (단순 알림 서비스) 주제에 대한 새 객체에 대한 S3 이벤트 알림 활성화 각 애플리케이션에 대한 Amazon SQS (단순 대기열 서비스) 대기열 생성 및 처리를 위해 각 대기열에 각 대기열을 구독합니다. #\rAnswer\r...\rAnswer: C\r#\rQ401\r#\r회사는 데이터를 두 부분으로 처리하는 레거시 애플리케이션을 보유하고 있습니다.프로세스의 두 번째 부분은 첫 번째 단계보다 오래 걸리므로 회사는 애플리케이션을 독립적으로 확장할 수 있는 Amazon ECS에서 실행되는 두 개의 마이크로서비스로 다시 작성하기로 결정했습니다. 솔루션 설계자는 마이크로서비스를 어떻게 통합해야 합니까?\nA. 마이크로 서비스 1에 코드를 구현하여 Amazon S3 버킷으로 데이터를 전송합니다.S3 이벤트 알림을 사용하여 마이크로 서비스 2 호출 B. 마이크로 서비스 1에 코드를 구현하여 Amazon SNS 주제에 데이터를 게시합니다.코드 구현 마이크로 서비스 2에서 이 주제를 구독하십시오. C. 마이크로 서비스 1에 코드를 구현하여 Amazon Kinesis Data Firehose에 데이터를 전송합니다.마이크로서비스 2의 코드를 구현하여 Kinesis Data Firehose에서 읽을 수 있습니다. D. 마이크로 서비스 1에 코드를 구현하여 Amazon SQS 대기열로 데이터를 전송합니다.마이크로서비스 2의 코드를 구현하여 큐에서 메시지를 처리합니다. #\rAnswer\r...\rAnswer: D\r#\rQ402\r#\r한 회사는 Auto Scaling 그룹에 속해 있으며 여러 Linux 인스턴스가 실행 중인 빌드 서버를 보유하고 있습니다. 빌드 서버에는 작업 및 구성을 위해 일관되고 마운트 가능한 공유 NFS 스토리지가 필요합니다.솔루션 설계자가 권장해야 하는 스토리지 옵션은 무엇입니까?\nA. Amazon S3 B. Amazon FSX C. Amazon Elastic Block Store (Amazon EBS) D. Amazon Elastic File System (Amazon EFS) #\rAnswer\r...\rAnswer: D\r#\rQ403\r#\r회사가 회사 기밀이라는 Amazon S3 버킷에 액세스할 수 없는 새 클라우드 엔지니어를 고용했습니다. 클라우드 엔지니어는 AdminTools라는 S3 버킷에서 읽고 쓸 수 있어야 합니다. 이러한 요구 사항을 충족하는 IAM 정책은 무엇입니까?\nA. 옵션 A B. 옵션 B C. 옵션 C D. 옵션 D #\rAnswer\r...\rAnswer: A\r#\rQ404\r#\r솔루션 설계자는 고성능 기계 학습을 포함하는 회사 애플리케이션을 위한 관리형 스토리지 솔루션을 설계해야 합니다.이 애플리케이션은 AWS Fargate에서 실행됩니다. 연결된 스토리지는 파일에 동시 액세스해야 하며 고성능을 제공해야 합니다. 솔루션 설계자가 권장해야 하는 스토리지 옵션은 무엇입니까?\nA. 애플리케이션용 Amazon S3 버킷을 생성하고 Fargate가 Amazon S3와 통신할 IAM 역할을 설정합니다. B. Lustre 파일 공유용 Amazon FSX를 생성하고 Fargate가 Lustre용 FSX와 통신할 수 있도록 IAM 역할을 설정합니다. C. Amazon 탄력적 파일 시스템 (Amazon EFS\u0026gt; 파일 공유 및 Fargate가 Amazon EFS와 통신할 수 있도록 IAM 역할을 설정합니다. D. 애플리케이션용 Amazon EBS (엘라스틱 블록 스토어) 볼륨을 생성하고 Fargate가 Amazon EBS와 통신할 수 있도록 IAM 역할을 설정합니다. #\rAnswer\r...\rAnswer: B\r#\rQ405\r#\r회사 온프레미스에서 웹 사이트를 호스팅하고 AWS 클라우드로 마이그레이션하려고 합니다. 웹 사이트는 단일 호스트 이름을 인터넷에 노출하지만 URL 경로를 기반으로 기능을 다른 온프레미스 서버 그룹으로 라우팅합니다. 서버 그룹은지원 기능 회사에 온프레미스 네트워크에 AWS Direct Connect 연결이 구성되어 있습니다. 올바른 서버 그룹으로 트래픽을 전송하기 위해 경로 기반 라우팅을 제공하려면 솔루션 설계자가 어떻게 해야 합니까?\nA. 모든 트래픽을 인터넷 게이트웨이로 라우팅 인터넷 게이트웨이에서 패턴 일치 규칙을 구성하여 트래픽을 해당 경로를 지원하는 서버 그룹으로 라우팅합니다. B. 모든 트래픽을 각 서버 그룹에 대한 대상 그룹이 있는 NLB (네트워크 로드 밸런서) 로 라우팅 NLB에서 패턴 일치 규칙을 사용하여 트래픽을 올바른 대상 그룹으로 라우팅합니다. C. 모든 트래픽을 ALB (애플리케이션 로드 밸런서) 로 라우팅 ALB에서 경로 기반 라우팅을 구성하여 트래픽을 해당 경로를 지원하는 서버의 올바른 대상 그룹으로 라우팅합니다. D. Amazon Route 53을 DNS 서버로 사용 Route 53 경로 기반 별칭 레코드를 구성하여 해당 경로를 지원하는 서버 그룹에 대한 올바른 탄력적 로드 밸런서로 트래픽을 라우팅합니다. #\rAnswer\r...\rAnswer: B\r#\rQ406\r#\r솔루션 설계자는 Windows IIS (인터넷 정보 서비스) 웹 애플리케이션을 AWS로 마이그레이션해야 합니다. 애플리케이션은 현재 사용자의 온프레미스 NAS (네트워크 연결 스토리지) 에서 호스팅되는 파일 공유를 사용합니다.솔루션 설계자는 스토리지 솔루션에 연결된 여러 가용 영역의 Amazon EC2 인스턴스로 IIS 웹 서버를 마이그레이션하고 인스턴스에 연결된 Elastic Load Balancer를 구성할 것을 제안했습니다.가장 복원력이 뛰어나고 내구성이 뛰어난 온-프레미스 파일 공유를 대체하는 것은 무엇입니까?\nA. 파일 공유를 Amazon RDS로 마이그레이션합니다. B. 파일 공유를 AWS 스토리지 게이트웨이로 마이그레이션합니다. C. 파일 공유를 Windows 파일 서버용 Amazon FSX로 마이그레이션합니다. D. Amazon EFS (탄력적 파일 시스템) 로 파일 공유 마이그레이션 #\rAnswer\r...\rAnswer: C\r#\rQ407\r#\r한 회사가 Amazon CIOUdFront에 대한 오리진인 Amazon S3 버킷에 정적 웹 사이트를 호스팅하고 있습니다. 이 회사는 미국에 사용자가 있습니다.캐나다, 유럽, 비용 절감을 원하고 있습니다.솔루션 설계자는 무엇을 추천해야합니까?\nA. CloudFront 캐싱 시간을 기본값에서 더 긴 기간으로 조정합니다 (TTL). B. Lambda @Edge 를 사용하여 CloudFront 이벤트를 구현하여 웹 사이트의 데이터 처리를 실행합니다. C. 제공되는 국가의 위치만 포함하도록 CloudFront 요금 클래스를 수정합니다. D. CloudFront SSL (보안 소켓 계층) 인증서를 구현하여 서비스를 제공하는 국가의 위치에 보안을 더 가깝게 밀어넣습니다. #\rAnswer\r...\rAnswer: C\r#\rQ408\r#\r회사는 사용자에게 글로벌 속보, 로컬 알림 및 날씨 업데이트를 제공하는 웹 기반 포털을 운영하고 있습니다. 포털은 정적 콘텐츠와 동적 콘텐츠를 혼합하여 각 사용자에게 개인화된 보기를 제공합니다. 콘텐츠는 Amazon EC2 인스턴스에서 실행되는 API 서버를 통해 HTTPS를 통해 제공됩니다.ALB (애플리케이션 로드 밸런서) 를 지원합니다.이 회사는 포털이 가능한 한 빨리 전 세계 사용자에게 이 콘텐츠를 제공하기를 원합니다. 솔루션 설계자는 모든 사용자에게 최소한의 지연 시간을 보장하도록 애플리케이션을 설계하는 방법은 무엇입니까?\nA. 단일 AWS 지역에 애플리케이션 스택 배포 Amazon CloudFront를 사용하여 ALB를 오리진으로 지정하여 모든 정적 및 동적 콘텐츠를 제공할 수 있습니다. B. 두 AWS 리전에 애플리케이션 스택 배포 Amazon Route 53 지연 시간 라우팅 정책을 사용하여 가장 가까운 리전에 있는 ALB의 모든 콘텐츠를 제공합니다. C. 단일 AWS 지역에 애플리케이션 스택 배포 Amazon CloudFront를 사용하여 정적 콘텐츠 제공 ALB에서 직접 동적 콘텐츠를 제공합니다. D. 두 AWS 리전에서 애플리케이션 스택 배포 Amazon Route 53 지리적 위치 라우팅 정책을 사용하여 가장 가까운 리전에 있는 ALB의 모든 콘텐츠를 제공합니다. #\rAnswer\r...\rAnswer: B\r#\rQ409\r#\r회사는 300개 이상의 글로벌 웹 사이트 및 애플리케이션을 호스팅합니다.이 회사는 매일 30TB 이상의 클릭스트림 데이터를 분석할 수 있는 플랫폼을 필요로 합니다.솔루션 설계자는 클릭스트림 데이터를 전송하고 처리하기 위해 무엇을해야합니까?\nA. Amazon S3 버킷에 데이터를 보관하고 분석을 생성하기 위해 데이터와 함께 Amazon EMR 클러스터를 실행하도록 AWS 데이터 파이프라인을 설계합니다. B. Amazon EC2 인스턴스의 Auto Scaling 그룹을 생성하여 데이터를 처리하고 Amazon S3 데이터 레이크에 전송하여 Amazon Redshift가 분석에 사용할 수 있도록 합니다. C. 데이터를 Amazon CloudFront에 캐시합니다.Amazon S3 버킷에 데이터를 저장합니다.객체가 S3 버킷에 추가되면 AWS Lambda 함수를 실행하여 분석을 위해 데이터를 처리합니다. D. Amazon Kinesis 데이터 스트림에서 데이터를 수집합니다.Amazon Kinesis 데이터 파이어호스를 사용하여 Amazon S3 데이터 레이크에 데이터를 전송합니다.분석을 위해 Amazon Redshift에 데이터를 로드합니다. #\rAnswer\r...\rAnswer: D\r#\rQ410\r#\r회사의 웹 애플리케이션은 여러 Linux Amazon EC2 인스턴스를 사용하고 Amazon EBS 볼륨에 데이터를 저장하고 있습니다.이 회사는 장애 발생 시 애플리케이션의 복원력을 높이고 원 자성, 일관성, 격리 및 내구성 (ACID) 을 준수하는 스토리지를 제공하는 솔루션을 찾고 있습니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. 각 가용 영역의 EC2 인스턴스에서 애플리케이션을 시작합니다.EBS 볼륨을 각 EC2 인스턴스에 연결합니다. B. 여러 가용 영역에서 Auto Scaling 그룹을 사용하여 애플리케이션 로드 밸런서 생성 각 EC2 인스턴스에 인스턴스 스토어 마운트 C. 여러 가용 영역에서 Auto Scaling 그룹을 사용하여 애플리케이션 로드 밸런서를 생성합니다.Amazon EFS에 데이터를 저장하고 각 인스턴스에 대상을 마운트합니다. D. 여러 가용 영역에서 Auto Scaling 그룹을 사용하여 애플리케이션 로드 밸런서 생성 Amazon S3 원 영역 드문 액세스 (S3 One 영역-IA) 를 사용하여 데이터 저장 #\rAnswer\r...\rAnswer: C\r#\rQ411\r#\rAmazon Elastic 컨테이너 서비스 (Amazon ECS) 를 사용하여 애플리케이션을 호스팅하고 있으며 고가용성을 보장하고자 합니다.회사는 한 가용 영역의 노드에 액세스할 수 없는 경우에도 애플리케이션에 대한 업데이트를 배포할 수 있기를 원합니다.애플리케이션의 예상 요청 볼륨은 초당 100개의 요청이며 각 컨테이너 작업은 초당 60개 이상의 요청을 처리할 수 있습니다. 회사는 최소 정상 백분율 매개 변수를 50% 로 설정하고 최대 백분율은 100% 로 설정된 롤링 업데이트 배포 유형으로 Amazon ECS를 설정합니다. 이러한 요구 사항을 충족하는 작업 및 가용 영역 구성은 무엇입니까?\nA. 각 가용 영역에 하나의 작업으로 애플리케이션을 두 가용 영역에 배포합니다. B. 두 가용 영역에 애플리케이션을 배포하고 각 가용 영역에서 두 개의 태스크를 수행합니다. C. 세 가용 영역에 애플리케이션을 배포하고 각 가용 영역에 하나의 태스크를 사용합니다. D. 각 가용 영역에서 두 개의 작업을 사용하여 세 개의 가용 영역에 애플리케이션을 배포합니다. #\rAnswer\r...\rAnswer: D\r#\rQ412\r#\r회사는 파일 공유에 저장된 데이터에 액세스해야 하는 여러 비즈니스 시스템을 보유하고 있습니다. 비즈니스 시스템은 SMB (서버 메시지 블록) 프로토콜을 사용하여 파일 공유에 액세스합니다.파일 공유 솔루션은 회사의 레거시 온프레미스 환경과 AWS에서 모두 액세스할 수 있어야 합니다. 어떤 서비스가 비즈니스 요구 사항을 변경합니까?(두 개를 선택합니다.)\nA. 아마존 EBS B. 아마존 EFS C. 윈도우용 아마존 FSX D. 아마존 S3 E. AWS 스토리지 게이트웨이 파일 게이트웨이 #\rAnswer\r...\rAnswer: C E\r#\rQ413\r#\r솔루션 설계자는 AWS 클라우드에 배포되는 새 애플리케이션의 아키텍처를 설계하고 있습니다. 애플리케이션은 Amazon EC2 온 디맨드 인스턴스에서 실행되며 여러 가용 영역에 걸쳐 자동으로 확장됩니다. EC2 인스턴스는 하루 종일 자주 확장 및 축소됩니다.ALB (애플리케이션 로드 밸런서) 가 로드 분산을 처리합니다. 아키텍처는 분산 세션 데이터 관리를 지원해야 합니다. 회사는 필요한 경우 코드를 변경할 의향이 있습니다. 아키텍처가 분산 세션 데이터 관리를 지원하는지 확인하기 위해 솔루션 설계자는 무엇을해야합니까?\nA. Amazon ElastiCache를 사용하여 세션 데이터를 관리하고 저장합니다. B. ALB의 세션 선호도 (고정 세션) 를 사용하여 세션 데이터를 관리합니다. C. AWS 시스템 관리자의 세션 관리자를 사용하여 세션 관리 D. AWS 보안 토큰 서비스 (AWS STS) 에서 GetSessionToken API 작업을 사용하여 세션을 관리합니다. #\rAnswer\r...\rAnswer: A\r#\rQ414\r#\r회사는 여러 온프레미스 애플리케이션에서 사용하는 온프레미스 데이터 센터에 저장된 데이터를 보유하고 있습니다.이 회사는 기존 애플리케이션 환경을 유지하고 데이터 분석 및 향후 시각화를 위해 AWS 서비스를 사용할 수 있기를 원합니다.솔루션 설계자가 권장해야 하는 스토리지 서비스는 무엇입니까?\nA. 아마존 레드시프트 B. 파일용 AWS 스토리지 게이트웨이 C. 아마존 엘라스틱 블록 스토어 (아마존 EBS) D. 아마존 탄력적 파일 시스템 (아마존 EFS) #\rAnswer\r...\rAnswer: B\r#\rQ415\r#\r회사는 AWS Lambda에 마이크로서비스 중 하나를 구현하여 아마존 DynamoDB 테이블 이름이 도서입니다.솔루션 설계자는 Lambda 함수의 IAM 역할에 연결될 IAM 정책을 설계하여 Books 테이블에서 항목을 배치, 업데이트 및 삭제할 수 있는 액세스 권한을 부여합니다. IAM 정책은 기능이 Books 테이블이나 다른 테이블에서 다른 작업을 수행하지 못하도록 해야 합니다. 이러한 요구 사항을 충족하고 최소 권한 액세스를 제공하는 IAM 정책은 무엇입니까?\nA. 옵션 A B. 옵션 B C. 옵션 C D. 옵션 D #\rAnswer\r...\rAnswer: A\r#\rQ416\r#\r회사는 웹 응용 프로그램으로 새로운 비디오 게임을 개발했습니다.애플리케이션은 MySQL용 Amazon RDS를 사용하는 VPC의 3 계층 아키텍처에 있습니다. 데이터베이스 계층에서 여러 플레이어가 동시에 온라인으로 경쟁합니다.게임 개발자는 상위 10 스코어 보드를 거의 실시간으로 표시하고 현재 점수를 유지하면서 게임을 중지 및 복원 할 수있는 기능을 제공하려고합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. 웹 애플리케이션의 점수를 캐시하도록 Memcached용 Amazon ElastiCache 클러스터를 설정합니다. B. Redis 용 Amazon ElastiCache 클러스터를 설정하여 표시할 웹 애플리케이션의 점수를 계산하고 캐시합니다. C. Amazon CloudFront 배포를 웹 애플리케이션 앞에 배치하여 스코어 보드를 애플리케이션 섹션에 캐시합니다. D. MySQL용 Amazon RDS에 읽기 전용 복제본을 생성하여 스코어보드를 계산하고 읽기 트래픽을 웹 애플리케이션에 제공하는 쿼리를 실행합니다. #\rAnswer\r...\rAnswer: D\r#\rQ417\r#\r회사는 온프레미스 데이터베이스 서버를 위한 내구성 있는 백업 스토리지 솔루션을 필요로 하며, 온프레미스 애플리케이션이 이러한 백업에 대한 액세스를 유지하여 신속한 복구를 가능하게 합니다.이 회사는 이러한 백업의 대상으로 AWS 스토리지 서비스를 사용할 것입니다. 솔루션 설계자는 운영 오버헤드가 최소화된 솔루션을 설계하고 있으며 솔루션 설계자는 어떤 솔루션을 구현해야 합니까?\nA. 온프레미스로 AWS 스토리지 게이트웨이 파일 게이트웨이를 배포하고 이를 Amazon S3 버킷과 연결합니다. B. 데이터베이스를 AWS 스토리지 게이트웨이 볼륨 게이트웨이에 백업하고 Amazon S3 API를 사용하여 액세스합니다. C. 데이터베이스 백업 파일을 Amazon EC2 인스턴스에 연결된 Amazon EBS (Elastic Block Store) 볼륨으로 전송합니다. D. 데이터베이스를 AWS Snowball 디바이스에 직접 백업하고 수명 주기 규칙을 사용하여 데이터를 Amazon S3 Glacier 딥 아카이브로 이동합니다. #\rAnswer\r...\rAnswer: A\r#\rQ418\r#\r회사는 ELB 애플리케이션 로드 밸런서 뒤에 Amazon EC2 인스턴스에서 웹 사이트를 운영합니다.Amazon 루트 53은 DNS에 사용됩니다.회사는 기본 웹 사이트가 다운된 경우 사용자가 연결할 수 있는 전화 번호 및 전자 메일 주소를 포함한 메시지가 포함된 백업 웹 사이트를 설정하려고 합니다. 이 솔루션을 어떻게 배포해야 합니까?\nA. 백업 웹 사이트에 Amazon S3 웹 사이트 호스팅을 사용하고 Route 53 장애 조치 라우팅 정책을 사용하십시오. B. 백업 웹 사이트에 Amazon S3 웹 사이트 호스팅을 사용하고 Route 53 지연 시간 라우팅 정책을 사용합니다. C. 애플리케이션을 다른 AWS 지역에 배포하고 장애 조치 라우팅에 ELB 상태 확인을 사용합니다. D. 다른 AWS 지역에 애플리케이션을 배포하고 기본 웹 사이트에서 서버 측 리디렉션을 사용합니다. #\rAnswer\r...\rAnswer: A\r#\rQ419\r#\r회사 AWS 클라우드로 마이그레이션하고 있습니다.파일 서버는 마이그레이션할 첫 번째 워크로드입니다.사용자는 SMB (서버 메시지 블록) 프로토콜을 사용하여 파일 공유에 액세스할 수 있어야 합니다. 이러한 요구 사항을 충족하는 AWS 관리형 서비스는 무엇입니까?\nA. Amazon EBS B. Amazon EC2 C. Amazon FSX D. Amazon S3 #\rAnswer\r...\rAnswer: C\r#\rQ420\r#\r솔루션 설계자는 가용성이 높고 자동으로 확장되는 노드 jS 기반 웹 애플리케이션을 배포해야 합니다.마케팅 팀은 응용 프로그램 릴리스를 신속하게 롤백해야하며 운영 대시보드가 필요합니다.마케팅 팀은 Linux 서버에 대한 운영 체제 패치 배포를 관리하기를 원하지 않습니다. 이러한 요구 사항을 충족하는 AWS 서비스는 무엇입니까?\nA. Amazon EC2 B. Amazon API 게이트웨이 C. AWS Elastic Beanstalk D. Amazon EC2 #\rAnswer\r...\rAnswer: C\r#\rQ421\r#\r스타트업 회사는 us-east-1 리전에 기반을 둔 웹 애플리케이션을 보유하고 있으며, 여러 가용 영역에서 애플리케이션 로드 밸런서 뒤에서 실행되는 여러 Amazon EC2 인스턴스가 여러 가용 영역에 걸쳐 애플리케이션 로드 밸런서 뒤에서 실행되는 회사의 사용자 기반이 us-east-1 리전에서 성장함에 따라 지연 시간이 짧고 가용성이 높은 3개의 솔루션이 필요합니다. 이를 달성하기 위해 솔루션 설계자는 무엇을해야합니까?\nA. us-west-1에서 EC2 인스턴스를 프로비저닝합니다.애플리케이션 로드 밸런서를 네트워크 로드 밸런서로 전환하여 리전 간 로드 밸런싱을 수행합니다. B. us-west-1의 EC2 인스턴스 및 애플리케이션 로드 밸런서 프로비저닝 로드 밸런서가 요청 위치에 따라 트래픽을 배포하도록 합니다. C. us-west-1에 EC2 인스턴스를 프로비저닝하고 애플리케이션 로드 밸런서를 구성합니다.두 리전의 로드 밸런서 엔드포인트를 포함하는 엔드포인트 그룹을 사용하는 AWS Global Accelerator에서 Accelerator를 생성합니다. D. us-west-1 Amazon Route 53 구성에서 EC2 인스턴스를 프로비저닝하고 애플리케이션 로드 밸런서를 구성하십시오.Route 53에서 애플리케이션 로드 밸런서를 가리키는 별칭 레코드 생성 #\rAnswer\r...\rAnswer: C\r#\rQ422\r#\r회사는 인기 곡의 클립으로 만든 벨소리를 판매하고 있습니다.벨소리가 포함된 파일은 Amazon S3 Standard에 저장되며 크기가 123KB 이상입니다. 이 회사는 수백만 개의 파일을 보유하고 있지만 90일이 지난 벨소리의 경우 다운로드가 자주 발생하지 않습니다. 이 회사는 사용자가 가장 많이 액세스하는 파일을 쉽게 사용할 수 있도록 유지하면서 스토리지 비용을 절감해야 합니다.이러한 요구 사항을 가장 비용 효율적으로 충족하기 위해 회사는 어떤 조치를 취해야 합니까?\nA. 객체의 초기 스토리지 계층에 대해 S3 Standard-infrequent Access (S3 Standard-IA) 스토리지를 구성합니다. B. 파일을 S3 Intelliginet 계층화로 이동하고 90일 후에 객체를 저렴한 스토리지 계층으로 이동하도록 구성합니다. C. 객체를 관리하도록 S3 인벤토리를 구성하고 90일 후에 S3 Standard-infrequent Access (S3 표준-IA) 로 이동시킵니다. D. 90일 후에 객체를 S3 표준에서 S3 표준 Standard Infrequent Access (S3 표준-IA) 로 이동하는 S3 수명 주기 정책을 구현합니다. #\rAnswer\r...\rAnswer: A\r#\rQ423\r#\r개발자는 사용자가 이전 일일 보고서를 생성하는 스크립트가 있습니다.스크립트는 다음과 같이 일관되게 완료됩니다. 10 분.개발자는 비용 효율적인 방식으로 프로세스를 자동화해야합니다.개발자는 어떤 서비스 조합을 사용해야합니까?(두 개 선택)\nA. AWS Lambda B. AWS CloudTrail C. Amazon EC2 인스턴스의 Cron D. 사용자 데이터가 있는 Amazon EC2 온 디맨드 인스턴스 E. Amazon EventBridge (Amazon CloudWatch 이벤트) #\rAnswer\r...\rAnswer: A B\r#\rQ424\r#\r회사가 Amazon RDS DB 인스턴스에서 대부분의 메타데이터를 읽는 모바일 게임을 보유하고 있습니다. 게임의 인기가 증가함에 따라 개발자는 게임의 메타데이터 로드 시간과 관련된 속도 저하를 발견했습니다. 성능 메트릭은 단순히 데이터베이스를 확장해도 도움이되지 않는다는 것을 나타냅니다. 솔루션 설계자는스냅샷 복제 기능과 밀리초 미만의 응답 시간을 포함하는 모든 옵션을 살펴보십시오. 솔루션 설계자는 이러한 문제를 해결하기 위해 무엇을 권장해야합니까?\nA. Aurora 복제본을 사용하여 데이터베이스를 Amazon Aurora로 마이그레이션 B. 글로벌 테이블을 사용하여 데이터베이스를 Amazon DyramoDB로 마이그레이션합니다. C. 데이터베이스 앞에 Redis용 Amazon ElastiCache 레이어를 추가합니다. D. 데이터베이스 앞에 Memcached 계층용 Amazon ElastiCache를 추가합니다. #\rAnswer\r...\rAnswer: B\r#\rQ425\r#\r한 회사에서 NoSQL 데이터베이스 클러스터를 Amazon EC2로 마이그레이션하고 있습니다.데이터베이스 는 데이터를 자동으로 복제하여 최소한 세 개의 데이터 복사본을 유지합니다.서버의 I/O 처리량이 가장 높은 우선 순위입니다.솔루션 설계자가 마이그레이션을 위해 권장해야 하는 인스턴스 유형은 무엇입니까?\nA. 인스턴스 스토어가 있는 스토리지 최적화 인스턴스 B. Amazon EBS (Elastic Block Store) 볼륨이 있는 버스트 가능한 범용 인스턴스 C. Amazon EBS (Elastic Block Store) 최적화가 활성화된 메모리 최적화 인스턴스 D. Amazon EBS (Elastic Block Store) 최적화가 활성화된 컴퓨팅 최적화 인스턴스 #\rAnswer\r...\rAnswer: A\r#\rQ426\r#\r전자 상거래 회사의 솔루션 설계자가 애플리케이션 로그 데이터를 Amazon S3에 백업하려고 합니다. 솔루션 설계자는 로그에 얼마나 자주 액세스할지 또는 가장 많이 액세스할지 확신하지 못합니다. 회사는 적절한 S3 스토리지 클래스를 사용하여 가능한 한 낮은 비용을 유지하려고 합니다. 이러한 요구 사항을 충족하기 위해 어떤 S3 스토리지 클래스를 구현해야 합니까?\nA. S3 Glacier B. S3 Intelliginet 계층화 C. S3 표준 Standard Infrequent Access (S3 표준-IA) D. S3 One Zone Standard Infrequent Access (S3 One Zone-IA) #\rAnswer\r...\rAnswer: B\r#\rQ427\r#\r회사가 인터넷 연결 애플리케이션 로드 밸런서 (ALB) 뒤에 있는 VPC에 API를 배포했습니다. 클라이언트로 API를 사용하는 애플리케이션은 NAT 게이트웨이 뒤에 있는 프라이빗 서브넷의 두 번째 계정에 배포됩니다.클라이언트 응용 프로그램에 대한 요청이 증가하면 NAT 게이트웨이 비용이 예상보다 높습니다.솔루션 설계자가 ALB를 내부로 구성했습니다.아키텍처 변경 사항의 조합으로 NAT 게이트웨이 비용을 줄일 수 있습니까?(두 개 선택)\nA. 두 VPC 간에 VPC 피어링 연결을 구성합니다. 개인 주소를 사용하여 API에 액세스 B. 두 VPC 간에 AWS Direct Connect 연결을 구성합니다.개인 주소를 사용하여 API에 액세스합니다. C. API에 대한 ClassicLink 연결을 클라이언트 VPC에 구성합니다. ClassicLink 주소를 사용하여 API에 액세스합니다. D. API에 대한 PrivateLink 연결을 클라이언트 VPC에 구성합니다.개인 링크 주소를 사용하여 API에 액세스합니다. E. 두 계정 간의 AWS 리소스 액세스 관리자 연결 구성 프라이빗 주소를 사용하여 API에 액세스합니다. #\rAnswer\r...\rAnswer: D E\r#\rQ428\r#\r사용자가 매시간 3.600 대의 렌트카로부터 위치 업데이트를 수신하는 새로운 서비스를 설계하고 있습니다.차량이 Amazon S3 버킷에 위치를 업로드합니다. 각 위치에서 원래 임대 위치와의 거리를 확인해야 합니다. 어떤 서비스가 업데이트를 처리하고 자동으로 확장됩니까?\nA. Amazon EC2 및 Amazon Elastic Block Store (Amazon EBS) B. Amazon Kinesis Data Firehose 및 Amazon S3 C. Amazon 탄력적 컨테이너 서비스 (Amazon ECS) 및 Amazon RDS D. Amazon S3 이벤트 및 AWS Lambda #\rAnswer\r...\rAnswer: B\r#\rQ429\r#\r한 회사가 AWS에 배포된 기존 워크로드에 대해 잘 설계된 AWS 프레임워크 검토를 수행하고 있습니다.이 검토에서는 다른 AWS 서비스를 지원하기 위해 최근에 설치되었던 Microsoft Active Directory 도메인 컨트롤러와 동일한 Amazon EC2 인스턴스에서 실행되는 공개 웹 사이트를 확인했습니다.솔루션 설계자는 아키텍처의 보안을 향상시키고 IT 직원의 관리 요구를 최소화할 수 있는 새로운 설계를 추천해야 합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. AWS 디렉토리 서비스를 사용하여 관리형 Active Directory를 생성합니다.현재 EC2 인스턴스에서 액티브 디렉토리를 제거합니다. B. 동일한 서브넷에 다른 EC2 인스턴스를 생성하고 Active Directory를 다시 설치합니다.액티브 디렉토리를 제거합니다. C. AWS 디렉토리 서비스를 사용하여 액티브 디렉토리 커넥터를 생성합니다.현재 EC2 인스턴스에서 실행 중인 활성 도메인 컨트롤러에 프록시 Active Directory를 요청합니다. D. 현재 Active Directory 컨트롤러와 SAML (보안 어설 션 마크업 언어) 2.0 페더레이션으로 AWS SSO (단일 사인온) 를 활성화합니다.EC2 인스턴스의 보안 그룹을 수정하여 Active Directory에 대한 공용 액세스를 거부합니다. #\rAnswer\r...\rAnswer: A\r#\rQ430\r#\r회사는 마이크로 소프트 윈도우 공유 파일 저장소가 필요한 온-프레미스에서 실행되는 대규모 마이크로 소프트 셰어 배포가 있습니다.이 회사는 이 워크로드를 AWS 클라우드로 마이그레이션하려고 하며 다양한 스토리지 옵션을 고려하고 있습니다.스토리지 솔루션은 가용성이 높고 액세스 제어를 위해 Active Directory와 통합되어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. Amazon EFS 스토리지를 구성하고 인증을 위한 액티브 디렉토리 도메인을 설정합니다. B. 두 가용 영역의 AWS 스토리지 게이트웨이 파일 게이트웨이에 SMB 파일 공유를 생성합니다. C. Amazon S3 버킷을 생성하고 볼륨으로 마운트하도록 마이크로소프트 윈도우 서버를 구성합니다. D. AWS에서 Windows용 Amazon FSX 파일 서버 파일 시스템을 생성하고 인증을 위한 액티브 디렉토리 도메인을 설정합니다. #\rAnswer\r...\rAnswer: D\r#\rQ431\r#\r애플리케이션은 프라이빗 서브넷의 Amazon EC2 인스턴스에서 실행됩니다.애플리케이션이 Amazon DynamoDB 테이블에 액세스해야 합니다.트래픽이 AWS 네트워크를 벗어나지 않도록 하면서 테이블에 액세스하는 가장 안전한 방법은 무엇입니까?\nA. DynamoDB에 VPC 엔드포인트를 사용합니다. B. 퍼블릭 서브넷에서 NAT 게이트웨이를 사용합니다. C. 프라이빗 서브넷에서 NAT 인스턴스를 사용합니다. D. VPC에 연결된 인터넷 게이트웨이를 사용합니다. #\rAnswer\r...\rAnswer: A\r#\rQ432\r#\r회사에서 주간 분석 보고서를 위한 로컬 저장소로 Amazon S3를 사용하고 있습니다. 전사적 요구 사항 중 하나는 암호화를 사용하여 미사용 데이터를 보호하는 것입니다.이 회사는 Amazon 53 서버 측 암호화 (SSE) 를 선택하여 GET 요청이 실행될 때 객체를 어떻게 해독할 수 있습니까?\nA. 객체의 암호를 해독하려면 Put 요청이 필요합니다. B. 사용자는 개인 키를 사용하여 객체의 암호를 해독해야 합니다. C. Amazon S3가 암호화 및 암호 해독을 자동으로 관리 D. Amazon S3는 객체의 암호를 해독하기 위한 서버 측 키를 제공합니다. #\rAnswer\r...\rAnswer: D\r#\rQ433\r#\r솔루션 설계자는 Amazon S3와 함께 Amazon CloudFront를 사용하여 정적 웹 사이트를 저장하는 솔루션을 설계해야 합니다.회사 보안 정책에 따라 AWS WAF에서 모든 웹 사이트 트래픽을 검사해야 합니다. 이러한 요구 사항을 갖춘 솔루션 설계자는 어떻게 해야 합니까?\nA. AWS WAF Amazon 리소스 이름 (ARN) 에서 오는 요청만 수락하도록 S3 버킷 정책을 구성합니다. B. S3 오리진에서 콘텐츠를 요청하기 전에 들어오는 모든 요청을 AWS WAF로 전달하도록 Amazon CloudFront를 구성합니다. C. Amazon CloudFront IP 주소가 Amazon S3에 액세스하도록 허용하는 보안 그룹을 구성합니다. AWS WAF를 CloudFront에만 연결합니다. D. 원본 액세스 ID (OAI) 를 사용하여 S3 버킷에 대한 액세스를 제한하도록 Amazon CloudFront 및 Amazon S3를 구성합니다.배포에서 AWS WAF를 활성화합니다. #\rAnswer\r...\rAnswer: B\r#\rQ434\r#\r회사가 여러 Amazon EC2 인스턴스에서 애플리케이션을 호스팅합니다. 애플리케이션은 Amazon SQS 대기열의 메시지를 Amazon RDS 테이블에 기록하고 대기열에서 메시지를 삭제합니다. 때때로 중복 레코드가 RDS 테이블에 발견됨 SQS 대기열에 중복 메시지가 포함되지 않음보관 된 솔루션은 메시지가 한 번만 처리되도록해야합니까?\nA. CreateQueue API 호출을 사용하여 새 큐를 만듭니다. B. AddPermissions API 호출을 사용하여 적절한 사용 권한을 추가합니다. C. ReceiveMessage API 호출을 사용하여 적절한 대기 시간을 설정합니다. D. 변경 메시지 표시 유형 API 호출을 사용 하 여 표시 시간 초과 늘리기 #\rAnswer\r...\rAnswer: D\r#\rQ435\r#\r최근에 AWS를 사용하기 시작한 회사는 사내 데이터 센터와 AWS 사이에 사이트 간 VPN을 구축합니다.이 회사의 보안 의무에 따르면 샘플 웹 애플리케이션을 호스팅하는 Amazon ECS (Amazon Elastic Container Service) 클러스터와 통신할 때 온-프레미스에서 발생하는 트래픽이 회사의 프라이빗 IP 공간 내에 있어야 합니다. 이 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. Amazon ECS에 대한 게이트웨이 엔드포인트를 구성합니다.ECS 클러스터를 가리키는 엔트리를 포함하도록 라우팅 테이블을 수정합니다. B. ECS 클러스터를 호스팅하는 동일한 VPC에서 Amazon ECS용 네트워크 로드 밸런서 및 AWS PrivateLink 엔드포인트를 생성합니다. C. 한 VPC에 네트워크 로드 밸런서를 생성하고 다른 VPC에서 Amazon ECS용 AWS PrivateLink 엔드포인트를 생성합니다.VPC 피어링으로 두 VPC를 연결합니다. D. Amazon ECS를 대상으로 사용하여 Amazon Route 53 레코드를 구성합니다.SSL 오프로딩을 위해 AWS 인증서 관리자 (ACM) 에서 Route 53에 서버 인증서를 적용합니다. #\rAnswer\r...\rAnswer: C\r#\rQ436\r#\r솔루션 설계자는 온프레미스에서 AWS로 마이그레이션되는 영구 데이터베이스를 위한 솔루션을 설계해야 합니다.데이터베이스 관리자에 따라 64,000IOPS가 필요합니다.가능한 경우 데이터베이스 관리자는 단일 Amazon Elastic 블록 스토어 (Amazon EBS) 볼륨을 사용하여 데이터베이스 인스턴스를 호스팅하려고 합니다.데이터베이스 관리자의 기준을 효과적으로 충족하는 솔루션은 무엇입니까?\nA. 13개의 I/O 최적화 제품군의 인스턴스를 사용하고 로컬 휘발성 스토리지를 활용하여 IOPS 요구 사항을 충족합니다. B. Amazon EBS 프로비저닝된 IOPS SSD (io1) 볼륨이 연결된 니트로 기반 Amazon EC2 인스턴스를 생성합니다.64,000IOPS가 되도록 볼륨을 구성합니다. C. Amazon EFS (Elastic File System) 볼륨을 생성하여 데이터베이스 인스턴스에 매핑하고 볼륨을 사용하여 데이터베이스에 필요한 IOPS를 달성합니다. D. 두 개의 볼륨을 프로비저닝하고 각 볼륨에 32,000 IOPS를 할당합니다.IOPS 요구 사항을 충족하기 위해 두 볼륨을 집계하는 운영 체제 수준에서 논리 볼륨을 생성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ437\r#\r회사는 내부적으로 공유해야 하는 미디어 및 애플리케이션 파일을 보유하고 있습니다.사용자는 현재 Active Directory를 사용하여 인증되고 Microsoft Windows 플랫폼에서 파일에 액세스합니다.최고 실행 책임자는 동일한 사용자 권한을 유지하려고 하지만 회사가 스토리지 용량 한도에 도달함에 따라 프로세스를 개선하기를 원합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. 회사 Amazon S3 버킷을 설정하고 미디어 및 애플리케이션 파일을 이동합니다. B. Windows 파일 서버용 Amazon FSX를 구성하고 모든 미디어 및 애플리케이션 파일을 이동합니다. C. Amazon EFS (Elastic 파일 시스템) 를 구성하고 모든 미디어 및 애플리케이션 파일을 이동합니다. D. Windows에서 Amazon EC2를 설정하고, Amazon EBS (Elastic Block Store) 볼륨을 여러 개 연결하고, 모든 미디어 및 애플리케이션 파일을 이동합니다. #\rAnswer\r...\rAnswer: B\r#\rQ438\r#\r회사는 Auto Scaling 그룹에 속하며 여러 Linux 인스턴스를 실행하는 빌드 서버를 보유하고 있습니다. 빌드 서버에는 작업 및 구성을 위해 일관된 공유 NFS 스토리지가 필요합니다.솔루션 설계자가 권장해야 하는 스토리지 옵션은 무엇입니까?\nA. Amazon S3 B. Amazon FSX C. Amazon Elastic Block Store (Amazon EBS) D. Amazon Elastic File System (Amazon EFS) #\rAnswer\r...\rAnswer: D\r#\rQ439\r#\r솔루션 설계자는 회사의 모 놀리 식 웹 응용 프로그램을 다중 계층 응용 프로그램으로 변환 할 계획입니다. 이 회사는 자체 인프라를 관리하지 않으려 합니다.웹 애플리케이션의 최소 요구 사항은 고가용성 확장성과 피크 시간 동안 지역적으로 짧은 대기 시간입니다. 또한 솔루션은 애플리케이션의 API를 사용하여 밀리초 지연 시간으로 데이터를 저장하고 검색해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. AWS Fargate를 사용하여 백엔드 Amazon RDS 다중 AZ DB 인스턴스로 웹 애플리케이션 호스팅 B. 엣지에 최적화된 API 엔드포인트가 있는 Amazon API 게이트웨이를 사용하고, 컴퓨팅에는 AWS Lambda를, 데이터 저장소로 Amazon DynamoDB를 사용합니다. C. 정적 웹 사이트 호스팅이 있는 Amazon S3 버킷을 가리키고 Amazon DynamoDB를 데이터 저장소로 가리키는 지리적 위치와 함께 Amazon Route 53 라우팅 정책을 사용합니다. D. Amazon EC2 Auto Scaling 그룹과 함께 Elastic 로드 밸런서를 가리키는 Amazon CloudFront 배포 사용 및 Amazon RDS 다중 AZ DB 인스턴스 #\rAnswer\r...\rAnswer: D\r#\rQ440\r#\r회사는 온프레미스에서 AWS 클라우드 리소스에 안전하게 연결하기 위해 사이트 간 VPN 연결을 사용하고 있습니다.Amazon EC2 인스턴스에 대한 VPN 연결 간 트래픽이 증가하기 때문에 사용자는 VPN 연결 속도가 느려집니다.VPN 처리량을 향상시킬 솔루션은 무엇입니까?\nA. 동일한 네트워크에 여러 고객 게이트웨이를 구축하여 처리량 확장 B. 동일한 비용의 다중 경로 라우팅이 있는 전송 게이트웨이를 사용하고 VPN 터널을 추가합니다. C. 동일한 비용의 다중 경로 라우팅 및 다중 채널을 사용하여 가상 프라이빗 게이트웨이 구성 D. VPN 구성에서 터널 수를 늘려 처리량을 기본 제한을 초과하여 확장합니다. #\rAnswer\r...\rAnswer: B\r#\rQ441\r#\r솔루션 설계자가 스토리지용 Amazon S3 버킷을 사용하여 문서 검토 애플리케이션을 구현하고 있습니다. 솔루션은 실수로 문서가 삭제되는 것을 방지하고 모든 버전의 문서를 사용할 수 있는지 확인해야 합니다. 사용자는 문서를 다운로드, 수정 및 업로드할 수 있어야 합니다.이러한 요구 사항을 충족하기 위해 취해야 할 행동의?(두 개 선택)\nA. 읽기 전용 버킷 ACL 활성화 B. 버킷에서 버전 관리를 활성화합니다. C. 버킷에 IAM 정책 연결 D. 버킷에서 MFA 삭제 활성화 E. AWS KMS를 사용하여 버킷 암호화 #\rAnswer\r...\rAnswer: B D\r#\rQ442\r#\r회사는 지역 서비스 중단 시에도 가용성이 높아야 하는 결제 애플리케이션을 구축하고 있습니다. 솔루션 설계자는 다른 AWS 리전에서 쉽게 복제하고 사용할 수 있는 데이터 스토리지 솔루션을 설계해야 합니다.응용 프로그램은 또한 짧은 대기 시간 원 자성, 일관성, 격리 및 내구성 (ACID) 트랜잭션이 필요하며 보고서를 생성하기 위해 즉시 사용할 수 있어야 합니다. 개발 팀은 SQL을 사용해야 합니다.이러한 요구 사항을 충족하는 데이터 스토리지 솔루션은 무엇입니까?\nA. Amazon Aurora 글로벌 데이터베이스 B. Amazon DynamoDB 글로벌 테이블 C. 교차 리전 복제 및 Amazon Athena가 있는 Amazon S3 D. Amazon Elastic 블록 스토어 (Amazon EBS) 스냅샷 복제를 사용하는 Amazon EC2 인스턴스의 MySQL #\rAnswer\r...\rAnswer: A\r#\rQ443\r#\r회사는 인터넷 기반 웹 애플리케이션을 설계하고 있습니다.이 애플리케이션은 Amazon RDS MySQL 다중 AZ DB 인스턴스에 중요한 사용자 데이터를 저장하는 Linux 기반 인스턴스용 Amazon EC2에서 실행됩니다.EC2 인스턴스는 퍼블릭 서브넷에 있고 RDS DB 인스턴스는 프라이빗 서브넷에 있습니다.보안 팀은 웹 기반 공격으로부터 DB 인스턴스를 보호하도록 규정했습니다. 솔루션 설계자는 무엇을 권장해야 합니까?\nA. EC2 인스턴스가 Auto Scaling 그룹의 일부이며 애플리케이션 로드 밸런서 뒤에 있는지 확인합니다.의심스러운 웹 트래픽을 삭제하도록 EC2 인스턴스 iptables 규칙 구성 DB 인스턴스에 대한 보안 그룹 생성 개별 EC2 인스턴스의 포트 3306만 허용하도록 RDS 보안 그룹을 구성합니다. B. EC2 인스턴스가 Auto Scaling 그룹의 일부이며 애플리케이션 로드 밸런서 뒤에 있는지 확인합니다.EC2 인스턴스가 위치한 서브넷과 동일한 서브넷으로 DB 인스턴스를 이동합니다.DB 인스턴스에 대한 보안 그룹을 생성합니다.개별 EC2 인스턴스에서 포트 3306만 인바운드하도록 RDS 보안 그룹 구성 C. EC2 인스턴스가 Auto Scaling 그룹의 일부이며 애플리케이션 로드 밸런서 뒤에 있는지 확인합니다.AWS WAF를 사용하여 인바운드 웹 트래픽에 대한 위협 모니터링 웹 애플리케이션 서버에 대한 보안 그룹 및 DB 인스턴스에 대한 보안 그룹을 생성합니다.웹 애플리케이션 서버 보안 그룹에서 포트 3306 인바운드만 허용하도록 RDS 보안 그룹을 구성합니다. D. EC2 인스턴스가 Auto Scaling 그룹의 일부이며 애플리케이션 로드 밸런서 뒤에 있는지 확인합니다.AWS WAF를 사용하여 인바운드 웹 트래픽에 대한 위협 모니터링 Auto Scaling 그룹을 구성합니다. o Scaling 그룹 lo 트래픽이 많은 경우 자동으로 새 DB 인스턴스 생성 RDS DB 인스턴스에 대한 보안 그룹을 생성합니다.포트 3306 인바운드만 허용하도록 RDS 보안 그룹 구성 #\rAnswer\r...\rAnswer: C\r#\rQ444\r#\r회사가 AWS에 문서 스토리지 애플리케이션을 구축하고 있습니다.애플리케이션은 여러 가용 영역의 Amazon EC2 인스턴스에서 실행됩니다.이 회사는 문서 저장소가 고가용성이어야 합니다.서류는 요청 시 즉시 반환해야 합니다.수석 엔지니어는 Amazon Elastic Block Store (Amazon EBS) 를 사용하여 문서를 저장하도록 애플리케이션을 구성했지만 가용성 요구 사항을 충족하기 위해 다른 옵션을 고려할 의향이 있습니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. EBS 볼륨의 스냅샷을 정기적으로 생성하고 추가 가용 영역에서 해당 스냅샷을 사용하여 새 볼륨을 구축합니다. B. EC2 인스턴스 루트 볼륨에는 Amazon EBS를 사용합니다.Amazon S3에 문서 저장소를 빌드하도록 애플리케이션을 구성합니다. C. EC2 인스턴스 루트 볼륨에 Amazon EBS를 사용합니다.Amazon S3 Glacier에서 문서 저장소를 빌드하도록 애플리케이션을 구성합니다. D. EC2 인스턴스에 대해 프로비저닝된 IOPS EBS 볼륨을 3개 이상 사용합니다.RAID 5 구성의 EC2 인스턴스에 볼륨을 마운트합니다. #\rAnswer\r...\rAnswer: B\r#\rQ445\r#\r회사는 Amazon EC2 인스턴스에서 실행되는 사용자 지정 애플리케이션을 보유하고 있습니다.\nAmazon S3에서 대량의 데이터를 읽습니다. 다단계 분석을 수행합니다. 결과를 Amazon DynamoDB에 기록합니다. 응용 프로그램은 다단계 분석 중에 많은 수의 대용량 임시 파일을 씁니다.프로세스 성능은 임시 저장소 성능에 따라 다릅니다.임시 파일을 보관하기위한 가장 빠른 저장 옵션은 무엇입니까? A. 스토리지용 Transfer Acceleration이 있는 여러 Amazon S3 버킷 B. 프로비저닝된 IOPS 및 EBS 최적화를 지원하는 여러 Amazon EBS 드라이브 C. 네트워크 파일 시스템 버전 4.1 (NFSv4.1) 프로토콜을 사용하는 여러 개의 Amazon EFS 볼륨 D. 소프트웨어 RAID 0이 있는 여러 인스턴스 스토어 볼륨 #\rAnswer\r...\rAnswer: A\r#\rQ446\r#\r엔지니어링 팀이 AWS Lambda 함수를 개발 및 배포하고 있습니다.팀은 Lambda 함수의 권한을 구성하려면 AWS IAM에서 역할을 생성하고 정책을 관리해야 합니다. 팀에 대한 권한은 최소 권한의 개념을 준수하도록 어떻게 구성해야합니까?\nA. 연결된 관리형 정책을 사용하여 IAM 역할 생성 엔지니어링 팀 및 Lambda 함수가 이 역할을 수임하도록 허용 B. LAMFullAccess 정책이 연결된 엔지니어링 팀용 IAM 그룹 생성 팀의 모든 사용자를 이 IAM 그룹에 추가합니다. C. Lambda 함수에 대한 실행 역할을 만듭니다.이러한 Lambda 함수와 관련된 권한 경계가 있는 관리형 정책 연결 D. Lambda 함수와 관련된 권한 경계가 있는 관리형 정책이 연결된 IAM 역할 만들기 엔지니어링 팀에서 이 역할을 수임할 수 있도록 허용합니다. #\rAnswer\r...\rAnswer: D\r#\rQ447\r#\r회사는 여러 대륙의 도시에서 온도, 습도 및 대기압 데이터를 수집합니다. 매일 사이트당 수집되는 평균 데이터 양은 500GB입니다.각 사이트에는 고속 인터넷이 연결되어 있습니다.이 회사의 일기 예보 응용 프로그램은 단일 지역에 기반하며 매일 데이터를 분석합니다. 이러한 모든 글로벌 사이트에 대한 데이터를 집계하는 가장 빠른 방법은 무엇입니까?\nA. 대상 버킷에서 Amazon S3 Transfer Acceleration을 활성화합니다.멀티파트 업로드를 사용하여 사이트 데이터를 대상 버킷에 직접 업로드합니다. B. 가장 가까운 AWS 리전에 있는 Amazon S3 버킷에 사이트 데이터를 업로드합니다.S3 교차 리전 복제를 사용하여 객체를 대상 버킷에 복사합니다. C. 가장 가까운 AWS 리전에 있는 Amazon S3 버킷에 사이트 데이터를 업로드합니다.S3 교차 리전 복제를 사용하여 객체를 대상 버킷에 복사합니다. D. 닫힌 리전의 Amazon EC2 인스턴스에 데이터를 업로드합니다.Amazon EBS 볼륨에 데이터를 저장합니다.하루에 EBS 스냅샷을 만들어 중앙 지역에 복사합니다.중앙 집중식 리전에서 EBS 볼륨을 복원하고 매일 데이터에 대한 분석을 실행합니다. #\rAnswer\r...\rAnswer: B\r#\rQ448\r#\r한 회사는 단일 가용 영역에서 Amazon EC2를 사용하고 Amazon RDS 다중 AZ DB 인스턴스를 사용하는 상태 비저장 2계층을 설계했습니다.새로운 회사 경영진은 애플리케이션의 가용성을 보장하고자 합니다. 솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. 다중 AZ EC2 Auto Scaling을 사용하도록 애플리케이션을 구성하고 애플리케이션 로드 밸런서를 생성합니다. B. EC2 인스턴스의 스냅샷을 만들어 다른 AWS 리전으로 전송하도록 애플리케이션을 구성합니다. C. Amazon Route 53 지연 시간 기반 라우팅을 사용하여 애플리케이션에 요청을 공급하도록 애플리케이션을 구성합니다. D. 수신 요청을 처리하고 다중 AZ 애플리케이션 로드 밸런서를 생성하도록 Amazon Route 53 규칙을 구성합니다. #\rAnswer\r...\rAnswer: A\r#\rQ449\r#\r솔루션 설계자는 Amazon RDS Corporate 보안 정책에 데이터베이스를 포함시킬 솔루션을 설계하고 있습니다. 데이터베이스의 로그와 백업이 모두 암호화되도록 요구하고 있습니다. Amazon RDS를 사용하여 보안 정책을 이행하는 가장 효율적인 옵션은 무엇입니까?\nA. 암호화가 활성화된 Amazon RDS 인스턴스 시작 로그 및 백업에 대한 암호화 활성화 B. Amazon RDS 인스턴스 시작 데이터베이스, 로그 및 백업에 대한 암호화 활성화 C. 암호화가 활성화된 Amazon RDS 인스턴스 시작 로그 및 백업이 자동으로 암호화됩니다. D. Amazon RDS 인스턴스 시작 백업을 위한 암호화 활성화 데이터베이스 엔진 기능을 사용하여 로그 암호화 #\rAnswer\r...\rAnswer: C\r#\rQ450\r#\r회사는 AWS 클라우드에서 멀티 티어 전자 상거래 웹 애플리케이션을 실행하고 있습니다.이 애플리케이션은 Amazon RDS MySQL 무트\u0026gt;AZ DB 인스턴스와 함께 Amazon EC2 인스턴스에서 실행됩니다.Amazon RDS는 Amazon EBS 범용 SSD (gp2) 볼륨에 2,000GB의 스토리지가 있는 최신 세대 인스턴스로 구성됩니다.데이터베이스 성능은 수요가 많은 기간 동안 응용 프로그램에 영향을 미칩니다. Amazon CloudWatch 로그에서 로그를 분석한 후 데이터베이스 관리자는 읽기 및 쓰기 IOPS 수가 6.000보다 많을 때 애플리케이션 성능이 항상 저하된다는 것을 알게 되었습니다. 솔루션 설계자는 애플리케이션 성능을 향상시키기 위해 어떻게 해야 합니까?\nA. 볼륨을 마그네틱 볼륨으로 교체합니다. B. gp2 볼륨에서 IOPS 수를 늘립니다. C. 볼륨을 프로비저닝된 IOPS (PIOPS) 볼륨으로 교체합니다. D. 2,000GB gp2 볼륨을 두 개의 1,000GBGP2 볼륨으로 교체합니다. #\rAnswer\r...\rAnswer: C\r#\rQ451\r#\r솔루션 설계자는 원하는 Amazon EC2 용량에 도달하기 전에 야간 일괄 처리 작업이 1시간 동안 자동으로 확장된다는 것을 관찰합니다.최대 용량은 매일 밤 동일하며 배치 작업은 항상 IAM에서 시작됩니다.솔루션 설계자는 원하는 EC2 용량에 신속하게 도달하고 배치 작업이 완료된 후 Auto Scaling 그룹을 축소할 수 있는 비용 효율적인 솔루션을 찾아야 합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까?\nA. Auto Scaling 그룹의 최소 용량을 늘립니다. B. Auto Scaling 그룹의 최대 용량을 늘립니다. C. 원하는 계산 수준으로 확장되도록 예약된 크기 조정을 구성합니다. D. 조정 정책을 변경하여 각 조정 작업 중에 EC2 인스턴스를 추가합니다. #\rAnswer\r...\rAnswer: C\r#\rQ452\r#\r금융 서비스 회사는 미국 및 유럽 사용자에게 서비스를 제공하는 웹 애플리케이션을 보유하고 있습니다. 애플리케이션은 데이터베이스 계층과 웹 서버 계층으로 구성됩니다. 데이터베이스 계층은 us-east-1에서 호스팅되는 MySQL 데이터베이스로 구성됩니다. Amazon Route 53 지리적 근접성 라우팅은 트래픽을인스턴스 시스템의 성능 검토를 통해 유럽 사용자가 미국의 쿼리 성능 수준과 동일한 수준의 쿼리 성능을 받지 못하고 있음을 알 수 있습니다. 성능 향상을 위해 데이터베이스 계층을 변경해야 합니까?\nA. MySQL용 Amazon RDS로 데이터베이스 마이그레이션 유럽 지역 중 하나에서 다중 AZ 구성 B. Amazon DynamoDB로 데이터베이스 마이그레이션 DynamoDB 글로벌 테이블을 사용하여 추가 리전으로의 복제 활성화 C. 각 리전에 MySQL 인스턴스 배포 MySQL 앞에 애플리케이션 로드 밸런서를 배포하여 기본 인스턴스의 로드를 줄입니다. D. MySQL 호환성 모드에서 Amazon Aurora 글로벌 데이터베이스로 데이터베이스 마이그레이션 유럽 지역 중 하나에 읽기 전용 복제본 구성 #\rAnswer\r...\rAnswer: D\r#\rQ453\r#\r한 회사에서 Amazon EC2 인스턴스의 보안 평가를 자동화하려고 합니다.이 회사는 개발 프로세스 전반에 걸쳐 보안 및 규정 준수 표준을 준수하고 있음을 검증하고 입증해야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떻게 해야 합니까?\nA. Amazon Macie를 사용하여 EC2 인스턴스를 자동으로 검색, 분류 및 보호합니다. B. Amazon GuardDuty를 사용하여 Amazon SNS (단순 알림 서비스) 알림을 게시하십시오. C. Amazon CloudWatch와 함께 Amazon 검사기를 사용하여 Amazon SNS (단순 알림 서비스) 알림 게시 D. Amazon EventBridge (Amazon CloudWatch 이벤트) 를 사용하여 AWS 트러스트 어드바이저 확인 상태의 변경 사항을 감지하고 이에 대응합니다. #\rAnswer\r...\rAnswer: C\r#\rQ454\r#\r회사는 고정 IP 주소를 사용하는 여러 온-프레미스 서버에서 호스팅되는 하이브리드 응용 프로그램을 보유하고 있습니다.VPC와 온프레미스 네트워크 간에 연결을 제공하는 VPN이 이미 있습니다.이 회사는 인터넷 사용자를 위해 온-프레미스 서버에 TCP 트래픽을 배포하려고 합니다. 가용성과 확장성이 뛰어난 솔루션을 제공하기 위해 솔루션 설계자는 무엇을 권장해야 합니까?\nA. 인터넷 연결 네트워크 부하 분산 장치 (NLB) 를 시작하고 NLB에 온-프레미스 IP 주소를 등록합니다. B. 인터넷 연결 애플리케이션 로드 밸런서 (ALB) 를 시작하고 ALB에 온-프레미스 IP 주소를 등록합니다. C. Amazon EC2 인스턴스를 시작하고, Elastic IP 주소를 연결하고, 온프레미스 서버에 트래픽을 분산시킵니다. D. Auto Scaling 그룹에서 퍼블릭 IP 주소를 사용하여 Amazon EC2 인스턴스를 시작하고 트래픽을 온 프레미스 서버로 분산합니다. #\rAnswer\r...\rAnswer: B\r#\rQ455\r#\r한 회사에서 서로 다른 AWS 계정에 있는 수천 명의 서비스 소비자에게 보호된 상태 정보 (PHI) 를 전송할 애플리케이션을 만들려고 합니다. 애플리케이션 서버는 프라이빗 VPC 서브넷에 있습니다. 애플리케이션의 라우팅은 내결함성이 있어야 합니다. 이러한 요구 사항을 충족하기 위해해야 할 일은 무엇입니까?\nA. VPC 엔드포인트 서비스를 생성하고 특정 서비스 소비자에게 연결을 생성할 수 있는 권한을 부여합니다. B. 각 서비스 공급자 VPC 쌍과 서비스 소비자 VPC 쌍 간에 가상 프라이빗 게이트웨이 연결을 만듭니다. C. 서비스 공급자 VPC에 내부 애플리케이션 로드 밸런서를 생성하고 애플리케이션 서버를 그 뒤에 놓습니다. D. 서비스 공급자 VPC에 프록시 서버를 생성하여 서비스 소비자의 요청을 애플리케이션 서버로 라우팅합니다. #\rAnswer\r...\rAnswer: A\r#\rQ456\r#\r한 회사가 Amazon S3에 기밀 데이터를 저장할 준비를 하고 있습니다.규정 준수를 위해 데이터를 저장 시 암호화해야 합니다.감사 목적으로 암호화 키 사용을 기록해야 합니다.키는 매년 회전해야 합니다. 이러한 요구 사항을 충족하고 가장 효율적인 솔루션은 무엇입니까?\nA. 고객 제공 키를 사용한 서버 측 암호화 (SSE-C) B. Amazon S3 관리 키를 사용한 서버 측 암호화 (SSE-S3) C. AWS KMS (SSE-KMS) 고객 마스터 키 (CMK) 를 사용한 서버 측 암호화 (수동 순환 포함) D. 자동 순환 기능이 있는 AWS KMS (SSE-KMS) 고객 마스터 키 (CMK) 를 사용한 서버 측 암호화 #\rAnswer\r...\rAnswer: D\r#\rQ457\r#\r이미지 호스팅 회사가 대규모 자산을 Amazon S3 표준 버킷에 업로드합니다. 회사는 S3 API를 사용하여 멀티파트 업로드를 병렬로 사용하고 동일한 객체가 다시 업로드되면 덮어씁니다. 첫 번째 업로드 후 30일 후에 객체에 자주 액세스됩니다. 객체는 30일 후에 덜 자주 사용되지만 각 객체의 액세스 패턴은 일관성이 없습니다. 회사는 저장된 자산의 고가용성과 복원력을 유지하면서 S3 스토리지 비용을 최적화해야 합니다.조치는 솔루션 설계자가 이러한 요구 사항을 충족하도록 권장해야합니까?(두 개를 선택합니다.)\nA. 30일 후 S3 Intelliginet 계층화로 자산 이동 B. 불완전한 멀티파트 업로드를 정리하도록 S3 수명 주기 정책 구성 C. 만료된 객체 삭제 마커를 정리하도록 S3 수명 주기 정책 구성 D. 30일 후 S3 표준 Standard Infrequent Access (S3 표준-IA) 로 자산 이동 E. 30일 후에 자산을 S3 One Zone Standard Infrequent Access (S3 One Zone-IA) 로 이동 #\rAnswer\r...\rAnswer: C D\r#\rQ458\r#\r회사는 각각 약 5MB 크기의 많은 파일을 생성하는 응용 프로그램을 보유하고 있습니다.파일은 Amazon S3에 저장됩니다.회사 정책에 따라 파일을 삭제하기 전에 4년간 저장해야 합니다.파일에 재현하기 쉽지 않은 중요한 비즈니스 데이터가 포함되어 있으므로 항상 즉각적인 액세스가 필요합니다.파일은 객체 생성 후 처음 30일 동안 자주 액세스되지만 처음 30일 후에는 거의 액세스되지 않습니다. 가장 비용 효율적인 스토리지 솔루션은 무엇입니까?\nA. S3 버킷 수명 주기 정책을 생성하여 객체를 만든 후 30일 후에 S3 표준에서 S3 Glacier로 파일을 이동합니다.개체 생성 후 4 년 후에 파일을 삭제하십시오. B. S3 버킷 수명 주기 정책을 생성하여 객체를 만든 후 30일 후에 S3 표준에서 S3 1영역 Standard Infrequent Access (S3 원 영역-IA) 로 파일을 이동합니다.개체 생성 후 4 년 후에 파일을 삭제하십시오. C. S3 버킷 수명 주기 정책을 생성하여 S3 표준에서 S3 표준 Standard Infrequent Access (S3 표준-IA) 로 파일을 객체 생성 후 30일 이내에 이동합니다.개체 생성 후 4 년 후에 파일을 삭제하십시오. D. S3 버킷 수명 주기 정책을 생성하여 S3 표준에서 S3 표준 Standard Infrequent Access (S3 표준-IA) 로 파일을 객체 생성 후 30일 이내에 이동합니다.객체 생성 후 4년 후 S3 Glacier로 파일을 이동합니다. #\rAnswer\r...\rAnswer: C\r#\rQ459\r#\r회사는 기가바이트의 csv 파일에서 작동하고 몇 개월의 데이터를 나타내는 레거시 온-프레미스 분석 응용 프로그램을 사용합니다. 레거시 응용 프로그램은 증가하는 csv 파일을 처리할 수 없습니다. 새로운 csv 파일은 다양한 데이터 원본에서 중앙 온-프레미스 저장소 위치로 매일 추가됩니다.사용자가 AWS 분석 서비스를 배우는 동안 레거시 애플리케이션을 계속 지원하려고 합니다. 이를 위해 솔루션 설계자는 온프레미스와 Amazon S3에서 모든 csv 파일의 동기화된 복사본 두 개를 유지하려고 합니다. 솔루션 설계자가 권장해야 하는 솔루션은 무엇입니까?\nA. 온프레미스에 AWS DataSync 배포회사의 온-프레미스 저장소와 회사의 S3 버킷 간에 csv 파일을 지속적으로 복제하도록 DataSync를 구성합니다. B. 온 프레미스 파일 게이트웨이 배포 csv 파일을 파일 게이트웨이에 기록하도록 데이터 소스 구성 레거시 분석 애플리케이션을 파일 게이트웨이로 지정합니다. 파일 게이트웨이는 csv 파일을 Amazon S3에 복제해야 합니다. C. 온프레미스 볼륨 게이트웨이를 배포합니다.CSV 파일을 볼륨 게이트웨이에 기록하도록 데이터 원본을 구성합니다.레거시 분석 애플리케이션이 볼륨 게이트웨이를 가리키도록 합니다.볼륨 게이트웨이는 데이터를 Amazon S3로 복제해야 합니다. D. 온프레미스와 Amazon EFS (Elastic 파일 시스템) 간에 CSV 파일을 지속적으로 복제하도록 AWS DataSync 온 프레미스 데이터 비동기 구성을 배포하여 Amazon EFS에서 회사의 S3 버킷으로 복제를 활성화합니다. #\rAnswer\r...\rAnswer: A\r#\rQ460\r#\r회사는 최근 글로벌 사용자 기반에 콘텐츠를 제공하기 위해 웹 사이트를 시작했습니다.이 회사는 Amazon CloudFront를 오리진으로 연결된 Amazon EC2 인스턴스와 함께 활용하여 정적 콘텐츠를 저장하고 사용자에게 신속하게 전송하려고 합니다.솔루션 설계자는 애플리케이션의 고가용성을 어떻게 최적화해야 합니까?\nA. CloudFront에 Lambda @Edge 를 사용합니다. B. CloudFront에 대해 Amazon S3 Transfer Acceleration을 사용합니다 C. 다른 가용 영역의 다른 EC2 인스턴스를 오리진 그룹의 일부로 구성합니다. D. 다른 EC2 인스턴스를 동일한 가용 영역에서 오리진 서버 클러스터의 일부로 구성합니다. #\rAnswer\r...\rAnswer: A\r#\rQ461\r#\r회사는 3계층 이미지 공유 애플리케이션을 보유하고 있으며, 프런트 엔드 계층에는 Amazon EC2 인스턴스를 사용하고, 다른 인스턴스는 백엔드 계층에 사용하고, 세 번째는 MySQL 데이터베이스용으로 사용합니다. 솔루션 설계자는 가용성이 높은 솔루션을 설계해야 하며응용 프로그램을 참조하십시오. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. Amazon S3를 사용하여 프런트 엔드 계층 호스팅 및 백엔드 계층용 AWS Lambda 함수 데이터베이스를 Amazon DynamoDB 테이블로 이동하고 Amazon S3를 사용하여 사용자 이미지를 저장 및 제공합니다. B. 프런트 엔드 및 백엔드 계층에 로드 밸런싱된 다중 AZ AWS Elastic Beanstalk 환경 사용 데이터베이스를 여러 읽기 전용 복제본이 있는 Amazon RDS 인스턴스로 이동하여 사용자의 이미지를 저장하고 제공합니다. C. Amazon S3를 사용하여 백엔드 계층의 Auto Scaling 그룹에 프런트 엔드 계층과 Amazon EC2 인스턴스 집합을 호스팅하여 데이터베이스를 메모리에 최적화된 인스턴스 유형으로 이동하여 사용자 이미지를 저장하고 제공합니다. D. 프런트 엔드 및 백엔드 계층에 로드 밸런싱된 다중 AZ AWS Elastic Beanstalk 환경 사용 다중 AZ 배포가 있는 Amazon RDS 인스턴스로 데이터베이스 이동 Amazon S3를 사용하여 사용자 이미지 저장 및 제공 #\rAnswer\r...\rAnswer: D\r#\rQ462\r#\r회사에서 여러 Amazon EC2 인스턴스를 사용하여 사용자로부터 데이터를 수집하는 애플리케이션을 실행합니다. 그러면 데이터가 처리되어 장기 저장을 위해 Amazon S3로 전송됩니다. 애플리케이션을 검토한 결과 EC2 인스턴스가 사용되지 않는 데 오랜 시간이 걸렸습니다 A 솔루션설계자는 활용도를 최적화하고 비용을 절감할 수 있는 솔루션을 설계해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 온 디맨드 인스턴스가 있는 Auto Scaling 그룹에서 Amazon EC2를 사용합니다. B. 온디맨드 인스턴스와 함께 Amazon Lightsail을 사용하도록 애플리케이션 구축 C. 활동이 없을 때 EC2 인스턴스를 자동으로 중지하는 Amazon CloudWatch 크론 작업을 생성합니다. D. Amazon SQS (단순 대기열 서비스) 및 AWS Lambda에서 이벤트 중심 디자인을 사용하도록 애플리케이션을 다시 디자인합니다. #\rAnswer\r...\rAnswer: D\r#\rQ463\r#\r회사는 비디오 콘텐츠를 게시하고 모든 모바일 플랫폼에서 사용할 수 있도록 트랜스코딩을 위한 온라인 서비스를 제공합니다.애플리케이션 아키텍처는 Amazon EFS (Amazon Elastic File System) 표준을 사용하여 비디오를 수집 및 저장하므로 여러 Amazon EC2 Linux 인스턴스가 비디오 콘텐츠에 액세스할 수 있습니다. 시간이 지남에 따라 서비스 인기가 증가함에 따라 스토리지 비용이 너무 비쌉니다.솔루션이 가장 비용 효율적입니까?\nA. AWS 스토리지 게이트웨이를 사용하여 비디오 콘텐츠를 저장하고 처리합니다. B. 볼륨에 AWS 스토리지 게이트웨이를 사용하여 비디오 콘텐츠를 저장하고 처리합니다. C. Amazon EFS를 사용하여 비디오 콘텐츠 저장 처리가 완료되면 Amazon Elastic Block Store (Amazon EBS) 로 파일을 전송합니다. D. Amazon S3를 사용하여 비디오 콘텐츠 저장 처리를 위해 서버에 연결된 Amazon Elastic Block Store (Amazon EBS) 볼륨으로 파일을 임시로 이동합니다. #\rAnswer\r...\rAnswer: D\r#\rQ464\r#\r회사는 Amazon EC2의 단일 리전에서 애플리케이션을 실행하고 있으며 Amazon EBS (Elastic Block Store) 및 S3를 스토리지 설계의 일부로 사용하고 있습니다. 데이터 전송 비용을 줄이려면 어떻게 해야 합니까?\nA. 다른 AWS 리전에 컴퓨팅 환경의 복사본 생성 B. Lambda @Edge 에서 실행되도록 응용 프로그램 변환 C. Amazon S3를 오리진으로 사용하여 Amazon CloudFront 배포를 생성합니다. D. Amazon S3 데이터를 요청자와 가까운 AWS 리전의 버킷에 복제합니다. #\rAnswer\r...\rAnswer: C\r#\rQ465\r#\r회사는 현재 Amazon RDS MySQL 데이터베이스를 지원하는 웹 애플리케이션을 운영하고 있습니다. 매일 실행되며 암호화되지 않은 자동 백업이 있습니다. 보안 감사를 통해 향후 백업을 암호화하고 암호화되지 않은 백업을 폐기해야 합니다. 회사는 암호화된 백업을 하나 이상 만들 것입니다.이전 백업을 파괴하기 전에 향후 백업을 위해 암호화를 활성화하기 위해해야 할 일”\nA. 백업이 저장되는 Amazon S3 버킷에 대한 기본 암호화 활성화 B. 데이터베이스 구성의 백업 섹션을 수정하여 암호화 사용 확인란을 토글합니다. C. 데이터베이스의 스냅샷 생성 암호화된 스냅샷으로 복사 암호화된 스냅샷에서 데이터베이스 복원 D. MySQL용 RDS에서 암호화된 읽기 전용 복제본 활성화 암호화된 읽기 전용 복제본을 기본 복제본으로 승격 원본 데이터베이스 인스턴스 제거 #\rAnswer\r...\rAnswer: C\r#\rQ466\r#\r솔루션 설계자는 트래픽이 많은 전자 상거래 웹 애플리케이션을 위한 데이터베이스 솔루션을 설계해야 합니다.데이터베이스는 고객 프로파일과 장바구니 정보를 저장합니다.데이터베이스는 초당 수백만 개의 요청 최대 로드를 지원해야 하며 응답을 밀리초 단위로 전달해야 합니다.데이터베이스를 관리하고 확장하기 위한 운영 오버헤드를 최소화해야 합니다.솔루션 설계자가 권장해야 하는 데이터베이스 솔루션은 무엇입니까?\nA. Amazon Aurora B. Amazon DynamoDB C. Amazon RDS D. Amazon Redshift #\rAnswer\r...\rAnswer: A\r#\rQ467\r#\r회사가 AWS Direct Connect 링크를 사용하여 코로케이션 시설에서 us-east-1 리전의 Amazon S3 버킷으로 1PB의 데이터를 복사했습니다.이제 회사는 us-west-2 리전의 다른 S3 버킷에 데이터를 복사하려고 합니다.코로케이션 시설에서는 AWS Snowball을 사용할 수 없습니다. 이 작업을 수행하기 위해 솔루션 설계자는 무엇을 권장해야합니까?\nA. Snowball Edge 디바이스를 주문하여 한 지역에서 다른 리전으로 데이터를 복사합니다. B. S3 콘솔을 사용하여 원본 S3 버킷에서 대상 S3 버킷으로 콘텐츠를 전송합니다. C. aws S3 sync 명령을 사용하여 원본 버킷에서 대상 버킷으로 데이터를 복사합니다. D. 교차 리전 복제 구성을 추가하여 다른 Reg 의 S3 버킷 간에 객체를 복사합니다. #\rAnswer\r...\rAnswer: B\r#\rQ468\r#\r솔루션 설계자는 ALB (애플리케이션 로드 밸런서) 뒤에 Amazon EC2 인스턴스에서 실행되는 웹 애플리케이션을 설계하고 있습니다. 이 회사는 악성 인터넷 활동 및 공격으로부터 애플리케이션을 복원하고 새로운 일반적인 취약성 및 노출로부터 보호해야 합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. ALB 엔드포인트를 오리진으로 사용하여 Amazon CloudFront 활용 B. AWS WAF에 적합한 관리형 규칙을 배포하고 이를 ALB와 연결합니다. C. AWS Shield Advanced를 구독하고 일반적인 취약성 및 노출이 차단되도록 보장 D. 포트 80 및 443만 EC2 인스턴스에 액세스할 수 있도록 네트워크 ACL 및 보안 그룹을 구성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ469\r#\r애플리케이션 개발자는 비즈니스 보고 사용자가 애플리케이션을 지원하는 Amazon RDS 인스턴스에 대해 대규모 프로덕션 보고서를 실행할 때 프로덕션 애플리케이션이 매우 느리다는 것을 발견했습니다. 보고 쿼리는실행.비즈니스 보고 사용자는 애플리케이션 성능에 영향을 주지 않고 보고서를 생성할 수 있어야 합니다. 이 작업을 수행하는 작업은 무엇입니까?\nA. RDS 인스턴스의 크기를 늘립니다. B. 읽기 전용 복제본을 생성하고 애플리케이션을 해당 복제본에 연결합니다. C. RDS 인스턴스에서 여러 가용 영역 활성화 D. 읽기 전용 복제를 생성하고 비즈니스 보고서를 이 복제에 연결합니다. #\rAnswer\r...\rAnswer: D\r#\rQ470\r#\r개발 팀이 AWS에 신제품을 배포하고 있으며 배포의 일부로 AWS Lambda를 사용하고 있습니다.팀은 Lambda 함수 중 하나에 512MB의 메모리를 할당합니다.이 메모리 할당으로 2 분 안에 기능이 완료됩니다.이 함수는 매월 수백만 번 실행되며 개발 팀은 비용에 대해 우려하고 있습니다. 팀은 다양한 Lambda 메모리 할당이 함수 비용에 미치는 영향을 확인하기 위해 테스트를 수행합니다.제품에 대한 Lambda 비용을 절감할 수 있는 단계는 무엇입니까?{둘 선택.)\nA. 이 변경으로 인해 각 함수의 실행 시간이 1분 미만으로 발생할 경우 이 Lambda 함수에 대한 메모리 할당을 1,024MB로 늘립니다. B. 이 Lambda 함수에 대한 메모리 할당을 1.024MB로 늘립니다. 이 변경으로 인해 각 함수의 실행 시간이 90초 미만일 수 있습니다. C. 이 변경으로 인해 각 함수의 실행 시간이 4 분 미만으로 발생할 경우 이 Lambda 함수에 대한 메모리 할당을 256MB로 줄입니다. D. 이 Lambda 함수의 메모리 할당을 2,048MB로 늘립니다. 이 변경으로 인해 각 함수의 실행 시간이 1 분 미만으로 발생합니다. E. 이 변경으로 인해 각 함수의 실행 시간이 5분 미만으로 발생할 경우 이 Lambda 함수의 메모리 할당을 256MB로 줄입니다. #\rAnswer\r...\rAnswer: A C\r#\rQ471\r#\r회사는 전 세계 20,000개 이상의 소매 매장에 배포된 클라이언트를 서버하는 애플리케이션을 보유하고 있습니다.응용 프로그램은 포트 443에서 HTTPS를 통해 노출되는 백엔드 웹 서비스로 구성됩니다.애플리케이션은 애플리케이션 로드 밸런서 (ALB) 뒤에 있는 Amazon EC2 인스턴스에서 호스팅됩니다.소매 위치는 공용 인터넷을 통해 웹 응용 프로그램과 통신합니다.회사는 각 소매점에서 해당 지역 ISP에 의해 소매 위치가 할당된 IP 주소를 등록할 수 있도록 허용합니다. 회사의 보안 팀은 소매점에서 등록된 IP 주소에만 대한 액세스를 제한하여 애플리케이션 엔드포인트의 보안을 강화할 것을 권장합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. AWS WAF 웹 ACL을 ALB와 연결합니다.ALB에서 IP 규칙 집합을 사용하여 트래픽을 필터링합니다.등록된 IP 주소를 포함하도록 규칙의 IP 주소를 업데이트합니다. B. ALB를 관리하기 위해 AWS 방화벽 관리자를 배포합니다.ALB로 트래픽을 제한하도록 방화벽 규칙을 구성합니다.등록된 IP 주소를 포함하도록 방화벽 규칙을 수정합니다. C. IP 주소를 Amazon DynamicDB 테이블에 저장합니다.ALB에서 AWS Lambda 권한 부여 함수를 구성하여 수신 요청이 등록된 IP 주소에서 온 것임을 확인합니다. D. ALB의 공용 인터페이스를 포함하는 서브넷에서 네트워크 ACL을 구성합니다.등록된 각 IP 주소에 대한 항목으로 네트워크 ACL의 수신 규칙을 업데이트합니다. #\rAnswer\r...\rAnswer: C\r#\rQ472\r#\r회사에서 개발 목적으로 Amazon Aurora MySQL DB 클러스터를 추가로 배포하려고 합니다.클러스터는 프로덕션 쿼리 문제를 디버깅하는 데 몇 분 동안 일주일에 여러 번 사용됩니다.이 회사는 이 자원에 대한 오버헤드를 낮게 유지하려고 합니다.회사의 요구 사항을 가장 비용 효율적으로 충족하는 솔루션은 무엇입니까?\nA. DB 인스턴스용 예약 인스턴스를 구매합니다. B. Aurora 서버를 사용하지 않는 환경에서 DB 인스턴스 실행 C. DB 인스턴스에 대한 중지/시작 일정을 생성합니다. D. 활성 연결이 없는 DB 인스턴스를 중지하는 AWS Lambda 함수를 생성합니다. #\rAnswer\r...\rAnswer: D\r#\rQ473\r#\r회사는 신용 카드 결제를 처리하기 위해 3 계층 웹 애플리케이션을 운영하고 있습니다.더 프런트 엔드 사용자 인터페이스는 정적 웹 페이지로 구성됩니다.응용 프로그램 계층에는 장기 실행 프로세스가 있을 수 있습니다. 데이터베이스 계층은 MySQL을 사용합니다. 이 애플리케이션은 현재 범용 대형 단일 Amazon EC2 인스턴스에서 실행 중입니다. 솔루션 설계자는 웹 애플리케이션의 가용성을 높게 만들기 위해 서비스를 분리해야 합니다.가장 높은 가용성을 제공하는 솔루션은 무엇입니까?\nA. Amazon CloudFront로 정적 자산 이동 애플리케이션을 Auto Scaling 그룹에 EC2에 둡니다.데이터베이스를 Amazon RDS로 이동하여 다중 AZ를 배포합니다. B. 정적 자산 및 애플리케이션을 중간 EC2 인스턴스로 이동합니다.큰 인스턴스에 데이터베이스를 둡니다.두 인스턴스를 모두 Auto Scaling 그룹에 배치합니다. C. 정적 자산을 Amazon S3로 이동합니다.동시성 제한이 설정된 상태에서 애플리케이션을 AWS Lambda로 이동합니다.온디맨드 사용으로 설정된 상태로 데이터베이스를 Amazon DynamoDB로 이동합니다. D. 정적 자산을 Amazon S3로 이동합니다.Auto Scaling이 활성화된 Amazon Elastic 컨테이너 서비스 (Amazon ECS) 컨테이너로 애플리케이션을 이동합니다.데이터베이스를 Amazon RDS로 이동하여 다중 AZ 배포 #\rAnswer\r...\rAnswer: B\r#\rQ474\r#\r한 회사가 Amazon API 게이트웨이와 AWS Lambda를 사용하여 AWS에 RESTful 서버를 사용하지 않는 웹 애플리케이션을 구축하고 있습니다.이 웹 응용 프로그램의 사용자는 지리적으로 방해 받고 회사는 이러한 사용자에 대한 API 요청의 대기 시간을 줄이려고합니다.솔루션 설계자가 이러한 요구 사항을 충족하기 위해 어떤 유형의 엔드포인트를 사용해야 합니까?\nA. 프라이빗 엔드포인트 B. 지역 엔드포인트 C. VPC 엔드포인트 D. 엣지 최적화 엔드포인트 #\rAnswer\r...\rAnswer: A\r#\rQ475\r#\r솔루션 설계자는 시장이 폐쇄되는 동안 금융 시장의 성과를 분석하는 시스템을 설계하고 있습니다. 시스템은 매일 밤 4 시간 동안 일련의 컴퓨팅 집약적 인 작업을 실행합니다. 계산 작업을 완료하는 시간은 일정하게 유지되며 작업이 한 번 중단 될 수 없습니다.시작 완료 후 최소 1년 동안 시스템을 실행할 것으로 예상됩니다. 시스템 비용을 줄이기 위해 어떤 유형의 Amazon EC2 인스턴스를 사용해야 합니까?\nA. 스팟 인스턴스 B. 온 디맨드 C. 표준 예약 인스턴스 D. 예약된 예약 인스턴스 #\rAnswer\r...\rAnswer: D\r#\rQ476\r#\r회사 일부 의심스러운 IP 주소로 액세스 요청을 보고 있습니다.보안 팀은 요청이 동일한 CIDR 범위에서 서로 다른 IP 주소인 것을 발견합니다.솔루션 설계자가 팀에 무엇을 추천해야합니까?\nA. 보안 그룹의 인바운드 테이블에 규칙을 추가하여 해당 CIDR 범위의 트래픽을 거부합니다. B. 규칙 추가 보안 그룹의 아웃바운드 테이블에서 해당 CIDR 범위의 트래픽을 거부합니다. C. 다른 규칙보다 낮은 규칙 번호를 사용하여 네트워크 ACL의 인바운드 테이블에 거부 규칙을 추가합니다. D. 다른 규칙보다 타워 규칙 번호를 사용하여 네트워크 ACL의 아웃바운드 테이블에 거부 규칙을 추가합니다. #\rAnswer\r...\rAnswer: C\r#\rQ477\r#\r회사는 AWS에 웹 사이트를 호스팅합니다.이 회사는 매우 가변적인 수요를 해결하기 위해 Amazon EC2 Auto Scaling을 구현했습니다.경영진은 특히 3 계층 애플리케이션의 프런트엔드에서 인프라를 과도하게 프로비저닝하고 있다고 우려하고 있습니다.솔루션 설계자는 성능에 영향을 주지 않고 비용을 최적화해야 합니다.솔루션 설계자는이를 달성하기 위해 무엇을해야합니까?\nA. 예약 인스턴스에 Auto Scaling을 사용합니다. B. 예약된 조정 정책과 함께 Auto Scaling을 사용합니다 C. 일시 중지 다시 시작 기능과 함께 Auto Scaling 사용 D. Auto Scaling을 대상 추적 조정 정책과 함께 사용합니다. #\rAnswer\r...\rAnswer: D\r#\rQ478\r#\r회사는 PostgreSQL 단일 AZ DB 인스턴스 관리를 위한 Amazon RDS에 모든 주문을 저장하는 온라인 쇼핑 애플리케이션을 호스팅하고 있으며, 단일 장애 지점을 제거하고자 하며, 솔루션 설계자에게응용 프로그램 코드를 참조하십시오. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 데이터베이스 인스턴스를 수정하고 다중 AZ 옵션을 지정하여 기존 데이터베이스 인스턴스를 다중 AZ 배포로 변환합니다. B. 새 RDS 다중 AZ 배포 만들기 현재 RDS 인스턴스의 스냅샷을 만들고 스냅샷과 함께 새 다중 AZ 배포를 복원합니다. C. 다른 가용 영역에 PostgreSQL 데이터베이스의 읽기 전용 복제본 생성 Amazon Route 53 가중치 레코드 세트를 사용하여 데이터베이스 전체에 요청을 분산합니다. D. PostgreSQL용 RDS 데이터베이스를 Amazon EC2 Auto Scaling 그룹에 배치하며, 최소 그룹 크기가 두 개인 Amazon Route 53 가중치 레코드 세트 사용 인스턴스를 통해 요청을 분산시킵니다. #\rAnswer\r...\rAnswer: A\r#\rQ479\r#\r개발자가 AWS Lambda 함수를 사용하여 Amazon S3에 파일을 업로드하고 작업을 수행하는 데 필요한 권한이 필요한 애플리케이션을 보유하고 있습니다.개발자가 이미 Amazon S3에 필요한 유효한 IAM 자격 증명을 가진 IAM 사용자를 보유하고 있습니다.솔루션 설계자는 권한을 부여하기 위해 무엇을해야합니까?\nA. Lambda 함수의 리소스 정책에 필요한 IAM 권한을 추가합니다. B. Lambda 함수의 기존 IAM 자격 증명을 사용하여 서명된 요청을 생성합니다. C. 새 IAM 사용자를 생성하고 Lambda 함수에서 기존 IAM 자격 증명 사용 D. 필요한 권한을 가진 IAM 실행 역할을 생성하고 IAM 역할을 Lambda 함수에 연결합니다. #\rAnswer\r...\rAnswer: C\r#\rQ480\r#\r회사는 최근 새로운 감사 시스템을 구축하여 운영 체제 버전, 패치 적용 및 Amazon EC2 인스턴스용 설치된 소프트웨어입니다.솔루션 설계자는 EC2 Auto Scaling 그룹을 통해 프로비저닝된 모든 인스턴스가 실행 및 종료되는 즉시 감사 시스템에 보고서를 성공적으로 전송하도록 보장해야 합니다. 이러한 목표를 가장 효율적으로 달성하는 솔루션은 무엇입니까?\nA. 예약된 AWS Lambda 함수를 사용하고 모든 EC2 인스턴스에서 원격으로 스크립트를 실행하여 감사 시스템으로 데이터를 전송합니다. B. EC2 Auto Scaling 수명 주기 후크를 사용하여 인스턴스가 시작되고 종료될 때 감사 시스템에 데이터를 전송하는 사용자 지정 스크립트를 실행합니다. C. EC2 Auto Scaling 시작 구성을 사용하여 사용자 데이터를 통해 사용자 정의 스크립트를 실행하여 인스턴스가 시작되고 종료될 때 감사 시스템으로 데이터를 전송합니다. D. 인스턴스 운영 체제에서 사용자 지정 스크립트를 실행하여 감사 시스템으로 데이터를 전송합니다.인스턴스가 시작되고 종료될 때 EC2 Auto Scaling 그룹에서 실행되도록 스크립트를 구성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ481\r#\r회사가 온프레미스 오라클 데이터베이스를 Amazon Aurora PostgreSQL로 이전하고 있습니다.데이터베이스에는 동일한 테이블에 쓰는 여러 응용 프로그램이 있습니다.애플리케이션은 각 마이그레이션 관리 데이터베이스 읽기 및 쓰기 수가 많은 우려를 표명했다 사이에 한 달 하나씩 마이그레이션해야합니다.데이터는 타이 마이그레이션을 통해 두 데이터베이스 간에 동기화 상태로 유지되어야 합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. 초기 마이그레이션을 위해서는 AWS DataSync를 사용하십시오.AWS 데이터베이스 마이그레이션 서비스 (AWS DMS) 를 사용하여 변경 데이터 캡처 (CDC) 복제 작업을 만들고 테이블 매핑을 생성하여 모든 케이블을 선택합니다. B. 초기 마이그레이션을 위해 AVvs DataSync를 사용합니다.AWS DMS (데이터베이스 마이그레이션 서비스) 를 사용하여 전체 로드 및 변경 데이터 캡처 (CDC) 복제 작업을 생성하고, ail 테이블을 선택하는 테이블 매핑을 생성할 수 있습니다. C. 메모리 최적화 복제 인스턴스를 사용하여 AWS 데이터베이스 마이그레이션 서비스 (AWS DMS) 에서 주도하는 AWS 스키마 변환 사용 Tui 로드 및 변경 데이터 캡처 (CDC) 복제 작업 및 테이블 매핑 lo 모든 테이블을 선택합니다. D. 컴퓨팅 최적화 함축 인스턴스를 사용하여 AWS DMS (데이터베이스 마이그레이션 서비스) 와 함께 AWS 스키마 변환 도구를 사용하여 전체 로드 및 변경 데이터 캡처 (CDC) 복제 작업과 테이블 매핑을 생성하여 가장 큰 테이블을 선택합니다. #\rAnswer\r...\rAnswer: B\r#\rQ482\r#\r회사는 Amazon RDS MySQL DB 인스턴스에서 정보를 검색하는 자격 증명이 내장된 사용자 지정 애플리케이션을 보유하고 있습니다.관리는 최소한의 프로그래밍 노력으로 응용 프로그램이 더 안전하게 만들어져야한다고 말합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. AWS KMS (키 관리 서비스) 고객 마스터 키 (CMK) 를 사용하여 키를 생성합니다.AWS KMS에서 데이터베이스 자격 증명을 로드하도록 애플리케이션을 구성합니다. 자동 키 순환을 활성화합니다. B. 애플리케이션 사용자에 대한 MySQL용 RDS 데이터베이스에서 자격 증명을 생성하고 AWS 비밀 관리자에 자격 증명을 저장합니다.보안 관리자에서 데이터베이스 자격 증명을 로드하도록 응용 프로그램을 구성합니다.보안 관리자에서 자격 증명을 순환하는 AWS Lambda 함수를 생성합니다. C. MySQL용 RDS 데이터베이스에서 애플리케이션 사용자에 대한 자격 증명을 생성하고 AWS 비밀 관리자에 자격 증명을 저장합니다.보안 관리자에서 데이터베이스 자격 증명을 로드하도록 응용 프로그램을 구성합니다.암호 관리자를 사용하여 MySQL용 RDS 데이터베이스에서 애플리케이션 사용자에 대한 자격 증명 순환 일정을 설정합니다. D. MySQL용 RDS 데이터베이스에서 애플리케이션 사용자에 대한 자격 증명을 생성하고 AWS 시스템 관리자 매개 변수 저장소에 자격 증명을 저장합니다.매개 변수 저장소에서 데이터베이스 인증서를 로드하도록 응용 프로그램을 구성합니다.매개 변수 저장소를 사용하여 RDS for MySQL 데이터베이스에서 애플리케이션 사용자에 대한 자격 증명 순환 일정을 설정합니다. #\rAnswer\r...\rAnswer: D\r#\rQ483\r#\r회사는 매달 약 300TB의 Amazon S3 표준 스토리지를 유지 관리하고 있습니다.S3 객체는 일반적으로 각각 약 50GB 크기이며 글로벌 애플리케이션에 의해 멀티파트 업로드로 대체되는 경우가 많습니다.S3 객체의 수와 크기는 일정하게 유지되지만 회사의 S3 스토리지 비용은 매월 증가하고 있습니다. 이 상황에서 솔루션 설계자는 어떻게 비용을 줄여야 합니까?\nA. 멀티파트 업로드에서 Amazon S3 Transfer Acceleration화로 전환 B. 불완전한 멀티파트 업로드를 삭제하는 S3 수명 주기 정책 활성화 C. 객체가 너무 빨리 아카이빙되지 않도록 S3 인벤토리 구성 D. Amazon S3에 저장되는 객체 수를 줄이도록 Amazon CloudFront를 구성합니다. #\rAnswer\r...\rAnswer: D\r#\rQ484\r#\r모바일 게임 회사는 Amazon EC2 인스턴스에서 애플리케이션 서버를 실행합니다.서버는 15 분마다 플레이어로부터 업데이트를 수신합니다.모바일 게임은 마지막 업데이트 이후 게임에서 진행된 JSON 객체를 생성하고 JSON 객체를 애플리케이션 로드 밸런서로 전송합니다.모바일 게임이 재생되면 게임 업데이트가 손실됩니다.이 회사는 이전 버전의 업데이트를 가져올 수있는 내구성있는 방법을 만들려고합니다. 솔루션 설계자는 시스템을 분리하기 위해 무엇을 권장해야합니까?\nA. Amazon Kinesis Data Streams을 사용하여 데이터를 캡처하고 JSON 객체를 Amazon S3에 저장합니다. B. Amazon Kinesis Data Firehose를 사용하여 데이터를 캡처하고 JSON 객체를 Amazon S3에 저장합니다. C. Amazon SQS (단순 대기열 서비스) FIFO 대기열을 사용하여 데이터를 캡처하고 EC2 인스턴스를 사용하여 대기열의 메시지를 처리합니다. D. Amazon SNS (단순 알림 서비스) 를 사용하여 데이터 및 EC2 인스턴스를 캡처하여 애플리케이션 로드 밸런서로 전송된 메시지를 처리합니다. #\rAnswer\r...\rAnswer: C\r#\rQ485\r#\r회사의 웹 사이트는 초당 50,000 건의 요청을 수신합니다.회사는 웹 사이트 사용자의 탐색 패턴을 분석하기 위해 여러 응용 프로그램을 사용하여 경험을 개인화할 수 있기를 원합니다.솔루션 설계자가 웹 사이트의 페이지 클릭 수를 수집하고 각 사용자에 대해 순차적으로 처리하는 데 어떤 AWS 서비스 또는 기능을 사용해야 합니까?\nA. Amazon Kinesis Data Streams B. Amazon SQS (단순 대기열 서비스) 표준 대기열 C. Amazon SQS (단순 대기열 서비스) FIFO 대기열 D. AWS CloudTrail #\rAnswer\r...\rAnswer: A\r#\rQ486\r#\r재해 대응 팀이 드론을 사용하여 최근 폭풍 피해 이미지를 수집하고 있습니다.대응 팀의 노트북에는 이미지를 전송하고 데이터를 처리할 수 있는 스토리지와 컴퓨팅 용량이 부족합니다.팀은 처리를 위한 Amazon EC2 인스턴스와 스토리지용 Amazon S3 버킷을 보유하고 있지만 네트워크 연결은 간헐적이며 신뢰할 수 없습니다.손상을 평가하기 위해 이미지를 처리해야합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. AWS Snowball Edge 디바이스를 사용하여 이미지를 처리하고 저장합니다. B. EC2 인스턴스에 간헐적으로 연결하는 동안 Amazon SOS (단순 대기열 서비스) 에 이미지를 업로드합니다. C. Amazon Kinesis Data Firehose를 구성하여 스토리지용 S3 버킷과 이미지 처리를 위한 EC2 인스턴스를 별도로 대상으로 여러 전송 스트림을 생성합니다. D. 하드웨어 어플라이언스에 사전 설치된 AWS Storage Gateway를 사용하여 Amazon S3용 이미지를 로컬로 캐싱하여 연결이 가능해지면 이미지를 처리합니다. #\rAnswer\r...\rAnswer: B\r#\rQ487\r#\r회사는 AWS에서 고성능 컴퓨팅 (HPC) 워크로드를 실행합니다.워크로드는 긴밀하게 연결된 노드 간 통신으로 지연 시간이 짧은 네트워크 성능과 높은 네트워크 처리량을 필요로 했습니다.Amazon EC2 인스턴스는 컴퓨팅 및 스토리지 용량에 맞게 크기가 적절하게 조정되며 기본 옵션을 사용하여 시작됩니다. 솔루션 설계자는 워크로드의 성능을 향상시키기 위해 무엇을 제안해야합니까?\nA. Amazon EC2 인스턴스를 시작하는 동안 클러스터 배치 그룹 선택 B. Amazon EC2 인스턴스를 시작하는 동안 전용 인스턴스 테넌시 선택 C. Amazon EC2 인스턴스를 시작하는 동안 탄력적 추론 Accelerator 선택 D. Amazon EC2 인스턴스를 시작하는 동안 필요한 용량 예약을 선택합니다. #\rAnswer\r...\rAnswer: A\r#\rQ488\r#\r미디어 회사는 비디오 콘텐츠를 Amazon EBS (Elastic Block Store) 볼륨에 저장합니다.특정 비디오 파일이 인기를 얻었으며 전 세계 많은 수의 사용자가이 콘텐츠에 액세스하고 있습니다.이로 인해 비용이 증가했습니다.사용자 접근성에 영향을 주지 않으면서 비용을 절감할 수 있는 조치는 무엇입니까?\nA. 비디오를 Amazon S3 버킷에 저장하고 Amazon CloudFront 배포를 생성합니다. B. 비디오를 여러 개의 작은 세그먼트로 분할하여 사용자가 요청된 비디오 세그먼트로만 라우팅되도록 합니다. C. 각 리전에서 Amazon S3 버킷을 지우고 비디오를 업로드하여 사용자가 가장 가까운 S3 버킷으로 라우팅되도록 합니다. D. EBS 볼륨을 프로비저닝된 IOPS (PIOPS) 로 변경합니다. #\rAnswer\r...\rAnswer: A\r#\rQ489\r#\r회사는 보안상의 이유로 프라이빗 서브넷에 여러 Amazon EC2 인스턴스를 설정하고 있습니다. 이러한 인스턴스는 Amazon S3에서 정기적으로 대량의 데이터를 읽고 쓰는 애플리케이션을 호스팅합니다.현재 서브넷 라우팅은 인터넷으로 향하는 모든 트래픽을 NAT 게이트웨이를 통해 지시합니다. 회사는 애플리케이션이 Amazon S3 또는 외부 인터넷과 통신할 수 있는 능력에 영향을 주지 않고 전체 비용을 최적화하고자 하는 경우 솔루션 설계자가 비용을 최적화하려면 어떻게 해야 합니까?\nA. 추가 NAT 게이트웨이 생성 NAT 게이트웨이로 라우팅할 라우팅 테이블을 업데이트하여 S3 트래픽을 허용하도록 네트워크 ACL을 업데이트합니다. B. 인터넷 게이트웨이 생성 라우팅 테이블을 업데이트하여 트래픽을 인터넷 게이트웨이로 라우팅합니다. S3 트래픽을 허용하도록 네트워크 ACL을 업데이트합니다. C. Amazon S3용 VPC 엔드포인트 생성 엔드포인트에 엔드포인트 정책 연결 VPC 엔드포인트로 트래픽을 전송하도록 라우팅 테이블을 업데이트합니다. D. VPC 외부에서 AWS Lambda 함수를 생성하여 S3 요청을 처리하기 위해 IAM 정책을 EC2 인스턴스에 연결하여 Lambda 함수를 호출할 수 있도록 합니다. #\rAnswer\r...\rAnswer: C\r#\rQ490\r#\r회사가 온프레미스 Oracle 데이터베이스를 Amazon RDS (또는 미국 동부 지역의 Oracle 다중 AZ DB 인스턴스) 로 마이그레이션했습니다.솔루션 설계자가 데이터베이스를 프로비저닝하도록 재해 복구 전략을 설계하고 있습니다. us-west-2 지역에서 데이터베이스를 us-east-1 리전에서 사용할 수 없게 될 경우설계에서는 데이터베이스가 us-west-2 리전에서 최대 2시간 내에 프로비저닝되고 데이터 손실 기간은 3시간을 넘지 않아야 합니다. 이러한 요구 사항을 어떻게 충족시킬 수 있습니까?\nA. DB 인스턴스를 편집하고 us-west-2에 읽기 전용 복제본을 생성합니다.재해 복구 환경을 활성화해야 하는 경우 읽기 전용 복제본을 master인 us-west-2로 승격합니다. B. us-west-2에 대기 인스턴스를 프로비저닝하려면 다중 리전 옵션을 선택합니다.재해 복구 환경을 만들어야 하는 경우 대기 인스턴스는 자동으로 master로 승격됩니다. us-west-2. C. 데이터베이스 인스턴스의 스냅샷을 자동으로 생성하여 3시간마다 us-west-2로 복사합니다.재해 복구 환경을 활성화해야 하는 경우 us-west-2에 다른 데이터베이스 인스턴스를 프로비저닝하려면 최신 스냅샷을 복원합니다. D. 여러 AWS 리전에서 멀티 마스터 읽기/쓰기 인스턴스 생성 us-east-1의 VPC를 선택하고 us-west-2에서 배포합니다.재해 복구 환경을 활성화할 필요가 없도록 us-west-2의 마스터 읽기/쓰기 인스턴스를 사용할 수 있도록 유지합니다. #\rAnswer\r...\rAnswer: A\r#\rQ491\r#\r회사는 미션 크리티컬 3대 웹 애플리케이션을 온프레미스에서 AWS 클라우드로 마이그레이션할 계획입니다.백엔드 데이터베이스는 다른 온-프레미스 시스템과 호환되며 온프레미스 데이터 센터에 남아 있습니다. 애플리케이션 계층은 프레젠테이션 계층과 데이터베이스 간의 빠르고 예측 가능한 응답 시간을 필요로 하며 클라이언트 웹 브라우저와 VPC 간에 전송되는 데이터를 위해 암호화가 필요합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. VPC와 온프레미스 데이터 센터 간의 데이터 전송을 위해 AWS Direct Connect 연결을 통한 VPN 터널을 사용합니다. B. 웹 트래픽 암호화에 SSL/TLS 사용 VPC와 온프레미스 데이터 센터 간의 데이터 전송에 VPN 터널을 사용합니다. C. 웹 트래픽 암호화에 SSL/TLS 사용 VPC와 온프레미스 데이터 센터 간의 데이터 전송에 AWS Direct Connect 연결을 사용합니다. D. 웹 트래픽 암호화에 SSL/TLS를 사용합니다.VPC와 온프레미스 데이터 센터 간의 데이터 전송을 위해 AWS Direct Connect 연결을 통한 VPN 터널을 사용합니다. #\rAnswer\r...\rAnswer: D\r#\rQ492\r#\r솔루션 설계자는 두 AWS 리전인 도쿄에 배포되는 동적 웹 사이트 “example.com”을 위한 솔루션을 설계하고 있습니다.일본과 시드니.호주.아키텍트는 호주에 있는 사용자가 시드니 AWS 리전에 배포된 웹 사이트로 이동하도록 하고 일본에 있는 사용자가 “example.com”을 탐색할 때 도쿄 AWS 리전의 웹 사이트로 이동하도록 하려고 합니다.최소 관리 노력으로이 목표를 달성하기 위해 건축가는 어떤 서비스를 사용해야합니까?\nA. 지리적 위치 라우팅을 지원하는 Amazon CloudFront B. Amazon 국도 53 C. 애플리케이션 로드 밸런서 D. 여러 지역에 배포된 네트워크 로드 밸런서 #\rAnswer\r...\rAnswer: A\r#\rQ493\r#\r회사는 VPC 피어링 전략을 사용하여 단일 리전에 VPC를 연결하여 교차 통신을 허용합니다.최근 계정 생성 및 VPC가 증가함에 따라 VPC 피어링 전략을 유지하기가 어려워졌으며, 이 회사는 수백 개의 VPC로 성장할 것으로 예상하고 있습니다.일부 VPC를 사용하여 사이트 간 VPN을 생성하라는 새로운 요청도 있습니다.솔루션 설계자는 여러 계정, VPNS 및 VPN에 대한 중앙 집중식 네트워킹 설정을 만드는 임무를 맡았습니다. 이러한 요구 사항을 충족하는 네트워킹 솔루션은 무엇입니까?\nA. 공유 VPC 및 VPN을 구성하고 서로 공유 B. 허브앤스포크를 구성하고 모든 트래픽을 VPC 피어링으로 라우팅합니다. C. 모든 VPC와 VPN 간에 AWS Direct Connect을 구성합니다. D. AWS 전송 게이트웨이를 사용하여 전송 게이트웨이를 구성하고 모든 VPC 및 VPN을 연결합니다. #\rAnswer\r...\rAnswer: D\r#\rQ494\r#\r회사는 상태 비저장 UDP 기반 워크로드의 가용성과 성능을 향상시키고자 합니다.워크로드가 여러 AWS 리전의 Amazon EC2 인스턴스에 배포됩니다. 이를 위해 솔루션 설계자는 무엇을 권장해야 합니까?\nA. EC2 인스턴스를 각 리전의 NLB (네트워크 로드 밸런서) 뒤에 배치 AWS 글로벌 Accelerator를 사용하여 Accelerator를 만듭니다.NLB를 Accelerator의 엔드 포인트로 사용 B. EC2 인스턴스를 각 리전의 ALB (애플리케이션 로드 밸런서) 뒤에 배치합니다.AWS 글로벌 Accelerator를 사용하여 Accelerator 생성 Accelerator의 엔드 포인트로 ALB를 사용 C. EC2 인스턴스를 각 리전의 NLB (네트워크 로드 밸런서) 뒤에 배치합니다.Amazon Route 53 지연 시간 기반 라우팅을 사용하여 요청을 NLB로 라우팅하는 오리진으로 Amazon CloudFront 배포를 생성합니다. D. 각 리전의 애플리케이션 로드 밸런서 (ALB) 뒤에 EC2 인스턴스를 배치 Amazon Route 53 지연 시간 기반 라우팅을 사용하여 요청을 ALB로 라우팅하는 오리진으로 Amazon CloudFront 배포를 만듭니다. #\rAnswer\r...\rAnswer: D\r#\rQ495\r#\r회사는 Amazon EC2 인스턴스에서 최대 200GB의 스토리지 공간이 필요한 애플리케이션을 호스팅합니다.이 응용 프로그램은 드물게 사용되며 아침과 저녁 시간에 봉우리가 사용됩니다. 디스크 I/O는 다양하지만 최대 3,000 IOPS입니다.이 회사의 최고 재무 책임자는 비용에 대해 우려하고 있으며 솔루션 설계자에게 성능을 저하시키지 않는 가장 비용 효율적인 스토리지 옵션을 추천해 달라고 요청했습니다. 솔루션 설계자는 어떤 솔루션을 권장해야합니까?\nA. Amazon EBS 콜드 HDD (sc1) B. Amazon EBS 범용 SSD (gp2) C. Amazon EBS 프로비저닝된 IOPS SSD (Io1) D. Amazon EBS 처리량 최적화 HDD (st1) #\rAnswer\r...\rAnswer: B\r#\rQ496\r#\r운영 팀은 IAM 정책을 사용자에게 직접 적용해서는 안 된다는 표준을 가지고 있습니다.일부 신입 회원은이 표준을 따르지 않았습니다.운영 관리자는 연결된 정책을 가진 사용자를 쉽게 식별할 수 있는 방법이 필요합니다.이를 달성하기 위해 솔루션 설계자는 무엇을해야합니까?\nA. AWS CloudTrail 사용 모니터링 B. 매일 실행할 AWS Config 규칙 생성 C. Amazon SNS에 대한 IAM 사용자 변경 사항 게시 D. 사용자가 수정되면 AWS Lambda 실행 #\rAnswer\r...\rAnswer: C\r#\rQ497\r#\r솔루션 설계자는 애플리케이션용 인프라를 설계하고 있습니다.응용 프로그램에 관리되는 MySQL 데이터베이스 매트가 있어야 고가용성이 있습니다.데이터베이스는 동일한 VPC의 리소스에 의해서만 검열됩니다. 데이터베이스에는 스토리지 및 컴퓨팅을 위한 Auto Scaling이 있어야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. MySQL용 Amazon RDS B. MySQL과 호환성이있는 Amazon Aurora C. MySQL의 호환성을 갖춘 Amazon Aurora 서버리스 D. Amazon EFS (Elastic 파일 시스템) 를 사용하는 Amazon EC2 인스턴스의 MySQL #\rAnswer\r...\rAnswer: A\r#\rQ498\r#\r솔루션 설계자는 이미지 카탈로그에 액세스하고 사용자에게 이미지 사용자 지정 요청을 제출할 수 있는 기능을 제공하는 솔루션을 설계하고 있습니다. 이미지 사용자 지정 매개 변수는 AWS API Gateway API로 전송되는 모든 요청에 포함됩니다.사용자 지정 이미지는 필요에 따라 생성되며 사용자가 클릭하여 사용자 지정 이미지를 보거나 다운로드할 수 있는 링크를 받게 됩니다.이 솔루션은 이미지를 보고 사용자 지정할 수 있는 가용성이 높아야 합니다. 이러한 요구 사항을 충족하는 가장 비용 효율적인 솔루션은 무엇입니까?\nA. Amazon EC2 인스턴스를 사용하여 원본 이미지를 요청된 사용자 지정으로 조작 원본 이미지 및 조작된 이미지를 Amazon S3에 저장 EC2 인스턴스 앞에 Elastic 로드 밸런서 구성 B. AWS Lambda를 사용하여 원본 이미지를 요청된 사용자 지정으로 조작된 원본 이미지를 Amazon S3에 저장 S3 버킷을 오리진으로 사용하여 Amazon CloudFront 배포를 구성합니다. C. AWS Lambda를 사용하여 원본 이미지를 요청된 사용자 지정으로 조작 원본 이미지를 Amazon S3에 저장하고 조작된 이미지를 Amazon DynamoDB에 저장 Amazon EC2 인스턴스 앞에 탄력적 로드 밸런서 구성 D. Amazon EC2 인스턴스를 사용하여 원본 이미지를 요청된 사용자 지정으로 조작 원본 이미지를 Amazon S3에 저장하고 조작된 이미지를 Amazon DynamoDB에 저장합니다. S3 버킷을 오리진으로 사용하여 Amazon CloudFront 배포를 구성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ499\r#\r회사는 Amazon S3에 과거 기상 기록을 호스팅합니다.레코드는 도메인 이름으로 확인되는 URL을 통해 회사 웹 사이트에서 다운로드됩니다.전 세계 사용자가 구독을 통해 이 콘텐츠에 액세스합니다. 타사 공급업체는 회사의 루트 도메인 이름을 호스팅하지만, 최근 일부 서비스를 Amazon Route 53로 마이그레이션했습니다. 회사는 계약을 통합하고, 사용자의 지연 시간을 줄이며,응용 프로그램을 구독자에게 제공합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. Amazon CloudFront에 웹 배포를 생성하여 애플리케이션용 S3 콘텐츠를 제공할 수 있습니다. Route 53 호스팅 영역에서 애플리케이션의 URL 도메인 이름을 확인하는 CloudFront 배포를 가리키는 CNAME 레코드를 생성합니다. B. 애플리케이션에 대한 S3 콘텐츠를 제공할 Amazon CloudFront에 웹 배포를 생성하여 애플리케이션의 URL 도메인 이름을 확인하는 CloudFront 배포를 가리키는 Amazon Route 53 호스팅 영역에 ALIAS 레코드 생성 C. 애플리케이션에 대한 Route 53 호스팅 영역에서 A 레코드 생성 웹 애플리케이션에 대한 Route 53 트래픽 정책을 생성하고 지리적 위치 규칙을 구성합니다.확인할 상태 확인 구성 (엔드포인트의 상태 및 엔드포인트가 비정상 상태인 경우 DNS 쿼리를 다른 엔드포인트로 라우팅합니다. D. 애플리케이션에서 Route 53 호스팅 영역에서 A 레코드를 생성합니다.웹 애플리케이션에 대한 Route 53 트래픽 정책을 생성하고 지리적 근접 규칙을 구성합니다.엔드포인트의 상태를 확인하고 엔드포인트가 비정상인 경우 DNS 쿼리를 다른 엔드포인트로 라우팅하도록 상태 확인을 구성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ500\r#\r솔루션 설계자가 Amazon EC2에서 고성능 컴퓨팅 (HPC) 워크로드를 설계하고 있습니다. EC2 인스턴스는 서로 자주 통신해야 하며 지연 시간이 짧고 처리량이 높은 네트워크 성능이 필요합니다. 어떤 EC2 구성이 이러한 요구 사항을 충족합니까?\nA. 하나의 가용 영역에 있는 클러스터 배치 그룹에서 EC2 인스턴스 시작 B. 하나의 가용 영역에 있는 스프레드 배치 그룹에서 EC2 인스턴스 시작 C. 두 리전의 Auto Scaling 그룹에서 EC2 인스턴스를 시작하고 VPC를 피어링합니다. D. 여러 가용 영역에 걸쳐 있는 Auto Scaling 그룹에서 EC2 인스턴스 시작 #\rAnswer\r...\rAnswer: A\r#\rQ501\r#\r개발 팀은 Amazon RDS MySQL DB 인스턴스 사용자 이름과 암호 자격 증명을 구성 파일에 저장합니다.구성 파일은 팀 Amazon EC2 인스턴스의 루트 디바이스 볼륨에 일반 텍스트로 저장됩니다.팀의 응용 프로그램이 데이터베이스에 도달해야하는 경우, 파일을 읽고 코드에 자격 증명을로드합니다.팀은 응용 프로그램만 콘텐츠를 읽을 수 있도록 구성 파일의 사용 권한을 수정했습니다. 솔루션 설계자는 보다 안전한 솔루션을 설계해야 합니다. 솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. 구성 파일을 Amazon S3에 저장합니다.응용 프로그램에 구성 파일을 읽을 수 있는 액세스 권한을 부여합니다. B. 데이터베이스에 액세스할 수 있는 권한이 있는 IAM 역할을 생성합니다. 이 IAM 역할을 EC2 인스턴스에 연결합니다. C. 데이터베이스 인스턴스에서 SSL 연결을 활성화합니다.로그인할 때 SSL을 요구하도록 데이터베이스 사용자를 변경합니다. D. 구성 파일을 EC2 인스턴스 스토어로 이동하고 인스턴스의 Amazon 머신 이미지 (AMI) 를 생성합니다.이 AMI에서 새 인스턴스를 시작합니다. #\rAnswer\r...\rAnswer: B\r#\rQ502\r#\r한 회사에서 온-프레미스 네트워크에서 공격자의 침해를 경험했습니다.공격자는 포트 스캔을 시작하고 아웃 바운드 Do5 공격에 대해 벌어지고 암호 해독 마이닝을 수행했습니다.이 회사는 계정 수준에서 이러한 유형의 공격을 모니터링하고 해결하는 보다 탄력적인 아키텍처를 구축하기 위해 AWS로 이전하고 있습니다. 회사는 이러한 요구 사항을 충족하기 위해 AWS 서비스를 어떻게 사용해야 합니까?\nA. Amazon GuardDuty에서 검색 결과를 생성하도록 설정합니다.식별된 위협의 자동 치료를 위해 AWS Lambda를 트리거합니다. B. AWS Config를 활성화하고 위반을 모니터링하도록 정책을 구성합니다.비준수 리소스의 자동 치료를 위해 AWS Lambda를 트리거합니다. C. Amazon Maie가 보안 위협을 식별하고 분류할 수 있도록 합니다.위협의 심각도에 따라 작업을 트리거하도록 Amazon EventBridge (Amazon CloudWatch 이벤트) 에서 이벤트를 구성합니다. D. Amazon Inspector이 평가 보고서를 생성할 수 있도록 합니다.식별된 위협에 따라 작업을 트리거하도록 Amazon EventBridge (Amazon CloudWatch 이벤트) 에서 이벤트를 구성합니다. #\rAnswer\r...\rAnswer: A\r#\rQ503\r#\r솔루션 설계자는 퍼블릭 및 프라이빗 서브넷이 있는 VPC를 설계하고 있습니다.VPC와 서브넷은 IPv4 CIDR 블록을 사용합니다.고가용성을 위해 3개의 가용 영역 (AZ) 각각에 퍼블릭 서브넷과 1개의 프라이빗 서브넷이 있습니다.인턴!게이트웨이는 퍼블릭 서브넷에 대한 인터넷 액세스를 제공하는 데 사용됩니다.프라이빗 서브넷은 Amazon EC2 인스턴스에서 소프트웨어 업데이트를 다운로드할 수 있도록 인터넷에 액세스해야 합니다.솔루션 설계자는 프라이빗 서브넷에 대한 인터넷 액세스를 활성화하기 위해 무엇을해야합니까?\nA. 각 AZ의 퍼블릭 서브넷마다 하나씩 3개의 NAT 게이트웨이를 생성합니다.VPC가 아닌 트래픽을 해당 AZ의 NAT 게이트웨이로 전달하는 각 AZ에 대한 프라이빗 라우팅 테이블 생성 B. 각 AZ의 프라이빗 서브넷마다 하나씩 3개의 NAT 인스턴스를 생성합니다.VPC가 아닌 트래픽을 해당 AZ의 NAT 인스턴스로 전달하는 각 AZ에 대해 프라이빗 라우팅 테이블을 생성합니다. C. 사설 서브넷 중 하나에 두 번째 인터넷 게이트웨이를 만듭니다.VPC 이외의 트래픽을 프라이빗 인터넷 게이트웨이로 전달하는 프라이빗 서브넷에 대한 라우팅 테이블 업데이트 D. 공용 서브넷 중 하나에 송신 전용 인터넷 게이트웨이를 만듭니다.VPC가 아닌 트래픽을 송신 전용 인터넷 게이트웨이로 전달하는 프라이빗 서브넷에 대한 라우팅 테이블 업데이트 #\rAnswer\r...\rAnswer: A\r#\rQ504\r#\r기업이 하이브리드 애플리케이션의 가용성과 성능을 개선하고자 합니다. 애플리케이션은 여러 AWS 리전의 Amazon EC2 인스턴스에서 호스팅되는 상태 저장 TCP 기반 워크로드와 온프레미스에서 호스팅되는 상태 비저장 UOP 기반 워크로드로 구성됩니다.가용성 및 성능을 향상시키기 위해 솔루션 설계자가 수행해야 하는 작업 조합은 무엇입니까?(두 개를 선택합니다.)\nA. AWS 글로벌 Accelerator를 사용하여 Accelerator를 만듭니다.로드 밸런서를 엔드포인트로 추가합니다. B. Amazon Route 53 지연 시간 기반 라우팅을 사용하여 요청을 로드 밸런서로 라우팅하는 오리진을 사용하여 Amazon CloudFront 배포를 생성합니다. C. 각 리전에서 두 개의 애플리케이션 로드 밸런서를 구성합니다.첫 번째 엔드 포인트는 EC2 엔드 포인트로 라우팅되고 두 번째 엔드 포인트는 온-프레미스 엔드 포인트로 라우팅됩니다. D. EC2 엔드 포인트를 처리하도록 각 리전에서 네트워크 로드 밸런서 구성 온 프레미스 엔드포인트로 라우팅하는 각 리전에서 네트워크 로드 밸런서 구성 E. EC2 엔드 포인트를 처리하도록 각 리전에서 네트워크 로드 밸런서 구성 온 프레미스 엔드포인트로 라우팅하는 각 리전에서 애플리케이션 로드 밸런서 구성 #\rAnswer\r...\rAnswer: A B\r#\rQ505\r#\r회사는 Amazon EC2 인스턴스 집합을 사용하여 온 프레미스 데이터 원본에서 데이터를 수집하고 있습니다.데이터는 JSON 형식이며 수집 속도는 1MB/s까지 높을 수 있습니다. EC2 인스턴스를 재부팅하면 진행 중인 데이터가 손실됩니다.이 회사의 데이터 과학 팀은 거의 실시간으로 수집한 데이터를 쿼리하려고 합니다. 데이터 손실을 최소화하면서 확장 가능한 거의 실시간 데이터 쿼리를 제공하는 솔루션은 무엇입니까?\nA. Amazon Kinesis Data Streams에 데이터를 게시합니다.Kinesis Data Analytics을 사용하여 데이터를 쿼리합니다. B. Amazon Redshift를 대상으로 하여 Amazon Kinesis Data Firehose에 데이터를 게시합니다.Amazon Redshift를 사용하여 데이터를 쿼리합니다. C. 수집한 데이터를 EC2 인스턴스 스토어에 저장 Amazon S3를 대상으로 사용하여 Amazon Kinesis 데이터 Firehose에 데이터를 게시합니다.Amazon Athena를 사용하여 데이터를 쿼리합니다. D. 수집한 데이터를 Amazon EBS (Elastic Block Store) 볼륨에 저장합니다.레디스용 Amazon 엘라스티카슈에 데이터를 게시합니다.Redis 채널을 구독하여 데이터를 쿼리합니다. #\rAnswer\r...\rAnswer: A\r#\rQ506\r#\r회사는 Amazon S3를 사용하여 기밀 감사 문서를 저장합니다.S3 버킷은 버킷 정책을 사용하여 최소 권한의 원칙에 따라 감사 팀 IAM 사용자 자격 증명에 대한 액세스를 제한합니다.회사 관리자는 S3 버킷에서 실수로 문서를 삭제하는 것에 대해 우려하고 있으며 보다 안전한 솔루션을 원합니다. 솔루션 설계자는 감사 문서를 보호하기 위해 무엇을 해야 합니까?\nA. AWS 키 관리 서비스 (AWS KMS\u0026gt;를 사용하여 S3 버킷을 암호화하고 감사 팀 IAM 사용자 계정이 KMS 키에 액세스하지 못하도록 제한합니다. B. 감사 팀의 IAM 사용자 계정에 S3 수명 주기 정책을 추가하여 감사 날짜 중 S3:DeleteOB|ect 작업을 거부합니다. C. 각 감사 팀 IAM 사용자 계정에 대한 IAM 사용자 자격 증명에서 멀티 팩터 인증 (MFA) 을 활성화합니다. D. S3 버킷에서 버전 관리 및 MFA 삭제 기능 활성화 #\rAnswer\r...\rAnswer: D\r#\rQ507\r#\r회사는 최근 AWS Direct Connect를 사용하여 하이브리드 클라우드 연결을 구현했으며 데이터를 Amazon S3로 마이그레이션하고 있습니다.이 회사는 온프레미스 스토리지 시스템과 AWS 스토리지 서비스 간의 데이터 복제를 자동화하고 가속화할 수 있는 완전 관리형 솔루션을 찾고 있습니다. 솔루션 설계자는 데이터를 비공개로 유지하기 위해 어떤 솔루션을 권장해야합니까?\nA. 온프레미스 환경에 AWS DataSync 에이전트 배포 데이터를 복제하고 AWS 서비스 엔드포인트에 연결하도록 동기화 작업을 구성합니다. B. 온프레미스 환경에 대해 AWS DataSync 에이전트를 배포합니다.지정 시간 스냅샷을 AWS에 복제하도록 배치 작업을 예약합니다. C. 온프레미스 환경을 위한 AWS Storage Gateway 볼륨 게이트웨이 배포 데이터를 로컬에 저장하고 특정 시점 스냅샷을 AWS에 비동기적으로 백업하도록 구성합니다. D. 온프레미스 환경에 대한 AWS 스토리지 게이트웨이 파일 게이트웨이를 배포합니다.데이터를 로컬에 저장하고 시점 스냅샷을 AWS에 비동기적으로 백업하도록 구성합니다. #\rAnswer\r...\rAnswer: A\r#\rQ508\r#\r회사는 상용 애플리케이션을 온프레미스 데이터 센터에서 AWS로 마이그레이션할 계획입니다.이 소프트웨어에는 예측 가능한 용량 및 가동 시간 요구 사항이 있는 소켓과 코어를 사용하는 소프트웨어 라이선스 모델이 있습니다.이 회사는 올해 초에 구입한 기존 라이선스를 사용하려고 합니다. 가장 비용 효율적인 Amazon EC2 요금 옵션은 무엇입니까?\nA. 전용 예약 호스트 B. 전용 주문형 호스트 C. 전용 예약 인스턴스 D. 전용 주문형 인스턴스 #\rAnswer\r...\rAnswer: A\r#\rQ509\r#\r회사가 VPC의 프라이빗 서브넷에서 호스팅되는 Amazon EC2 인스턴스에서 애플리케이션을 실행하고 있습니다.EC2 인스턴스는 Elastic 로드 밸런서 (ELB) 뒤에 있는 Auto Scaling 그룹에 구성되어 있습니다. EC2 인스턴스는 아웃바운드 인터넷 액세스를 위해 NAT 게이트웨이를 사용합니다. 그러나 EC2 인스턴스는 퍼블릭 인터넷에 연결하여 소프트웨어 업데이트를 다운로드할 수 없습니다. 이 문제의 근본 원인은 무엇입니까?(두 개 선택)\nA. ELB가 적절한 상태 확인으로 구성되지 않았습니다. B. VPC의 라우팅 테이블이 잘못 구성되었습니다. C. EC2 인스턴스가 Elastic IP 주소와 연결되지 않음 D. NAT 게이트웨이에 연결된 보안 그룹이 잘못 구성되었습니다. E. EC2 인스턴스에 연결된 보안 그룹의 아웃바운드 규칙이 잘못 구성되었습니다. #\rAnswer\r...\rAnswer: B E\r#\rQ510\r#\r임대 회사는 매월 모든 고객을 위해 PDF 명세서를 생성하고 이메일로 보냅니다.각 문의 크기는 약 400KB입니다.고객은 명세서가 생성된 날로부터 최대 30일 동안 웹 사이트에서 명세서를 다운로드할 수 있습니다.3년 임대 기간이 끝나면 고객에게 ZIP 파일을 이메일로 보내드립니다. 이 상황에서 가장 경제적인 스토리지 솔루션이란 무엇입니까?\nA. Amazon S3 표준 스토리지 클래스를 사용하여 명세서 저장 1일 후에 문을 Amazon S3 Glacier 스토리지로 이동하는 수명 주기 정책을 생성합니다. B. Amazon S3 Glacier 스토리지 클래스를 사용하여 명세서를 저장합니다. 30일 후에 명세서를 Amazon S3 Glacier 딥 아카이브 스토리지로 이동하는 수명 주기 정책을 생성합니다. C. Amazon S3 표준 스토리지 클래스를 사용하여 문을 저장합니다.30일 후에 명세서를 Amazon S3 원 영역 자주 사용되지 않는 액세스 (S3 원 영역-IA) 스토리지로 이동하는 수명 주기 정책을 생성합니다. D. Amazon S3 표준 자주 액세스 (S3 표준-IA) 스토리지 클래스를 사용하여 명세서를 저장합니다.30일 후에 명세서를 Amazon S3 Glacier 스토리지로 이동하는 수명 주기 정책을 생성합니다. #\rAnswer\r...\rAnswer: D\r#\rQ511\r#\r회사는 관리 및 프로덕션이라는 두 개의 VPC를 보유하고 있습니다.관리 VPC는 고객 게이트웨이를 통해 VPN을 사용하여 데이터 센터의 단일 디바이스에 연결합니다. 프로덕션 VPC는 두 개의 AWS Direct Connect 연결이 연결된 가상 프라이빗 게이트웨이를 사용합니다.관리 VPC와 프로덕션 VPC는 모두 단일 VPC 피어링 연결을 사용하여 애플리케이션 간의 통신을 허용합니다. 이 아키텍처의 단일 장애 지점을 완화하기 위해 솔루션 설계자는 무엇을해야합니까?\nA. 관리 VPC와 운영 VPC 사이에 VPN 집합을 추가합니다. B. 두 번째 가상 프라이빗 게이트웨이를 추가하고 관리 VPC에 연결합니다. C. 두 번째 고객 게이트웨이 디바이스에서 관리 VPC에 두 번째 VPN 집합을 추가합니다. D. 관리 VPC와 프로덕션 VPC 간에 두 번째 VPC 피어링 연결을 추가합니다. #\rAnswer\r...\rAnswer: B\r#\rQ512\r#\r회사가 내부 브라우저 기반 애플리케이션을 운영합니다. 애플리케이션은 애플리케이션 로드 밸런서 뒤의 Amazon EC2 인스턴스에서 실행됩니다. 인스턴스는 여러 가용 영역에 걸쳐 Amazon EC2 Auto Scaling 그룹에서 실행됩니다. Auto Scaling 그룹은 작업 시간 동안 최대 20개의 인스턴스로 확장되지만 축소됩니다.에 2 개의 인스턴스 밤새 직원은 아침까지 잘 실행되지만 하루가 시작될 때 응용 프로그램이 매우 느리다고 불평하고 있습니다.직원의 불만 사항을 해결하고 비용을 최소한으로 유지하기 위해 스케일링을 어떻게 변경해야 합니까?\nA. 사무실이 열리기 직전에 원하는 용량을 20으로 설정하는 예약된 작업을 구현합니다. B. 낮은 CPU 임계값에서 트리거된 단계 조정 작업을 구현하고 휴지 기간을 줄입니다. C. 낮은 CPU 임계값에서 트리거된 대상 추적 동작을 구현하고 휴지 기간을 줄입니다. D. 사무실이 열리기 직전에 최소 및 최대 용량을 20으로 설정하는 예약된 작업을 구현합니다. #\rAnswer\r...\rAnswer: A\r#\rQ513\r#\r솔루션 설계자는 고객 대면 애플리케이션을 설계하고 있습니다.이 애플리케이션은 연중 시간에 따라 읽기 및 쓰기의 양이 다양하고 일년 내내 명확하게 정의된 액세스 패턴을 가질 것으로 예상됩니다.관리를 위해서는 AWS 클라우드에서 데이터베이스 감사 및 확장을 관리해야 합니다.RPO (복구 시점 목표) 는 5시간 미만이어야 합니다. 어떤 솔루션을 통해 이를 달성할 수 있습니까?(두 개를 선택합니다.)\nA. 자동 크기 조정과 함께 Amazon DynamoDB를 사용합니다.온 디맨드 백업 및 AWS CloudTrail을 사용합니다. B. 자동 크기 조정과 함께 Amazon DynamoDB를 사용합니다.온 디맨드 백업 및 Amazon DynamoDB 스트림을 사용합니다. C. Amazon Redshift 동시성 조정 구성을 사용합니다.감사 로깅을 활성화합니다.4시간마다 데이터베이스 스냅숏을 수행합니다. D. 프로비저닝된 IOPS로 Amazon RDS를 사용합니다.데이터베이스 감사 매개 변수를 활성화합니다.데이터베이스 스냅숏을 5시간마다 수행합니다. E. Amazon RDS를 자동 크기 조정으로 사용합니다.데이터베이스 감사 매개 변수를 활성화합니다.백업 보존 기간을 최소 1일 이상으로 구성합니다. #\rAnswer\r...\rAnswer: A E\r#\rQ514\r#\rAmazon S3의 웹 사이트.이 웹 사이트는 매월 페타바이트의 아웃바운드 트래픽을 제공하며, 이는 회사의 AWS 비용의 대부분을 차지합니다.솔루션 설계자는 비용을 절감하기 위해 무엇을해야합니까?\nA. 기존 웹 사이트를 오리진으로 사용하여 Amazon CloudFront를 구성합니다. B. 스토리지를 위해 Amazon EBS 볼륨이 있는 Amazon EC2로 웹 사이트를 이동합니다. C. AWS Global Accelerator를 사용하여 기존 웹 사이트를 엔드포인트로 지정합니다. D. Amazon API 게이트웨이와 AWS Lambda의 조합으로 실행되도록 웹 사이트를 재설계합니다. #\rAnswer\r...\rAnswer: A\r#\rQ515\r#\r회사는 단일 공장에 위치한 여러 기계에서 매일 10TB의 계측 데이터를 받습니다. 데이터는 공장 내에 있는 온프레미스 데이터 센터의 SAN (저장 영역 네트워크) 에 저장된 JSON 파일로 구성됩니다.이 회사는 Amazon S3로 이 데이터를 전송하려고 합니다. 이 데이터는 실제와 가까운 중요한 분석을 제공하는 몇 가지 추가 시스템에서 액세스할 수 있습니다.데이터가 민감한 것으로 간주되기 때문에 보안 전송이 중요합니다.가장 신뢰할 수 있는 데이터 전송을 제공하는 솔루션은 무엇입니까?\nA. 퍼블릭 인터넷을 통한 AWS 데이터비동기 B. AWS Direct Connect을 통한 AWS 데이터비동기 C. 퍼블릭 인터넷을 통한 AWS 데이터베이스 마이그레이션 서비스 (AWS DMS) D. AWS Direct Connect을 통한 AWS 데이터베이스 마이그레이션 서비스 (AWS DMS) #\rAnswer\r...\rAnswer: D\r#\rQ516\r#\r회사는로드 밸런싱 된 프론트 엔드로 구성된 전자 상거래 애플리케이션을 개발하고 있습니다. 컨테이너 기반 애플리케이션 및 관계형 데이터베이스 솔루션 설계자는 가능한 한 적은 수동 개입으로 작동하는 고가용성 솔루션을 만들어야합니다.요구 사항이 있습니까?(두 개를 선택합니다.)\nA. 다중 AZ 모드에서 Amazon RDS DB 인스턴스 생성 B. Amazon RDS DB 인스턴스와 다른 가용 영역에 하나 이상의 복제본 생성 C. 동적 애플리케이션 로드를 처리할 Amazon EC2 인스턴스 기반 Docker 클러스터를 생성합니다. - D. Fargate 시작 유형을 사용하여 동적 애플리케이션 로드를 처리할 Amazon ECS (Amazon Elastic Container Service) 클러스터를 생성합니다. E. Amazon EC2 시작 유형으로 Amazon ECS (탄력적 컨테이너 서비스) 클러스터를 생성하여 동적 애플리케이션 로드를 처리합니다. #\rAnswer\r...\rAnswer: A D\r#\rQ517\r#\r회사는 데이터를 수집하여 온-프레미스 NFS 서버에 저장하는 온-프레미스 응용 프로그램을 보유하고 있습니다.이 회사는 최근 10Gbps의 AWS Direct Connect 연결을 설정했습니다.이 회사는 온프레미스에서 스토리지 용량이 부족합니다.이 회사는 온프레미스 애플리케이션의 데이터에 대한 액세스 지연 시간을 줄이면서 온프레미스 애플리케이션의 애플리케이션 데이터를 온프레미스에서 AWS 클라우드로 마이그레이션해야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. 애플리케이션 데이터에 대한 AWS 스토리지 게이트웨이를 배포하고 파일 게이트웨이를 사용하여 Amazon S3에 데이터를 저장합니다.NFS를 사용하여 온-프레미스 응용 프로그램 서버를 파일 게이트웨이에 연결합니다. B. Amazon EFS (Elastic 파일 시스템) 파일 시스템을 NFS 서버에 연결하고 애플리케이션 데이터를 EFS 파일 시스템으로 복사합니다.그런 다음 온프레미스 애플리케이션을 Amazon EFS에 연결합니다. C. AWS 스토리지 게이트웨이를 볼륨 게이트웨이로 구성합니다.NFS 서버 및 Amazon EBS (Elastic Block Store) 스냅샷에서 온 프레미스 애플리케이션에서 애플리케이션 데이터를 사용할 수 있도록 합니다. D. NFS 서버를 소스 위치로 사용하고 Amazon EFS (Elastic 파일 시스템) 파일 시스템을 애플리케이션 데이터 전송의 대상으로 사용하여 AWS DataAsync 에이전트를 생성합니다.EFS 파일 시스템에 온-프레미스 응용 프로그램을 연결합니다. #\rAnswer\r...\rAnswer: A\r#\rQ518\r#\r한 회사에서 Amazon EC2를 사용하여 빅 Data Analytics 워크로드를 실행하고 있습니다.이러한 가변 워크로드는 매일 밤 실행되며 다음 날 업무 시작까지 완료하는 것이 중요합니다.솔루션 설계자는 가장 비용 효율적인 솔루션을 설계하는 임무를 맡았습니다. 어떤 솔루션이 이것을 달성 할 것인가?\nA. 스팟 플릿 B. 스팟 인스턴스 C. 예약 인스턴스 D. 온 디맨드 인스턴스 #\rAnswer\r...\rAnswer: C\r#\rQ519\r#\r경영진은 예산 계획의 일환으로 사용자별로 나열된 AWS 청구 항목에 대한 보고서를 원합니다.데이터는 부서 예산을 생성하는 데 사용됩니다.솔루션 설계자는 이 보고서 정보를 얻는 가장 효율적인 방법을 결정해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. Amazon Athena와 쿼리를 실행하여 보고서를 생성합니다. B. 비용 탐색기에서 보고서를 생성하고 보고서를 다운로드합니다. C. 결제 대시보드에서 청구서 세부 정보에 액세스하여 청구서를 다운로드합니다. D. Amazon SES (단순 이메일 서비스) 를 통해 경고하도록 AWS 예산의 비용 예산을 수정합니다. #\rAnswer\r...\rAnswer: B\r#\rQ520\r#\r회사가 Amazon S3 버킷에 60TB의 프로덕션 수준 데이터를 호스팅하고 있습니다. 솔루션 설계자는 분기별 감사 요구 사항을 위해 해당 데이터를 온프레미스로 가져와야 합니다. 전송 중에 데이터를 암호화해야 합니다. 이 회사는 AWS와 온프레미스 데이터 간에 네트워크 대역폭이 낮습니다.Center 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. 데이터 전송을 위한 90일 복제 윈도우가 있는 AWS 마이그레이션 허브를 배포합니다. B. AWS에 AWS 스토리지 게이트웨이 볼륨 게이트웨이 배포 90일 복제 기간 사용 가능 데이터 전송 C. 수명 주기 정책이 활성화된 Amazon EFS (Elastic 파일 시스템) 를 AWS에 배포합니다.데이터를 전송하는 데 사용하십시오. D. AWS Snowball 콘솔에서 내보내기 작업 요청을 완료한 후 온프레미스 데이터 센터에 AWS Snowball 디바이스를 배포합니다. #\rAnswer\r...\rAnswer: D\r#\rQ521\r#\r솔루션 설계자가 2계층 웹 애플리케이션을 설계하고 있습니다. 애플리케이션은 퍼블릭 서브넷의 Amazon EC2에서 호스팅되는 공용 웹 티어로 구성됩니다. 데이터베이스 계층은 프라이빗 서브넷의 Amazon EC2에서 실행되는 Microsoft SQL Server로 구성되며 보안은 회사의 우선 순위입니다.보안 그룹을 구성할 수 있습니까?(두 개 선택)\nA. 0.0.0.0/0에서 포트 443에서 인바운드 트래픽을 허용하도록 웹 계층에 대한 보안 그룹을 구성합니다. B. 0.0.0.0/0 C에서 포트 443에서 아웃바운드 트래픽을 허용하도록 웹 계층에 대한 보안 그룹을 구성합니다. C. 웹 계층의 보안 그룹에서 포트 1433의 인바운드 트래픽을 허용하도록 데이터베이스 계층에 대한 보안 그룹을 구성합니다. D. 포트 443과 1433에서 웹 계층의 보안 그룹에 대한 아웃바운드 트래픽을 허용하도록 데이터베이스 계층에 대한 보안 그룹을 구성합니다. E. 웹 계층의 보안 그룹에서 포트 443과 1433의 인바운드 트래픽을 허용하도록 데이터베이스 계층에 대한 보안 그룹을 구성합니다. #\rAnswer\r...\rAnswer: A C\r#\rQ522\r#\r다음 IAM 정책이 IAM 그룹에 연결됩니다.이 정책은 그룹에 적용되는 유일한 정책입니다.\n그룹 구성원에 대한 이 정책의 유효한 IAM 권한은 무엇입니까?\nA. 그룹 구성원은 uss-east-1 리전 내에서 Amazon EC2 작업을 수행할 수 있습니다.허용 권한 이후의 문은 적용되지 않습니다. B. 그룹 구성원은 멀티 팩터 인증 (MFA) 으로 태그가 지정되지 않은 경우 us-east-1 리전에서 Amazon EC2 권한이 거부됩니다. C. 그룹 멤버는 멀티 팩터 인증 (MFA) 으로 로그인한 경우 모든 리전에 대해 EC2:Stop 인스턴스 및 EC2:종료 권한을 사용할 수 있습니다.그룹 구성원은 다른 Amazon EC2 작업을 승인했습니다. D. 그룹 멤버는 다중 요소 인증 (MFA) 으로 로그인한 경우에만 EC2:Stop lnstances 및 EC2:us-east-1 리전에 대한 lnstances 종료 권한이 허용됩니다.그룹은 us-east-1 리전 내에서 다른 모든 Amazon EC2 작업이 허용됩니다. #\rAnswer\r...\rAnswer: D\r#\rQ523\r#\r솔루션 설계자는 직원과 파트너가 파일을 교환할 수 있는 온-프레미스 솔루션을 완전히 관리되는 대체품을 제공해야 합니다. 온-프레미스 시스템, 원격 직원 및 외부 파트너로부터 연결하는 직원이 솔루션에 쉽게 액세스할 수 있어야 합니다.요구 사항이 있습니까?\nA. SFTP를 위한 AWS 전송을 사용하여 Amazon S3에서 파일을 송수신합니다. B. 로컬 스토리지 및 대규모 데이터 전송에 AWS Snowball Edge를 사용합니다. C. Amazon FSX를 사용하여 파일을 저장하고 전송하여 원격으로 사용할 수 있도록 설정 D. AWS 스토리지 게이트웨이를 사용하여 Amazon S3에 파일을 저장하고 전송할 볼륨 게이트웨이를 생성합니다. #\rAnswer\r...\rAnswer: A\r#\rQ524\r#\r한 회사에서 여러 가용 영역에 걸쳐 Elastic 로드 밸런서 뒤에 Amazon EC2 인스턴스를 사용하여 웹 사이트를 호스팅하고 있습니다.인스턴스는 EC2 Auto Scaling 그룹에서 실행됩니다.이 웹 사이트는 Amazon EBS (Elastic Block Store) 볼륨을 사용하여 사용자가 다운로드할 수 있도록 제품 설명서를 저장합니다. 회사는 제품 콘텐츠를 자주 업데이트하므로 Auto Scaling 그룹에서 시작한 새 인스턴스에는 오래된 데이터가 있는 경우가 많습니다.새 인스턴스가 모든 업데이트를 수신하는 데 최대 30분이 걸릴 수 있습니다.또한 업데이트에는 업무 시간 중에 EBS 볼륨의 크기를 조정해야 합니다.이 회사는 아키텍처가 사용자 수요 증가에 따라 신속하게 조정되는 모든 데이터에 대한 제품 설명서가 항상 적합한지 확인하려고 합니다.솔루션 설계자는 회사에서 응용 프로그램 코드를 업데이트하거나 웹 사이트를 조정하지 않고도 이러한 요구 사항을 충족해야 합니다.솔루션 설계자는이 목표를 달성하기 위해 무엇을해야합니까?\nA. 제품 설명서를 EBS 볼륨에 저장합니다.해당 볼륨을 EC2 인스턴스에 마운트합니다. B. 제품 설명서를 Amazon S3 버킷에 저장합니다.다운로드를 이 버킷으로 리디렉션합니다. C. Amazon EFS (Elastic 파일 시스템) 볼륨에 제품 설명서를 저장합니다. 해당 볼륨을 EC2 인스턴스에 마운트합니다. D. 제품 설명서를 Amazon S3 표준 Standard Infrequent Access (S3 Standard-IA) 버킷에 저장합니다. 다운로드를 이 버킷으로 리디렉션합니다. #\rAnswer\r...\rAnswer: C\r#\rQ525\r#\r한 회사에서 포렌직 회계 데이터가 Amazon RDS DB 인스턴스에 저장되어 외부 감사자와 공유하려고 합니다. Auditor는 자체 AWS 계정을 보유하고 있으며 자체 데이터베이스 복사본이 필요합니다. 회사가 감사자와 데이터베이스를 안전하게 공유하려면 어떻게 해야 합니까?\nA. 데이터베이스의 읽기 전용 복제본을 생성하고 IAM 표준 데이터베이스 인증을 구성하여 감사자에게 액세스 권한을 부여합니다. B. 데이터베이스의 스냅샷을 Amazon S3로 복사하고 감사자에게 IAM 역할을 할당하여 해당 버킷의 객체에 대한 액세스 권한을 부여합니다. C. 데이터베이스 콘텐츠를 텍스트 파일로 내보내고, 파일을 Amazon S3에 저장하고, 해당 버킷에 액세스할 수 있는 감사자를 위한 새 IAM 사용자를 생성합니다. D. 데이터베이스의 암호화된 스냅샷을 만들고, 스냅샷을 공유하고, AWS KMS (키 관리 서비스) 암호화 키에 대한 액세스를 허용합니다. #\rAnswer\r...\rAnswer: D\r#\rQ526\r#\r저장 객체의 내구성이나 성능에 영향을 주지 않고 운영 환경에서 Amazon S3 스토리지 비용을 절감하고자 하는 회사는 이러한 목표를 달성하기 위해 수행해야 하는 첫 번째 단계는 무엇입니까?\nA. 비즈니스 크리티컬한 S3 버킷에서 Amazon Made 활성화 객체의 민감도를 분류합니다. B. S3 분석을 통해 S3 표준 - Standard Infrequent Access (S3 표준-IA) 로 전환할 수 있는 S3 버킷을 식별할 수 있습니다. C. 모든 비즈니스 크리티컬 S3 버킷에서 버전 관리를 활성화합니다. D. 모든 S3 버킷의 객체를 S3 Intelliginet 타이 링으로 마이그레이션합니다. #\rAnswer\r...\rAnswer: D\r#\rQ527\r#\r회사는 월 단위로 통화 녹음을 저장 통계적으로, 기록 된 데이터는 1 년 이내에 무작위로 참조 될 수 있지만 1 년 후에는 거의 액세스 1 년 이상 된 파일을 쿼리하고 가능한 한 빨리 검색해야합니다.이전 파일 검색 지연이 허용됩니다. 솔루션 설계자는 최소한의 비용으로 기록 된 데이터를 저장해야합니다. 어떤 솔루션이 가장 비용 효율적입니까?\nA. Amazon S3 Glacier에 개별 파일을 저장하고 S3 Glacier 쿼리 S3 Glacier 태그에 생성된 객체 태그에 검색 메타데이터를 저장하고 S3 Glacier에서 파일을 검색합니다. B. Amazon S3에 개별 파일 저장 1년 후에 수명 주기 정책을 사용하여 파일을 Amazon S3 Glacier로 이동합니다.Amazon S3 또는 S3 Glacier에서 파일을 쿼리하고 검색합니다. C. Amazon S3의 각 아카이브에 대한 개별 파일 보관 및 검색 메타데이터 저장 1년 후 수명 주기 정책을 사용하여 파일을 Amazon S3 Glacier로 이동 Amazon S3에서 메타데이터를 검색하여 파일을 쿼리하고 검색합니다. D. Amazon S3에 개별 파일 보관 1년 후 수명 주기 정책을 사용하여 파일을 Amazon S3 Glacier로 이동 Amazon DynamoDB에 검색 메타데이터 저장 DynamoDB에서 파일을 쿼리하고 Amazon S3 또는 S3 Glacier에서 해당 파일을 검색합니다. #\rAnswer\r...\rAnswer: B\r#\rQ528\r#\r한 회사에서 데이터 처리를 위해 하이브리드 워크로드를 실행하려고 합니다.NFS 프로토콜을 사용하여 로컬 데이터 처리를 위해 온프레미스 애플리케이션에서 데이터에 액세스해야 하며, 추가 분석 및 배치 처리를 위해 AWS 클라우드에서도 액세스할 수 있어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. AWS 스토리지 게이트웨이 fife 게이트웨이를 사용하여 AWS에 파일 스토리지를 제공한 다음 AWS 클라우드의 데이터에 대한 분석을 수행합니다. B. AWS Storage Gateway 테이프 게이트웨이를 사용하여 로컬 데이터의 백업을 AWS에 복사한 다음 AWS 클라우드에서 이 데이터에 대한 분석을 수행합니다. C. 저장된 볼륨 구성에서 AWS Storage Gateway 볼륨 게이트웨이를 사용하여 로컬 데이터의 스냅샷을 정기적으로 생성한 다음 데이터를 AWS로 복사합니다. D. 캐시된 볼륨 구성에서 AWS Storage Gateway 볼륨 게이트웨이를 사용하여 AWS 클라우드의 모든 로컬 스토리지를 백업한 다음 클라우드에서 이 데이터에 대한 분석을 수행합니다. #\rAnswer\r...\rAnswer: A\r#\rQ529\r#\r회사는 관계형 데이터베이스 서버에 대한 운영 체제 권한이 필요합니다. 고가용성 데이터베이스 아키텍처의 구성으로 솔루션 설계자는 무엇을 제안해야합니까?\nA. 두 개의 가용 영역을 사용하는 데이터베이스 복제 구성의 여러 Amazon EC2 인스턴스 B. 선택한 데이터베이스가 설치된 독립형 Amazon FC2 인스턴스 C. 프로비저닝된 IOPS가 포함된 다중 AZ 구성 D. 배치 그룹을 사용하는 복제 구성의 여러 Amazon EC2 인스턴스 #\rAnswer\r...\rAnswer: A\r#\rQ530\r#\r회사가 마이크로서비스 애플리케이션을 개발했습니다. Amazon API Gateway와 함께 클라이언트 연결 API와 Amazon EC2 인스턴스에서 호스팅되는 여러 내부 서비스를 사용하여 사용자 요청을 처리합니다. API는 예측할 수 없는 트래픽 급증을 지원하도록 설계되었지만 내부 서비스가 압도될 수 있으며서지 중 일정 기간 동안 응답하지 않음 솔루션 설계자는 내부 서비스가 응답하지 않거나 사용할 수 없게 될 때 오류를 줄이는 보다 안정적인 솔루션을 설계해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. 트래픽이 급증하는 경우 AWS Auto Scaling을 사용하여 내부 서비스를 확장할 수 있습니다. B. 다른 가용 영역을 사용하여 내부 서비스 호스팅 내부 서비스가 응답하지 않을 경우 시스템 관리자에게 알림 보내기 C. Elastic 로드 밸런서를 사용하여 내부 서비스 간에 트래픽 분산 Amazon CloudWatch 지표를 구성하여 내부 서비스에 대한 트래픽을 모니터링합니다. D. Amazon SQS (단순 대기열 서비스) 를 사용하여 사용자 요청 도착 시 저장 처리를 위해 대기열에서 요청을 검색하도록 내부 서비스를 변경합니다. #\rAnswer\r...\rAnswer: D\r#\rQ531\r#\r전 세계 사용자를 위해 AWS에 선거 보고 웹 사이트를 호스팅하고 있습니다. 웹 사이트는 애플리케이션 로드 밸런서가 있는 Auto Scaling 그룹의 웹 및 애플리케이션 계층에 Amazon EC2 인스턴스를 사용합니다. 데이터베이스 계층은 MySQL용 Amazon RDS를 사용합니다. 웹 사이트는한 시간에 한 번 결과를 얻었으며 역사적으로 수백 명의 사용자가 보고서에 액세스하는 것을 관찰했습니다. 회사는 상당한 증가를 기대하고 있습니다.솔루션 설계자가 개선해야 함 추가 EC2 인스턴스에 대한 필요성을 최소화하면서 추가 수요를 처리할 수 있는 웹 사이트의 기능 어떤 솔루션이 이러한 요구 사항을 충족합니까?\nA. Amazon ElastiCache 클러스터를 시작하여 일반적인 데이터베이스 쿼리를 캐시합니다. B. Amazon CloudFront 웹 배포를 시작하여 일반적으로 요청되는 웹 사이트 콘텐츠를 캐시합니다. C. EC2 인스턴스에서 디스크 기반 캐싱을 활성화하여 일반적으로 요청되는 웹 사이트 콘텐츠를 캐시합니다. D. 일반적으로 요청되는 웹 사이트 콘텐츠에 대해 캐싱이 활성화된 EC2 인스턴스를 사용하여 설계에 역방향 프록시를 배포합니다. #\rAnswer\r...\rAnswer: B\r#\rQ532\r#\r회사는 매일 데이터를 처리하고 있습니다.운영 결과는 매일 1주일 동안 분석되는 Amazon S3 버킷에 저장되며, 가끔 분석을 위해 즉시 액세스할 수 있어야 합니다. 현재 구성에 비해 가장 비용 효율적인 스토리지 솔루션은 무엇입니까?\nA. 30일 후에 객체를 삭제하도록 수명 주기 정책을 구성합니다. B. 30일 후 객체를 Amazon S3 Glacier로 전환하도록 수명 주기 정책을 구성합니다. C. 30일 후에 객체를 Amazon S3 표준 Standard Infrequent Access (S3 표준-IA) 로 전환하도록 수명 주기 정책을 구성합니다. D. 30일 후에 객체를 Amazon S3 원 영역 Standard Infrequent Access (S3 원 영역-IA) 로 전환하도록 수명 주기 정책을 구성합니다. #\rAnswer\r...\rAnswer: D\r#\rQ533\r#\r웹 사이트는 정오에 매일 트래픽 폭증을 수신하는 웹 응용 프로그램을 실행합니다.사용자는 매일 새로운 사진과 콘텐츠를 업로드하지만 시간 초과에 대해 불평하고 있습니다.아키텍처는 Amazon EC2 Auto Siteing을 사용하며 사용자 지정 애플리케이션은 사용자 요청에 응답하기 전에 부팅 시 일관되게 시작하는 데 1분 정도 걸립니다. 어떻게 솔루션 설계자는 변화하는 트래픽에 더 잘 대응하기 위해 아키텍처를 다시 설계해야 합니까?\nA. 느린 시작 구성으로 네트워크 로드 밸런서를 구성합니다. B. 서버에 직접 요청을 오프로드하도록 Redis용 AWS ElastiCache를 구성합니다. C. 인스턴스 예열 조건을 사용하여 Auto Scaling 단계 조정 정책을 구성합니다. D. 애플리케이션 로드 밸런서를 오리진으로 사용하도록 Amazon CloudFront를 구성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ534\r#\r한 회사는 지난 몇 년 동안 Amazon RDS 인스턴스에 분석 데이터를 저장해 왔습니다.이 회사는 솔루션 설계자에게 사용자가 API를 사용하여이 데이터에 액세스 할 수있는 솔루션을 찾도록 요청했습니다. 응용 프로그램이 비활성 기간을 경험하지만 몇 초 내에 트래픽이 폭발할 수 있다는 기대는 솔루션 설계자가 제안해야하는 솔루션은 무엇입니까?\nA. Amazon API 게이트웨이를 설정하고 Amazon ECS를 사용합니다. B. Amazon API 게이트웨이를 설정하고 AWS Elastic Beanstalk 사용 C. Amazon API 게이트웨이 설정 및 AWS Lambda 함수 사용 D. Amazon API 게이트웨이를 설정하고 자동 크기 조정과 함께 Amazon EC2를 사용합니다. #\rAnswer\r...\rAnswer: C\r#\rQ535\r#\r한 회사에서 10TB Amazon Aurora MySQL DB 클러스터에서 워크로드 집약적 쿼리를 실행하려고 합니다. 월별 보고서를 생성하려면 데이터베이스에 임시 스키마를 변경해야 합니다. 그러나 진행 중인 프로덕션 클러스터에는 이러한 변경 사항이 필요하지 않습니다. 이러한 요구 사항을 충족하려면 운영 효율성이 가장 높은 솔루션을 선택해야 합니다. 회사는 어떤 솔루션을 선택해야합니까?\nA. 데이터베이스 클론을 생성하고 보고에 복제본을 사용합니다. B. Aurora 읽기 전용 복제본을 생성하여 보고에 사용 C. 필요한 테이블을 Amazon S3로 내보냅니다. Amazon을 사용하여 데이터를 쿼리합니다. D. 프로덕션 DB 클러스터의 스냅샷 생성 보고를 위해 스냅샷을 새 데이터베이스로 복원합니다. #\rAnswer\r...\rAnswer: B\r#\rQ536\r#\r최근에 인수한 회사는 AWS에 자체 인프라를 구축하고 한 달 이내에 여러 애플리케이션을 클라우드로 마이그레이션해야 합니다.각 애플리케이션에는 약 50TB의 데이터를 전송할 수 있습니다. 마이그레이션 작업이 완료되면 모회사는 데이터 센터에서 애플리케이션까지 일관된 처리량과 함께 안전한 네트워크 연결이 필요합니다.솔루션 설계자는 일회성 데이터 마이그레이션과 지속적인 네트워크 연결을 보장해야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. AWS 다이렉트 커넥트 (Direct Connect) 는 초기 전송 B. 초기 전송 및 지속적인 연결을 위한 AWS 사이트 간 VPN. C. 초기 전송을 위해서는 AWS Snowball을 사용하고 지속적인 연결을 위해서는 AWS 다이렉트 커넥트. D. 초기 전송을 위한 AWS Snowball과 지속적인 연결을 위한 AWS 사이트 간 VPN입니다. #\rAnswer\r...\rAnswer: C\r#\rQ537\r#\r회사는 사용자에게 최소한의 지연 시간이 필요한 모바일 앱용 아키텍처를 만들고 있습니다. 이 회사의 아키텍처는 Auto Scaling 그룹에서 실행되는 애플리케이션 로드 밸런서 뒤에 있는 Amazon EC2 인스턴스로 구성됩니다. EC2 인스턴스는 Amazon RDS에 연결됩니다.애플리케이션 베타 테스트에서 데이터를 읽을 때 속도가 느려지는 것으로 나타났습니다. 그러나 메트릭은 EC2 인스턴스가 CPU 사용률 임계값을 넘지 않는다는 것을 나타냅니다. 어떻게 이 문제를 해결할 수 있습니까?\nA. Auto Scaling 그룹에서 CPU 사용률에 대한 임계값 감소 B. 애플리케이션 로드 밸런서를 네트워크 로드 밸런서로 교체합니다. C. RDS 인스턴스에 대한 읽기 전용 복제본을 추가하고 읽기 트래픽을 복제본으로 직접 전송합니다. D. RDS 인스턴스에 다중 AZ 지원을 추가하고 새 EC2 인스턴스로 읽기 트래픽을 전송합니다. #\rAnswer\r...\rAnswer: C\r#\rQ538\r#\r회사는 7개의 Amazon EC2 인스턴스를 사용하여 AWS에서 웹 애플리케이션을 호스팅합니다. 회사는 DNS 쿼리에 응답하여 모든 정상 EC2 인스턴스의 IP 주소를 반환해야 합니다. 이 요구 사항을 충족하기 위해 어떤 정책을 사용해야 합니까?\nA. 단순 라우팅 정책 B. 지연 시간 라우팅 정책 C. 다중값 라우팅 정책 D. 지리적 위치 라우팅 정책 #\rAnswer\r...\rAnswer: C\r#\rQ539\r#\r회사는 Amazon ECS를 사용하여 애플리케이션을 실행합니다.애플리케이션은 원본 이미지의 크기가 조정된 버전을 생성한 다음 Amazon S3 API를 호출하여 크기가 조정된 이미지를 Amazon S3에 저장합니다.솔루션 설계자는 애플리케이션에 Amazon S3에 액세스할 수 있는 권한이 있는지 어떻게 확인할 수 있습니까?\nA. Amazon ECS에서 읽기/쓰기 액세스를 허용하도록 AWS IAM에서 S3 역할을 업데이트한 다음 컨테이너를 다시 시작합니다. B. S3 권한을 가진 IAM 역할을 생성한 다음 해당 역할을 작업 정의에서 TaskroLearn 로 지정합니다. C. Amazon ECS에서 Amazon S3로의 액세스를 허용하는 보안 그룹을 생성하고 ECS 클러스터에서 사용하는 시작 구성을 업데이트합니다. D. S3 권한이 있는 IAM 사용자를 생성한 다음 이 계정으로 로그인한 상태에서 ECS 클러스터의 Amazon EC2 인스턴스를 다시 시작합니다. #\rAnswer\r...\rAnswer: B\r#\rQ540\r#\r회사에는 두 개의 애플리케이션이 있습니다. 처리할 페이로드가 있는 메시지를 보내는 발신자 애플리케이션과 페이로드가 포함된 메시지를 수신하기 위한 처리 애플리케이션 이 회사는 두 애플리케이션 간에 메시지를 처리하기 위해 AWS 서비스를 구현하려고 합니다.보낸 사람 응용 프로그램은 매시간 약 1,000개의 메시지를 보낼 수 있습니다. 메시지가 처리되기까지 최대 2일이 걸릴 수 있습니다. 메시지가 처리되지 않으면 나머지 메시지의 처리에 영향을 미치지 않도록 보존해야 합니다.효율적입니까?\nA. Redis 데이터베이스를 실행하는 Amazon EC2 인스턴스 설정 두 애플리케이션 모두 인스턴스를 사용하도록 구성 메시지를 각각 저장, 처리 및 삭제합니다. B. Amazon Kinesis Data Streams을 사용하여 발신자 애플리케이션의 메시지 수신 처리 애플리케이션을 Kinesis 클라이언트 라이브러리 (KCL) 와 통합 C. 보낸 사람 및 프로세서 애플리케이션을 Amazon SQS (단순 대기열 서비스) 대기열과 통합합니다.처리에 실패한 메시지를 수집하도록 데드 레터 큐를 구성합니다. D. 처리 애플리케이션을 Amazon SNS (단순 알림 서비스) 주제에 구독하여 처리할 알림을 수신합니다. 발신자 애플리케이션을 통합하여 SNS 주제에 씁니다. #\rAnswer\r...\rAnswer: C\r#\rQ541\r#\r회사는 API에 의해 구동되는 클라우드 통신 플랫폼 평가판을 설계하고 있습니다.애플리케이션은 NLB (네트워크 로드 밸런서) 뒤에 있는 Amazon EC2 인스턴스에서 호스팅됩니다.이 회사는 Amazon API Gateway를 사용하여 외부 사용자에게 API를 통해 애플리케이션에 대한 액세스 권한을 제공합니다.이 회사는 SQL Injection과 같은 웹 공격으로부터 플랫폼을 보호하고자 하며 크고 정교한 DDoS 공격을 탐지하고 완화하고자 합니다. 어떤 솔루션 조합이 MosT 보호를 제공합니까?(두 개를 선택합니다.)\nA. AWS WAF를 사용하여 NLB 보호 B. NLB와 함께 AWS 쉴드 어드밴스 사용 C. AWS WAF를 사용하여 Amazon API 게이트웨이 보호 D. AWS 실드 표준과 함께 Amazon GuardDuty 사용 E. Amazon API 게이트웨이와 함께 AWS 실드 표준 사용 #\rAnswer\r...\rAnswer: A D\r#\rQ542\r#\rAmazon EC2 인스턴스에서 호스팅되는 회사의 애플리케이션은 Amazon S3 버킷에 액세스해야 합니다.데이터 민감도로 인해 트래픽이 인터넷을 통과 할 수 없습니다. 솔루션 설계자는 액세스를 어떻게 구성해야합니까?\nA. Amazon Route 53을 사용하여 프라이빗 호스팅 영역을 생성합니다. B. VPC에서 Amazon S3에 대한 VPC 게이트웨이 엔드포인트를 구성합니다. C. EC2 인스턴스와 S3 버킷 간에 AWS 프라이버트링크를 구성합니다. D. VPC와 S3 버킷 간에 사이트 간 VPN 연결을 설정합니다. #\rAnswer\r...\rAnswer: B\r#\rQ543\r#\r회사는 Amazon S3 버킷을 외부 공급업체와 공유해야 합니다.버킷 소유자는 모든 객체에 액세스할 수 있어야 합니다. S3 버킷을 공유하기 위해 수행해야 하는 작업은 무엇입니까?\nA. 버킷을 요청자 지불 버킷으로 업데이트합니다. B. 버킷을 업데이트하여 원본 간 리소스 공유 (CPORS) 를 활성화합니다. C. 사용자가 객체를 업로드할 때 버킷 소유자 전체를 허용하도록 요구하는 버킷 정책을 생성합니다. D. 객체를 업로드할 때 버킷 소유자에게 모든 권한을 부여하도록 요구하는 IAM 정책을 생성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ544\r#\r회사는 150TB의 아카이빙된 이미지 데이터를 온프레미스에 저장하여 깎아 내야 합니다. 를 다음 달 이내에 AWS 클라우드로 마이그레이션할 수 있습니다.이 회사의 현재 네트워크 연결은 야간에만 최대 100Mbps의 업로드를 허용합니다.이 데이터를 이동하고 마이그레이션 기한을 충족할 수 있는 가장 경제적인 메커니즘은 무엇입니까?\nA. AWS 스노우모빌을 사용하여 데이터를 AWS로 발송합니다. B. 데이터를 AWS로 전송하기 위해 여러 AWS Snowball 디바이스를 주문합니다. C. Amazon S3 Transfer Acceleration을 활성화하고 데이터를 안전하게 업로드합니다. D. Amazon S3 VPC 엔드포인트를 생성하고 VPN을 설정하여 데이터를 업로드합니다. #\rAnswer\r...\rAnswer: B\r#\rQ545\r#\rAmazon EC2 인스턴스에서 실행되는 애플리케이션은 Amazon DynamoDB 테이블에 액세스해야 합니다. EC2 인스턴스와 DynamoDB 테이블이 모두 동일한 AWS 계정에 있습니다. 솔루션 설계자는 필요한 권한을 구성해야 합니다. EC2 인스턴스에서 DynamoDB 테이블에 대한 최소 권한 액세스를 허용하는 솔루션은 무엇입니까?\nA. 적절한 정책을 사용하여 IAM 역할 생성 DynamoDB 테이블에 대한 액세스를 허용하기 위한 인스턴스 프로필을 생성하여 이 IAM 역할을 EC2 인스턴스에 할당합니다. B. DynamoDB 테이블에 대한 액세스를 허용하는 적절한 정책으로 IAM 역할 생성 EC2 인스턴스를 신뢰 관계 정책 문서에 추가하여 역할을 수임할 수 있도록 허용합니다. C. 적절한 정책을 사용하여 IAM 사용자를 생성하여 DynamoDB 테이블에 대한 액세스를 허용하십시오. 자격 증명을 Amazon S3 버킷에 저장하고 애플리케이션 코드 내에서 직접 읽습니다. D. DynamoDB 테이블에 대한 액세스를 허용하는 적절한 정책을 사용하여 IAM 사용자 생성 애플리케이션이 로컬 스토리지에 IAM 자격 증명을 안전하게 저장하고 이를 사용하여 DynamoDB #\rAnswer\r...\rAnswer: A\r#\rQ546\r#\r회사는 사용자 데이터를 AWS에 저장합니다.데이터는 업무 시간 동안 최대 사용량에 따라 지속적으로 사용됩니다. 액세스 패턴은 다양하며 일부 데이터는 한 번에 몇 달 동안 사용되지 않습니다.솔루션 설계자는 고가용성을 유지하면서 최고 수준의 내구성을 유지하는 비용을 선택해야 합니다. 이러한 요구 사항을 충족하는 스토리지 솔루션은 무엇입니까?\nA. Amazon S3 표준 B. Amazon S3 지능형 계층화 C. Amazon S3 Glacier 딥 아카이브 D. Amazon S3 One Zone Standard Infrequent Access (S3 원 영역-IA) #\rAnswer\r...\rAnswer: B\r#\rQ547\r#\r회사는 대규모 데이터 세트를 분석하기 위해 Amazon S3에 데이터 레이크 솔루션을 개발하고 있습니다.이 솔루션은 자주 사용되지 않는 SOL 쿼리만 수행하며, 인프라 비용을 최소화하고자 합니다. 이러한 요구 사항을 충족하려면 어떤 AWS 서비스를 사용해야 합니까?\nA. Amazon Athena B. Amazon Redshift 스펙트럼 C. PostgreSQL을 위한 Amazon RDS D. Amazon Aurora #\rAnswer\r...\rAnswer: A\r#\rQ548\r#\r한 회사가 Amazon S3 버킷을 사용하여 여러 위치에서 다른 부서에서 업로드한 데이터를 저장하고 있습니다. AWS의 잘 설계된 검토를 통해 재무 관리자는 매달 10TB의 S3 표준 스토리지 데이터가 청구되었음을 알립니다. 그러나 Amazon S3용 AWS 관리 콘솔에서는모든 파일과 폴더를 선택하는 명령은 총 크기가 5TB입니다. 이 차이의 가능한 원인은 무엇입니까?(두 개 선택)\nA. 일부 파일은 중복 제거와 함께 저장됩니다. B. S3 버킷의 버전 관리가 활성화되었습니다. C. S3 멀티파트 업로드가 불완전합니다. D. S3 버킷에 AWS KMS (키 관리 서비스) 가 활성화되어 있음 E. S3 버킷에 Intelliginet 계층화가 활성화되어 있습니다. #\rAnswer\r...\rAnswer: A E\r#\rQ549\r#\r솔루션 설계자는 AWS에 배포되는 새로운 애플리케이션을 위한 클라우드 아키텍처를 설계하고 있습니다.이 응용 프로그램을 사용하면 대화 형으로 파일을 다운로드하고 업로드 할 수 있습니다.2년 이상 된 파일은 자주 액세스할 수 없습니다.솔루션 설계자는 높은 가용성과 내구성을 유지하면서 응용 프로그램을 원하는 수의 파일로 확장할 수 있도록 해야 합니다.솔루션 설계자가 권장해야 하는 확장 가능한 솔루션은 무엇입니까?(두 개를 선택합니다.)\nA. 2년 이상 된 객체를 S3 Glacier로 이동하는 수명 주기 정책과 함께 파일을 Amazon S3에 저장합니다. B. 2년 이상 된 객체를 S3 표준 Standard Infrequent Access (S3 표준-IA) 로 이동하는 수명 주기 정책과 함께 Amazon S3에 파일을 저장합니다. C. 2년 이상 된 객체를 EFS IA (Standard Infrequent Access 권한) 로 이동하는 수명 주기 정책과 함께 Amazon EFS (Elastic File System) 에 파일을 저장합니다. D. Amazon EBS (Elastic Block Store) 볼륨에 파일을 저장합니다.볼륨의 스냅샷을 예약합니다.스냅샷을 사용하여 2년 이상 된 데이터를 아카이브합니다. E. 파일을 RAID 스트라이프 Amazon Elastic Block Store (Amazon EBS) 볼륨에 저장합니다.볼륨의 스냅샷을 예약합니다.스냅샷을 사용하여 2년 이상 된 데이터를 아카이브합니다. #\rAnswer\r...\rAnswer: A B\r#\rQ550\r#\r회사는 기존 파일 공유 서비스를 보유하고 있지 않습니다.새 프로젝트를 수행하려면 온-프레미스 데스크톱용 드라이브로 마운트할 수 있는 파일 저장소에 대한 액세스가 필요합니다.파일 서버는 Active Directory 도메인에 대해 사용자를 인증해야 저장소에 액세스할 수 있습니다.Active Directory 사용자가 데스크톱에 스토리지를 드라이브로 마운트할 수 있는 서비스는 무엇입니까?\nA. Amazon S3 Glacier B. AWS 데이터비동기 C. AWS Snowball Edge D. AWS 스토리지 게이트웨이 #\rAnswer\r...\rAnswer: D\r#\rQ551\r#\r애플리케이션 팀은 Amazon EMR을 사용하여 Amazon S3에 있는 데이터 세트를 사용하여 배치 작업을 실행하기 시작했습니다. 워크로드의 초기 테스트 중에 솔루션 설계자는 계정이 NAT 게이트웨이 데이터 처리 비용을 발생하기 시작한다는 사실을 알립니다. 어떻게 학습을 통해 워크로드 비용을 최적화할 수 있습니까?\nA. Amazon EMR 클러스터가 실행 중인 서브넷에서 NAT 게이트웨이를 분리합니다. B. NAT 게이트웨이를 고객 게이트웨이로 교체 C. NAT 게이트웨이를 S3 VPC 엔드포인트로 교체 D. Amazon EMR 클러스터가 실행 중인 서브넷에 네트워크 ACL을 구성하여 Amazon S3에 대한 액세스를 엽니다. #\rAnswer\r...\rAnswer: A\r#\rQ552\r#\r회사는 사용자가 방문하는 장소에 체크인하고 장소의 순위를 매기며 경험에 대한 리뷰를 추가 할 수있는 응용 프로그램을 만들었습니다. 응용 프로그램은 매달 사용자 수가 급격히 증가함에 따라 성공적입니다. 최고 기술 책임자는 현재 인프라를 지원하는 데이터베이스를 두려워합니다.는 MySQL용 Amazon RDS 인스턴스가 읽기 요청으로 인한 리소스 소모와 관련된 경보를 트리거했기 때문에 다음 달에 새 로드를 처리하지 못할 수도 있습니다.솔루션 설계자는 코드 변경을 최소화하면서 데이터베이스 계층에서 서비스 중단을 방지하기 위해 무엇을 권장 할 수 있습니까?\nA. RDS 읽기 전용 복제본을 생성하고 읽기 전용 트래픽을 읽기 전용 복제본 엔드 포인트로 리디렉션 다중 AZ 배포를 활성화합니다. B. Amazon EMR 클러스터를 생성하고 복제 계수가 3인 하둡 분산 파일 시스템 (HDFS) 으로 데이터를 마이그레이션합니다. C. Amazon ElastiCache 클러스터를 생성하고 모든 읽기 전용 트래픽을 클러스터로 리디렉션합니다.세 개의 가용 영역을 배포하도록 클러스터를 설정합니다. D. Amazon DynamoDB 테이블을 생성하여 RDS 인스턴스를 대체하고 모든 읽기 전용 트래픽을 DynamoDB 테이블로 리디렉션하여 DynamoDB Accelerator를 활성화하여 기본 테이블에서 트래픽을 오프로드합니다. #\rAnswer\r...\rAnswer: A\r#\rQ553\r#\r회사는 온프레미스에서 다중 계층 웹 애플리케이션을 실행하고 있습니다.웹 응용 프로그램은 컨테이너화되고 사용자 레코드를 포함하는 PostgreSQL 데이터베이스에 연결된 여러 Linux 호스트에서 실행됩니다.인프라 유지 관리 및 용량 계획의 운영 오버헤드로 인해 회사의 성장이 제한되고 있습니다. 솔루션 설계자는 애플리케이션의 인프라를 개선해야 합니다.이 작업을 수행하기 위해 솔루션 설계자가 수행해야 하는 작업 조합은 무엇입니까?(두 개를 선택합니다.)\nA. PostgreSQL 데이터베이스를 Amazon Aurora로 마이그레이션 B. Amazon EC2 인스턴스에서 호스팅할 웹 애플리케이션을 마이그레이션합니다. C. 웹 애플리케이션 콘텐츠에 대한 Amazon CloudFront 배포를 설정합니다. D. 웹 애플리케이션과 PostgreSQL 데이터베이스 간에 Amazon ElastiCache를 설정합니다. E. Amazon Elastic 컨테이너 서비스 (Amazon ECS) 를 사용하여 AWS Fargate에서 호스팅할 웹 애플리케이션을 마이그레이션합니다. #\rAnswer\r...\rAnswer: A E\r#\rQ554\r#\r회사는 두 개의 가용 영역에 걸쳐 Amazon EC2 인스턴스에서 실행되는 웹 사이트를 보유하고 있습니다.이 회사는 특정 휴일에는 트래픽이 급증할 것으로 예상하며 일관된 사용자 환경을 제공하고자 합니다.솔루션 설계자는 어떻게 이러한 요구 사항을 충족시킬 수 있습니까?\nA. 단계 스케일링을 사용합니다. B. 단순 배율 조정을 사용합니다. C. 수명 주기 후크를 사용합니다. D. 스케줄링된 크기 조정을 사용합니다. #\rAnswer\r...\rAnswer: D\r#\rQ555\r#\r회사가 여러 애플리케이션 로드 밸런서 뒤에 웹 사이트를 호스팅하고 있습니다.이 회사는 전 세계의 콘텐츠에 대해 서로 다른 배포 권한을 가지고 있습니다.솔루션 설계자는 배포 권한을 위반하지 않고 사용자에게 올바른 콘텐츠를 제공하는지 확인해야 합니다.솔루션 설계자는 이러한 요구 사항을 충족하기 위해 어떤 구성을 선택해야 합니까?\nA. AWS WAF를 사용하여 Amazon CloudFront을 구성합니다 B. AWS WAF를 사용하여 애플리케이션 로드 밸런서를 구성합니다. C. 지리적 위치 정책을 사용하여 Amazon Route 53을 구성합니다. D. 지리적 근접 라우팅 정책을 사용하여 Amazon Route 53을 구성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ556\r#\r한 회사가 새로운 서버를 사용하지 않는 워크로드를 배포할 준비를 하고 있습니다.솔루션 설계자는 AWS Lambda 함수를 호출하기 위한 권한을 구성해야 합니다.이 함수는 Amazon 이벤트 브리지 (Amazon 클라우드워치 이벤트) 규칙에 의해 트리거됩니다.권한은 최소 권한의 원칙을 사용하여 구성되어야 합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. Lambda (LNvokeFunction) 를 액션으로, *를 주체로 사용하여 함수에 실행 역할을 추가합니다. B. Lambda를 사용하여 함수에 실행 로트를 추가합니다. LNVokeFunction을 작업 및 서비스로 추가합니다. 이벤트를 주체로 삼았습니다. C. Lambda (lambda) 를 사용하여 함수에 리소스 기반 정책을 추가합니다. 이벤트를 주체로 간주합니다. D. Lambda를 사용하여 함수에 리소스 기반 정책을 추가합니다. 작업 및 서비스로 호출함수를 호출합니다. #\rAnswer\r...\rAnswer: C\r#\rQ557\r#\r한 회사에서 Amazon S3를 객체 스토리지 솔루션으로 사용하고 있습니다.이 회사는 데이터를 저장하는 데 사용하는 수천 개의 S3를 보유하고 있습니다.일부 S3 버킷에는 다른 버킷보다 자주 액세스하지 않는 데이터가 있습니다.솔루션 설계자는 수명 주기 정책이 일관되게 구현되지 않거나 부분적으로 구현되지 않아 데이터가 고가의 스토리지에 저장된다는 사실을 발견했습니다.객체의 가용성을 저하시키지 않으면서 비용을 절감할 수 있는 솔루션은 무엇입니까?\nA. S3 ACL 사용 B. Amazon Elastic Block Store EBS 사용) 자동화된 스냅샷 C. S3 Intelliginet 계층화 스토리지 사용 D. S3 One Zone Standard Infrequent Access (S3 One Zone-IA) 를 사용합니다. #\rAnswer\r...\rAnswer: C\r#\rQ558\r#\r모놀리식 애플리케이션이 최근에 AWS로 마이그레이션되었으며 이제 단일 Amazon EC2 인스턴스에서 실행 중입니다.응용 프로그램 제한 사항으로 인해 자동 크기 조정을 응용 프로그램을 확장 할 수 있습니다. CTO (최고 기술 책임자) 는 기본 하드웨어에 장애가 발생할 경우 EC2 인스턴스를 복원하기 위한 자동화된 솔루션을 원합니다. 가능한 한 빨리 EC2 인스턴스를 자동으로 복구 할 수있는 것은 무엇입니까?\nA. EC2 인스턴스가 손상될 경우 이를 트리거하는 Amazon CloudWatch 경보를 구성합니다. B. EC2 인스턴스가 손상되었을 때 CTO에 경보를 알리는 SNS 메시지를 트리거하도록 Amazon CloudWatch 경보를 구성합니다. C. EC2 인스턴스의 상태와 장애가 발생하면 트리거된 인스턴스 복구를 모니터링하도록 AWS CloudTrail을 구성합니다. D. EC2 인스턴스의 상태를 확인하고 EC2 인스턴스가 비정상인 경우 인스턴스 복구를 트리거하는 AWS Lambda 함수를 한 시간에 한 번 트리거하도록 Amazon EventBridge 이벤트를 구성합니다. #\rAnswer\r...\rAnswer: A\r#\rQ559\r#\r회사는 개발자가 기존 IAM 정책을 기존 IAM 역할에 연결하여 사용할 수 있도록 허용합니다 (실험 및 민첩성 그러나 보안 운영 팀은 개발자가 기존 관리자 정책을 연결할 수 있다고 우려하고 있습니다. 따라서 개발자는 다른보안 정책 솔루션 설계자는 이 문제를 어떻게 해결해야 합니까?\nA. 개발자가 새 정책을 생성할 때마다 알림을 전송하도록 Amazon SNS 주제를 생성합니다. B. 서비스 제어 정책을 사용하여 조직 구성 단위 C의 모든 계정에서 IAM 활동을 비활성화합니다. C. 개발자가 정책을 연결하지 못하도록 하고 모든 IAM 임무를 보안 운영 팀에 할당하지 못하도록 합니다. D. 관리자 정책 첨부를 명시적으로 거부하는 개발자 IAM 역할에 IAM 권한 경계를 설정합니다. #\rAnswer\r...\rAnswer: D\r#\rQ560\r#\r최근 기업의 IT 비용을 분석한 결과 백업 비용을 절감해야 하는 필요성을 강조했습니다.이 회사의 최고 정보 책임자는 물리적 백업 테이프를 사용하지 않아도 온프레미스 백업 인프라를 간소화하고 비용을 절감하고자 합니다.이 회사는 온-프레미스 백업 응용 프로그램 및 워크플로에 대한 기존 투자를 보존해야 합니다. 솔루션 설계자는 무엇을 추천해야합니까?\nA. NFS 인터페이스를 사용하여 백업 애플리케이션과 연결하도록 AWS 스토리지 게이트웨이를 설정합니다. B. NFS 인터페이스를 사용하여 백업 애플리케이션과 연결하는 Amazon EFS 파일 시스템 설정 C. iSCSI 인터페이스를 사용하여 백업 애플리케이션과 연결하는 Amazon EFS 파일 시스템을 설정합니다. D. iSCSI-가상 테이프 라이브러리 (VTL) 인터페이스를 사용하여 백업 애플리케이션과 연결하도록 AWS 스토리지 게이트웨이를 설정합니다. #\rAnswer\r...\rAnswer: D\r#\rQ561\r#\r회사에는 매일 1TB의 상태 경고를 총괄적으로 생성하는 수천 개의 에지 장치가 있습니다. 각 경고의 크기는 약 2KB입니다. 솔루션 아키텍트는 다음과 같은 솔루션을 구현해야합니다. 향후 분석을 위해 경고를 수집하고 저장합니다. 회사는 고 가용성 솔루션을 원합니다. 그러나 회사는 비용을 최소화해야하고 추가 인프라를 관리하고 싶지 않습니다. 또한 회사는 즉각적인 분석을 위해 14 일의 데이터를 보관하고 14 일이 지난 데이터를 보관하려고합니다. 이러한 요구 사항을 충족하는 가장 효율적인 운영 솔루션은 무엇입니까?\nA. Amazon Kinesis Data Firehose 전송 스트림을 생성하여 알림을 수집합니다. Amazon S3 버킷에 알림을 전송하도록 Kinesis Data Firehose 스트림을 구성합니다. 14 일 후에 데이터를 Amazon S3 Glacier로 전환하도록 S3 수명주기 구성을 설정합니다. B. 두 가용 영역에서 Amazon EC2 인스턴스를 시작하고 Elastic Load Balancer 뒤에 배치하여 알림을 수집합니다. Amazon S3 버킷에 경고를 저장할 EC2 인스턴스에서 스크립트를 생성합니다. 14 일 후에 데이터를 Amazon S3 Glacier로 전환하도록 S3 수명주기 구성을 설정합니다. C. Amazon Kinesis Data Firehose 전송 스트림을 생성하여 알림을 수집합니다. Amazon Elasticsearch Service (Amazon ES) 클러스터에 알림을 전송하도록 Kinesis Data Firehose 스트림을 구성합니다. 매일 수동 스냅 샷을 생성하고 14 일보다 오래된 데이터를 클러스터에서 삭제하도록 Amazon ES 클러스터를 설정합니다. D. Amazon Simple Queue Service (Amazon SQS) 표준 대기열을 생성하여 알림을 수집하고 메시지 보존 기간을 14 일로 설정합니다. SQS 대기열을 폴링하도록 소비자를 구성하여 메시지의 수명을 확인하고 메시지가 14 일이 지난 경우 필요에 따라 메시지 데이터를 분석합니다. 소비자는 메시지를 Amazon S3 버킷에 복사하고 SQS 대기열에서 메시지를 삭제해야합니다. #\rAnswer\r...\rAnswer: A\r#\rQ562\r#\r솔루션 아키텍트는 부하에 따라 10 ~ 50 개의 Amazon EC2 동시 인스턴스가 실행되는 탄력적 인 애플리케이션을 설계하고 있습니다. 각 인스턴스는 동일한 50GB 폴더를 읽고 쓸 스토리지를 마운트해야합니다. 요구 사항을 충족하는 스토리지 유형은 무엇입니까?\nA. Amazon S3 B. Amazon Elastic File System (Amazon EFS) C. Amazon Amazon Elastic Block Store (Amazon EBS) 볼륨 D. Amazon EC2 인스턴스 스토어 #\rAnswer\r...\rAnswer: B\r#\rQ563\r#\r회사는 회사 데이터 센터에서 useast-1 리전의 VPC로 AWS Direct Connect 연결을 가지고 있습니다. 이 회사는 최근에 여러 VPC와 온 프레미스 데이터 센터와 eu-west-2 리전 간의 Direct Connect 연결이있는 회사를 인수했습니다. 회사와 회사의 VPC에 대한 CIDR 블록은 겹치지 않습니다. 회사는 두 지역과 데이터 센터 간의 연결이 필요합니다. 이 회사는 운영 오버 헤드를 줄이면서 확장 가능한 솔루션이 필요합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. VPC m us-east-1과 eu-west-2의 VPC간에 리전 간 VPC 피어링을 설정합니다. B. us-east-1의 Direct Connect 연결에서 euwest-2의 VPC로 프라이빗 가상 인터페이스를 생성합니다. C. Amazon EC2에서 호스팅하는 완전히 메시 된 VPN 네트워크에서 VPN 어플라이언스 설정 AWS VPN CloudHub를 사용하여 데이터 센터와 각 VPC간에 데이터를 보내고받습니다. D. 기존 Direct Connect 연결을 Direct Connect 게이트웨이에 연결합니다. 각 리전의 VPC 가상 프라이빗 게이트웨이에서 Direct Connect 게이트웨이로 트래픽을 라우팅합니다. #\rAnswer\r...\rAnswer: D\r#\rQ564\r#\rAmazon EC2 인스턴스에서 시작된 애플리케이션은 Amazon Simple Notification Service (Amazon SNS)를 사용하는 고객에 대한 PH (개인 식별 정보)를 게시해야합니다. 애플리케이션은 Amazon VPC 내의 프라이빗 서브넷에서 시작됩니다. 애플리케이션이 동일한 AWS 리전의 서비스 엔드 포인트에 액세스하도록 허용하는 가장 안전한 방법은 무엇입니까?\nA. 인터넷 게이트웨이 사용 B. AWS PrivateLink 사용 C. NAT 게이트웨이를 사용합니다. D. 프록시 인스턴스 사용 #\rAnswer\r...\rAnswer: B\r#\rQ565\r#\r솔루션 아키텍트는 AWS Cloud Formation 템플릿을 사용하여 3 계층 웹 애플리케이션을 배포합니다. 웹 애플리케이션은 Amazon DynamoDB 테이블에서 사용자 데이터를 저장하고 검색하는 웹 계층과 애플리케이션 계층으로 구성됩니다. 웹 및 애플리케이션 계층은 Amazon EC2 인스턴스에서 호스팅되며 데이터베이스 계층은 공개적으로 액세스 할 수 없습니다. 애플리케이션 EC2 인스턴스는 템플릿에서 API 자격 증명을 노출하지 않고 DynamoDB 테이블에 액세스해야합니다. 솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. DynamoOB 테이블을 읽을 IAM 역할을 생성합니다. 인스턴스 프로필을 참조하여 역할을 애플리케이션 인스턴스와 연결합니다. B. DynamoOB 테이블에서 읽고 쓰는 데 필요한 권한이있는 IAM 역할을 생성합니다. EC2 인스턴스 프로필에 역할을 추가하고 인스턴스 프로필을 apphcanon 인스턴스와 연결합니다. C. AWS CkHidFormaton 템플릿의 파라미터 섹션을 사용하여 사용자 입력 액세스 권한을 부여하고 이미 생성 된 IAM 사용자 매트의 보안 키는 DynamoOB 테이블에서 읽고 쓰는 데 필요한 권한을 갖습니다. D. DynamoOB 테이블에서 읽고 쓰는 데 필요한 권한이있는 AWS CioudFormation 템플릿에서 IAM 사용자를 생성합니다. GetAti 함수를 사용하여 액세스 및 비밀 키를 검색하고 사용자 데이터를 통해 애플리케이션 인스턴스에 전달합니다. #\rAnswer\r...\rAnswer: B\r#\rQ566\r#\r회사에서 Amazon Route 53, Application Load Balancer (ALB) 및 Amazon EC2 Auto Scaling 그룹을 사용하여 새 애플리케이션을 시작하려고합니다. 이 회사는 사용자 경험 테스트를 준비하고 있으며 프로젝트의이 단계에 대한 예산이 제한되어 있습니다. 회사는 향후 부하 테스트를 수행 할 계획이지만 불필요한 EC2 자동 확장을 제한하기 위해 사용자가 현재 부하 테스트를하지 못하게하려고합니다. 솔루션 아키텍트는 사용자 경험 테스트 비용을 최소화하기 위해 무엇을해야합니까?\nA. AWS Shield의 클라이언트 요청 임계 값을 클라이언트 당 100 개의 연결로 구성합니다. B. 각 클라이언트가 만들 수있는 요청 수를 제한하도록 구성된 속도 기반 규칙을 사용하여 ALB에 AWS WAF를 배포합니다. C. 고급 요청 라우팅 정책으로 ALB를 구성하여 Auto Scaling 그룹으로 전송되는 클라이언트 연결을 제한합니다. D. ALB와 Auto Scaling 그룹 사이에 Amazon Simple Queue Service (Amazon SQS)를 배포하여 클라이언트 요청을 대기시키고 Auto Scaling 그룹 최대 크기를 1로 변경합니다. #\rAnswer\r...\rAnswer: B\r#\rQ567\r#\r한 회사에는 수백만 개의 연결된 장치에서 보안 위협을 스캔하고 스캔 로그를 Amazon S3 버킷에 푸시하는 애플리케이션이 있습니다. 매주 총 70GB의 데이터가 생성되며 회사는 이력보고를 위해 3 년 분량의 데이터를 저장해야합니다. 회사는 복잡한 분석 쿼리를 수행하고 최소한의 시간에 조인하여 Amazon S3의 데이터를 처리, 집계 및 보강해야합니다. 집계 된 데이터 세트는 Amazon QuickSight 대시 보드에 시각화됩니다. 솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 무엇을 권장해야합니까?\nA. AWS Glue에서 ETL 작업을 생성하고 실행하여 Amazon S3의 데이터를 처리하고 Amazon Redshift에로드합니다. Amazon Redshift에서 집계 쿼리를 수행합니다. B. S3 PutObject 이벤트 트리거를 기반으로 AWS Lambda 함수를 사용하여 증분 변경 사항을 Amazon DynamoDB에 복사합니다. DynamoDB에서 집계 쿼리를 수행합니다. C. S3 PutObject 이벤트 트리거를 기반으로하는 AWS Lambda 함수를 사용하여 증분 변경 사항을 Amazon Aurora MySQL에 복사 Aurora MySQL에서 집계 쿼리를 수행합니다. D. AWS Glue를 사용하여 Amazon S3의 데이터를 분류합니다. Amazon Athena를 사용하여 카탈로그 화 된 테이블에서 집계 쿼리를 수행합니다. Amazon S3에서 직접 데이터를 쿼리합니다. #\rAnswer\r...\rAnswer: A\r#\rQ568\r#\r레스토랑 예약 애플리케이션은 대기자 명단에 액세스해야합니다. 고객이 예약을하려고하는데 사용 가능한 것이없는 경우 고객 애플리케이션은 사용자를 대기자 명단에 추가하고 애플리케이션은 테이블이 비어있을 때 고객에게 알립니다. 대기자 명단은 고객이 대기자 명단에 추가 된 순서를 유지해야합니다. 솔루션 아키텍트는이 대기자 명단을 저장하기 위해 어떤 서비스를 권장해야합니까?\nA. Amazon Simple Notification Service (Amazon SNS) B. AWS Lambda 함수를 호출하는 AWS Step Functions C. Amazon Simple Queue Service (Amazon SQS)의 FIFO 대기열 D. Amazon Simple Queue Service (Amazon SQS)의 표준 대기열 #\rAnswer\r...\rAnswer: C\r#\rQ569\r#\r솔루션 아키텍트는 활용도를 가장 효과적으로 최적화하기 위해 무엇을해야합니까?\nA. 오리지널 Aurora 데이터베이스에서 Auto Scaling을 활성화합니다. B. 오리지널 Aurora 데이터베이스를 Aurora 병렬 쿼리로 변환합니다. C. 오리지널 Aurora 데이터베이스를 Aurora 글로벌 데이터베이스로 변환합니다. D. 오리지널 Aurora 데이터베이스를 Aurora Aurora 서버리스로 변환합니다. #\rAnswer\r...\rAnswer: D\r#\rQ570\r#\r한 회사에서 Amazon DynamoDB를 사용하여 1GB의 제품 카탈로그를 준비하고 있습니다. 제품 항목은 평균 100KB의 데이터로 구성되고 평균 트래픽은 초당 약 250 개 요청이므로 데이터베이스 관리자는 3.000 RCU의 읽기 용량 처리량을 프로비저닝했습니다. 그러나 일부 제품은 매우 인기가 있으며 사용자는 제한으로 인해 지연 또는 시간 초과가 발생합니다. 이 문제에 대한 장기적인 해결책을 제공하는 개선점은 무엇입니까?\nA. 처리량 프로비저닝을 6.000 RCU (읽기 용량 단위)로 늘립니다. B. Amazon DynamoDB Accelerator를 사용하여 자주 읽는 항목을 유지합니다. C. Amazon S3에 저장된 세부 정보와 함께 주요 제품 속성 만 저장하여 Amazon DynamoDB를 확장합니다. D. 제품 키가 아닌 제품 키와 제품 유형의 해시로 구성되도록 파티션 키를 변경합니다. #\rAnswer\r...\rAnswer: B\r#\rQ571\r#\r회사에서 Amazon CloudFront를 통해 제공되는 정적 웹 사이트를 실행하려고합니다. Amazon Elastic Block Store (Amazon EBS) 볼륨 대신 Amazon S3 버킷에 웹 사이트 콘텐츠를 저장하면 어떤 이점이 있습니까?\nA. S3 버킷은 전역 적으로 복제되므로 대규모 확장이 가능합니다. EBS 볼륨은 AWS 리전 내에서만 복제됩니다. B. S3는 CloudFront의 오리진입니다. EBS 볼륨은 오리진이 되려면 Elastic Load Balancing로드 밸런서 뒤에있는 EC2 인스턴스가 필요합니다. C. S3 버킷을 암호화하여 웹 파일을 안전하게 저장할 수 있습니다. EBS 볼륨은 암호화 할 수 없습니다. D. S3 버킷은 객체 수준의 읽기 제한을 지원하여 남용을 방지합니다. EBS 볼륨은 객체 수준 조절을 제공하지 않습니다. #\rAnswer\r...\rAnswer: B\r#\rQ572\r#\r한 회사에서 다양한 유형의 Amazon EC2 온 디맨드 인스턴스를 사용하고 있습니다. 회사는 이러한 인스턴스가 워크로드에 필요한 것보다 더 큰 CPU 및 메모리 용량을 가지고 있다고 의심합니다. 비용 최적화를위한 권장 사항을 얻기 위해 회사는 어떤 조치를 취해야합니까? (2 개 선택)\nA. 인스턴스 유형 권장 사항에는 AWS Trusted Advisor를 사용합니다. B. 인스턴스 유형 권장 사항에 AWS Compute Optimizer를 사용합니다. C. 인스턴스 유형 권장 사항에 AWS 예산을 사용합니다. D. Cost Explorer 적정 크기 권장 사항을 사용합니다. E. Amazon Inspector를 사용하여 활용도가 낮은 EC2 인스턴스를 식별합니다. #\rAnswer\r...\rAnswer: A, D\r#\rQ573\r#\r전자 상거래 애플리케이션은 Amazon Simple Queue Service (Amazon SQS) 대기열에 주문합니다. 메시지가 수신되면 Amazon EC2 작업자 인스턴스가 요청을 처리합니다. EC2 인스턴스는 Auto Scaling 그룹에 있습니다. 최소한의 운영 오버 헤드로 Auto Scaling 그룹을 확장하려면 아키텍처를 어떻게 설계해야합니까?\nA. EC2 CPU에서 Amazon CloudWatch 경보를 사용하여 Auto Scaling 그룹을 확장 및 축소합니다. B. 확장 또는 축소를 위해 EC2 인스턴스에서 처리 된 메시지에 대해 Amazon EC2 Auto Scaling 상태 확인을 사용합니다. C. 대기열의 메시지 수에 따라 Amazon CloudWatch 경보를 사용하여 Auto Scaling 그룹을 확장 또는 축소합니다. D. CPU 기반 Amazon CloudWatch 경보를 사용하여 Auto Scaling 그룹을 확장 또는 축소합니다. #\rAnswer\r...\rAnswer: C\r#\rQ574\r#\r한 회사에 Amazon 시작 유형을 사용하여 Amazon Elastic Container Service (Amazon EC2)에서 서비스로 실행되는 애플리케이션이 있습니다. 애플리케이션 코드는 AWS API를 호출하여 Amazon Simple Queue Service (Amazon SQS)에 메시지를 게시합니다. Amazon SQS에 메시지를 게시 할 수있는 권한을 애플리케이션에 부여하는 가장 안전한 방법은 무엇입니까?\nA. AWS Identity and Access Management (IAM)를 사용하여 ECS 클러스터의 Auto Scaling 그룹에 대한 시작 구성에서 사용하는 역할에 SQS 권한을 부여합니다. B. SQS 권한이있는 새 IAM 사용자를 생성합니다. 작업 정의를 업데이트하여 액세스 키 ID 및 보안 액세스 키를 환경 변수로 선언합니다. C. SQS 권한이있는 새 IAM 역할을 생성합니다. 작업 역할 설정에이 역할을 사용하도록 작업 정의를 업데이트합니다. D. Amazon SQS에 대한 액세스를 허용하도록 ECS 클러스터에서 사용하는 보안 그룹을 업데이트합니다. #\rAnswer\r...\rAnswer: B\r#\rQ575\r#\r한 도시에서 ALB (Application Load Balancer) 뒤의 AmazonEC2 인스턴스에서 실행되는 웹 애플리케이션을 배포했습니다. 응용 프로그램의 사용자는 산발적 인 성능을보고했습니다. 임의의 IP 주소에서 발생하는 DDoS 공격과 관련된 것으로 보입니다. 시에는 최소한의 구성 변경이 필요하고 DDoS 소스에 대한 감사 추적을 제공하는 솔루션이 필요합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까 ..?\nA. ALB에서 AWS WAF 웹 ACL을 활성화하고 알 수없는 소스의 트래픽을 차단하도록 규칙을 구성합니다. B. Amazon inspector를 구독하십시오. AWS DDoS 리소스 팀 (DRT)에 참여하여 마이그레이션 제어를 서비스에 통합합니다. C. AWS Shield Advanced를 구독합니다. AWS DDoS 대응 팀 (DRT)에 참여하여 마이그레이션 제어를 서비스에 통합합니다. D. 애플리케이션에 대한 Amazon CloudFront 배포를 생성하고 ALB를 오리진으로 설정합니다. 배포에서 AWS WAF 웹 ACL을 활성화하고 알 수없는 소스의 트래픽을 차단하도록 규칙을 구성합니다. #\rAnswer\r...\rAnswer: C\r#\rQ576\r#\r솔루션 아키텍트가 회사의 예정된 야간 유지 관리 비용을 검토하고 있습니다. 솔루션 아키텍트는 3 개의 Amazon EC2 인스턴스가 각각 완료하는 데 5 분도 채 걸리지 않는 9 개의 스크립팅 된 작업을 수행하기 위해 실행되고 있음을 확인합니다. 스크립트는 모두 Python으로 작성되었습니다. 회사는 야간 유지 보수 비용을 최적화하기 위해 어떤 조치를 취해야합니까?\nA. 세 EC2 인스턴스의 스크립트를 통합하여 하나의 EC2 인스턴스에서 실행합니다. B. 스크립트를 AWS Lambda 함수로 변환하고 Amazon EventBridge (Amazon CloudWatch Events)를 사용하여 예약합니다. C. 실행중인 EC2 인스턴스에 대한 컴퓨팅 절약 계획을 구매합니다. D. 스크립트 실행을 위해 실행중인 EC2 인스턴스를 대체 할 스팟 집합을 생성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ577\r#\r회사의 웹 사이트는 매일 수백만 건의 요청을 처리합니다. 요청 수가 계속 증가하고 있습니다. 솔루션 아키텍트는 웹 애플리케이션의 응답 시간을 개선해야합니다. 솔루션 아키텍트는 Amazon DynamoDB 테이블에서 제품 세부 정보를 검색 할 때 애플리케이션이 지연 시간을 줄여야한다고 결정합니다.\nA. DynamoOB Accelerator (DAX) 클러스터 설정 DAX를 통해 모든 읽기 요청을 라우팅합니다. B. Amazon ElasliCache (또는 DynamoOB 테이블과 웹 애플리케이션간에 Redis를 설정합니다. Redis를 통해 모든 읽기 요청을 라우팅합니다. C. DynamoOB 테이블과 웹 애플리케이션간에 Memcached 용 Amazon ElasliCache를 설정합니다. 모든 읽기 요청을 Memcached를 통해 라우팅합니다. D. 테이블에 Amazon DynamoOB 스트림을 설정하고 AWS Lambda가 테이블에서 읽도록하고 Amazon ElastiCache를 채 웁니다. ElasliCache를 통해 모든 읽기 요청을 라우팅합니다. #\rAnswer\r...\rAnswer: A\r#\rQ578\r#\r회사는 중요한 애플리케이션에 대한 애플리케이션 로그 파일을 10 년 동안 보관해야합니다. 애플리케이션 팀은 문제 해결을 위해 지난 달의 로그에 정기적으로 액세스하지만 1 개월 이상 지난 로그에는 거의 액세스하지 않습니다. 이 애플리케이션은 매월 10TB 이상의 로그를 생성합니다. 이러한 요구 사항을 가장 비용 효율적으로 충족하는 스토리지 옵션은 무엇입니까?\nA. Amazon S3에 로그를 저장합니다. AWS Backup을 사용하여 1 개월이 지난 로그를 S3 Glacier Deep Archive로 이동합니다. B. Amazon S3에 로그를 저장합니다. S3 수명주기 정책을 사용하여 1 개월이 지난 로그를 S3 Glacier Deep Archive로 이동합니다. C. Amazon CloudWatch Logs에 로그를 저장합니다. AWS Backup을 사용하여 1 개월이 지난 로그를 S3 Glacier Deep Archive로 이동합니다. D. Amazon CloudWatch Logs에 로그를 저장합니다. Amazon S3 수명주기 정책을 사용하여 1 개월이 지난 로그를 S3 Glacier Deep Archive로 이동합니다. #\rAnswer\r...\rAnswer: B\r#\rQ579\r#\r회사는 온-프레미스에서 호스팅되는 온라인 미디어 사이트를 운영합니다. 한 직원이 동영상과 사진이 포함 된 제품 리뷰를 게시했습니다. 리뷰가 입소문이 났고 회사는 웹 사이트 트래픽 급증을 처리해야합니다. 즉각적인 해결책을 제공하는 조치는 무엇입니까?\nA. Amazon ElasbCache for Redis를 사용하여 오리진의로드 요청을 캐싱하고 줄입니다. B. 뉴스 사이트를 오리진으로 사용하여 생성 된 Amazon CloudFront 배포를 사용하여 이미지와 비디오를 제공합니다. C. Amazon API Gateway를 사용하도록 웹 사이트를 재 설계하고 AWS Lambda를 사용하여 콘텐츠를 제공합니다. D. Amazon EC2를 사용하여 서버 인스턴스를 추가하고 장애 조치 라우팅 정책과 함께 Amazon Route 53을 사용합니다. #\rAnswer\r...\rAnswer: B\r#\rQ580\r#\r회사에 Amazon EC2 온 디맨드 인스턴스에서 실행되는 애플리케이션이 있습니다. 애플리케이션은 확장되지 않으며 인스턴스는 하나의 AWS 리전에서 실행됩니다. 이 회사는 향후 운영 체제를 Windows에서 AWS Linux로 변경할 수있는 유연성을 원합니다. 회사는 추가적인 운영 오버 헤드 나 애플리케이션 변경없이 인스턴스 비용을 줄여야합니다. 회사가 이러한 요구 사항을 충족하기 위해 무엇을 구입해야합니까? 비용 효율적입니까?\nA. 사용중인 인스턴스 유형에 대한 전용 호스트. B. 사용중인 인스턴스 유형에 대한 Compute Savings Plan. C. EC2 인스턴스 절약 계획 또는 사용중인 인스턴스 유형. D. 전환 형 예약 인스턴스 또는 사용중인 인스턴스 유형. #\rAnswer\r...\rAnswer: D\r#\rQ581\r#\r회사에 AWS로 마이그레이션해야하는 Windows 기반 애플리케이션이 있습니다. 이 애플리케이션은 가용 영역에 배포 된 여러 Amazon EC2 Windows 인스턴스에 연결된 공유 Windows 파일 시스템을 사용해야합니다. 솔루션 설계자는 이 요구 사항을 충족하기 위해 무엇을 해야합니까?\nA. 볼륨 게이트웨이 모드에서 AWS Storage Gateway를 구성합니다. 각 Windows 인스턴스에 볼륨을 마운트하십시오. B. Windows 파일 서버용 Amazon FSx를 구성합니다. Amazon FSx 파일 시스템을 각 Windows 인스턴스에 탑재합니다. C. Amazon Elastic File System (Amazon EFS)을 사용하여 파일 시스템 구성 EFS 파일 시스템을 각 Windows 인스턴스에 마운트합니다. D. 필요한 크기로 Amazon Elastic Block Store (Amazon EBS) 볼륨을 구성합니다. 각 인스턴스를 볼륨에 연결합니다. 볼륨 내의 파일 시스템을 각 Windows 인스턴스에 마운트합니다. #\rAnswer\r...\rAnswer: C\r#\rQ582\r#\r한 글로벌 기업은 Amazon DynamoOB 테이블에서 지역 알레르겐에 대한 정보를 추적 및 저장하고 웹 사이트에서이 데이터를 쿼리 할 계획입니다. 회사는 웹 사이트 트래픽이 변동될 것으로 예상합니다. 회사는 지정된 날짜의 조건의 심각도에 따라 결합 된 읽기 및 쓰기 용량 단위의 범위가 초당 10,000,000에이를 것으로 예상합니다. 솔루션 아키텍트는 제한 문제를 방지하고 용량을 효율적으로 관리하는 솔루션을 설계해야합니다. 솔루션 설계자는 이러한 요구 사항을 가장 비용 효율적으로 충족하기 위해 무엇을해야합니까?\nA. 프로비저닝 된 용량 모드를 사용합니다. 테이블의 읽기 용량 단위를 10,000으로 설정합니다. B. DynamoDB Auto Scaling에서 프로비저닝 된 용량 모드와 조정 정책을 사용합니다. C. 몇 달 동안 온 디맨드 용량을 사용한 다음 프로비저닝 된 용량 모드로 전환합니다. D. 주문형 용량 모드 만 사용합니다. DynamoDB Accelerator (DAX)가 탭 앞에 오도록 구성합니다. #\rAnswer\r...\rAnswer: B\r#\rQ583\r#\r한 게임 회사가 Amazon DynamoDB를 사용하여 최고 점수 리더 보드를 실행하고 사용자의 게임 진행 상황을 기록하고 있습니다. 이 회사는 수년간 활동할 것으로 예상되는 새로운 게임을 출시하고 있습니다. 시작시 데이터베이스 활동을 예측할 수 없습니다. 그러나 4 주 후에 안정화 될 것으로 예상됩니다. 현재 이 회사는 모든 DynamoDB 테이블에서 읽기 및 쓰기를 처리하기 위해 온 디맨드 용량 모드를 사용하고 있습니다. 새 게임 출시 중에 회사가 DynamoDB 용량을 제어 할 수있는 가장 비용 효율적인 방법은 무엇입니까?\nA. 온 디맨드 모드를 사용하고 게임 시작 첫 4 주 동안 DynamoDB 예약 용량을 구매합니다. B. 프로비저닝 된 용량 모드를 사용하고 게임 시작 첫 4 주 동안 DynamoDB 예약 용량을 구매합니다. C. 게임 시작에 프로비저닝 된 용량 모드를 사용하고 4 주 후에 온 디맨드 모드로 다시 전환 한 다음 DynamoDB 예약 용량을 구매합니다. D. 게임 시작시 온 디맨드 모드를 사용하고 4 주 후에 프로비저닝 된 용량 모드로 전환 한 다음 DynamoDB 예약 용량을 구매합니다. #\rAnswer\r...\rAnswer: D\r#\rQ584\r#\r사용자는 요청에 대해 최대 100ms의 대기 시간을 예상하는 다양한 클라이언트가 액세스하는 MySQL 데이터베이스를 소유합니다. 레코드가 데이터베이스에 저장되면 거의 변경되지 않습니다. 클라이언트는 한 번에 하나의 레코드에만 액세스합니다. 클라이언트 수요 증가로 인해 데이터베이스 액세스가 기하 급수적으로 증가하고 있습니다. 결과로드는 곧 구매 가능한 가장 비싼 하드웨어의 용량을 초과하게됩니다. 사용자는 AWS로 마이그레이션하기를 원하고 데이터베이스 시스템을 기꺼이 변경합니다. 데이터베이스 로드 문제를 완화하고 미래를 위해 사실상 무제한 확장성을 제공하는 서비스는 무엇입니까?\nA. Amazon RDS B. Amazon DynamoDB C. Amazon Redshift D. AWS Data Pipeline #\rAnswer\r...\rAnswer: B\r#\rQ585\r#\r한 회사에 공통 Amazon RDS MySQL 다중 AZ 인스턴스에 자주 액세스해야하는 여러 웹 서버가 있습니다. 회사는 웹 서버가 연결할 수있는 안전한 방법을 원합니다. 사용자 자격 증명을 자주 교체해야하는 보안 요구 사항을 충족하는 동안 회사에는 공통 Amazon ROS MySQL Muto-AZ DB 인스턴스에 자주 액세스해야하는 여러 웹 서버가 있습니다. 이 회사는 사용자 자격 증명을 자주 교체하는 보안 요구 사항을 충족하면서 웹 서버가 데이터베이스에 연결하는 안전한 방법을 원합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. AWS Secrets Manager에 데이터베이스 사용자 자격 증명 저장 웹 서버가 AWS Secrets Manager에 액세스하도록 허용하는 데 필요한 IAM 권한을 부여합니다. B. 데이터베이스 사용자 자격 증명 저장 m AWS Systems Manager OpsCenter 웹 서버가 OpsCenter에 액세스하도록 허용하는 데 필요한 IAM 권한을 부여합니다. C. 데이터베이스 사용자 자격 증명을 안전한 Amazon S3 버킷에 저장 웹 서버가 자격 증명을 검색하고 데이터베이스에 액세스 할 수 있도록 필요한 IAM 권한을 부여합니다. D. 웹 서버 파일 시스템에서 AWS Key Management Service (AWS KMS)로 암호화 된 fries에 데이터베이스 사용자 자격 증명을 저장합니다. 웹 서버는 파일을 해독하고 데이터베이스에 액세스 할 수 있어야합니다. #\rAnswer\r...\rAnswer: A\r#\rQ586\r#\r한 회사가 새로운 웹 서비스를 출시하고 있지만이 서비스가 얼마나 많은 고객을 유치할지 확신 할 수 없습니다. 그러나 회사는 다운 타임을 받아들이지 않습니다. 솔루션 아키텍트가 회사에 권장 할 수있는 것은 무엇입니까?\nA. Amazon EC2 B. Amazon RDS C. AWS CtoudTrail D. Amazon DynamoDB #\rAnswer\r...\rAnswer: B\r#\rQ587\r#\r한 회사에서 다양한 유형의 Amazon EC-2 온 디맨드 인스턴스를 사용하고 있습니다. 회사는 이러한 인스턴스가 워크로드에 필요한 것보다 더 큰 CPU 및 메모리 용량을 가지고 있다고 의심합니다. 비용 최적화를위한 권장 사항을 얻기 위해 회사는 어떤 조치를 취해야합니까?\nA. 인스턴스 유형 권장 사항에는 AWS Trusted Advisor를 사용합니다. B. 인스턴스 유형 권장 사항에 AWS Compute Optimizer를 사용합니다. C. 인스턴스 유형 권장 사항에 AWS 예산을 사용합니다. D. Cost Explorer 적정 크기 권장 사항을 사용합니다. E. Amazon Inspector를 사용하여 활용도가 낮은 EC2 인스턴스를 식별합니다. #\rAnswer\r...\rAnswer: A, D\r#\rQ588\r#\r한 회사는 사용자 기반이 1년에 걸쳐 5배 증가 할 것으로 예상합니다. 애플리케이션은 한 지역에서 호스팅되며 MySQL 용 Amazon RDS 데이터베이스, Application Load Balance, Amazon Elastic Container Service (Amazon ECS)를 사용하여 웹 사이트와 마이크로 서비스를 호스팅합니다. 예상되는 성장을 지원하기 위해 솔루션 설계자가 권장해야하는 디자인 변경은 무엇입니까? (2 개 선택)\nA. Amazon ECS에서 Amazon S3로 정적 파일을 이동합니다. B. Amazon Route 53 지리적 위치 라우팅 정책을 사용합니다. C. 실시간 AWS CloudTrail 로그를 기반으로 환경을 확장합니다. D. 각 마이크로 서비스에 대한 전용 Elastic Load Balancer를 생성합니다. E. RDS 리드 복제본을 생성하고 이러한 복제본을 사용하도록 애플리케이션을 변경합니다. #\rAnswer\r...\rAnswer: A, E\r#\rQ589\r#\r한 회사에서 애플리케이션을위한 안정적인 아키텍처를 설계하기 위해 솔루션 아키텍트를 고용했습니다. 애플리케이션은 1 개의 Amazon RDS DB 인스턴스와 2 개의 수동 프로비저닝 된 Amazon EC2로 구성됩니다. 웹 서버를 실행하는 인스턴스. EC2 인스턴스는 단일 가용 영역에 있습니다. 직원이 최근에 DB 인스턴스를 삭제했으며 그 결과 24 시간 동안 애플리케이션을 사용할 수 없었습니다. 회사는 환경의 전반적인 안정성에 관심이 있습니다. 솔루션 아키텍트는 애플리케이션 인프라의 안정성을 극대화하기 위해 무엇을해야합니까?\nA. 하나의 EC2 인스턴스를 삭제하고 다른 EC2 인스턴스에서 종료 방지를 활성화합니다. DB 인스턴스를 Muto-AZ로 업데이트하고 삭제 방지를 활성화합니다. B. DB 인스턴스를 다중 AZ로 업데이트하고 삭제 보호 활성화 EC2 인스턴스를 Application Load Balancer 뒤에 배치하고 여러 가용 영역에 걸쳐 EC2 Auto Seating 그룹에서 실행합니다. C. Amazon API Gateway 및 AWS Lambda 함수와 함께 추가 DB 인스턴스를 생성합니다. API Gateway를 통해 Lambda 함수를 호출하도록 애플리케이션을 구성합니다. Lambda 함수가 두 DB 인스턴스에 데이터를 쓰도록합니다. D. 여러 가용 영역에 여러 서브넷이있는 EC2 Auto Scaling 그룹에 EC2 인스턴스를 배치합니다. 온 디맨드 인스턴스 대신 스팟 인스턴스를 사용하십시오. 인스턴스 상태를 모니터링하도록 Amazon CloudWatch 경보를 설정합니다. DB 인스턴스를 다중 AZ로 업데이트하고 삭제 방지를 활성화합니다. #\rAnswer\r...\rAnswer: B\r#\rQ590\r#\r솔루션 아키텍트는 AWS 외부에서 호스팅되는 여러 웹 서버에서 제공하는 고 가용성 웹 사이트를 설계하고 있습니다. 인스턴스가 응답하지 않는 경우 설계자는 해당 인스턴스를 회전에서 제거해야합니다. 이 요구 사항을 충족하는 가장 효율적인 방법은 무엇입니까?\nA. Amazon CloudWatch를 사용하여 사용률을 모니터링합니다. B. Amazon API Gateway를 사용하여 가용성을 모니터링합니다. C. Amazon Elastic Load Balancer를 사용합니다. D. Amazon Route 53 상태 확인을 사용합니다. #\rAnswer\r...\rAnswer: C\r#\rQ591\r#\r한 회사에서 Amazon Aurora DB 클러스터의 테이블에 대한 일련의 스키마 변경을 계획하고 있습니다. 솔루션 아키텍트는 가능한 가장 비용 효율적인 방식으로 변경 사항을 테스트해야합니다. 솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. 현재 Aurora DB 클러스터의 복제본을 생성합니다. 클론에서 스키마 변경을 수행합니다. 변경 사항을 테스트하고 성능이 만족 스러우면 원래 클러스터에 동일한 변경 사항을 적용합니다. 클론을 삭제합니다. B. MySQL 용 Amazon RDS 복제본을 생성합니다. 복제본에서 스키마 변경을 수행하십시오. 변경 사항이 테스트되고 성능이 만족 스러우면 동일한 변경 사항을 복제본에 적용합니다. 변경 사항이 테스트되고 성능이 만족 스러우면 기본 DB 인스턴스에 동일한 변경 사항을 적용합니다. 복제본을 삭제하십시오. C. 추가 Aurora 복제본 생성 Aurora 복제본에서 스키마 변경을 수행하십시오. 변경 사항이 테스트되고 성능이 만족 스러우면 기본 DB 인스턴스에 동일한 변경 사항을 적용합니다. Aurora 복제본을 삭제하십시오. D. 현재 Aurora DB 클러스터의 스냅 샷을 생성합니다. 클러스터의 스냅 샷을 새 클러스터로 복원하십시오. 복원 된 클러스터에서 스키마 변경을 수행합니다. 변경 사항이 테스트되고 성능이 만족 스러우면 원본 클러스터에 동일한 변경 사항을 적용합니다. 복원된 클러스터를 삭제합니다. #\rAnswer\r...\rAnswer: A\r#\rQ592\r#\r회사에는 Amazon API Gateway가 AWS Lambda 함수를 트리거하여 Amazon RDS DB 인스턴스에 대한 쓰기 및 업데이트 작업을 수행하는 비동기 웹 애플리케이션이 있습니다. 극단적으로 사용하는 기간에는 수신 워크로드에 대응하여 API Gateway 및 Lambda가 확장되지만 Amazon RDS와의 혼잡으로 인해 서비스 중단이 발생합니다. 이 회사는 이러한 혼잡을 완화하기 위해 비용 효율적인 설계를 찾고 있습니다. 솔루션 설계자는 무엇을 권장해야합니까?\nA. 더 큰 인스턴스 유형으로 RDS 스토리지 자동 확장을 구현합니다. B. 데이터베이스에 대한 읽기 요청을 줄이기 위해 읽기 전용 복제본을 만듭니다. C. Amazon Kinesis를 사용하여 API Gateway에서 Lambda 함수로 들어오는 요청을 폴링합니다. D. Amazon Simple Queue Service (Amazon SQS)를 사용하여 수신 요청을 Lambda 함수로 전달하기 전에 버퍼링합니다. #\rAnswer\r...\rAnswer: D\r#\rQ593\r#\r한 회사에서 MySQL 용 Amazon RDS를 사용하고 있습니다. 회사 재해 복구 요구 사항에 따르면 데이터베이스의 거의 실시간 복제본을 온 프레미스에서 유지 관리해야합니다. 회사는 전송 중에 데이터가 암호화되기를 원합니다. 이러한 요구 사항을 충족하는 솔루션은 무엇입니까?\nA. AWS Database Migration Service (AWS DMS) 및 AWS Direct Connect를 사용하여 AWS에서 온 프레미스로 데이터를 마이그레이션합니다. B. MySQL 복제를 사용하여 AWS Direct Connect 연결 위에있는 IPsec VPN을 통해 AWS에서 온 프레미스로 복제합니다. C. AWS Data Pipeline을 사용하여 AWS Direct Connect 연결 위에있는 IPsec VPN을 통해 AWS에서 온 프레미스로 복제합니다. D. Amazon RDS Multi-Az 기능을 사용합니다. AWS Direct Connect 연결 위에있는 IPsec VPN을 통해 장애 조치 가용 영역으로 온 프레미스를 선택합니다. #\rAnswer\r...\rAnswer: D\r#\rQ594\r#\r회사는 온-프레미스에서 호스팅되는 온라인 미디어 사이트를 운영합니다. 한 직원이 동영상과 사진이 포함 된 제품 리뷰를 게시했습니다. 리뷰가 입소문이 났고 회사는 웹 사이트 트래픽 급증을 처리해야합니다. 즉각적인 해결책을 제공하는 조치는 무엇입니까?\nA. Amazon API Gateway를 사용하도록 웹 사이트를 재 설계하고 AWS Lambda를 사용하여 콘텐츠를 제공합니다. B. Amazon EC2를 사용하여 서버 인스턴스를 추가하고 장애 조치 라우팅 정책과 함께 Ama\rzon Route 53을 사용합니다. C. 뉴스 사이트를 오리진으로 사용하여 생성 된 Amazon CloudFront 배포를 사용하여 이미지와 비디오를 제공합니다. D. Amazon ElasbCache for Redis를 사용하여 오리진의로드 요청을 캐싱하고 줄입니다. #\rAnswer\r...\rAnswer: C\r#\rQ595\r#\r솔루션 아키텍트가 AWS Lambda 함수가 Amazon DynamoDB 테이블에 액세스하는 새로운 워크로드를 설계하고 있습니다. Lambda 함수에 DynamoDB 테이블에 대한 액세스 권한을 부여하는 가장 안전한 방법은 무엇입니까?\nA. DynamoDB 테이블에 액세스하는 데 필요한 권한이있는 IAM 역할을 생성합니다. Lambda 함수에 역할을 할당합니다. B. DynamoDB 사용자 이름과 암호를 생성하고 Lambda 함수에서 사용할 수 있도록 개발자에게 제공합니다. C. IAM 사용자를 생성하고 사용자에 대한 액세스 및 보안 키를 생성합니다. 사용자에게 DynarnoOB 테이블에 액세스하는 데 필요한 권한을 부여하십시오. 개발자가 이러한 키를 사용하여 리소스에 액세스하도록합니다. D. AWS Lambda에서 액세스를 허용하는 IAM 역할 생성 DynamoDB 테이블에 역할을 할당합니다. #\rAnswer\r...\rAnswer: A\r#\rQ596\r#\rRoute 53 지연 시간 기반 라우팅으로 요청을 UDP 기반 애플리케이션으로 라우팅하여 전 세계 사용자에게 애플리케이션이 미국 아시아 및 유럽에있는 회사의 온 프레미스 데이터 센터에있는 중복 서버에서 호스팅됩니다. 회사의 규정 준수 요구 사항에 따르면 애플리케이션은 온 프레미스에서 호스팅되어야합니다. 회사는 애플리케이션의 성능과 가용성을 개선하고자합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을해야합니까?\nA. 온 프레미스 엔드 포인트를 처리하도록 3 개의 AWS 리전에서 네트워크로드 밸런서 (NLB) 구성 AWS Global Accelerator를 사용하여 액셀러레이터를 생성하고 NLB를 엔드 포인트로 등록합니다. 가속기 DNS를 가리키는 CNAML을 사용하여 애플리케이션에 대한 액세스를 제공합니다. B. 온 프레미스 엔드 포인트를 무선으로 연결하기 위해 3 개의 AWS 리전에서 3 개의 Application Load Balancer (ALG)를 구성합니다. AWS Global Accelerator를 사용하여 액셀러레이터를 생성하고 ALB를 엔드 포인트로 등록합니다. 가속기 UNS를 가리키는 CNAK1L을 사용하여 응용 프로그램에 대한 액세스를 제공합니다. C. 3 개의 AWS 리전에 3 개의 NLB (Network Load Balancer)를 구성하여 Route 53에서 온 프레미스 엔드 포인트를 처리합니다. 3 개의 NLB를 가리키는 지연 시간 기반 레코드를 생성합니다. Amazon CloudFront 배포의 오리진으로 사용 CloudFront DNS를 가리키는 CNAML을 사용하여 애플리케이션에 대한 액세스를 제공합니다. D. 온 프레미스 엔드 포인트를 처리하기 위해 3 개의 AWS 리전에 3 개의 Application Load Balancer (ALB)를 구성합니다. Route 53에서 3 개의 ALU를 가리키는 지연 시간 기반 레코드를 생성하고 Amazon CloudFront 배포의 오리진으로 CloudFront DNS를 가리키는 CNAME를 사용하여 애플리케이션에 대한 액세스를 제공합니다. #\rAnswer\r...\rAnswer: C\r#\rQ597\r#\r솔루션 아키텍트는 웹 애플리케이션 및 데이터베이스 계층을 포함하는 아키텍처를 설계하고 있습니다. 웹 계층은 자동 확장이 가능해야합니다. 솔루션 아키텍트는 각 계층을 자체 서브넷으로 분리하기로 결정했습니다. 이 설계에는 2 개의 퍼블릭 서브넷과 4 개의 프라이빗 서브넷이 포함됩니다. 보안 팀은 비즈니스 요구가 있고 다른 모든 네트워크 트래픽이 차단될 때만 계층이 서로 통신 할 수 있어야합니다. 솔루션 아키텍트는 이러한 요구 사항을 충족하기 위해 무엇을 해야합니까?\nA. 통신을 제어하기 위해 Amazon GuardDuty 소스 설명 규칙 세트를 생성합니다. B. 모든 계층에 대해 하나의 보안 그룹을 생성하여 필요한 원본 및 대상으로 만 트래픽을 제한합니다. C. 각 계층에 대한 특정 보안 그룹을 생성하여 필요한 소스 및 대상으로 만 트래픽을 제한합니다. D. 6 개 서브넷 모두에 네트워크 ACL을 만들어 애플리케이션이 작동하는 데 필요한 소스 및 대상으로 트래픽을 제한합니다. #\rAnswer\r...\rAnswer: D\r#\r"},{"id":65,"href":"/cloud/docs/Azure/MicrosoftAzure/Azure08/","title":"Azure DevOps","section":"Azure docs","content":"\rAzure DevOps\r#\r#\rAzure DevOps Services를 사용하여 애플리케이션에 연속 통합, 제공 및 배포를 제공하는 빌드 및 릴리스 파이프라인을 만들 수 있습니다. 리포지토리 및 애플리케이션 테스트를 통합하고, 애플리케이션 모니터링을 수행하고, 빌드 아티팩트로 작업할 수 있습니다. #\r#\rAzure DevOps\r#\r#\rAzure DevOps Services(이전 명칭: Visual Studio Team Services 또는 VSTS)는 고성능 파이프라인, 무료 비공개 Git 리포지토리, 구성 가능한 Kanban 보드, 광범위한 자동 및 클라우드 기반 부하 테스트를 비롯한 개발 협업 도구를 제공합니다. #\r#\rAzure DevTest Labs\r#\r배포 파이프라인에서 바로 애플리케이션을 테스트하거나 시연하는 데 사용할 수 있는 주문형 Windows 및 Linux 환경을 신속하게 만듭니다. #\r"},{"id":66,"href":"/cloud/docs/Azure/MicrosoftAzure/Azure09/","title":"Azure HybridCloud","section":"Azure docs","content":"\r****\r#\r#\r****\r#\r#\r#\r****\r#\r#\r#\r"},{"id":67,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-01/","title":"OpenStack Ussuri : Overview","section":"OpenStack Training","content":"\rOpenStack Ussuri : Overview\r#\r#\rOpenStack Ussuri : Overview\r#\r#\r#\rOpenStack Ussuri 설치는 위의 그림과 표에 맞춰 설치가 진행됩니다. minimal 기본 설치는 keystone, glance, nova, neutron, cinder, horizon이며 여기서는 가능한 모든 서비스를 설치하도록 하겠습니다. #\rOS HOST NAME CPU/thead RAM DISK Network Interface-1 Network Interface-2 CentOS8 controller 4/8 6144 100G Nat host1 CentOS8 network 2/4 2048 40G Nat host1 CentOS8 compute 4/8 4096 40G host1 CentOS8 storage1 1/2 1024 50G host1 CentOS8 storage2 1/2 1024 50G host1 CentOS8 storage3 1/2 1024 50G host1 #\rService Code Name Description Identity Service Keystone User Management Compute Service Nova Virtual Machine Management Image Service Glance Manages Virtual image like kernel image or disk image Dashboard Horizon Provides GUI console via Web browser Object Storage Swift Provides Cloud Storage Block Storage Cinder Storage Management for Virtual Machine Network Service Neutron Virtual Networking Management Orchestration Service Heat Provides Orchestration function for Virtual Machine Metering Service Ceilometer Provides the function of Usage measurement for accounting Database Service Trove Database resource Management Data Processing Service Sahara Provides Data Processing function Bare Metal Provisioning Ironic Provides Bare Metal Provisioning function Messaging Service Zaqar Provides Messaging Service function Shared File System Manila Provides File Sharing Service DNS Service Designate Provides DNS Server Service Key Manager Service Barbican Provides Key Management Service #\r"},{"id":68,"href":"/cloud/docs/OpenStack/OpenStack/Sahara/","title":"Sahara","section":"OpenStack docs","content":"\rSahara\r#\r#\r데이터 프로세싱 서비스 Sahara\r#\r오픈스택 위 빅데이터를 다루기 위한 Hadoop이나 Spark를 쉽게 제공할 수 있게 도와주는 서비스 Sahara는 다음 요소로 구성 Auth: 클라이언트 인증 및 권한을 부여, 오픈스택 인증 서비스 Keystone과 통신 DAL: Data Access Layer의 약어로 데이터 엑세스 계층을 의미, DB의 내부 모델을 유지 Secure Storage Access Layer: 암호 및 개인 키 같은 인증 데이터를 안전한 저장소에 보관 Provisioning Engine: 오픈스택 컴퓨트 서비스 Nova, Heat, Cinder, Glance, Designate와 통신을 담당하는 구성 요소 Vendor Plugins: 프로비저닝된 VM에서 데이터 처리 프레임워크를 구성하고 시작하는 기능을 담당하는 플러그 가능한 메커니즘 EDP: Elastic Data Processing의 약어로 Sahara가 제공하는 클러스테에서 데이터 처리 작업을 예약하고 관리 REST API: REST HTTP 인터페이스로 Sahara 기능을 호출 Python Sahara Client: 다른 오픈스택 구성 요소와 마찬가지로 Sahara에는 자체 Python 클라이언트가 있음 Sahara Pages: Sahara용 GUI로 오픈스택 대시보드인 Horizon에 있음 "},{"id":69,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-02/","title":"OpenStack Ussuri : 환경설정","section":"OpenStack Training","content":"\rOpenStack Ussuri : 기본 환경설정\r#\r#\r----------------------- | [ Controller Node ] | | | | MariaDB RabbitMQ | | Memcached | ----------------------- #\rOpenStack Ussuri : 기본 환경설정\r#\r#\r앞 기본 환경설정을 모든 노드에서 진행한 후, DB, RabbitMQ, Memcached는 controller에서만 설치를 진행합니다. $ all\u0026gt; $ controller\u0026gt; $ controller ~(keystone)\u0026gt; $ compute\u0026gt; $ network\u0026gt; # 위와 같은 호스트를 주의헤 주세요 ! # (keystone)은 keystone 설치 후 인증 받은 터미널입니다. #\rUssuri repository 등록\r#\r#\rOpenStack 구현을 위해 Ussuri repository를 구현합니다. $ all\u0026gt; dnf -y install centos-release-openstack-ussuri $ all\u0026gt; sed -i -e \u0026#34;s/enabled=1/enabled=0/g\u0026#34; /etc/yum.repos.d/CentOS-OpenStack-ussuri.repo $ all\u0026gt; dnf --enablerepo=centos-openstack-ussuri -y upgrade #\r#\rNTP ( Network Time Protocol ) Server 설치\r#\r#\rNTP Server는 모든 Node에서 설정을 진행합니다. $ all\u0026gt; dnf --enablerepo=centos-openstack-ussuri -y install openstack-selinux # SELinux를 설치합니다. $ all\u0026gt; dnf install -y wget # wget을 설치합니다. $ all\u0026gt; dnf --enablerepo=powertools -y install epel-release # epel 레포지터리를 등록합니다. $ all\u0026gt; dnf --enablerepo=powertools -y install checkpolicy # 만약 Checkpolicy가 설치되어 있지 않으면, 패키지를 다운 받습니다. $ all\u0026gt; dnf -y install chrony $ all\u0026gt; vi /etc/chrony.conf # pool 2.centos.pool.ntp.org iburst pool ntp.nict.jp iburst allow 10.10.10.0/24 $ all\u0026gt; systemctl enable --now chronyd # chrony 파일을 수정합니다. allow에는 사용대역을 기입합니다. $ all\u0026gt; firewall-cmd --add-service=ntp --permanent $ all\u0026gt; firewall-cmd --reload $ all\u0026gt; init 6 $ all\u0026gt; chronyc sources ^+ ntp-k1.nict.jp 1 6 17 10 -588us[-2093us] +/- 28ms ^+ ntp-a3.nict.go.jp 1 6 17 10 -2468us[-3973us] +/- 30ms ^* ntp-b3.nict.go.jp 1 6 17 10 +1015us[ -490us] +/- 22ms ^- ntp-b2.nict.go.jp 1 6 17 10 +2720us[+2720us] +/- 22ms # 방화벽을 등록 후 확인합니다. #\r#\rController MariaDB 설치\r#\r#\r$ controller\u0026gt; dnf module -y install mariadb:10.3 $ controller\u0026gt; vi /etc/my.cnf.d/charaset.cnf [mysqld] character-set-server = utf8mb4 [client] default-character-set = utf8mb4 # mariadb를 설치 후, charaset 설정을 변경하기 위해 파일을 수정합니다. $ controller\u0026gt; systemctl restart --now mariadb $ controller\u0026gt; systemctl enable --now mariadb # DB를 재시작 합니다. $ controller\u0026gt; firewall-cmd --add-service=mysql --permanent $ controller\u0026gt; firewall-cmd --reload # 방화벽을 설정합니다. $ controller\u0026gt; mysql_secure_installation $ controller\u0026gt; mysql -u root -p # 설정을 초기화 후, 비빌번호를 생성합니다. #\r#\rRabbitMQ, Memcached 설치\r#\r#\rRabbitMQ는 오픈 소스 메시지 브로커 소프트웨어이며, AMQP를 구현합니다. RabbitMQ는 OpenStack에서는 서로간의 통신을 위해 사용됩니다. Memcached이란 Memcached 는 범용 분산 캐시 시스템로, OpenStack에서 캐시값을 관리합니다. RabbitMq, Memcached는 Controller에서만 설치를 진행합니다. $ controller\u0026gt; dnf --enablerepo=powertools -y install rabbitmq-server memcached $ controller\u0026gt; vi /etc/my.cnf.d/mariadb-server.cnf [mysqld] ..... ..... max_connections=500 # 인증허용 시간 값을 추가합니다. $ controller\u0026gt; vi /etc/sysconfig/memcached OPTIONS=\u0026#34;-l 0.0.0.0,::\u0026#34; # 모두가 사용할 수 있도록 값을 수정합니다. $ controller\u0026gt; systemctl restart mariadb rabbitmq-server memcached $ controller\u0026gt; systemctl enable mariadb rabbitmq-server memcached # RabbitMQ, Memcached 서비스를 등록합니다. $ controller\u0026gt; rabbitmqctl add_user openstack qwer1234 $ controller\u0026gt; rabbitmqctl set_permissions openstack \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; # rabbitmq를 사용할 openstack 유저를 패스워드 qwer1234로 생성하고 모든 권한을 줍니다. $ controller\u0026gt; vi rabbitmqctl.te module rabbitmqctl 1.0; require { type rabbitmq_t; type rabbitmq_var_log_t; type rabbitmq_var_lib_t; type etc_t; type init_t; class file write; class file getattr; } #============= rabbitmq_t ============== allow rabbitmq_t etc_t:file write; #============= init_t ================== allow init_t rabbitmq_var_lib_t:file getattr; allow init_t rabbitmq_var_log_t:file getattr; $ controller\u0026gt; checkmodule -m -M -o rabbitmqctl.mod rabbitmqctl.te $ controller\u0026gt; semodule_package --outfile rabbitmqctl.pp --module rabbitmqctl.mod $ controller\u0026gt; semodule -i rabbitmqctl.pp # rabbitmq의 설정을 추가 후 등록시킵니다. $ controller\u0026gt; firewall-cmd --add-service=memcache --permanent $ controller\u0026gt; firewall-cmd --add-port=5672/tcp --permanent $ controller\u0026gt; firewall-cmd --reload # 방화벽을 설정합니다. "},{"id":70,"href":"/cloud/docs/OpenStack/OpenStack/Ironic/","title":"Ironic","section":"OpenStack docs","content":"\rIronic\r#\r#\r베어메탈 서비스 Ironic\r#\r물리적인 컴퓨터를 관리하고 자원을 제공하는 구성요소의 모음\nIronic은 구성에 따라 다음과 같은 다른 여러 오픈스택 서비스와 상호 작용할 수 있음\nIPMI 메트릭을 사용하는 오픈스택 텔레미터 모듈(Ceilometer)\n인증 요청 및 다른 오픈스택 서비스를 인증하는 오픈스택 인증 서비스(Keystone)\n이미지 및 이미지 메타데이터를 검색할 수 있는 오픈스택 이미지 서비스(Glance)\nDHCP 및 네트워크를 구성하는 오픈스택 네트워크 서비스(Neutron)\n오픈스택 네트워크 서비스인 Nova는 베어메탈 서비스와 함꼐 작동하고, 인스턴스를 관리하는 사용자용 API를 제공\n오픈스택 컴퓨트 서비스는 베어메탈 서비스가 제공하지 않는 예약 기능, 테넌트 할당량, IP 할당, 기타 서비스를 제공\n오픈스택 오브젝트 스토리지 서비스인 Swift는 드라이브 설정, 사용자 이미지, 배포 로그 및 점검 데이터 임시 저장 장소를 제공\nIronic은 다음 요소로 구성\nironic-api: 응용프로그램 요청을 원격 프로시저 호출(RPC)을 이용해서 ironic-conductor로 전송한 후 응용프로그램 요청을 처리하는 RESTful API\nironic-conductor: 노드를 추가, 편집, 삭제하며 IPMI 또는 SSH를 사용해 노드를 켜고 끌수 있음, 베어메탈 노드를 프로비저닝, 배치 정리 수행\nironic-python-agent: 원격 엣세스, 하드웨어 제어, 하드웨어 기본 스펙으로 ironic-conductor 및 ironic-inspector 서비스를 제공하려고 임시 RAM 디스크에서 실행되는 python 서비스\n"},{"id":71,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-03/","title":"OpenStack Ussuri : Keystone","section":"OpenStack Training","content":"\rOpenStack Ussuri : Keystone\r#\r#\r----------------------- | [ Controller Node ] | | | | MariaDB RabbitMQ | | Memcached Keystone | | httpd | ----------------------- #\rOpenStack Ussuri : Keystone\r#\r#\rKeystone은 OpenStack에서 인증 서비스를 구성하고 있습니다. Keystone에 대한 자세한 설명은 Keystone을 참조해주세요. #\rKeystone 유저와 DB를 생성합니다.\r#\r#\r$ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database keystone; $ MariaDB\u0026gt; grant all privileges on keystone.* to keystone@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on keystone.* to keystone@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit; #\r#\rKeystone을 설치합니다.\r#\r#\r$ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,epel,powertools -y install openstack-keystone python3-openstackclient httpd mod_ssl python3-mod_wsgi python3-oauth2client # keystone 및 관련 모듈을 설치합니다. $ controller\u0026gt; vi /etc/keystone/keystone.conf [cache] memcache_servers = controller:11211 [database] connection = mysql+pymysql://keystone:qwer1234@controller/keystone [token] provider = fernet $ controller\u0026gt; su -s /bin/bash keystone -c \u0026#34;keystone-manage db_sync\u0026#34; $ controller\u0026gt; keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone $ controller\u0026gt; keystone-manage credential_setup --keystone-user keystone --keystone-group keystone # Keystone DB를 임포트 시킵니다. $ controller\u0026gt; keystone-manage bootstrap --bootstrap-password qwer1234 \\ --bootstrap-admin-url http://controller:5000/v3/ \\ --bootstrap-internal-url http://controller:5000/v3/ \\ --bootstrap-public-url http://controller:5000/v3/ \\ --bootstrap-region-id RegionOne $ controller\u0026gt; setsebool -P httpd_use_openstack on $ controller\u0026gt; setsebool -P httpd_can_network_connect on $ controller\u0026gt; setsebool -P httpd_can_network_connect_db on $ controller\u0026gt; vi keystone-httpd.te module keystone-httpd 1.0; require { type httpd_t; type keystone_log_t; class file create; class dir { add_name write }; } #============= httpd_t ============== allow httpd_t keystone_log_t:dir { add_name write }; allow httpd_t keystone_log_t:file create; $ controller\u0026gt; checkmodule -m -M -o keystone-httpd.mod keystone-httpd.te $ controller\u0026gt; semodule_package --outfile keystone-httpd.pp --module keystone-httpd.mod $ controller\u0026gt; semodule -i keystone-httpd.pp $ controller\u0026gt; firewall-cmd --add-port=5000/tcp --permanent $ controller\u0026gt; firewall-cmd --reload # 방화벽 및 SELinux를 설정합니다. $ controller\u0026gt; vi /etc/httpd/conf/httpd.conf ServerName controller:80 # 99번 줄에 추가합니다. $ controller\u0026gt; ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/ $ controller\u0026gt; systemctl enable --now httpd # httpd 서비스를 등록합니다. #\r#\rKeystone Project 생성\r#\r$ controller\u0026gt; vi ~/admin_key export OS_PROJECT_DOMAIN_NAME=default export OS_USER_DOMAIN_NAME=default export OS_PROJECT_NAME=admin export OS_USERNAME=admin export OS_PASSWORD=qwer1234 export OS_AUTH_URL=http://controller:5000/v3 export OS_IDENTITY_API_VERSION=3 export OS_IMAGE_API_VERSION=2 export PS1=\u0026#39;[\\u@\\h \\W~(keystone)]\\$ \u0026#39; $ controller\u0026gt; chmod 600 ~/admin_key $ controller\u0026gt; source ~/admin_key $ controller\u0026gt; echo \u0026#34;source ~/admin_key \u0026#34; \u0026gt;\u0026gt; ~/.bash_profile # keystone 인증파일 생성 후 시작시 등록되게 등록시킵니다. $ controller ~(keystone)\u0026gt; openstack project create --domain default --description \u0026#34;Service Project\u0026#34; service +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Service Project | | domain_id | default | | enabled | True | | id | 7c10c02365be496fb47f12bfd40fe4a7 | | is_domain | False | | name | service | | options | {} | | parent_id | default | | tags | [] | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack project list +----------------------------------+---------+ | ID | Name | +----------------------------------+---------+ | 7c10c02365be496fb47f12bfd40fe4a7 | service | | c76211c24a1f460ca67274d655d46725 | admin | +----------------------------------+---------+ #\r"},{"id":72,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-04/","title":"OpenStack Ussuri : Glance","section":"OpenStack Training","content":"\rOpenStack Ussuri : Glance\r#\r#\r----------------------- | [ Controller Node ] | | | | MariaDB RabbitMQ | | Memcached Keystone | | httpd Glance | ----------------------- #\rOpenStack Ussuri : Glance\r#\r#\rGlance는 OpenStack에서 이미지 생성에 필요한 Iamge 관리 서비스를 구성하고 있습니다. Glance에 자세한 설명은 Glance를 참조해주세요. #\rGlance service 및 User 생성\r#\r$ contoller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 glance +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | 7c10c02365be496fb47f12bfd40fe4a7 | | domain_id | default | | enabled | True | | id | 03f5b16a7be84cb688617d1943c8fe8c | | name | glance | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ contoller ~(keystone)\u0026gt; openstack role add --project service --user glance admin $ contoller ~(keystone)\u0026gt; openstack service create --name glance --description \u0026#34;OpenStack Image service\u0026#34; image +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Image service | | enabled | True | | id | af365771c17a4a25ae1d0c659e2dc0eb | | name | glance | | type | image | +-------------+----------------------------------+ $ contoller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne image public http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | cc65faecd7b042ffafd0f262cd7547df | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | af365771c17a4a25ae1d0c659e2dc0eb | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ $ contoller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne image internal http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | ea41c7b17c844e658ac83c547eddcf6d | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | af365771c17a4a25ae1d0c659e2dc0eb | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ $ contoller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne image admin http://controller:9292 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 1393a64ef0ec428ba437602ac5b390f6 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | af365771c17a4a25ae1d0c659e2dc0eb | | service_name | glance | | service_type | image | | url | http://controller:9292 | +--------------+----------------------------------+ #\r#\rGlance 유저의 DB를 생성합니다.\r#\r#\r$ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database glance; $ MariaDB\u0026gt; grant all privileges on glance.* to glance@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on glance.* to glance@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit; #\r#\rGlance 설치\r#\r$ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-glance # Glacne 및 관련 모듈을 설치합니다. $ controller\u0026gt; vi /etc/glance/glance-api.conf [DEFAULT] bind_host = 0.0.0.0 [glance_store] stores = file,http default_store = file filesystem_store_datadir = /var/lib/glance/images/ [database] connection = mysql+pymysql://glance:qwer1234@controller/glance [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = glance password = qwer1234 [paste_deploy] flavor = keystone # glacne 파일을 수정합니다. $ controller\u0026gt; su -s /bin/bash glance -c \u0026#34;glance-manage db_sync\u0026#34; $ controller\u0026gt; systemctl enable --now openstack-glance-api # Glance DB를 임포트 시킨후 서비스를 등록합니다. #\r$ controller\u0026gt; setsebool -P glance_api_can_network on $ controller\u0026gt; vi glanceapi.te module glanceapi 1.0; require { type glance_api_t; type httpd_config_t; type iscsid_exec_t; class dir search; class file { getattr open read }; } #============= glance_api_t ============== allow glance_api_t httpd_config_t:dir search; allow glance_api_t iscsid_exec_t:file { getattr open read }; $ controller\u0026gt; checkmodule -m -M -o glanceapi.mod glanceapi.te $ controller\u0026gt; semodule_package --outfile glanceapi.pp --module glanceapi.mod $ controller\u0026gt; semodule -i glanceapi.pp $ controller\u0026gt; firewall-cmd --add-port=9292/tcp --permanent $ controller\u0026gt; firewall-cmd --reload #\r#\rGlance Image 생성\r#\r#\r$ controller ~(keystone)\u0026gt; mkdir -p /var/kvm/images $ controller ~(keystone)\u0026gt; wget http://download.cirros-cloud.net/0.5.1/cirros-0.5.1-x86_64-disk.img # 이미지를 다운받습니다. $ controller ~(keystone)\u0026gt; openstack image create \u0026#34;cirros\u0026#34; --file cirros-0.5.1-x86_64-disk.img --disk-format qcow2 +------------------+------------------------------------------------------------ -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -+ | Field | Value | +------------------+------------------------------------------------------------ -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -+ | checksum | 1d3062cd89af34e419f7100277f38b2b | | container_format | bare | | created_at | 2020-08-06T11:08:39Z | | disk_format | qcow2 | | file | /v2/images/dc7c2474-8ec9-4f74-a1c3-7cf6a9ad3d16/file | | id | dc7c2474-8ec9-4f74-a1c3-7cf6a9ad3d16 | | min_disk | 0 | | min_ram | 0 | | name | Cirros | | owner | c76211c24a1f460ca67274d655d46725 | | properties | os_hash_algo=\u0026#39;sha512\u0026#39;, os_hash_value=\u0026#39;553d220ed58cfee7dafe0 03c446a9f197ab5edf8ffc09396c74187cf83873c877e7ae041cb80f3b91489acf687183adcd689b 53b38e3ddd22e627e7f98a09c46\u0026#39;, os_hidden=\u0026#39;False\u0026#39;, owner_specified.openstack.md5=\u0026#39; 1d3062cd89af34e419f7100277f38b2b\u0026#39;, owner_specified.openstack.object=\u0026#39;images/Cirr os\u0026#39;, owner_specified.openstack.sha256=\u0026#39;c4110030e2edf06db87f5b6e4efc27300977683d5 3f040996d15dcc0ad49bb5a\u0026#39;, self=\u0026#39;/v2/images/dc7c2474-8ec9-4f74-a1c3-7cf6a9ad3d16\u0026#39; | | protected | False | | schema | /v2/schemas/image | | size | 16338944 | | status | active | | tags | | | updated_at | 2020-08-06T11:08:39Z | | visibility | shared | +------------------+------------------------------------------------------------ -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -------------------------------------------------------------------------------- -+ # 이미지를 등록합니다. $ controller ~(keystone)\u0026gt; openstack image list +--------------------------------------+--------+--------+ | ID | Name | Status | +--------------------------------------+--------+--------+ | dc7c2474-8ec9-4f74-a1c3-7cf6a9ad3d16 | Cirros | active | +--------------------------------------+--------+--------+ # 이미지를 확인합니다. #\r"},{"id":73,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-05/","title":"OpenStack Ussuri : Nova","section":"OpenStack Training","content":"\rOpenStack Ussuri : Nova\r#\r#\r----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | | | Libvirt | | MariaDB RabbitMQ | | Nova-compute | | Memcached Keystone | | Open vSwitch | | httpd nova | | L2 Agent | | Nova-API | ----------------------- ----------------------- #\rOpenStack Ussuri : Nova\r#\r#\rNova는 OpenStack에서 인스턴스를 생성하는 서비스입니다. Nova에 대한 자세한 설명은 Nova를 참조해주세요. #\r#\rNova, ceilometer service 및 User 생성\r#\r#\r$ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 nova +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | 7c10c02365be496fb47f12bfd40fe4a7 | | domain_id | default | | enabled | True | | id | f26027517d5e4b5b984b5db8d42398c8 | | name | nova | | options | {} | | qwer1234_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 placement +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | 7c10c02365be496fb47f12bfd40fe4a7 | | domain_id | default | | enabled | True | | id | 2394500b4512456f9d9d5066a5ecb1f7 | | name | placement | | options | {} | | qwer1234_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user nova admin $ controller ~(keystone)\u0026gt; openstack role add --project service --user placement admin $ controller ~(keystone)\u0026gt; openstack service create --name nova --description \u0026#34;OpenStack Compute service\u0026#34; compute +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Compute service | | enabled | True | | id | 28d495eca718439f9dc6ce395e0720dc | | name | nova | | type | compute | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack service create --name placement --description \u0026#34;OpenStack Compute Placement service\u0026#34; placement +-------------+-------------------------------------+ | Field | Value | +-------------+-------------------------------------+ | description | OpenStack Compute Placement service | | enabled | True | | id | 8515d3d046834de9b71b2938aae89898 | | name | placement | | type | placement | +-------------+-------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne compute public http://controller:8774/v2.1/%\\(tenant_id\\)s --------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | f13ca97a20eb46a3a1c1dfab546a00cc | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 28d495eca718439f9dc6ce395e0720dc | | service_name | nova | | service_type | compute | | url | http://controller:8774/v2.1/%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne compute internal http://controller:8774/v2.1/%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | 1bc41c829f2f47e7962cba46f0da8ddc | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 28d495eca718439f9dc6ce395e0720dc | | service_name | nova | | service_type | compute | | url | http://controller:8774/v2.1/%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne compute admin http://controller:8774/v2.1/%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | 8022a415f22c400c92989320a2be3133 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 28d495eca718439f9dc6ce395e0720dc | | service_name | nova | | service_type | compute | | url | http://controller:8774/v2.1/%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne placement public http://controller:8778 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 5e988f2be72242f0b3923e27e9db009c | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 8515d3d046834de9b71b2938aae89898 | | service_name | placement | | service_type | placement | | url | http://controller:8778 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne placement internal http://controller:8778 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | a68cf8b6eeb043c2aa1ec95d7711cb50 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 8515d3d046834de9b71b2938aae89898 | | service_name | placement | | service_type | placement | | url | http://controller:8778 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne placement admin http://controller:8778 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 63e47fcbfd7841dd95bb4d9d9a910ab5 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 8515d3d046834de9b71b2938aae89898 | | service_name | placement | | service_type | placement | | url | http://controller:8778 | +--------------+----------------------------------+ #\r#\rNova 유저의 DB를 생성합니다.\r#\r#\r$ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database nova; $ MariaDB\u0026gt; grant all privileges on nova.* to nova@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on nova.* to nova@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; create database nova_api; $ MariaDB\u0026gt; grant all privileges on nova_api.* to nova@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on nova_api.* to nova@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; create database nova_cell0; $ MariaDB\u0026gt; grant all privileges on nova_cell0.* to nova@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on nova_cell0.* to nova@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; create database placement; $ MariaDB\u0026gt; grant all privileges on placement.* to placement@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on placement.* to placement@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit; #\r#\rNova 설치\r#\r#\r$ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-nova openstack-placement-api # nova 및 관련 모듈을 설치합니다. $ controller\u0026gt; vi /etc/nova/nova.conf [DEFAULT] my_ip = 10.10.10.10 # my_ip는 반드시 IP로 적어주세요 ! state_path = /var/lib/nova enabled_apis = osapi_compute,metadata log_dir = /var/log/nova transport_url = rabbit://openstack:qwer1234@controller [api] auth_strategy = keystone [glance] api_servers = http://controller:9292 [vnc] enabled = true server_listen = $my_ip server_proxyclient_address = $my_ip [oslo_concurrency] lock_path = $state_path/tmp [api_database] connection = mysql+pymysql://nova:qwer1234@controller/nova_api [database] connection = mysql+pymysql://nova:qwer1234@controller/nova [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = nova password = qwer1234 [placement] auth_url = http://controller:5000 os_region_name = RegionOne auth_type = password project_domain_name = default user_domain_name = default project_name = service username = placement password = qwer1234 [wsgi] api_paste_config = /etc/nova/api-paste.ini $ controller\u0026gt; vi /etc/placement/placement.conf [DEFAULT] debug = false [api] auth_strategy = keystone [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = placement password = qwer1234 [placement_database] connection = mysql+pymysql://placement:qwer1234@controller/placement $ controller\u0026gt; vi /etc/httpd/conf.d/00-placement-api.conf \u0026lt;Directory /usr/bin\u0026gt; Require all granted \u0026lt;/Directory\u0026gt; # 15번 줄에 추가시킵니다. $ controller\u0026gt; su -s /bin/bash placement -c \u0026#34;placement-manage db sync\u0026#34; $ controller\u0026gt; su -s /bin/bash nova -c \u0026#34;nova-manage api_db sync\u0026#34; $ controller\u0026gt; su -s /bin/bash nova -c \u0026#34;nova-manage cell_v2 map_cell0\u0026#34; $ controller\u0026gt; su -s /bin/bash nova -c \u0026#34;nova-manage db sync\u0026#34; $ controller\u0026gt; su -s /bin/bash nova -c \u0026#34;nova-manage cell_v2 create_cell --name cell1\u0026#34; # nova DB에 임포트 시킵니다. $ controller\u0026gt; semanage port -a -t http_port_t -p tcp 8778 $ controller\u0026gt; firewall-cmd --add-port={6080/tcp,6081/tcp,6082/tcp,8774/tcp,8775/tcp,8778/tcp} --permanent $ controller\u0026gt; firewall-cmd --reload $ controller\u0026gt; systemctl restart httpd $ controller\u0026gt; chown placement. /var/log/placement/placement-api.log $ controller\u0026gt; for service in api conductor scheduler novncproxy; do systemctl enable --now openstack-nova-$service done # Selinux 및 방화벽을 설정합니다. $ controller ~(keystone)\u0026gt; openstack compute service list +----+----------------+------------+----------+---------+-------+----------------------------+ | ID | Binary | Host | Zone | Status | State | Updated At | +----+----------------+------------+----------+---------+-------+----------------------------+ | 4 | nova-conductor | controller | internal | enabled | up | 2020-08-06T12:10:34.000000 | | 5 | nova-scheduler | controller | internal | enabled | up | 2020-08-06T12:10:38.000000 | +----+----------------+------------+----------+---------+-------+----------------------------+ #\r#\rConpute node Nova 설치\r#\r#\rnova 설차\r#\r#\r#\rNova 서비스를 설치하기 전에 가상화를 위한 KVM + QEMU를 설치합니다. 이를 위해서는 Inter VT나 AMD-V가 필요합니다. ( CPU ) $ lsmod | grep kvm kvm_amd 110592 0 ccp 98304 1 kvm_amd kvm 786432 1 kvm_amd irqbypass 16384 1 kvm #\r$ compute\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install qemu-kvm libvirt virt-install libguestfs-tools # KVM 관련 모듈을 설치합니다. $ compute\u0026gt; systemctl enable --now libvirtd # libvirtd 서비스를 등록 및 시작합니다. $ compute\u0026gt; nmcli connection add type bridge autoconnect yes con-name br0 ifname br0 # br0의 가상 브릿지를 추가합니다. $ compute\u0026gt; nmcli connection modify br0 ipv4.addresses 10.10.10.30/24 ipv4.method manual # 가상 브리지의 IP를 추가합니다. ( compute node ip ) $ compute\u0026gt; nmcli connection modify br0 ipv4.gateway 10.10.10.10 # 가상 브리지의 GATEWAY를 등록합니다. $ compute\u0026gt; nmcli connection modify br0 ipv4.dns 8.8.8.8 # 가상 브릿지의 DNS를 등록합니다. $ compute\u0026gt; nmcli connection del ens34 # 본래의 네트워크 인터페이스를 삭제합니다. $ compute\u0026gt; nmcli connection add type bridge-slave autoconnect yes con-name ens34 ifname ens34 master br0 # 삭제한 네트워크 인터페이스 대신 브릿지를 매핑시키고 네트워크를 재시작 시킵니다. # 제 compute node의 내부대역 IP는 10.10.10.30/24 ens34입니다 햇갈리지 마세요 ! $ compute\u0026gt; init 6 $ compute\u0026gt; ipfconfig br0: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 inet 10.10.10.30 netmask 255.255.255.0 broadcast 10.10.10.255 inet6 fe80::6765:fe91:a94b:5529 prefixlen 64 scopeid 0x20\u0026lt;link\u0026gt; ether 00:0c:29:80:33:15 txqueuelen 1000 (Ethernet) RX packets 465 bytes 56335 (55.0 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 348 bytes 66663 (65.1 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 ens34: flags=4163\u0026lt;UP,BROADCAST,RUNNING,MULTICAST\u0026gt; mtu 1500 ether 00:0c:29:80:33:15 txqueuelen 1000 (Ethernet) RX packets 471 bytes 63205 (61.7 KiB) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 450 bytes 75797 (74.0 KiB) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 # 재시작후 네트워크 인터페이스를 확인하면 위와 같이 생성된 것을 확인할 수 있습니다. #\r#\r$ compute\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-nova-compute # nova 및 관련 모듈을 설치합니다. $ controller\u0026gt; scp /etc/nova/nova.conf compute:/etc/nova/nova.conf # nova의 기본설정파일을 복사합니다. $ compute\u0026gt; vi /etc/nova/nova.conf [default] my_ip = 10.10.10.30 # my_ip는 반드시 IP로 적어주세요 ! [libvirt] virt_type = qemu [vnc] enabled = True server_listen = 0.0.0.0 server_proxyclient_address = $my_ip novncproxy_base_url = http://controller:6080/vnc_auto.html # nova관련 설정을 추가합니다. $ compute\u0026gt; firewall-cmd --add-port=5900-5999/tcp --permanent $ compute\u0026gt; firewall-cmd --reload $ compute\u0026gt; systemctl enable --now libvirtd $ compute\u0026gt; systemctl enable --now openstack-nova-compute #\r#\rNova 설치 확인\r#\r#\r$ controller\u0026gt; su -s /bin/bash nova -c \u0026#34;nova-manage cell_v2 discover_hosts\u0026#34; # DB에 compute의 대한 설정을 업데이트 합니다. $ controller\u0026gt; nova-manage cell_v2 discover_hosts --verbose # compute 노드가 검색이 안되었을 시 추가적으로 검색합니다. $ controller ~(keystone)\u0026gt; openstack compute service list +----+----------------+------------+----------+---------+-------+----------------------------+ | ID | Binary | Host | Zone | Status | State | Updated At | +----+----------------+------------+----------+---------+-------+----------------------------+ | 4 | nova-conductor | controller | internal | enabled | up | 2020-08-06T21:40:34.000000 | | 5 | nova-scheduler | controller | internal | enabled | up | 2020-08-06T21:40:37.000000 | | 8 | nova-compute | compute | nova | enabled | up | 2020-08-06T21:40:36.000000 | +----+----------------+------------+----------+---------+-------+----------------------------+ #\r"},{"id":74,"href":"/cloud/docs/OpenStack/OpenStack/Service/","title":"Service","section":"OpenStack docs","content":"\r****\r#\r#\r옵셔널 서비스\r#\r컴퓨트, 오브젝트 스토리지, 이미지, 인증, 네트워크, 블록 스토리지, 대시보드 서비스만으로도 오픈스택을 구축할 수 있음 텔레미터, 오케스트레이션, 데이터베이스 같은 서비스를 제대로 사용한다면 효율적인 클라우드 관리와 운영에 많은 도움을 많을 수 있음 메시징 서비스 Zaqar 공유 파일 시스템 서비스 Manila DNS 서비스 Designate "},{"id":75,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-06/","title":"OpenStack Ussuri : Neutron","section":"OpenStack Training","content":"\rOpenStack Ussuri : Neutron\r#\r#\r----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Neutron | | L2 Agent | | metadata agent | | Nova-API Compute | ----------------------- ----------------------- | L2 agent L3 agent | | metadata agent | | Neutron Server | ----------------------- #\rOpenStack Ussuri : Neutron\r#\r#\rNeutron는 OpenStack에서 네트워크 전반을 관리하는 서비스입니다. Neutron에 대한 자세한 설명은 Neutron를 참조해주세요. #\r#\rNeutron service 및 User 생성\r#\r#\r$ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 neutron +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | 7c10c02365be496fb47f12bfd40fe4a7 | | domain_id | default | | enabled | True | | id | 943fbb4370164c77ae6bf7fa455292f8 | | name | neutron | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user neutron admin $ controller ~(keystone)\u0026gt; openstack service create --name neutron --description \u0026#34;OpenStack Networking service\u0026#34; network +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Networking service | | enabled | True | | id | 055e5f6e38004338b0ae4a86e77932ae | | name | neutron | | type | network | +-------------+----------------------------------+ # neutron service 및 user을 생성합니다. $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne network public http://controller:9696 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 350c666f597a41e59234b09f534aa72f | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 055e5f6e38004338b0ae4a86e77932ae | | service_name | neutron | | service_type | network | | url | http://controller:9696 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne network internal http://controller:9696 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | b9cad959e1634ff797e27f00d50e9578 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 055e5f6e38004338b0ae4a86e77932ae | | service_name | neutron | | service_type | network | | url | http://controller:9696 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne network admin http://controller:9696 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 72fc145deb1d4d508e3691b3bf77708e | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 055e5f6e38004338b0ae4a86e77932ae | | service_name | neutron | | service_type | network | | url | http://controller:9696 | +--------------+----------------------------------+ # neutron endpoint를 등록합니다. #\r#\rneutron 유저의 DB를 생성합니다.\r#\r#\r$ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database neutron_ml2; $ MariaDB\u0026gt; grant all privileges on neutron_ml2.* to neutron@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on neutron_ml2.* to neutron@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit; #\r#\rNeutron 설치\r#\r#\r$ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-neutron openstack-neutron-ml2 # neutron 및 관련 모듈을 설치합니다. $ controller\u0026gt; vi /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router auth_strategy = keystone state_path = /var/lib/neutron dhcp_agent_notification = True allow_overlapping_ips = True notify_nova_on_port_status_changes = True notify_nova_on_port_data_changes = True transport_url = rabbit://openstack:qwer1234@controller [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = qwer1234 [database] connection = mysql+pymysql://neutron:qwer1234@controller/neutron_ml2 [nova] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = nova password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ controller\u0026gt; vi /etc/neutron/metadata_agent.ini [DEFAULT] nova_metadata_host = controller metadata_proxy_shared_secret = metadata_secret [cache] memcache_servers = controller:11211 $ controller\u0026gt; vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = vxlan mechanism_drivers = openvswitch extension_drivers = port_security [ml2_type_flat] flat_networks = physnet1 [ml2_type_vxlan] vni_ranges = 1:1000 $ controller\u0026gt; vi /etc/nova/nova.conf [default] ... ... use_neutron = True linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver firewall_driver = nova.virt.firewall.NoopFirewallDriver [neutron] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = qwer1234 service_metadata_proxy = True metadata_proxy_shared_secret = metadata_secret $ controller\u0026gt; setsebool -P neutron_can_network on $ controller\u0026gt; setsebool -P daemons_enable_cluster_mode on $ controller\u0026gt; firewall-cmd --add-port=9696/tcp --permanent $ controller\u0026gt; firewall-cmd --reload # 방화벽 및 SELinux를 설정합니다. $ controller\u0026gt; ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini $ controller\u0026gt; su -s /bin/bash neutron -c \u0026#34;neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugin.ini upgrade head\u0026#34; $ controller\u0026gt; systemctl enable --now neutron-server neutron-metadata-agent $ controller\u0026gt; systemctl restart openstack-nova-api # neutron DB를 임포트 시킨 후, 서비스를 등록 합니다. #\r#\rneutron Network Node 설치\r#\r#\rNeutron 설치\r#\r#\r$ network\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch libibverbs # neutron 및 관련 모듈을 설치합니다. $ network\u0026gt; vi /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router auth_strategy = keystone state_path = /var/lib/neutron allow_overlapping_ips = True # RabbitMQ connection info transport_url = rabbit://openstack:qwer1234@controller [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = qwer1234 [oslo_concurrency] lock_path = $state_path/lock $ network\u0026gt; vi /etc/neutron/dhcp_agent.ini [DEFAULT] interface_driver = openvswitch dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq enable_isolated_metadata = true $ network\u0026gt; vi /etc/neutron/metadata_agent.ini nova_metadata_host = controller metadata_proxy_shared_secret = metadata_secret [cache] memcache_servers = controller:11211 $ network\u0026gt; vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = vxlan mechanism_drivers = openvswitch extension_drivers = port_security [ml2_type_flat] flat_networks = physnet1 [ml2_type_vxlan] vni_ranges = 1:1000 # 끝에 추가합니다. $ network\u0026gt; vi /etc/neutron/plugins/ml2/openvswitch_agent.ini [securitygroup] firewall_driver = openvswitch enable_security_group = true enable_ipset = true [agent] tunnel_types = vxlan prevent_arp_spoofing = True [ovs] local_ip = 10.10.10.20 bridge_mappings = physnet1:br-eth1 # 끝에 추가합니다. # 여기는 IP 를 반드시 적어야 해요 ! $ network\u0026gt; setsebool -P neutron_can_network on $ network\u0026gt; setsebool -P haproxy_connect_any on $ network\u0026gt; setsebool -P daemons_enable_cluster_mode on $ network\u0026gt; vi ovsofctl.te module ovsofctl 1.0; require { type neutron_t; type neutron_exec_t; type neutron_t; type dnsmasq_t; class file execute_no_trans; class capability { dac_override sys_rawio }; } #============= neutron_t ============== allow neutron_t self:capability { dac_override sys_rawio }; allow neutron_t neutron_exec_t:file execute_no_trans; #============= dnsmasq_t ============== allow dnsmasq_t self:capability dac_override; $ network\u0026gt; checkmodule -m -M -o ovsofctl.mod ovsofctl.te $ network\u0026gt; semodule_package --outfile ovsofctl.pp --module ovsofctl.mod $ network\u0026gt; semodule -i ovsofctl.pp $ network\u0026gt; systemctl disable --now firewalld # Selinux 및 방화벽을 설정합니다. $ network\u0026gt; ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini $ network\u0026gt; systemctl enable --now openvswitch $ network\u0026gt; ovs-vsctl add-br br-int $ network\u0026gt; ovs-vsctl add-br br-eth1 $ network\u0026gt; ovs-vsctl add-port br-eth1 ens32 $ network\u0026gt; vi /etc/sysconfig/network-scripts/ifcfg-ens32 TYPE=Ethernet BOOTPROTO=static NAME=ens32 DEVICE=ens32 ONBOOT=yes $ network\u0026gt; vi /var/tmp/network_interface.sh #!/bin/bash ip link set up br-eth1 ip addr add 192.168.10.20/24 dev br-eth1 route add default gw 192.168.10.2 dev br-eth1 echo \u0026#34;nameserver 8.8.8.8\u0026#34; \u0026gt; /etc/resolv.conf $ network\u0026gt; chmod 755 /var/tmp/network_interface.sh $ network\u0026gt; vi /etc/systemd/system/set_interface.service [Unit] Description=Description for sample script goes here After=network.target [Service] Type=simple ExecStart=/var/tmp/network_interface.sh TimeoutStartSec=0 [Install] WantedBy=default.target $ systemctl enable set_interface $ init 6 # network 인터페이스 주의 !!! ( ex : ens32 ) $ network\u0026gt; for service in dhcp-agent l3-agent metadata-agent openvswitch-agent; do systemctl enable --now neutron-$service done # neutron 서비스를 등록합니다. #\rneutron compute Node 설치\r#\rNeutron 설치\r#\r#\r$ compute\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch # neutron 및 관련 모듈을 설치합니다. $ compute\u0026gt; vi /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router auth_strategy = keystone state_path = /var/lib/neutron allow_overlapping_ips = True transport_url = rabbit://openstack:qwer1234@controller [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = qwer1234 [oslo_concurrency] lock_path = $state_path/lock $ compute\u0026gt; vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = vxlan mechanism_drivers = openvswitch extension_drivers = port_security [ml2_type_flat] flat_networks = physnet1 [ml2_type_vxlan] vni_ranges = 1:1000 # 끝에 추가합니다. $ compute\u0026gt; vi /etc/neutron/plugins/ml2/openvswitch_agent.ini [securitygroup] firewall_driver = openvswitch enable_security_group = true enable_ipset = true [agent] tunnel_types = vxlan prevent_arp_spoofing = True [ovs] local_ip = 10.10.10.20 # 끝에 추가합니다. # 여기는 반드시 IP로 적어야 해요 ! $ compute\u0026gt; vi /etc/nova/nova.conf [default] ... ... use_neutron = True linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver firewall_driver = nova.virt.firewall.NoopFirewallDriver vif_plugging_is_fatal = True vif_plugging_timeout = 300 [neutron] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = qwer1234 service_metadata_proxy = True metadata_proxy_shared_secret = metadata_secret $ compute\u0026gt; setsebool -P neutron_can_network on $ compute\u0026gt; setsebool -P daemons_enable_cluster_mode on $ compute\u0026gt; vi ovsofctl.te module ovsofctl 1.0; require { type neutron_t; type neutron_exec_t; type neutron_t; type dnsmasq_t; class file execute_no_trans; class capability { dac_override sys_rawio }; } #============= neutron_t ============== allow neutron_t self:capability { dac_override sys_rawio }; allow neutron_t neutron_exec_t:file execute_no_trans; #============= dnsmasq_t ============== allow dnsmasq_t self:capability dac_override; $ network\u0026gt; checkmodule -m -M -o ovsofctl.mod ovsofctl.te $ network\u0026gt; semodule_package --outfile ovsofctl.pp --module ovsofctl.mod $ network\u0026gt; semodule -i ovsofctl.pp $ systemctl disable --now firewalld # Selinux 및 방화벽을 설정합니다. $ compute\u0026gt; ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini $ compute\u0026gt; systemctl enable --now openvswitch $ compute\u0026gt; ovs-vsctl add-br br-int $ compute\u0026gt; systemctl restart openstack-nova-compute $ compute\u0026gt; systemctl enable --now neutron-openvswitch-agent # neutron 서비스를 등록합니다. #\r#\r확인\r#\r#\r$ controller ~(keystone)\u0026gt; openstack router create router +-------------------------+----------------------------------------------------- -------------------------------------------------------------------------------- --------------------+ | Field | Value | +-------------------------+----------------------------------------------------- -------------------------------------------------------------------------------- --------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2020-08-07T00:05:40Z | | description | | | distributed | False | | external_gateway_info | null | | flavor_id | None | | ha | False | | id | f40d6130-a01c-486a-b088-3f27c9f57607 | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;d efault\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, re gion_name=\u0026#39;\u0026#39;, zone= | | name | router | | project_id | c76211c24a1f460ca67274d655d46725 | | revision_number | 1 | | routes | | | status | ACTIVE | | tags | | | updated_at | 2020-08-07T00:05:40Z | +-------------------------+----------------------------------------------------- -------------------------------------------------------------------------------- --------------------+ $ controller ~(keystone)\u0026gt; openstack network create int --provider-network-type vxlan +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2020-08-07T00:05:58Z | | description | | | dns_domain | None | | id | 0edec63e-cc62-4e93-8962-d0ad2df27bc8 | | ipv4_address_scope | None | | ipv6_address_scope | None | | is_default | False | | is_vlan_transparent | None | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;default\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, region_name=\u0026#39;\u0026#39;, zone= | | mtu | 1450 | | name | int | | port_security_enabled | True | | project_id | c76211c24a1f460ca67274d655d46725 | | provider:network_type | vxlan | | provider:physical_network | None | | provider:segmentation_id | 1 | | qos_policy_id | None | | revision_number | 1 | | router:external | Internal | | segments | None | | shared | False | | status | ACTIVE | | subnets | | | tags | | | updated_at | 2020-08-07T00:05:58Z | +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack subnet create int-sub --network int \\ --subnet-range 1.1.1.0/24 --gateway 1.1.1.1 \\ --dns-nameserver 8.8.8.8 +----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | allocation_pools | 1.1.1.2-1.1.1.254 | | cidr | 1.1.1.0/24 | | created_at | 2020-08-07T00:06:25Z | | description | | | dns_nameservers | 8.8.8.8 | | dns_publish_fixed_ip | None | | enable_dhcp | True | | gateway_ip | 1.1.1.1 | | host_routes | | | id | 800bc5af-45e9-4719-8969-4c154bc111d6 | | ip_version | 4 | | ipv6_address_mode | None | | ipv6_ra_mode | None | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;default\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, region_name=\u0026#39;\u0026#39;, zone= | | name | int-sub | | network_id | 0edec63e-cc62-4e93-8962-d0ad2df27bc8 | | prefix_length | None | | project_id | c76211c24a1f460ca67274d655d46725 | | revision_number | 0 | | segment_id | None | | service_types | | | subnetpool_id | None | | tags | | | updated_at | 2020-08-07T00:06:25Z | +----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack router add subnet router int-sub $ controller ~(keystone)\u0026gt; openstack network create \\ --provider-physical-network physnet1 \\ --provider-network-type flat --external ext +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | admin_state_up | UP | | availability_zone_hints | | | availability_zones | | | created_at | 2020-08-07T00:06:47Z | | description | | | dns_domain | None | | id | 68e5adb0-a8c4-473b-88a9-fdaaf6f12ec2 | | ipv4_address_scope | None | | ipv6_address_scope | None | | is_default | False | | is_vlan_transparent | None | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;default\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, region_name=\u0026#39;\u0026#39;, zone= | | mtu | 1500 | | name | ext | | port_security_enabled | True | | project_id | c76211c24a1f460ca67274d655d46725 | | provider:network_type | flat | | provider:physical_network | physnet1 | | provider:segmentation_id | None | | qos_policy_id | None | | revision_number | 1 | | router:external | External | | segments | None | | shared | False | | status | ACTIVE | | subnets | | | tags | | | updated_at | 2020-08-07T00:06:47Z | +---------------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack subnet create ext-sub \\ --network ext --subnet-range 192.168.10.0/24 \\ --allocation-pool start=192.168.10.150,end=192.168.10.200 \\ --gateway 192.168.10.2 --dns-nameserver 8.8.8.8 +----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | allocation_pools | 192.168.10.150-192.168.10.200 | | cidr | 192.168.10.0/24 | | created_at | 2020-08-07T00:07:21Z | | description | | | dns_nameservers | 8.8.8.8 | | dns_publish_fixed_ip | None | | enable_dhcp | True | | gateway_ip | 192.168.10.2 | | host_routes | | | id | 31a92331-f102-4c4e-8c02-f97baa9eab28 | | ip_version | 4 | | ipv6_address_mode | None | | ipv6_ra_mode | None | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;default\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, region_name=\u0026#39;\u0026#39;, zone= | | name | ext-sub | | network_id | 68e5adb0-a8c4-473b-88a9-fdaaf6f12ec2 | | prefix_length | None | | project_id | c76211c24a1f460ca67274d655d46725 | | revision_number | 0 | | segment_id | None | | service_types | | | subnetpool_id | None | | tags | | | updated_at | 2020-08-07T00:07:21Z | +----------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack router set router --external-gateway ext $ controller ~(keystone)\u0026gt; openstack network rbac list +--------------------------------------+-------------+--------------------------------------+ | ID | Object Type | Object ID | +--------------------------------------+-------------+--------------------------------------+ | 4e8ebe0b-60f0-485c-8696-74378068c844 | network | 68e5adb0-a8c4-473b-88a9-fdaaf6f12ec2 | +--------------------------------------+-------------+--------------------------------------+ $ controller ~(keystone)\u0026gt; wget http://cloud-images.ubuntu.com/releases/18.04/release/ubuntu-18.04-server-cloudimg-amd64.img -P /var/kvm/images $ controller ~(keystone)\u0026gt; openstack image create \u0026#34;Ubuntu1804\u0026#34; --file /var/kvm/images/ubuntu-18.04-server-cloudimg-amd64.img --disk-format qcow2 --container-format bare --public # Ubuntu18.04 이미지를 다운로드 후, 등록합니다. $ controller ~(keystone)\u0026gt; openstack security group create all-port +-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | created_at | 2020-08-07T00:10:31Z | | description | all-port | | id | 97224218-b304-4076-9645-d68092a9366a | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;default\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, region_name=\u0026#39;\u0026#39;, zone= | | name | all-port | | project_id | c76211c24a1f460ca67274d655d46725 | | revision_number | 1 | | rules | created_at=\u0026#39;2020-08-07T00:10:32Z\u0026#39;, direction=\u0026#39;egress\u0026#39;, ethertype=\u0026#39;IPv6\u0026#39;, id=\u0026#39;333de7e9-5c1b-4b2f-bb0e-2da1b878abb6\u0026#39;, updated_at=\u0026#39;2020-08-07T00:10:32Z\u0026#39; | | | created_at=\u0026#39;2020-08-07T00:10:32Z\u0026#39;, direction=\u0026#39;egress\u0026#39;, ethertype=\u0026#39;IPv4\u0026#39;, id=\u0026#39;644e18e1-4f4e-42ad-bef8-937e47254a27\u0026#39;, updated_at=\u0026#39;2020-08-07T00:10:32Z\u0026#39; | | stateful | True | | tags | [] | | updated_at | 2020-08-07T00:10:32Z | +-----------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack security group rule create --protocol icmp --ingress all-port +-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | created_at | 2020-08-07T00:13:31Z | | description | | | direction | ingress | | ether_type | IPv4 | | id | 27688481-047b-4fc0-948c-de109e46d7f5 | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;default\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, region_name=\u0026#39;\u0026#39;, zone= | | name | None | | port_range_max | None | | port_range_min | None | | project_id | c76211c24a1f460ca67274d655d46725 | | protocol | icmp | | remote_group_id | None | | remote_ip_prefix | 0.0.0.0/0 | | revision_number | 0 | | security_group_id | 97224218-b304-4076-9645-d68092a9366a | | tags | [] | | updated_at | 2020-08-07T00:13:31Z | +-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack security group rule create --protocol tcp --dst-port 22:22 all-port +-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ | created_at | 2020-08-07T00:13:36Z | | description | | | direction | ingress | | ether_type | IPv4 | | id | da2afd20-818a-4bfe-9017-c837b2bf30ec | | location | cloud=\u0026#39;\u0026#39;, project.domain_id=, project.domain_name=\u0026#39;default\u0026#39;, project.id=\u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, project.name=\u0026#39;admin\u0026#39;, region_name=\u0026#39;\u0026#39;, zone= | | name | None | | port_range_max | 22 | | port_range_min | 22 | | project_id | c76211c24a1f460ca67274d655d46725 | | protocol | tcp | | remote_group_id | None | | remote_ip_prefix | 0.0.0.0/0 | | revision_number | 0 | | security_group_id | 97224218-b304-4076-9645-d68092a9366a | | tags | [] | | updated_at | 2020-08-07T00:13:36Z | +-------------------+---------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; ssh-keygen -q -N \u0026#34;\u0026#34; $ controller ~(keystone)\u0026gt; openstack keypair create --public-key ~/.ssh/id_rsa.pub MyKey +-------------+-------------------------------------------------+ | Field | Value | +-------------+-------------------------------------------------+ | fingerprint | a3:8f:44:f6:e1:4e:da:a0:90:f1:5d:dc:6a:8b:ad:76 | | name | MyKey | | user_id | 57ce8f772e374a7c9282f2674fda1ba7 | +-------------+-------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack flavor create --ram 1024 --disk 10 --vcpus 1 m1.small +----------------------------+--------------------------------------+ | Field | Value | +----------------------------+--------------------------------------+ | OS-FLV-DISABLED:disabled | False | | OS-FLV-EXT-DATA:ephemeral | 0 | | disk | 10 | | id | dabfebd4-cd05-4cec-9567-78b8c9e3d6b6 | | name | m1.small | | os-flavor-access:is_public | True | | properties | | | ram | 1024 | | rxtx_factor | 1.0 | | swap | | | vcpus | 1 | +----------------------------+--------------------------------------+ $ controller ~(keystone)\u0026gt; openstack server create --image Ubuntu1804 --flavor m1.small --key Mykey --network int --security-group all-port Ubuntu $ controller ~(keystone)\u0026gt; openstack floating ip create ext +---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | Field | Value | +---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ | created_at | 2020-08-07T00:16:15Z | | description | | | dns_domain | None | | dns_name | None | | fixed_ip_address | None | | floating_ip_address | 192.168.10.191 | | floating_network_id | 68e5adb0-a8c4-473b-88a9-fdaaf6f12ec2 | | id | 409a4724-1e13-4150-a2e1-6b3a205c4ff6 | | location | Munch({\u0026#39;cloud\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;region_name\u0026#39;: \u0026#39;\u0026#39;, \u0026#39;zone\u0026#39;: None, \u0026#39;project\u0026#39;: Munch({\u0026#39;id\u0026#39;: \u0026#39;c76211c24a1f460ca67274d655d46725\u0026#39;, \u0026#39;name\u0026#39;: \u0026#39;admin\u0026#39;, \u0026#39;domain_id\u0026#39;: None, \u0026#39;domain_name\u0026#39;: \u0026#39;default\u0026#39;})}) | | name | 192.168.10.191 | | port_details | None | | port_id | None | | project_id | c76211c24a1f460ca67274d655d46725 | | qos_policy_id | None | | revision_number | 0 | | router_id | None | | status | DOWN | | subnet_id | None | | tags | [] | | updated_at | 2020-08-07T00:16:15Z | +---------------------+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack server add floating ip Ubuntu 192.168.10.191 $ controller ~(keystone)\u0026gt; #\r"},{"id":76,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-07/","title":"OpenStack Ussuri : Cinder","section":"OpenStack Training","content":"\rOpenStack Ussuri : Cinder\r#\r#\r----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | ----------------------- | L2 agent L3 agent | | NFS | | metadata agent | ----------------------- | Neutron Server | ----------------------- #\rOpenStack Ussuri : Cinder\r#\r#\rCinder는 OpenStack에서 전체적인 볼륨, 디스크를 관리하는 서비스입니다. Cinder 서비스는 다른 Storage Node들과 함께 사용하도록 NFS 서버 또한 구축하여 백업 서비스를 활성하할 수 있게 구성핟록 하겠습니다. Cinder에 대한 자세한 설명은 Cinder를 참조해주세요. #\r#\rCinder service 및 User 생성\r#\r#\r$ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 cinder +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | 7c10c02365be496fb47f12bfd40fe4a7 | | domain_id | default | | enabled | True | | id | 1f9dbcbb529a45c28b5bb8b035ea277a | | name | cinder | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user cinder admin $ controller ~(keystone)\u0026gt; openstack service create --name cinderv3 --description \u0026#34;OpenStack Block Storage\u0026#34; volumev3 +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Block Storage | | enabled | True | | id | 225ceadb699d4e79adf30769cd872fef | | name | cinderv3 | | type | volumev3 | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne volumev3 public http://controller:8776/v3/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | 6bf917232caa43eab3b83959fb19cb45 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 225ceadb699d4e79adf30769cd872fef | | service_name | cinderv3 | | service_type | volumev3 | | url | http://controller:8776/v3/%(tenant_id)s | +--------------+-----------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne volumev3 internal http://controller:8776/v3/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | c5987fc3d9eb4fb79a2e8cf73a274936 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 225ceadb699d4e79adf30769cd872fef | | service_name | cinderv3 | | service_type | volumev3 | | url | http://controller:8776/v3/%(tenant_id)s | +--------------+-----------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne volumev3 admin http://controller:8776/v3/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | eff2398584944c0fa7575d1991d725fe | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 225ceadb699d4e79adf30769cd872fef | | service_name | cinderv3 | | service_type | volumev3 | | url | http://controller:8776/v3/%(tenant_id)s | +--------------+-----------------------------------------+ # Cinder의 Endpoint를 생성합니다. #\r#\rCinder 유저의 DB를 생성합니다.\r#\r#\r$ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database cinder; $ MariaDB\u0026gt; grant all privileges on cinder.* to cinder@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on cinder.* to cinder@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit; #\r#\rCinder 설치\r#\r#\r$ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-cinder # cinder 및 관련 모듈을 설치합니다. $ controller\u0026gt; vi /etc/cinder/cinder.conf [DEFAULT] my_ip = controller log_dir = /var/log/cinder state_path = /var/lib/cinder auth_strategy = keystone transport_url = rabbit://openstack:qwer1234@controller enable_v3_api = True [database] connection = mysql+pymysql://cinder:qwer1234@controller/cinder [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = cinder password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ controller\u0026gt; su -s /bin/bash cinder -c \u0026#34;cinder-manage db sync\u0026#34; $ controller\u0026gt; systemctl enable --now openstack-cinder-api openstack-cinder-scheduler # cinder DB를 임포트 시키고, 서비스를 등록합니다. $ controller\u0026gt; echo \u0026#34;export OS_VOLUME_API_VERSION=3\u0026#34; \u0026gt;\u0026gt; ~/admin_key $ controller\u0026gt; source ~/admin_key # key파일을 수정합니다. $ controller\u0026gt; firewall-cmd --add-port=8776/tcp --permanent $ controller\u0026gt; firewall-cmd --reload # 방화벽을 설정합니다. #\r#\rCinder compute node 설치\r#\r#\r$ compute\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-cinder targetcli # cinder 및 관련 모듈을 설치합니다. $ compute\u0026gt; fdisk ... # LVM의 타입으로 파티션을 추가합니다. # cinder 이름으로 vg를 생성합니다. $ controller\u0026gt; scp /etc/cinder/cinder.conf compute:/etc/cinder/cinder.conf $ compute\u0026gt; vi /etc/cinder/cinder.conf [default] my_ip = compute ... ... glance_api_servers = http://controller:9292 enabled_backends = lvm [lvm] target_helper = lioadm target_protocol = iscsi target_ip_address = compute volume_group = cinder volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volumes_dir = $state_path/volumes $ compute\u0026gt; vi /etc/nova/nova.conf [cinder] os_region_name = RegionOne $ compute\u0026gt; systemctl restart openstack-nova-compute $ compute\u0026gt; systemctl enable --now openstack-cinder-volume $ compute\u0026gt; vi iscsiadm.te module iscsiadm 1.0; require { type iscsid_t; class capability dac_override; } #============= iscsid_t ============== allow iscsid_t self:capability dac_override; $ compute\u0026gt; checkmodule -m -M -o iscsiadm.mod iscsiadm.te $ compute\u0026gt; semodule_package --outfile iscsiadm.pp --module iscsiadm.mod $ compute\u0026gt; semodule -i iscsiadm.pp $ compute\u0026gt; firewall-cmd --add-service=iscsi-target --permanent $ compute\u0026gt; firewall-cmd --reload # SELinux 및 방화벽을 설정합니다. #\r#\r확인\r#\r$ controller ~/(keystone)\u0026gt; openstack volume service list +------------------+-------------+------+---------+-------+----------------------------+ | Binary | Host | Zone | Status | State | Updated At | +------------------+-------------+------+---------+-------+----------------------------+ | cinder-scheduler | controller | nova | enabled | up | 2020-08-07T01:29:22.000000 | | cinder-volume | compute@lvm | nova | enabled | up | 2020-08-07T01:29:22.000000 | +------------------+-------------+------+---------+-------+----------------------------+ $ controller ~/(keystone)\u0026gt; openstack volume create --size 1 test +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | attachments | [] | | availability_zone | nova | | bootable | false | | consistencygroup_id | None | | created_at | 2020-08-07T01:46:06.000000 | | description | None | | encrypted | False | | id | aa07bf85-424d-478c-ae52-648ddc588465 | | migration_status | None | | multiattach | False | | name | test | | properties | | | replication_status | None | | size | 1 | | snapshot_id | None | | source_volid | None | | status | creating | | type | __DEFAULT__ | | updated_at | None | | user_id | 57ce8f772e374a7c9282f2674fda1ba7 | +---------------------+--------------------------------------+ $ controller ~/(keystone)\u0026gt; openstack volume list +--------------------------------------+------+-----------+------+-------------+ | ID | Name | Status | Size | Attached to | +--------------------------------------+------+-----------+------+-------------+ | aa07bf85-424d-478c-ae52-648ddc588465 | test | available | 1 | | +--------------------------------------+------+-----------+------+-------------+ #\r#\r오류가 있어 수정 중입니다 !\r#\r#\rCinder 백업 서비스 구성\r#\rNFS 구성참조 #\r$ compute\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install nfs-utils # nfs-utils을 설치합니다. $ compute\u0026gt; vi /etc/exports /nfs 10.10.10.0/24(rw,no_root_squash) # ro: 마운트 된 볼륨의 데이터를 읽기만 가능 # rw: 마운트 된 볼륨에 쓰기 또한 가능 # no_root_squash: 루트 자격을 가진 사용자만 쓰기 가능 # noaccess: 디렉터리 접근 불가 $ compute\u0026gt; systemctl enable --now rpcbind nfs-server # NFC-server 서비스를 등록 및 시작합니다. $ vi /etc/cinder/cinder.conf [default] ... ... enabled_backends = lvm,nfs [nfs] volume_driver = cinder.volume.drivers.nfs.NfsDriver volume_backend_name = NFS nfs_shares_config = /etc/cinder/nfs_shares nfs_mount_point_base = $state_path/mnt_nfs # cinder.conf 파일의 nfs를 추가합니다. $ compute\u0026gt; vi /etc/cinder/nfs_shares compute:/nfs # 공유될 디렉토리를 지정합니다. $ compute\u0026gt; chmod 640 /etc/cinder/nfs_shares $ compute\u0026gt; chgrp cinder /etc/cinder/nfs_shares $ compute\u0026gt; systemctl restart openstack-cinder-volume $ compute\u0026gt; chown -R cinder. /var/lib/cinder/mnt_nfs # cinder nfs 파일의 권한을 변경하고 cinder 서비스를 재시작합니다. $ compute\u0026gt; firewall-cmd --add-service=nfs --permanent $ compute\u0026gt; firewall-cmd --reload # 방화벽을 설정합니다. $ compute\u0026gt; vi iscsiadm.te module iscsiadm 1.0; require { type iscsid_t; class capability dac_override; } #============= iscsid_t ============== allow iscsid_t self:capability dac_override; $ compute\u0026gt; checkmodule -m -M -o iscsiadm.mod iscsiadm.te $ compute\u0026gt; semodule_package --outfile iscsiadm.pp --module iscsiadm.mod $ compute\u0026gt; semodule -i iscsiadm.pp $ compute\u0026gt; systemctl restart openstack-nova-compute # SELinux를 설정하고 compute 서비스를 재시작합니다. #\r#\rCinder 백업 서비스 구성\r#\r#\r$ compute\u0026gt; vi /etc/cinder/cinder.conf [default] ... ... backup_driver = cinder.backup.drivers.nfs.NFSBackupDriver backup_mount_point_base = $state_path/backup_nfs backup_share = compute:/var/lib/cinder-backup # ciner 백업 서비스를 활성화하기 이해 cinder.conf 파일의 설정을 추가합니다. $ compute\u0026gt; systemctl enable --now openstack-cinder-backup $ compute\u0026gt; chown -R cinder. /var/lib/cinder/backup_nfs $ cinder backup 서비스를 활성화합니다. #\r#\r확인\r#\r#\r$ controller ~(keystone)\u0026gt; openstack volume service list +------------------+-------------+------+---------+-------+----------------------------+ | Binary | Host | Zone | Status | State | Updated At | +------------------+-------------+------+---------+-------+----------------------------+ | cinder-scheduler | controller | nova | enabled | up | 2020-08-12T04:31:53.000000 | | cinder-volume | compute@lvm | nova | enabled | up | 2020-08-12T04:31:46.000000 | | cinder-volume | compute@nfs | nova | enabled | up | 2020-08-12T04:31:46.000000 | +------------------+-------------+------+---------+-------+----------------------------+ $ controller ~(keystone)\u0026gt; $ controller ~(keystone)\u0026gt; $ controller ~(keystone)\u0026gt; $ controller ~(keystone)\u0026gt; "},{"id":77,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-08/","title":"OpenStack Ussuri : Horizon","section":"OpenStack Training","content":"\rOpenStack : Horizon\r#\r#\rOpenStack : Horizon\r#\r#\rHorizon은 openstack에서 GUI 환경을 제공해주는 서비스입니다. Horizon에 대한 자세한 설명은 Horizon을 참조해주세요. #\r$ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-dashboard $ controller\u0026gt; vi /etc/openstack-dashboard/local_settings ALLOWED_HOSTS = [\u0026#39;*\u0026#39;,\u0026#39;\u0026#39;] # 모든 host의 접속이 가능하게 설정합니다. CACHES = { \u0026#39;default\u0026#39;: { \u0026#39;BACKEND\u0026#39;: \u0026#39;django.core.cache.backends.memcached.MemcachedCache\u0026#39;, \u0026#39;LOCATION\u0026#39;: \u0026#39;controller:11211\u0026#39;, }, } SESSION_ENGINE = \u0026#34;django.contrib.sessions.backends.cache\u0026#34; OPENSTACK_HOST = \u0026#34;controller\u0026#34; OPENSTACK_KEYSTONE_URL = \u0026#34;http://controller:5000/v3\u0026#34; # openstack host와 SESSION 서버의 host를 지정합니다. TIME_ZONE = \u0026#34;Asia/Seoul\u0026#34; # 시간을 지정합니다. WEBROOT = \u0026#39;/dashboard/\u0026#39; LOGIN_URL = \u0026#39;/dashboard/auth/login/\u0026#39; LOGOUT_URL = \u0026#39;/dashboard/auth/logout/\u0026#39; LOGIN_REDIRECT_URL = \u0026#39;/dashboard/\u0026#39; OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = \u0026#39;Default\u0026#39; OPENSTACK_API_VERSIONS = { \u0026#34;identity\u0026#34;: 3, \u0026#34;volume\u0026#34;: 3, \u0026#34;compute\u0026#34;: 2, } # 끝에 추가합니다. $ controller\u0026gt; vi /etc/httpd/conf.d/openstack-dashboard.conf .... .... WSGIApplicationGroup %{GLOBAL} # 상단에 추가합니다. $ controller\u0026gt; systemctl restart httpd # httpd를 재 시작합니다. $ controller\u0026gt; setsebool -P httpd_can_network_connect on $ controller\u0026gt; firewall-cmd --add-service={http,https} --permanent $ controller\u0026gt; firewall-cmd --reload # SELinux 및 방화벽을 설정합니다. #\r#\r확인\r#\r#\r접속확인 http://[ controller의 IP ]/dashboard/ "},{"id":78,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-09/","title":"OpenStack Ussuri : Swift","section":"OpenStack Training","content":"\r#\rOpenStack Ussuri : Swift\r#\r#\r----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | ----------------------- | metadata agent | ----------------------- | Neutron Server | ----------------------- --------------------------------- | [ Storage Node 1, 2, 3 ] | | | | Swift-account-auditor | | Swift-account-replicator | | Swift-account | | Swift-container-auditor | | Swift-container-replicator | | Swift-container-updater | | Swift-container | | Swift-object-auditor | | Swift-object-replicator | | Swift-object-updater | | Swift-swift-object | --------------------------------- #\rOpenStack Ussuri : Swift\r#\r#\rSwift는 우리가 흔히 사용하는 네이버 클라우드, 구글 드라이브와 같은 오브젝트 스토리지 서비스 입니다. Swift 설치는 network, Storage 순으로 이루어집니다. Swift*에 대한 설명은 Swift을 참조해주세요. #\r#\r$ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 swift +--------------------------------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | b470c69e28db47cdbfc81e06cc67f627 | | domain_id | default | | enabled | True | | id | dd2f0225406249b195e4feff91eca393 | | name | swift | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user swift admin $ controller ~(keystone)\u0026gt; openstack service create --name swift --description \u0026#34;OpenStack Object Storage\u0026#34; object-store +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Object Storage | | enabled | True | | id | d9d7bc4b99774d3ba701e2eae93edfe2 | | name | swift | | type | object-store | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne object-store public http://network:8080/v1/AUTH_%\\(tenant_id\\)s +--------------+------------------------------------+ | Field | Value | +--------------+------------------------------------+ | enabled | True | | id | a70e1ac16a9144529ea49132cd7dd39e | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | d9d7bc4b99774d3ba701e2eae93edfe2 | | service_name | swift | | service_type | object-store | | url | http://network:8080/v1/AUTH_%(tenant_id)s | +--------------+------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne object-store internal http://network:8080/v1/AUTH_%\\(tenant_id\\)s +--------------+------------------------------------+ | Field | Value | +--------------+------------------------------------+ | enabled | True | | id | 6b5ea7b028f94035aef5601cf35d3a29 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | d9d7bc4b99774d3ba701e2eae93edfe2 | | service_name | swift | | service_type | object-store | | url | http://network:8080/v1/AUTH_%(tenant_id)s | +--------------+------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne object-store admin http://network:8080/v1 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 08c18a5313f642d59de980f51666f830 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | d9d7bc4b99774d3ba701e2eae93edfe2 | | service_name | swift | | service_type | object-store | | url | http://network:8080/v1 | +--------------+----------------------------------+ #\r#\rNetwork Node Swift-Proxy 설치\r#\r#\r$ network\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-swift-proxy python3-memcached openssh-clients # swift-proxy 및 관련 모듈을 설치합니다. $ network\u0026gt; vi /etc/swift/proxy-server.conf [filter:cache] use = egg:swift#memcache memcache_servers = controller:11211 [filter:authtoken] paste.filter_factory = keystonemiddleware.auth_token:filter_factory # admin_tenant_name = %SERVICE_TENANT_NAME% # admin_user = %SERVICE_USER% # admin_password = %SERVICE_PASSWORD% # auth_host = 127.0.0.1 # auth_port = 35357 # auth_protocol = http # signing_dir = /tmp/keystone-signing-swift # 주석처리 후, 하단의 아래의 항모들을 추가합니다.합니다. www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = swift password = qwer1234 delay_auth_decision = true $ network\u0026gt; vi /etc/swift/swift.conf [swift-hash] swift_hash_path_suffix = swift_shared_path swift_hash_path_prefix = swift_shared_path # 파일 안에 내용들을 삭제 후, 생성합니다. $ network\u0026gt; swift-ring-builder /etc/swift/account.builder create 12 3 1 $ network\u0026gt; swift-ring-builder /etc/swift/container.builder create 12 3 1 $ network\u0026gt; swift-ring-builder /etc/swift/object.builder create 12 3 1 $ network\u0026gt; swift-ring-builder /etc/swift/account.builder add r0z0-10.10.10.50:6202/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/container.builder add r0z0-10.10.10.50:6201/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/object.builder add r0z0-10.10.10.50:6200/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/account.builder add r1z1-10.10.10.51:6202/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/container.builder add r1z1-10.10.10.51:6201/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/object.builder add r1z1-10.10.10.51:6200/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/account.builder add r2z2-10.10.10.52:6202/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/container.builder add r2z2-10.10.10.52:6201/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/object.builder add r2z2-10.10.10.52:6200/device 100 $ network\u0026gt; swift-ring-builder /etc/swift/account.builder rebalance $ network\u0026gt; swift-ring-builder /etc/swift/container.builder rebalance $ network\u0026gt; swift-ring-builder /etc/swift/object.builder rebalance $ network\u0026gt; chown swift. /etc/swift/*.gz $ network\u0026gt; systemctl enable --now openstack-swift-proxy $ network\u0026gt; firewall-cmd --add-port=8080/tcp --permanent $ network\u0026gt; firewall-cmd --reload #\r#\rSwift Stoage Node 설치\r#\r#\r$ storage all\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-swift-account openstack-swift-container openstack-swift-object openstack-selinux xfsprogs rsync rsync-daemon openssh-clients # swift 밒 관련 모듈을 설치합니다. $ storage all\u0026gt; mkfs.xfs -i size=1024 -s size=4096 /dev/sdb1 $ storage all\u0026gt; mkdir -p /srv/node/device $ storage all\u0026gt; mount -o noatime,nodiratime /dev/sdb1 /srv/node/device $ storage all\u0026gt; chown -R swift. /srv/node # 하드 디스크를 임포트 후, XFS로 포맷을 진행합니다. $ storage all\u0026gt; vi /etc/fstab /dev/sdb1 /srv/node/device xfs noatime,nodiratime 0 0 # 설정을 fstab의 등록합니다. $ network\u0026gt; scp /etc/swift/*.gz storage1:/etc/swift/ $ network\u0026gt; scp /etc/swift/*.gz storage2:/etc/swift/ $ network\u0026gt; scp /etc/swift/*.gz storage3:/etc/swift/ # 설정을 복사합니다. $ storage all\u0026gt; chown swift. /etc/swift/*.gz $ storage all\u0026gt; vi /etc/swift/swift.conf [swift-hash] swift_hash_path_suffix = swift_shared_path swift_hash_path_prefix = swift_shared_path $ storage all\u0026gt; vi /etc/swift/account-server.conf bind_ip = 0.0.0.0 bind_port = 6202 $ storage all\u0026gt; vi /etc/swift/container-server.conf bind_ip = 0.0.0.0 bind_port = 6201 $ storage all\u0026gt; vi /etc/swift/object-server.conf bind_ip = 0.0.0.0 bind_port = 6200 $ storage all\u0026gt; vi /etc/rsyncd.conf pid file = /var/run/rsyncd.pid log file = /var/log/rsyncd.log uid = swift gid = swift pid file = /var/run/rsyncd.pid log file = /var/log/rsyncd.log uid = swift gid = swift address = storage1 or storage2 or storage3 [account] path = /srv/node read only = false write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 25 lock file = /var/lock/account.lock [container] path = /srv/node read only = false write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 25 lock file = /var/lock/container.lock [object] path = /srv/node read only = false write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 25 lock file = /var/lock/object.lock [swift_server] path = /etc/swift read only = true write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 5 lock file = /var/lock/swift_server.lock $ storage all\u0026gt; semanage fcontext -a -t swift_data_t /srv/node/device $ storage all\u0026gt; restorecon /srv/node/device $ storage all\u0026gt; firewall-cmd --add-port={873/tcp,6200/tcp,6201/tcp,6202/tcp} --permanent $ storage all\u0026gt; firewall-cmd --reload # SELinux 및 방화벽을 설정합니다. $ storage all\u0026gt; systemctl enable --now rsyncd \\ openstack-swift-account-auditor \\ openstack-swift-account-replicator \\ openstack-swift-account \\ openstack-swift-container-auditor \\ openstack-swift-container-replicator \\ openstack-swift-container-updater \\ openstack-swift-container \\ openstack-swift-object-auditor \\ openstack-swift-object-replicator \\ openstack-swift-object-updater \\ openstack-swift-object # swift 서비스를 등록 및 시작합니다. #\r#\r확인\r#\r#\r$ controller ~(keystone)\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install python3-openstackclient python3-keystoneclient python3-swiftclient # swift 사용을 위해 관련 모듈을 설치합니다. $ controller ~(keystone)\u0026gt; openstack project create --domain default --description \u0026#34;Swift Service Project\u0026#34; swiftservice +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Swift Service Project | | domain_id | default | | enabled | True | | id | ab658f35464e49b7a3df626e09feab91 | | is_domain | False | | name | swiftservice | | options | {} | | parent_id | default | | tags | [] | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role create SwiftOperator +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | None | | domain_id | None | | id | 3818d26e54244c1ba5d0481e9ad44e6e | | name | SwiftOperator | | options | {} | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack user create --domain default --project swiftservice --password qwer1234 swiftuser01 +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | ab658f35464e49b7a3df626e09feab91 | | domain_id | default | | enabled | True | | id | 2ac2c69fd55a4bef95b2a8b728f131a7 | | name | swiftuser01 | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project swiftservice --user swiftuser01 SwiftOperator $ controller ~(keystone)\u0026gt; vi ~/swift export OS_PROJECT_DOMAIN_NAME=default export OS_USER_DOMAIN_NAME=default export OS_PROJECT_NAME=swiftservice export OS_USERNAME=swiftuser01 export OS_PASSWORD=qwer1234 export OS_AUTH_URL=http://controller:5000/v3 export OS_IDENTITY_API_VERSION=3 export PS1=\u0026#39;[\\u@\\h \\W(swift)]\\$ \u0026#39; $ controller ~(keystone)\u0026gt; chmod 600 ~/swift $ controller ~(keystone)\u0026gt; source ~/swift $ controller ~(keystone)\u0026gt; echo \u0026#34;source ~/swift \u0026#34; \u0026gt;\u0026gt; ~/.bash_profile $ controller ~(swift)\u0026gt; swift stat Account: AUTH_ab658f35464e49b7a3df626e09feab91 Containers: 0 Objects: 0 Bytes: 0 Content-Type: text/plain; charset=utf-8 X-Timestamp: 1597360203.35834 X-Put-Timestamp: 1597360203.35834 Vary: Accept X-Trans-Id: tx09982b0a02ac4b7eac244-005f35c849 X-Openstack-Request-Id: tx09982b0a02ac4b7eac244-005f35c849 $ controller ~(swift)\u0026gt; openstack container create test +---------------------------------------+-----------+------------------------------------+ | account | container | x-trans-id | +---------------------------------------+-----------+------------------------------------+ | AUTH_ab658f35464e49b7a3df626e09feab91 | test | txce00712612794927965f7-005f35c864 | +---------------------------------------+-----------+------------------------------------+ $ controller ~(swift)\u0026gt; openstack container list +------+ | Name | +------+ | test | +------+ $ controller ~(swift)\u0026gt; openstack object create testfile.txt test $ controller ~(swift)\u0026gt; openstack object list test $ controller ~(swift)\u0026gt; rm testfile.txt $ controller ~(swift)\u0026gt; openstack object save test testfile.txt $ controller ~(swift)\u0026gt; ll testfile.txt $ controller ~(swift)\u0026gt; openstack object delete test testfile.txt $ controller ~(swift)\u0026gt; openstack object list test #\r"},{"id":79,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-10/","title":"OpenStack Ussuri : Heat","section":"OpenStack Training","content":"\rOpenStack Ussuri : Heat\r#\r#\r----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | | Heat API | | metadata agent | ----------------------- | API-CFN | | Neutron Server | | Heat Engine | ----------------------- ----------------------- --------------------------------- | [ Storage Node 1, 2, 3 ] | | | | Swift-account-auditor | | Swift-account-replicator | | Swift-account | | Swift-container-auditor | | Swift-container-replicator | | Swift-container-updater | | Swift-container | | Swift-object-auditor | | Swift-object-replicator | | Swift-object-updater | | Swift-swift-object | --------------------------------- #\rOpenStack Ussuri : Heat\r#\r#\r클라우딩 컴퓨팅이 꽃인 Orchestaration 기능을 수행하는 Heat 서비스를 설치해보도록 하겠습니다. Heat 설치는 controller, network 노드 순으로 이루어집니다. 단 Heat는 controller에서는 API의 Endpoint만을 제공하며, 대부분의 설정은 network node에서 이루어집니다. Heat*에 대한 설명은 Heat을 참조해주세요. #\r#\rHeat service 및 User 생성\r#\r$ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 heat +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | b470c69e28db47cdbfc81e06cc67f627 | | domain_id | default | | enabled | True | | id | 148bafa480d84f87ba939968edb2585f | | name | heat | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user heat admin $ controller ~(keystone)\u0026gt; openstack role create heat_stack_owner +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | None | | domain_id | None | | id | d46789e4326e4055aa8f6fead7c777bb | | name | heat_stack_owner | | options | {} | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role create heat_stack_user +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | None | | domain_id | None | | id | ff45744ddbe247919034cea7c3f309e7 | | name | heat_stack_user | | options | {} | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project admin --user admin heat_stack_owner $ controller ~(keystone)\u0026gt; openstack service create --name heat --description \u0026#34;Openstack Orchestration\u0026#34; orchestration +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Openstack Orchestration | | enabled | True | | id | 6cd5b7c7a3234b39998073587c2d9f9a | | name | heat | | type | orchestration | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack service create --name heat-cfn --description \u0026#34;Openstack Orchestration\u0026#34; cloudformation +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Openstack Orchestration | | enabled | True | | id | 2fb2087bf8da472d8c51e9fee39c93ad | | name | heat-cfn | | type | cloudformation | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne orchestration public http://network:8004/v1/AUTH_%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | 50481bc9998b454a9f70682132ecb026 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 6cd5b7c7a3234b39998073587c2d9f9a | | service_name | heat | | service_type | orchestration | | url | http://network:8004/v1/AUTH_%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne orchestration internal http://network:8004/v1/AUTH_%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | 1015f4c570a747349109b76b7295876c | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 6cd5b7c7a3234b39998073587c2d9f9a | | service_name | heat | | service_type | orchestration | | url | http://network:8004/v1/AUTH_%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne orchestration admin http://network:8004/v1/AUTH_%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | ed21251a3f274ba6bb35061cef6cac1d | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 6cd5b7c7a3234b39998073587c2d9f9a | | service_name | heat | | service_type | orchestration | | url | http://network:8004/v1/AUTH_%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne cloudformation public http://network:8000/v1 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | fb2b67b2a13d43e1a55f775857908a5f | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 2fb2087bf8da472d8c51e9fee39c93ad | | service_name | heat-cfn | | service_type | cloudformation | | url | http://network:8000/v1 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne cloudformation internal http://network:8000/v1 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | a8f4517ecf4d4370beecee9e17183c6b | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 2fb2087bf8da472d8c51e9fee39c93ad | | service_name | heat-cfn | | service_type | cloudformation | | url | http://network:8000/v1 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne cloudformation admin http://network:8000/v1 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 66db714e538545879b7121f7150e72fc | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 2fb2087bf8da472d8c51e9fee39c93ad | | service_name | heat-cfn | | service_type | cloudformation | | url | http://network:8000/v1 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack domain create --description \u0026#34;Stack projects and users\u0026#34; heat +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Stack projects and users | | enabled | True | | id | 36fa9838b2fa43f6a6bbc95f0cdfd0a7 | | name | heat | | options | {} | | tags | [] | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack user create --domain heat --password qwer1234 heat_domain_admin +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | domain_id | 36fa9838b2fa43f6a6bbc95f0cdfd0a7 | | enabled | True | | id | c77bd90604254f8097aed49ea17f6fb3 | | name | heat_domain_admin | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --domain heat --user heat_domain_admin admin #\r#\r#\r#\rHeat 유저의 DB를 생성합니다.\r#\r#\r$ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database heat; $ MariaDB\u0026gt; grant all privileges on heat.* to heat@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on heat.* to heat@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit; #\r#\rNetwork Node Heat 설치\r#\r#\r$ Network\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-heat-api openstack-heat-api-cfn openstack-heat-engine python3-heatclient # Heat 및 관련 모듈을 설치합니다. $ Network\u0026gt; vi /etc/heat/heat.conf [DEFAULT] deferred_auth_method = trusts trusts_delegated_roles = heat_stack_owner heat_metadata_server_url = http://network:8000 heat_waitcondition_server_url = http://network:8000/v1/waitcondition heat_watch_server_url = http://network:8003 heat_stack_user_role = heat_stack_user stack_user_domain_name = heat stack_domain_admin = heat_domain_admin stack_domain_admin_password = qwer1234 transport_url = rabbit://openstack:qwer1234@controller [database] connection = mysql+pymysql://heat:qwer1234@controller/heat [clients_keystone] auth_uri = http://controller:5000 [ec2authtoken] auth_uri = http://controller:5000 [heat_api] bind_host = 0.0.0.0 bind_port = 8004 [heat_api_cfn] bind_host = 0.0.0.0 bind_port = 8000 [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = heat password = qwer1234 [trustee] auth_plugin = password auth_url = http://controller:5000 username = heat password = qwer1234 user_domain_name = default $ network\u0026gt; chgrp heat /etc/heat/heat.conf $ network\u0026gt; chmod 640 /etc/heat/heat.conf $ network\u0026gt; su -s /bin/bash heat -c \u0026#34;heat-manage db_sync\u0026#34; $ network\u0026gt; systemctl enable --now openstack-heat-api openstack-heat-api-cfn openstack-heat-engine # DB를 import 시키고, haet 서비스를 등록 및 시작합니다. $ network\u0026gt; firewall-cmd --add-port={8000/tcp,8004/tcp} --permanent $ network\u0026gt; firewall-cmd --reload # 방화벽을 설정합니다. #\r#\r확인\r#\r#\r$ controller ~(keystone)\u0026gt; vi sample-stack.yml heat_template_version: 2018-08-31 description: Heat Sample Template parameters: ImageID: type: string description: Image used to boot a server NetID: type: string description: Network ID for the server resources: server1: type: OS::Nova::Server properties: name: \u0026#34;Heat_Deployed_Server\u0026#34; image: { get_param: ImageID } flavor: \u0026#34;m1.tiny\u0026#34; networks: - network: { get_param: NetID } outputs: server1_private_ip: description: IP address of the server in the private network value: { get_attr: [ server1, first_address ] } $ controller ~(keystone)\u0026gt; openstack stack create -t sample-stack.yml --parameter \u0026#34;ImageID=cirros;NetID=Int_net\u0026#34; Sample-Stack # controller ~(keystone)\u0026gt; openstack stack list +--------------------------------------+--------------+----------------------------------+-----------------+----------------------+--------------+ | ID | Stack Name | Project | Stack Status | Creation Time | Updated Time | +--------------------------------------+--------------+----------------------------------+-----------------+----------------------+--------------+ | 4cb88c32-24f9-41cf-a44d-e18593c5eb2f | Sample-Stack | edd7025c02574d3aa2d3ab6e56208320 | CREATE_COMPLETE | 2020-08-13T09:39:16Z | None | +--------------------------------------+---- # controller ~(keystone)\u0026gt; openstack server list +--------------------------------------+----------------------+--------+-----------------------+--------+---------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+----------------------+--------+-----------------------+--------+---------+ | ab20d06c-955a-404b-9525-11e3e4b09484 | Heat_Deployed_Server | ACTIVE | int_net=192.168.100.6 | cirros | m1.tiny | +--------------------------------------+----------------------+--------+-----------------------+--------+---------+ #\r"},{"id":80,"href":"/cloud/docs/OpenStack/OpenStackTraining/Openstack-stein/","title":"Openstack Stain Manual 설치","section":"OpenStack Training","content":"\rOpenstack Stain Manual 설치\r#\r#\r1. 시스템 및 네트워크 구성\r#\r여기서는 Nat 네트워크를 외부, host1 대역을 내부로 사용하여 Openstack을 구축해보도록 하겠습니다. #\r운영체제 및 네트워크 구성 Hypervisor : Vmware Workstation 15 OS : CentOS7 #\r노드 구성 OS Hostname Network Interface Network Interface2 CPU RAM DISK CentOS7 controller Nat ( 192.168.10.100 ) HOST1 ( 10.10.10.10 ) 2cpu 4thread 8 RAm 30G CentOS7 natwork Nat ( 192.168.10.101 ) HOST1 ( 10.10.10.20 ) 1cpu 2thread 2 RAm 20G CentOS7 compute Nat ( 192.168.10.102 ) HOST1 ( 10.10.10.30 ) 1cpu 4thread 4 RAm 100G #\r기본적인 업데이트 및 설정을 모든 노드에 진행합니다. $ yum -y update # 업데이트 $ vi /etc/hosts 10.10.10.10 controller 10.10.10.20 network 10.10.10.30 compute # known host 등록 #\r설정이 완료되면 기본 구성을 모든 노드에 진행합니다. $ yum -y install chrony # 시간 동기화를 위한 chrony 설치 $ vi /etc/chrony.conf #server 0.centos.pool.ntp.org iburst #server 1.centos.pool.ntp.org iburst #server 2.centos.pool.ntp.org iburst #server 3.centos.pool.ntp.org iburst server ntp1.jst.mfeed.ad.jp iburst server ntp2.jst.mfeed.ad.jp iburst server ntp3.jst.mfeed.ad.jp iburst allow 10.10.10.0/24 # 시간동기화 $ firewall-cmd --add-service=ntp --permanent $ firewall-cmd --reload # ntp 방화벽 허용 및 리로딩 $ init 6 # 시스템 재시작 $ chronyc sources # 확인 #\r#\r2. Openstack 기본 패키지 구성\r#\rOpenstack의 기본 패키지 구성은 먼저 contorller 노드만을 통해 진행됨을 유의해주시길 바랍니다. controller 노드에는 다음의 패키지가 설치됩니다. MariaDB: OpenStack 서비스 및 VM 관련 설정들을 보관하기 위해 사용 RabbitMQ: OpenStack 서비스 간 상호 메시지를 주고 받기 위하나 메시지 큐로 사용 Memcached: 범용 분산 메모리 캐시 시스템으로, 자주 외부 데이터에 접근해야 하는 경우에 발생하는 오버헤드를 줄이기 위해 메모리르르 캐싱하고 읽어들이는 역할을 담당, OpenStack 서비스에서는 주로 인증 메커니즘에서 토큰 캐싱을 위해 사용됩니다. #\rOpenstack 패키지 설치 및 레포지토리 구성 $ yum -y install centos-release-openstack-stein $ sed -i -e \u0026#34;s/enabled=1/enabled=0/g\u0026#34; /etc/yum.repos.d/CentOS-OpenStack-stein.repo # stein 패캐지를 등록합니다. #\rMariaDB를 설치합니다. $ yum --enablerepo=centos-openstack-stein -y install mariadb-server $ vi /etc/my.cnf [mysqld] character-set-server=utf8 # charset을 utf-8으로 변경합니다 $ systemctl start mariadb $ systemctl enable mariadb # mariadb을 시작 및 자동시작을 등록합니다. $ mysql_secure_installation # 패스워드 설정을 진행합니다. $ firewall-cmd --add-service=mysql --permanent $ firewall-cmd --reload #\rRabbitMQ 및 Memcached를 설치합니다. $ yum --enablerepo=centos-openstack-stein -y install rabbitmq-server $ yum --enablerepo=centos-openstack-stein -y install memcached $ vi /etc/my.cnf.d/mariadb-server.cnf [mysqld] ... character-set-server=utf8 max_connections=500 # Mariadb의 위에 내용을 추가합니다. $ vi /etc/sysconfig/memcached OPTIONS=\u0026#34;-l 0.0.0.0,::\u0026#34; # mamcached를 모든 리스닝 상태로 전환시킵니다. $ systemctl restart mariadb rabbitmq-server memcached $ systemctl enable mariadb rabbitmq-server memcached # Mariadb와 함께 RabbitMQ 및 Memcached를 시작 및 자동시작을 등록합니다. $ rabbitmqctl add_user [ id ] [ pw ] # rabbitmq 유저를 생성합니다. 여기서는 openstack/qwer1234를 사용하도록 하겠습니다. $ rabbitmqctl set_permissions [ id ] \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; \u0026#34;.*\u0026#34; # 생성한 사용자에게 모든 권한을 부여합니다. $ firewall-cmd --add-port={11211/tcp,5672/tcp} --permanent $ firewall-cmd --reload #\r#\r3. Keystone ( 인증 서비스 ) 구성\r#\rKeystone 또한 controller의 설치를 진행합니다. keystone에 대한 설명은 keystone을 참조해주세요. #\rkeyston DB 생성 $ mysql -u root -p MariaDB [(none)]\u0026gt; create database keystone; MariaDB [(none)]\u0026gt; grant all privileges on keystone.* to keystone@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on keystone.* to keystone@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; flush privileges; # keystone 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. ) #\rkeystone 패키지 설치 및 수정 $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-keystone openstack-utils python-openstackclient httpd mod_wsgi # keystone 및 관련 패키지를 설치합니다. $ vi /etc/keystone/keystone.conf [cache] ... memcache_servers = controller:11211 [database] ... connection = mysql+pymysql://keystone:qwer1234@controller/keystone [token] ... provider = fernet # keystone 구성을 위해 설정파일 수정합니다. # hosts에 등록한 IP 혹은 controller의 IP를 기입하셔도 무관합니다. $ su -s /bin/bash keystone -c \u0026#34;keystone-manage db_sync\u0026#34; # 설정 값을 토대로 db의 설정을 저정합니다. $ keystone-manage fernet_setup --keystone-user keystone --keystone-group keystone $ keystone-manage credential_setup --keystone-user keystone --keystone-group keystone # 토큰 및 자격 증명 암호화를 위해 사용되는 키 저장소를 생성합니다. $ export controller=10.10.10.10 $ keystone-manage bootstrap --bootstrap-password qwer1234 \\ --bootstrap-admin-url http://$controller:5000/v3/ \\ --bootstrap-internal-url http://$controller:5000/v3/ \\ --bootstrap-public-url http://$controller:5000/v3/ \\ --bootstrap-region-id RegionOne # controlelr의 IP로 keystone을 부트스트랩합니다. $ setsebool -P httpd_use_openstack on $ setsebool -P httpd_can_network_connect on $ setsebool -P httpd_can_network_connect_db on $ firewall-cmd --add-port=5000/tcp --permanent $ firewall-cmd --reload # Selinux와 방화벽으르 설정합니다. $ ln -s /usr/share/keystone/wsgi-keystone.conf /etc/httpd/conf.d/ $ systemctl start httpd $ systemctl enable httpd # keystone 설정 활성화 및 httpd 를 시작합니다. #\r정상 동작 확인을 위한 토큰 파일 생성 $ vi ~/admin export OS_PROJECT_DOMAIN_NAME=default export OS_USER_DOMAIN_NAME=default export OS_PROJECT_NAME=admin export OS_USERNAME=admin export OS_PASSWORD=qwer1234 export OS_AUTH_URL=http://controller:5000/v3 export OS_IDENTITY_API_VERSION=3 export OS_IMAGE_API_VERSION=2 $ chmod 600 ~/admin $ source ~/admin #\rproject 생성 $ cd ~ $ . admin $ openstack project create --domain default --description \u0026#34;Service Project\u0026#34; service +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Service Project | | domain_id | default | | enabled | True | | id | 3f0b3ef5b8c94a0a9cca8e34ea2fdbd6 | | is_domain | False | | name | service | | parent_id | default | | tags | [] | +-------------+----------------------------------+ # project 생성 $ openstack project list +----------------------------------+---------+ | ID | Name | +----------------------------------+---------+ | 3f0b3ef5b8c94a0a9cca8e34ea2fdbd6 | service | | ec1a4336cfa64d04bbc8f908b26a6cda | admin | +----------------------------------+---------+ #\r이것으로 keystone에 대한 설치가 끝났습니다. 혹시 오류가 발생할 경우 /var/log/keystone/ 혹은 /var/log/httpd/에서 error 로그, keystone 로그를 검색하여 오류를 찾아내시면 보다 쉽게 문제를 해결하실 수 있습니다. #\r#\r4. Glance ( 이미지 서비스 ) 구성\r#\rGlance 또한 controller에서만 설치를 진행합니다. 에 대한 설명은 Glance을 참조해주세요. #\rglance 사용자 추가 $ source ~/admin # 전에 생성했던 토큰 값을 적용합니다. $ openstack user create --domain default --project service --password qwer1234 glance # glance 게정을 추가합니다. $ openstack role add --project service --user glance admin # glance에 admin의 권한을 부여합니다. $ openstack service create --name glance --description \u0026#34;OpenStack Image service\u0026#34; image # glance 서비스 엔트리를 생성합니다. $ export controller=10.10.10.10 $ openstack endpoint create --region RegionOne image public http://$controller:9292 $ openstack endpoint create --region RegionOne image internal http://$controller:9292 $ openstack endpoint create --region RegionOne image admin http://$controller:9292 # glance 서비스의 endpoint를 추가합니다 ( public, internal, admin ) $ openstack user list +----------------------------------+--------+ | ID | Name | +----------------------------------+--------+ | bd36365f2459468a9c480cb48bab3ac0 | glance | | e19db9d5ec2c4c30b7a85d18b8b0e589 | admin | +----------------------------------+--------+ $ openstack endpoint list +----------------------------------+-----------+--------------+--------------+---------+-----------+-----------------------------+ | ID | Region | Service Name | Service Type | Enabled | Interface | URL | +----------------------------------+-----------+--------------+--------------+---------+-----------+-----------------------------+ | 00b38774cef048ee9950eda6938accc3 | RegionOne | keystone | identity | True | public | http://10.10.10.10:5000/v3/ | | 4591b06391374fe888380fa23b8f5121 | RegionOne | glance | image | True | admin | http://10.10.10.10:9292 | | 53dd31fecf2d44949c141149a13c673b | RegionOne | keystone | identity | True | admin | http://10.10.10.10:5000/v3/ | | 555f3d900f7e416bb783120f7ce74fe8 | RegionOne | glance | image | True | internal | http://10.10.10.10:9292 | | 5b3ac620bb7d4d9aabdf0f33229ee346 | RegionOne | glance | image | True | public | http://10.10.10.10:9292 | | bdd7df7c8cba46f6ada2c12155a9f1d6 | RegionOne | keystone | identity | True | internal | http://10.10.10.10:5000/v3/ | +----------------------------------+-----------+--------------+--------------+---------+-----------+-----------------------------+ Glance DB 생성 $ mysql -u root -p MariaDB [(none)]\u0026gt; create database glance; MariaDB [(none)]\u0026gt; grant all privileges on glance.* to glance@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on glance.* to glance@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; flush privileges; # 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. ) #\rglance 패키지 설치 및 수정 $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-glance # glance 패키지를 설치합니다. $ vi /etc/glance/glance-api.conf [DEFAULT] bind_host = 0.0.0.0 [glance_store] stores = file,http default_store = file filesystem_store_datadir = /var/lib/glance/images/ # 이미지 경로 지정 [database] # database 연동 connection = mysql+pymysql://glance:qwer1234@controller/glance [keystone_authtoken] # keystone 인증 www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = glance password = qwer1234 [paste_deploy] flavor = keystone # glance.conf를 수정합니다. $ su -s /bin/bash glance -c \u0026#34;glance-manage db_sync\u0026#34; # glance db를 동기화 시킵니다. $ systemctl start openstack-glance-api $ systemctl enable openstack-glance-api # glance를 시작 및 실행시 자동시작을 등록합니다. $ setsebool -P glance_api_can_network on $ firewall-cmd --add-port=9292/tcp --permanent $ firewall-cmd --reload # Selinux 및 firewall을 설정합니다. #\r확인을 위한 이미지 생성 $ wget http://download.cirros-cloud.net/0.5.1/cirros-0.5.1-x86_64-disk.img # 확인을 위해 cirros 이미지를 다운 받습니다. $ openstack image create \u0026#34;Cirros\u0026#34; --file cirros-0.5.1-x86_64-disk.img --disk-format qcow2 # image 등록 $ openstack image list +--------------------------------------+--------+--------+ | ID | Name | Status | +--------------------------------------+--------+--------+ | 38e15009-022b-49ce-bcdf-b220eb3c5b12 | Cirros | active | +--------------------------------------+--------+--------+ # 확인 #\r#\r5. Nova ( 컴퓨트 서비스 ) 구성\r#\rNova 서비스는 controller 노드와 compute노드에 구성됩니다. 설치는 contoller \u0026gt; compute 순으로 진행하도록 하겠습니다. Nova에 대한 설명은 Nova을 참조해주세요. #\rNova, Placement 추가 및 등록 $ source ~/admin $ openstack user create --domain default --project service --password qwer1234 nova $ openstack role add --project service --user nova admin $ openstack user create --domain default --project service --password qwer1234 placement $ openstack role add --project service --user placement admin # nova 유저와 placement유저를 생성합니다. $ openstack service create --name nova --description \u0026#34;OpenStack Compute Service\u0026#34; compute # nova 서버 엔트리 저장 $ openstack service create --name placement --description \u0026#34;OpenStack Compute Placement Service\u0026#34; placement # placement 서버 엔트리 저장 $ openstack user list # 확인 +----------------------------------+-----------+ | ID | Name | +----------------------------------+-----------+ | 18bdf3e68a754aa182f93196a918ba65 | nova | | 18ff8b52493a408d9933596ed20cca9c | glance | | bfd0cf6d358e49bf88f183a463c689a2 | placement | | e19db9d5ec2c4c30b7a85d18b8b0e589 | admin | +----------------------------------+-----------+ $ export controller=10.10.10.10 $ openstack endpoint create --region RegionOne compute public http://$controller:8774/v2.1/%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne compute internal http://$controller:8774/v2.1/%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne compute admin http://$controller:8774/v2.1/%\\(tenant_id\\)s # nova 서비스의 endpoint를 추가합니다 $ openstack endpoint create --region RegionOne placement public http://$controller:8778 $ openstack endpoint create --region RegionOne placement internal http://$controller:8778 $ openstack endpoint create --region RegionOne placement admin http://$controller:8778 $ placement의 endpoint를 추가합니다. $ openstack endpoint list # 확인 -------+-----------+--------------------------------------------+ | ID | Region | Service Name | Service Type | Enabled | Interface | URL | +----------------------------------+-----------+--------------+--------------+---------+-----------+--------------------------------------------+ | 00b38774cef048ee9950eda6938accc3 | RegionOne | keystone | identity | True | public | http://10.10.10.10:5000/v3/ | | 04ca5fb6701348089777d68a68ca7cd2 | RegionOne | placement | placement | True | public | http://10.10.10.10:8778 | | 53ad55ce8897463b86ea616a8ba64d95 | RegionOne | glance | image | True | public | http://10.10.10.10:9292 | | 53dd31fecf2d44949c141149a13c673b | RegionOne | keystone | identity | True | admin | http://10.10.10.10:5000/v3/ | | 595a2045543b42c2bb6f23e2dd30a3bb | RegionOne | glance | image | True | internal | http://10.10.10.10:9292 | | 6820b49138d54b63ac34cd52f1be08f6 | RegionOne | placement | placement | True | internal | http://10.10.10.10:8778 | | 6ad740445fca4a0fb684d913909fe129 | RegionOne | nova | compute | True | admin | http://10.10.10.10:8774/v2.1/%(tenant_id)s | | 9863826e093943cf97a05dfc6e3c159a | RegionOne | nova | compute | True | internal | http://10.10.10.10:8774/v2.1/%(tenant_id)s | | b9f9701a57ec40e487ce493a63903cae | RegionOne | placement | placement | True | admin | http://10.10.10.10:8778 | | bd787b85b3124f0ab15854998624cb19 | RegionOne | nova | compute | True | public | http://10.10.10.10:8774/v2.1/%(tenant_id)s | | bdd7df7c8cba46f6ada2c12155a9f1d6 | RegionOne | keystone | identity | True | internal | http://10.10.10.10:5000/v3/ | | d394eaf13ac840b3b2e69e074c2c1c20 | RegionOne | glance | image | True | admin | http://10.10.10.10:9292 | +----------------------------------+-----------+--------------+--------------+---------+-----------+--------------------------------------------+ #\rNova DB 생성 $ mysql -u root -p MariaDB [(none)]\u0026gt; create database nova; MariaDB [(none)]\u0026gt; grant all privileges on nova.* to nova@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on nova.* to nova@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; create database nova_api; MariaDB [(none)]\u0026gt; grant all privileges on nova_api.* to nova@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on nova_api.* to nova@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; create database nova_placement; MariaDB [(none)]\u0026gt; grant all privileges on nova_placement.* to nova@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on nova_placement.* to nova@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; create database nova_cell0; MariaDB [(none)]\u0026gt; grant all privileges on nova_cell0.* to nova@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on nova_cell0.* to nova@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; flush privileges; # nova 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. ) #\rnova 서비스를 설치 및 수정합니다. $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-nova # nova 패키지를 설치합니다. $ vi /etc/nova/nova.conf [DEFAULT] my_ip = 10.10.10.10 state_path = /var/lib/nova enabled_apis = osapi_compute,metadata log_dir = /var/log/nova [api] auth_strategy = keystone [glance] api_servers = http://controller:9292 [oslo_concurrency] lock_path = $state_path/tmp [api_database] connection = mysql+pymysql://nova:qwer1234@controller/nova_api [database] connection = mysql+pymysql://nova:qwer1234@controller/nova [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = nova password = qwer1234 [placement] auth_url = http://controller:5000 os_region_name = RegionOne auth_type = password project_domain_name = default user_domain_name = default project_name = service username = placement password = qwer1234 [placement_database] connection = mysql+pymysql://nova:qwer1234@controller/nova_placement [wsgi] api_paste_config = /etc/nova/api-paste.ini # nova의 설정 파일을 수정합니다. #\rSelinux 및 firewalld을 설정합니다. $ yum --enablerepo=centos-openstack-stein -y install openstack-selinux $ semanage port -a -t http_port_t -p tcp 8778 $ firewall-cmd --add-port={6080/tcp,6081/tcp,6082/tcp,8774/tcp,8775/tcp,8778/tcp} --permanent $ firewall-cmd --reload #\rnova 서비스를 DB에 저장합니다. $ su -s /bin/bash nova -c \u0026#34;nova-manage api_db sync\u0026#34; $ su -s /bin/bash nova -c \u0026#34;nova-manage cell_v2 map_cell0\u0026#34; $ su -s /bin/bash nova -c \u0026#34;nova-manage db sync\u0026#34; $ su -s /bin/bash nova -c \u0026#34;nova-manage cell_v2 create_cell --name cell1\u0026#34; #\rnova 서비스를 시작 및 자동시작을 설정합니다. $ systemctl restart httpd $ chown nova. /var/log/nova/nova-placement-api.log $ for service in api consoleauth conductor scheduler novncproxy; do systemctl start openstack-nova-$service systemctl enable openstack-nova-$service done 이상으로 controller 노드에서의 구성을 마치겠습니다. 하단부터의 패키지 설치는 compute노드에서 진행해주세요 #\r#\rStein 레포지터리를 활성화합니다. $ yum -y install centos-release-openstack-stein $ sed -i -e \u0026#34;s/enabled=1/enabled=0/g\u0026#34; /etc/yum.repos.d/CentOS-OpenStack-stein.repo # stein 패캐지를 등록합니다. #\rKVM 하이퍼바이저를 구성합니다. $ yum -y install qemu-kvm libvirt virt-install bridge-utils # KVM 구성에 필요한 가상화 및 네트워크 도구들을 설치합니다. $ lsmod | grep kvm # 확인 $ systemctl start libvirtd $ systenctk ebable libvirtd #\rcompute 노드에 nova 서비스를 설치 및 수정합니다. $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-nova # nova 패키지를 설치합니다. $ vi /etc/nova/nova.conf [DEFAULT] my_ip = 10.10.10.30 state_path = /var/lib/nova enabled_apis = osapi_compute,metadata log_dir = /var/log/nova transport_url = rabbit://openstack:qwer1234@controller [api] auth_strategy = keystone [vnc] enabled = True server_listen = 0.0.0.0 server_proxyclient_address = 192.168.10.102 novncproxy_base_url = http://192.168.10.102/vnc_auto.html # vnc 화면으르 활성화 합니다. 추후 오픈스택 대시보드 혹은 vnc 클라이언트 프로그램으로 접속할 때 사용합니다. [glance] api_servers = http://controller:9292 [oslo_concurrency] lock_path = $state_path/tmp [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = nova password = qwer1234 [placement] auth_url = http://controller:5000 os_region_name = RegionOne auth_type = password project_domain_name = default user_domain_name = default project_name = service username = placement password = qwer1234 [wsgi] api_paste_config = /etc/nova/api-paste.ini # nova의 설정 파일을 수정합니다. #\rSelinux 및 firewall 설정 $ yum --enablerepo=centos-openstack-stein -y install openstack-selinux $ firewall-cmd --add-port=5900-5999/tcp --permanent $ firewall-cmd --reload #\rnova 서비스 시작 $ systemctl start openstack-nova-compute $ systemctl enable openstack-nova-compute \u0026amp; controller# openstack compute service list # 확인 +----+------------------+------------+----------+---------+-------+----------------------------+ | ID | Binary | Host | Zone | Status | State | Updated At | +----+------------------+------------+----------+---------+-------+----------------------------+ | 4 | nova-consoleauth | controller | internal | enabled | up | 2020-07-19T02:47:16.000000 | | 5 | nova-conductor | controller | internal | enabled | up | 2020-07-19T02:47:12.000000 | | 8 | nova-scheduler | controller | internal | enabled | up | 2020-07-19T02:47:12.000000 | | 9 | nova-compute | compute | nova | enabled | up | 2020-07-19T02:47:08.000000 | +----+------------------+------------+----------+---------+-------+----------------------------+ #\r#\r6. Neutron ( 네트워크 서비스 ) 구성\r#\rNeutron 서비스르르 구성하는 과정에서는 모든 노드에 설치가 진행됩니다. 기본적으로 openvswithch를 중심으로 진행하며, 경우에 따라서는 linuxbridge로 서비스를 대체하는 것이 가능합니다. 설치 과정은 controller, compute, network 노드 순으로 진행하겠습니다. Neutron에 대한 설명은 Neutron을 참조해주세요. #\rNeutron 사용자 추가 $ openstack user create --domain default --project service --password qwer1234 neutron $ openstack role add --project service --user neutron admin $ openstack service create --name neutron --description \u0026#34;OpenStack Networking service\u0026#34; network # Netutron 사용자를 추가 및 서비스를 등록합니다. $ export controller=10.10.10.10 $ openstack endpoint create --region RegionOne network public http://$controller:9696 $ openstack endpoint create --region RegionOne network internal http://$controller:9696 $ openstack endpoint create --region RegionOne network admin http://$controller:9696 # neutron의 endpoint를 생성합니다. #\rNeutron DB 생성 $ mysql -u root -p MariaDB [(none)]\u0026gt; create database neutron_ml2; MariaDB [(none)]\u0026gt; grant all privileges on neutron_ml2.* to neutron@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on neutron_ml2.* to neutron@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; flush privileges; # neutron 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. ) #\rNeutron 설치 및 설정 $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron openstack-neutron-ml2 # neutron 패키지 설치 $ vi /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router auth_strategy = keystone stae_path = /var/lib/neutron dhcp_agent_notification = True allow_overlapping_ips = True notify_nova_on_port_status_changes = True notify_nova_on_port_data_changes = True transport_url = rabbit://openstack:qwer1234@controller [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = qwer1234 [database] connection = mysql+pymysql://neutron:qwer1234@controller/neutron_ml2 [nova] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = nova password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ vi /etc/neutron/metadata_agent.ini [DEFAULT] nova_metadata_host = controller metadata_proxy_shared_secret = metadata_secret memcache_servers = controller:11211 # metadata_agent.ini 파일을 수정합니다. $ vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = mechanism_drivers = openvswitch extension_drivers = port_security # ml2_conf.ini 파일에 설정을 수정합니다. #\r이어 nova.conf 파일에 설정을 추가합니다. $ vi /etc/nova/nova.conf [DEFAULT] ... use_neutron = True linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver firewall_driver = nova.virt.firewall.NoopFirewallDriver [neutron] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = qwer1234 service_metadata_proxy = True metadata_proxy_shared_secret = metadata_secret #\rSelinux 및 방화벽 설정 $ yum --enablerepo=centos-openstack-stein -y install openstack-selinux $ setsebool -P neutron_can_network on $ setsebool -P daemons_enable_cluster_mode on $ firewall-cmd --add-port=9696/tcp --permanent $ firewall-cmd --reload # Selinux 및 방화벽을 설정합니다. #\rNeutron DB를 생성 및 서비스를 시작합니다. $ ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini $ su -s /bin/bash neutron -c \u0026#34;neutron-db-manage --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugin.ini upgrade head\u0026#34; # Neutron DB를 생성합니다. $ systemctl start neutron-server neutron-metadata-agent $ systemctl enable neutron-server neutron-metadata-agent $ systemctl restart openstack-nova-api #\r#\r이제 다음으로는 network 노드에 구현해보도록 하겠습니다. $ yum -y install centos-release-openstack-stein $ sed -i -e \u0026#34;s/enabled=1/enabled=0/g\u0026#34; /etc/yum.repos.d/CentOS-OpenStack-stein.repo # stein 패캐지를 등록합니다. $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch libibverbs # neutron 패키지를 설치합니다. #\rneutron 설정합니다. $ vi /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router auth_strategy = keystone stae_path = /var/lib/neutron allow_overlapping_ips = True transport_url = rabbit://openstack:qwer1234@controller [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ vi /etc/neutron/l3_agent.ini [DEFAULT] ... interface_driver = openvswitch # l3_agent.ini 파일을 수정합니다. $ vi /etc/neutron/dhcp_agent.ini [DEFAULT] ... interface_driver = openvswitch dhcp_driver = neutron.agent.linux.dhcp.Dnsmasq enable_isolated_metadata = true # dhcp_agent.ini 파일을 수정합니다. $ vi /etc/neutron/metadata_agent.ini [DEFAULT] nova_metadata_host = controller metadata_proxy_shared_secret = metadata_secret # metadata_agent.ini 파일을 수정합니다. $ vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = mechanism_drivers = openvswitch extension_drivers = port_security # ml2_conf.ini 파일에 설정을 수정합니다. $ vi /etc/neutron/plugins/ml2/openvswitch_agent.ini [securitygroup] firewall_driver = openvswitch enable_security_group = true enable_ipset = true # openvswitch_agent.ini 파일의 하단에 추가합니다. #\rSelinux 및 방화벽 설정 $ yum --enablerepo=centos-openstack-stein -y install openstack-selinux $ setsebool -P neutron_can_network on $ setsebool -P haproxy_connect_any on $ setsebool -P daemons_enable_cluster_mode on $ vi my-ovsofctl.te # create new module my-ovsofctl 1.0; require { type neutron_t; class capability sys_rawio; } #============= neutron_t ============== allow neutron_t self:capability sys_rawio; $ checkmodule -m -M -o my-ovsofctl.mod my-ovsofctl.te $ semodule_package --outfile my-ovsofctl.pp --module my-ovsofctl.mod $ semodule -i my-ovsofctl.pp # Selinux 및 방화벽을 추가설정합니다. #\r시스템을 재시작 합니다. $ ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini $ systemctl start openvswitch $ systemctl enable openvswitch $ ovs-vsctl add-br br-int $ systemctl restart openstack-nova-compute $ systemctl start neutron-openvswitch-agent $ systemctl enable neutron-openvswitch-agent #\r이어서 compute 노드에서의 설정을 진행하겠습니다. $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch # neutron 패키지를 설치합니다. #\rneutron 설정합니다. $ vi /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router auth_strategy = keystone stae_path = /var/lib/neutron allow_overlapping_ips = True transport_url = rabbit://openstack:qwer1234@controller [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = mechanism_drivers = openvswitch extension_drivers = port_security # ml2_conf.ini 파일에 설정을 수정합니다. $ vi /etc/neutron/plugins/ml2/openvswitch_agent.ini [securitygroup] firewall_driver = openvswitch enable_security_group = true enable_ipset = true # openvswitch_agent.ini 파일의 하단에 추가합니다. #\r이어서 Nova.conf 파일을 수정합니다. $ vi /etc/nova/nova.conf [DEFAULT] ... use_neutron = True linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver firewall_driver = nova.virt.firewall.NoopFirewallDriver vif_plugging_is_fatal = True vif_plugging_timeout = 300 [neutron] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = qwer1234 service_metadata_proxy = True metadata_proxy_shared_secret = metadata_secret #\rSelinux 및 방화벽 설정 $ yum --enablerepo=centos-openstack-stein -y install openstack-selinux $ setsebool -P neutron_can_network on $ setsebool -P haproxy_connect_any on $ setsebool -P daemons_enable_cluster_mode on $ vi my-ovsofctl.te # create new module my-ovsofctl 1.0; require { type neutron_t; class capability sys_rawio; } #============= neutron_t ============== allow neutron_t self:capability sys_rawio; $ checkmodule -m -M -o my-ovsofctl.mod my-ovsofctl.te $ semodule_package --outfile my-ovsofctl.pp --module my-ovsofctl.mod $ semodule -i my-ovsofctl.pp # Selinux 및 방화벽을 추가설정합니다. #\r시스템을 재시작 합니다. $ ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini $ systemctl start openvswitch $ systemctl enable openvswitch $ ovs-vsctl add-br br-int $ for service in dhcp-agent l3-agent metadata-agent openvswitch-agent; do systemctl start neutron-$service systemctl enable neutron-$service done #\r#\r이제 이어 compute 노드에서 neutron 서비스를 설치하도록 하겠습니다. $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron openstack-neutron-ml2 openstack-neutron-openvswitch # neutron 서비스를 설치합니다. $ vi /etc/neutron/neutron.conf [DEFAULT] core_plugin = ml2 service_plugins = router auth_strategy = keystone stae_path = /var/lib/neutron allow_overlapping_ips = True transport_url = rabbit://openstack:qwer1234@controller [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = neutron password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = mechanism_drivers = openvswitch extension_drivers = port_security $ vi /etc/neutron/plugins/ml2/openvswitch_agent.ini [securitygroup] firewall_driver = openvswitch enable_security_group = true enable_ipset = true #\r이어서 nova.conf 파일을 수정합니다. $ vi /etc/nova/nova.conf [DEFAULT] ... use_neutron = True linuxnet_interface_driver = nova.network.linux_net.LinuxOVSInterfaceDriver firewall_driver = nova.virt.firewall.NoopFirewallDriver vif_plugging_is_fatal = True vif_plugging_timeout = 300 [neutron] auth_url = http://controller:5000 auth_type = password project_domain_name = default user_domain_name = default region_name = RegionOne project_name = service username = neutron password = qwer1234 service_metadata_proxy = True metadata_proxy_shared_secret = metadata_secret #\rSelinux 및 방화벽 설정 $ yum --enablerepo=centos-openstack-stein -y install openstack-selinux $ setsebool -P neutron_can_network on $ setsebool -P haproxy_connect_any on $ setsebool -P daemons_enable_cluster_mode on $ vi my-ovsofctl.te # create new module my-ovsofctl 1.0; require { type neutron_t; class capability sys_rawio; } #============= neutron_t ============== allow neutron_t self:capability sys_rawio; $ checkmodule -m -M -o my-ovsofctl.mod my-ovsofctl.te $ semodule_package --outfile my-ovsofctl.pp --module my-ovsofctl.mod $ semodule -i my-ovsofctl.pp # Selinux 및 방화벽을 추가설정합니다. #\r서비스를 재시작 및 등록합니다. $ ln -s /etc/neutron/plugins/ml2/ml2_conf.ini /etc/neutron/plugin.ini $ systemctl start openvswitch $ systemctl enable openvswitch $ ovs-vsctl add-br br-int $ systemctl restart openstack-nova-compute $ systemctl start neutron-openvswitch-agent $ systemctl enable neutron-openvswitch-agent #\r#\r이제 다음으로는 본격적으로 neutron 네트워크를 구현해보도록 하겠습니다. 먼저 controller 노드에서 ml2_conf 파일을 수정 및 추가합니다. 위에서 tenant 타입을 비워둔 이유는, 타입에 따라 사용하는 네트워크 구조가 달라지기 때문입니다. 여기서는 vxlan을 사용해 구성해보도록 하겠습니다. $ vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] tenant_network_types = vxlan [ml2_type_flat] flat_networks = physnet1 [ml2_type_vxlan] vni_ranges = 1:1000 # ml2.conf 파일을 수정합니다 $ systemctl restart neutron-server # neutron 서비스를 재시작 합니다. #\r이제 Network 노드에서의 설치를 진행해보도록 하겠습니다. #\r$ ovs-vsctl add-br br-eth1 $ ovs-vsctl add-port br-eth1 ens33 # 네트워크 브릿지를 생성하고, 네트워크 노드의 외부대역의 인터페이스 번호를 바인딩합니다. #\rneutron 서비스 사용을 위한 설정을 진행합니다. $ vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = vxlan mechanism_drivers = openvswitch extension_drivers = port_security [ml2_type_flat] flat_networks = physnet1 [ml2_type_vxlan] vni_ranges = 1:1000 # ml2_conf.ini 파일에 설정을 추가 설정합니다. $ vi /etc/neutron/plugins/ml2/openvswitch_agent.ini [agent] tunnel_type = vxlan prevent_arp_spoofing = True [ovs] local_ip = 10.10.10.20 bridge_mappings = physnet1:br-eth1 # openvswitch_agent.ini 파일의 하단에 추가합니다. $ for service in dhcp-agent l3-agent metadata-agent openvswitch-agent; do systemctl restart neutron-$service done # neutron 서비스를 재시작합니다. $ systemctl stop firewalld $ systemctl disable firewalld # 방화벽을 해제합니다. #\r바인딩 오류를 해결하기 위해 설정을 진행합니다. $ vi /etc/sysconfig/network-scripts/ifcfg-ens33 TYPE=Ethernet BOOTPROTO=static DEFROUTE=yes NAME=ens33 DEVICE=ens33 ONBOOT=yes $ vi /var/tmp/create_interface.sh #!/bin/bash ip link set up br-eth1 ip addr add 192.168.10.101/24 dev br-eth1 route add default gw 192.168.10.2 dev br-eth1 echo \u0026#34;nameserver 8.8.8.8\u0026#34; \u0026gt; /etc/resolv.conf $ chmod 755 /var/tmp/create_interface.sh $ vi /etc/systemd/system/set_interface.service [Unit] Description=Description for sample script goes here After=network.target [Service] Type=simple ExecStart=/var/tmp/create_interface.sh TimeoutStartSec=0 [Install] WantedBy=default.target $ systemctl enable set_interface $ init 6 #\r이어 compute 노드에서의 설정을 진행합니다. $ vi /etc/neutron/plugins/ml2/ml2_conf.ini [ml2] type_drivers = flat,vlan,gre,vxlan tenant_network_types = vxlan mechanism_drivers = openvswitch extension_drivers = port_security [ml2_type_flat] flat_networks = physnet1 [ml2_type_vxlan] vni_ranges = 1:1000 # ml2_conf.ini 파일에 설정을 추가 설정합니다. $ vi /etc/neutron/plugins/ml2/openvswitch_agent.ini [agent] tunnel_type = vxlan prevent_arp_spoofing = True [ovs] local_ip = 10.10.10.30 # openvswitch_agent.ini 파일의 하단에 추가합니다. $ for service in dhcp-agent l3-agent metadata-agent openvswitch-agent; do systemctl restart neutron-$service done # neutron 서비스를 재시작합니다. $ systemctl stop firewalld $ systemctl disable firewalld # 방화벽을 해제합니다. #\r확인 $ openstack network agent list +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | ID | Agent Type | Host | Availability Zone | Alive | State | Binary | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ | 261bbd8f-ece9-4818-91c3-be75b928fa54 | Open vSwitch agent | network | None | :-) | UP | neutron-openvswitch-agent | | 26376b7b-e4d0-413c-85b9-521994c41bf6 | Open vSwitch agent | compute | None | :-) | UP | neutron-openvswitch-agent | | 8b520189-c500-47ec-b330-b84bc0a3b622 | Metadata agent | controller | None | :-) | UP | neutron-metadata-agent | | ba443e32-a931-465f-acff-05621dac0424 | Metadata agent | network | None | :-) | UP | neutron-metadata-agent | | be878ec2-b8c9-4923-8d01-111d7c11c8f1 | L3 agent | network | nova | :-) | UP | neutron-l3-agent | | cb74c09d-7ec5-4457-a384-8303235adc97 | DHCP agent | network | nova | :-) | UP | neutron-dhcp-agent | +--------------------------------------+--------------------+------------+-------------------+-------+-------+---------------------------+ $ openstack router create router01 $ openstack network create int --provider-network-type vxlan $ openstack subnet create int_sub --network int \\ --subnet-range 1.1.1.0/24 --gateway 1.1.1.2 \\ --dns-nameserver 8.8.8.8 # 라우터와 내부대역을 생성합니다. $ openstack router add subnet router01 int_sub # 라우터와 내부대벽을 연결시킵니다. $ openstack network create \\ --provider-physical-network physnet1 \\ --provider-network-type flat --external ext $ openstack subnet create subnet2 \\ --network ext_net --subnet-range 192.168.10.0/24 \\ --allocation-pool start=192.168.10.150,end=192.168.10.200 \\ --gateway 192.168.10.2 --dns-nameserver 8.8.8.8 # 외부대역을 생성합니다. 외부대역의 IP는 바인딩한 br-eth1의 IP 대역과 동일해야합니다. $ openstack router set router01 --external-gateway ext # 생성한 라우터의 게이트웨이를 생성한 외부대역에 바운딩시킵니다. $ openstack network list +--------------------------------------+------+--------------------------------------+ | ID | Name | Subnets | +--------------------------------------+------+--------------------------------------+ | 2875f833-2d46-4740-bdd4-09c75c53e2b1 | int | 698d35ae-8d7c-436f-be1b-fcf4319eb5fe | | 4a25933d-ed21-4a5c-a87b-4e782e93c14c | ext | 47b0ee11-b628-4260-9185-71d1dab401ea | +--------------------------------------+------+--------------------------------------+ $ openstack subnet list +--------------------------------------+---------+--------------------------------------+-----------------+ | ID | Name | Network | Subnet | +--------------------------------------+---------+--------------------------------------+-----------------+ | 47b0ee11-b628-4260-9185-71d1dab401ea | ext-sub | 4a25933d-ed21-4a5c-a87b-4e782e93c14c | 192.168.10.0/24 | | 698d35ae-8d7c-436f-be1b-fcf4319eb5fe | int-sub | 2875f833-2d46-4740-bdd4-09c75c53e2b1 | 1.1.1.0/24 | +--------------------------------------+---------+--------------------------------------+-----------------+ $ wget http://cloud-images.ubuntu.com/releases/18.04/release/ubuntu-18.04-server-cloudimg-amd64.img -P /var/kvm/images $ openstack image create \u0026#34;Ubuntu1804\u0026#34; --file /var/kvm/images/ubuntu-18.04-server-cloudimg-amd64.img --disk-format qcow2 --container-format bare --public # 이미지를 다운로드 및 등록합니다. $ openstack flavor create --ram 1024 --disk 10 --vcpus 1 m1.small # flavor를 생성합니다. $ ssh-keygen -q -N \u0026#34;\u0026#34; $ openstack keypair create --public-key ~/.ssh/id_rsa.pub mykey # keypair를 생성합니다. $ openstack floating ip create ext # floating ip를 생성합니다. $ openstack create server --image Ubuntu1804 --flavor m1.small --key mykey --network int Ubuntu $ openstack server add floating ip Ubuntu 192.168.10.170 # 인스턴스를 생성하고 floating ip를 추가합니다. $ openstack server list +--------------------------------------+--------+--------+-------------------------------+------------+----------+ | ID | Name | Status | Networks | Image | Flavor | +--------------------------------------+--------+--------+-------------------------------+------------+----------+ | 75fa0186-ab63-4aaa-a27c-3f2126e5d31d | Ubuntu | ACTIVE | int=1.1.1.248, 192.168.10.170 | Ubuntu1804 | m1.small | +--------------------------------------+--------+--------+-------------------------------+------------+----------+ $ openstack security group create open $ openstack security group rule create --protocol icmp --ingress open $ openstack security group rule create --protocol tcp --dst-port 22:22 open $ openstack security group rule create --protocol tcp --dst-port 80:80 open $ openstack server add security group Ubuntu open # 보안그룹을 생성하고 적용시킵니다. $ ssh ubuntu@192.168.10.170 $ ping 8.8.8.8 $ sudo apt -y install apache2 $ sudo service apache2 start # 본체 Host에서 접속해서 확인 이것으로 기본적인 openstack-stein 버전의 설치를 완료하였습니다. #\r#\r7. Horizon ( 대시보드 서비스 ) 구성\r#\rHorizon은 controller 노드에서 설치가 진행됩니다. 에 대한 설명은 Horizone을 참조해주세요. #\rHorizon 패키지 설치 $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-dashboard # Horizon 패키지를 설치합니다. #\r대시보드를 설정합니다. $ vi /etc/openstack-dashboard/local_settings ALLOWED_HOSTS = [\u0026#39;*\u0026#39;] # 수정 OPENSTACK_API_VERSIONS = { \u0026#34;identity\u0026#34;: 3, \u0026#34;image\u0026#34;: 3, \u0026#34;volume\u0026#34;: 3, \u0026#34;compute\u0026#34;: 2, } # 주석 제거 및 수정 OPENSTACK_KEYSTONE_MULTIDOMAIN_SUPPORT = True # 주석 해제 및 수정 OPENSTACK_KEYSTONE_DEFAULT_DOMAIN = \u0026#39;Default\u0026#39; # 주석 제거 CACHES = { \u0026#39;default\u0026#39;: { \u0026#39;BACKEND\u0026#39;: \u0026#39;django.core.cache.backends.memcached.MemcachedCache\u0026#39;, \u0026#39;LOCATION\u0026#39;: \u0026#39;127.0.0.1:11211\u0026#39;, }, } # 주석제거 OPENSTACK_HOST = \u0026#34;controller\u0026#34; # IP 변경 OPENSTACK_KEYSTONE_DEFAULT_ROLE = \u0026#34;member\u0026#34; # 수정 $ vi /etc/httpd/conf.d/openstack-dashboard.conf WSGIDaemonProcess dashboard WSGIProcessGroup dashboard WSGISocketPrefix run/wsgi WSGIApplicationGroup %{GLOBAL} # 추가 #\rSelinux 및 방화벽 설정 $ setsebool -P httpd_can_network_connect on $ firewall-cmd --add-service={http,https} --permanent $ firewall-cmd --reload $ systemctl restart httpd #\r** DB 생성** $ mysql -u root -p MariaDB [(none)]\u0026gt; create database keystone; MariaDB [(none)]\u0026gt; grant all privileges on .* to @\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on .* to @\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; flush privileges; # 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. ) #\r#\r8. Cinder ( 오브젝트 스토리지 및 블록 스토리지 구성 )\r#\rCinder는 기본적으로 독립적으로 storage 노드를 구성하거나 혹은 compute 노드에 추가하여 사용합니다. 여기서는 compute 노드에 포함하여 구성하도록 하겠습니다/ 구성 순서는 controller \u0026gt; compute 노드 순으로 진행하겠습니다. Cinder에 대한 설명은 Cinder을 참조해주세요. #\rCinder 서비스 등록 $ source ~/admin $ openstack user create --domain default --project service --password qwer1234 cinder $ openstack role add --project service --user cinder admin $ openstack service create --name cinderv3 --description \u0026#34;OpenStack Block service\u0026#34; volumev3 # cinder 사용자를 추가 및 서비스를 등록합니다. $ export controller=10.10.10.10 $ openstack endpoint create --region RegionOne volumev3 public http://$controller:8776/v3/%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne volumev3 internal http://$controller:8776/v3/%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne volumev3 admin http://$controller:8776/v3/%\\(tenant_id\\)s # cinder의 endpoint를 생성합니다. #\rCinder DB 생성 $ mysql -u root -p MariaDB [(none)]\u0026gt; create database cinder; MariaDB [(none)]\u0026gt; grant all privileges on cinder.* to cinder@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on cinder.* to cinder@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; flush privileges; # cinder 구성을 위한 db를 생성합니다. ( 저는 편의를 위해 모든 pw로 qwer1234 설정하였습니다. ) #\rcinder 패키지 설치 및 수정 $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-cinder $ vi /etc/cinder/cinder.conf [DEFAULT] my_ip = 10.10.10.10 log_dir = /var/log/cinder state_path = /var/lib/cinder auth_strategy = keystone transport_url = rabbit://openstack:qwer1234@controller enable_v3_api = True [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = cinder password = qwer1234 [database] connection = mysql+pymysql://cinder:qwer1234@controller/cinder [oslo_concurrency] lock_path = $state_path/tmp # cinder.conf 파일을 수정합니다. $ su -s /bin/bash cinder -c \u0026#34;cinder-manage db sync\u0026#34; # cinder db를 동기화시킵니다. $ systemctl start openstack-cinder-api openstack-cinder-scheduler $ systemctl enable openstack-cinder-api openstack-cinder-scheduler # cinder 시작 및 자동시작을 등록합니다. $ echo \u0026#34;export OS_VOLUME_API_VERSION=3\u0026#34; \u0026gt;\u0026gt; ~/admin $ source ~/admin # 볼륨 버전을 API 3로 지정합니다. $ firewall-cmd --add-port=8776/tcp --permanent $ firewall-cmd --reload #\r#\r이어서 compute 노드에 설치를 진행하겠습니다. cinder 패키지 설치 및 수정 $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-cinder python2-crypto targetcli $ vi /etc/cinder/cinder.conf [DEFAULT] my_ip = 10.10.10.30 log_dir = /var/log/cinder state_path = /var/lib/cinder auth_strategy = keystone transport_url = rabbit://openstack:qwer1234@controller glance_api_servers = http://controller:9292 enable_v3_api = True [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = cinder password = qwer1234 [database] connection = mysql+pymysql://cinder:qwer1234@controller/cinder [oslo_concurrency] lock_path = $state_path/tmp # cinder.conf 파일을 수정합니다. $ systemctl start openstack-cinder-volume $ systemctl enable openstack-cinder-volume # cinder 서비스를 시작 및 자동시작을 등록합니다. $ controller $openstack volume service list # 확인 +------------------+------------+------+---------+-------+----------------------------+ | Binary | Host | Zone | Status | State | Updated At | +------------------+------------+------+---------+-------+----------------------------+ | cinder-scheduler | controller | nova | enabled | up | 2020-07-20T04:02:31.000000 | +------------------+------------+------+---------+-------+----------------------------+ #\r#\r8-2. LVM으로 블록 스토리지 백엔드 구성\r#\r#\rcompute 노드에 cinder 서비스를 설치한 것에 이어 LVM 백엔드를 설정해보도록 하겠습니다. VG 생성 참조 $ fdisk /dev/sd[ n ] # 만약 디스크 파티션이 없으시면 새로 생성 후 등록합니다. # 저는 간단하게 100G 하드를 추가한 후, cinder 이름으로 vg를 생성하였습니다. $ vi /etc/cinder/cinder.conf [DEFAULT] ... enabled_backends = lvm [lvm] target_helper = lioadm target_protocol = iscsi target_ip_address = 10.10.10.30 volume_group = cinder volume_driver = cinder.volume.drivers.lvm.LVMVolumeDriver volume_dir = $state_path/volumes # cinder.conf의 상단에 내용을 추가설정합니다. $ firewall-cmd --add-service=iscsi-target --permanent $ firewall-cmd --reload # 방화벽 설정을 추가합니다. $ systemctl restart openstack-cinder-volume # 서비스를 재시작합니다. #\r이어서 compute 노드의 nova.conf 파일을 수정합니다. $ vi /etc/nova/nova.conf [cinder] os_region_name = RegionOne # nova.conf의 하단에 상단의 내용을 추가합니다. $ systemctl restart openstack-nova-compute # nova 서비스를 재시작합니다. $ controller $ openstack volume service list # 생성을 확인합니다. +------------------+-------------+------+---------+-------+----------------------------+ | Binary | Host | Zone | Status | State | Updated At | +------------------+-------------+------+---------+-------+----------------------------+ | cinder-scheduler | controller | nova | enabled | up | 2020-07-20T04:54:52.000000 | | cinder-volume | compute@lvm | nova | enabled | up | 2020-07-20T04:54:52.000000 | +------------------+-------------+------+---------+-------+----------------------------+ $ controller $ openstack volume cretae --size 1 test # 확인용 1G volume을 생성합니다. +---------------------+--------------------------------------+ | Field | Value | +---------------------+--------------------------------------+ | attachments | [] | | availability_zone | nova | | bootable | false | | consistencygroup_id | None | | created_at | 2020-07-20T05:00:21.000000 | | description | None | | encrypted | False | | id | f09ee80f-3ec8-4eaf-a4a5-af13cccbd5ae | | migration_status | None | | multiattach | False | | name | test | | properties | | | replication_status | None | | size | 1 | | snapshot_id | None | | source_volid | None | | status | creating | | type | None | | updated_at | None | | user_id | 296ce49d1dc94931b62a726fb64712e9 | +---------------------+--------------------------------------+ $ openstack volume list # 생성한 volume을 확인합니다. +--------------------------------------+------+-----------+------+-------------+ | ID | Name | Status | Size | Attached to | +--------------------------------------+------+-----------+------+-------------+ | f09ee80f-3ec8-4eaf-a4a5-af13cccbd5ae | test | available | 1 | | +--------------------------------------+------+-----------+------+-------------+ #\r#\r8-3. LBaaS 설치\r#\r로드밸런싱을 위해서는 LBaaS를 사용해야 합니다. LBaaS에 대해서는 LBaaS를 참조해주세요. $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron-lbaas net-tools # LBaaS 서비스를 설치합니다. $ vi /etc/neutron/neutron.conf service_plugins = router,lbaasv2 # lbaasv2 서비스를 추가합니다. $ vi /etc/neutron/neutron_lbaas.conf [service_providers] service_provider = LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default $ vi /etc/neutron/lbaas_agent.ini [DEFAULT] interface_driver = openvswitch $ su -s /bin/bash neutron -c \u0026#34;neutron-db-manage --subproject neutron-lbaas --config-file /etc/neutron/neutron.conf --config-file /etc/neutron/plugin.ini upgrade head\u0026#34; $ systemctl restart neutron-server #\rnetwork 노드와 compute 노드는 동일하게 진행합니다. $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-neutron-lbaas haproxy net-tools $ vi /etc/neutron/neutron.conf service_plugins = router,lbaasv2 $ vi /etc/neutron/neutron_lbaas.conf [service_providers] service_provider = LOADBALANCERV2:Haproxy:neutron_lbaas.drivers.haproxy.plugin_driver.HaproxyOnHostPluginDriver:default $ vi /etc/neutron/lbaas_agent.ini [DEFAULT] interface_driver = openvswitch $ systemctl start neutron-lbaasv2-agent $ systemctl enable neutron-lbaasv2-agent #\r#\r8-4. LFS, LVM 기반 다중 스토리지 노드 구성\r#\r#\r#\r9. Swift ( 오브젝트 스토리지 서비스 ) 구성\r#\rSwift란 오브젝트 스토리지 서비스로, 흔히 우리가 생각하는 네이버 클라우드와 거의 동일한 맥락이라 할 수 있습니다. swift는 기본적으로 controller에 설치하나 여기서는 비교적 자원소모가 적은 network 노드에 proxy-sever를, compute 노드를 storage로 사용하여 설치하여 진행하겠습니다. swift에 대한 설명은 swift을 참조해주세요.** #\rswift 서비스 생성 controlloer 노드에는 swift 관련 패키지를 설치하지는 않지만 서비스의 관리를 위해 유저, 엔드포인트, url을 생성합니다. $ openstack user create --domain default --project service --password qwer1234 swift $ openstack role add --project service --user swift admin $ openstack service create --name swift --description \u0026#34;OpenStack Object Storage\u0026#34; object-store # swfit 유저를 생성하고 관리자의 권한을 부여합니다. $ export swift_proxy=10.10.10.20 $ openstack endpoint create --region RegionOne object-store public http://$swift_proxy:8080/v1/AUTH_%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne object-store internal http://$swift_proxy:8080/v1/AUTH_%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne object-store admin http://$swift_proxy:8080/v1/AUTH_%\\(tenant_id\\)s # swift의 endpoint를 등록합니다. 여기서 proxy 서버는 네트워크 노드를 등록합니다. #\r#\r이어서 network 노드에서의 swift 설치 및 설정을 진행하겠습니다. $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-swift-proxy python-memcached openssh-clients # swift 서비스에 필요한 패키지를 설치합니다. $ vi /etc/swift/proxy-server.conf [filter:cache] use = egg:swift#memcache #memcache_servers = 127.0.0.1:11211 memcache_servers = controller:11211 [filter:authtoken] paste.filter_factory = keystonemiddleware.auth_token:filter_factory #admin_tenant_name = %SERVICE_TENANT_NAME% #admin_user = %SERVICE_USER% #admin_password = %SERVICE_PASSWORD% #admin_host = 127.0.0.1 #admin_port = 35357 #admin_protocol = http #admin_ /tmp/keystone-signing-swift # paste.filter_factory를 제외한 기존 정보는 주석처리 www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = swift password = qwer1234 delay_auth_decision = true # 위에 내용을 대신 주석 추가 # proxy-server.conf 파일을 수정합니다. # memcache_servers의 IP는 controller 노드의 IP로 수정합니다. $ vi /etc/swift/swift.conf [swift-hash] #swift_hash_path_suffix = %SWIFT_HASH_PATH_SUFFIX% swift_hash_path_suffix = swift_shared_path swift_hash_path_prefix = swift_shared_path #\rswift 서비스의 사용을 위해 account, container, object를 생성합니다. $ swift-ring-builder /etc/swift/account.builder create 12 1 1 $ swift-ring-builder /etc/swift/container.builder create 12 1 1 $ swift-ring-builder /etc/swift/object.builder create 12 1 1 # account, container, object를 생성합니다. # 12 = 한 클러스터 스토리지에서 생성 가능한 파티션의 수 # 1 = 오브젝트 복수 수 ( 스토리지의 개수 ) # 1 = 데이터 이동, 복제, 파티션 이동 등이 진행될 때 잠기는 최소 시간, 데이터 손실을 방지하기 위한 기능 $ swift-ring-builder /etc/swift/account.builder add r0z0-10.10.10.30:6202/device0 100 $ swift-ring-builder /etc/swift/container.builder add r0z0-10.10.10.30:6201/device0 100 $ swift-ring-builder /etc/swift/object.builder add r0z0-10.10.10.30:6200/device0 100 $ swift-ring-builder /etc/swift/account.builder rebalance $ swift-ring-builder /etc/swift/container.builder rebalance $ swift-ring-builder /etc/swift/object.builder rebalance # compute 노드의 builder에 region과 zone을 추가 후 반영시킵니다. # r = region, z = zone $ chown swift. /etc/swift/*.gz # swift 관련 파일의 소유권을 변경합니다. $ systemctl start openstack-swift-proxy $ systemctl enable openstack-swift-proxy # 프록시 서비스를 시작합니다. $ firewall-cmd --add-port=8080/tcp --permanent $ firewall-cmd --reload # 방화벽을 사용 중이라면 방화벽을 등록합니다. #\r#\r이제 이어 storage를 구성하기 위해 compute 노드에서의 설치를 진행해보도록 하겠습니다. compute 노드는 이미 cinder 서비스가 동작하고 있어 기본적인 네트워크, 시간 설정, 레포지터리 지정 등은 구성이 마친 상태의 노드입니다. 만약 다른 노드에 구성하시거나 swift 서비스를 다중 노드로 구성하시는 경우 위와 같은 설정을 먼저 진행해주시길 바랍니다. 여기서는 swift 서비스를 위해 100G의 버츄얼 디스크( dev/sdc )를 추가하여 진행하였습니다. $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-swift-account openstack-swift-container openstack-swift-object xfsprogs rsync openssh-clients # swift 서비스를 설치합니다. $ scp root@network:/etc/swift/*.gz /etc/swift/ $ chown swift. /etc/swift/*.gz # network 노드에서의 설정파일을 복사옵니다. $ vi /etc/swift/swift.conf [swift-hash] #swift_hash_path_suffix = %SWIFT_HASH_PATH_SUFFIX% swift_hash_path_suffix = swift_shared_path swift_hash_path_prefix = swift_shared_path $ swift.conf 파일을 설정합니다. $ vi /etc/swift/account-server.conf bind-ip = 0.0.0.0 bind_port = 6202 $ vi /etc/swift/container-server.conf bind-ip = 0.0.0.0 bind_port = 6201 $ vi /etc/swift/object-server.conf bind-ip = 0.0.0.0 bind_port = 6200 $ vi /etc/rsyncd.conf pid file = /var/run/rsymcd.pid log file = /var/log/rsymcd.log uid = swift gid = swift address = compute [account] path = /srv/node read only = false write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 25 lock file = /var/lock/account.lock [container] path = /srv/node read only = false write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 25 lock file = /var/lock/container.lock [object] path = /srv/node read only = false write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 25 lock file = /var/lock/object.lock [swift_server] path = /etc/swift read only = true write only = no list = yes incoming chmod = 0644 outgoing chmod = 0644 max connections = 5 lock file = /var/lock/swift_server.lock # swift 서비스관련 파일을 수정합니다. #\rcompute 노드에서 disk 설정을 진행합니다. $ mkfs.xfs -i size=1024 -s size=4096 /dev/sdb1 meta-data=/dev/sdc1 isize=1024 agcount=4, agsize=6553536 blks = sectsz=4096 attr=2, projid32bit=1 = crc=1 finobt=0, sparse=0 data = bsize=4096 blocks=26214144, imaxpct=25 = sunit=0 swidth=0 blks naming =version 2 bsize=4096 ascii-ci=0 ftype=1 log =internal log bsize=4096 blocks=12799, version=2 = sectsz=4096 sunit=1 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 # 디스크의 xfs의 유형으로 포맷시킵니다. $ mkdir -p /srv/node/device0 $ mount -o noatime,nodiratime,nobarrier /dev/sdc1 /srv/node/device0 $ chown -R swift. /srv/node # device0 디렉토리를 생성하고 해당 디렉토리에 sdb1 볼륨을 마운트시킨 후, swift로 소유권을 변경시킵니다. $ vi /etc/fstab /dev/sdc1 /srv/node/device0 xfs noatime,nodiratime,nobarrier 0 0 # 재부팅할 경우를 대비하여 생성한 볼륨을 fstab에 등록합니다. #\r#\rselinux 및 방화벽 관련 서비스를 설정합니다. $ semanage fcontext -a -t swift_data_t /srv/node/device0 $ restorecon /srv/node/device0 $ firewall-cmd --add-port={873/tcp,6200/tcp,6201/tcp,6202/tcp} --permanent $ firewall-cmd --reload #\rswift 관련 서비스를 재시작합니다. $ systemctl restart rsyncd openstack-swift-account-auditor openstack-swift-account-replicator openstack-swift-account openstack-swift-container-auditor openstack-swift-container-replicator openstack-swift-container-updater openstack-swift-container openstack-swift-object-auditor openstack-swift-object-replicator openstack-swift-object-updater openstack-swift-object $ systemctl enable rsyncd openstack-swift-account-auditor openstack-swift-account-replicator openstack-swift-account openstack-swift-container-auditor openstack-swift-container-replicator openstack-swift-container-updater openstack-swift-container openstack-swift-object-auditor openstack-swift-object-replicator openstack-swift-object-updater openstack-swift-object #\r확인을 위해 controller 노드에 httpd를 재시작합니다. $ systemctl restart httpd # 대시보드 접속 후 프로젝트에서 오브젝트 스토리지가 메뉴에 있는 지를 확인합니다. $ openstack container create test +---------------------------------------+-----------+------------------------------------+ | account | container | x-trans-id | +---------------------------------------+-----------+------------------------------------+ | AUTH_2ac06290d2d943d5a768fe3daa53b118 | test | tx22f3dd125f134a189602c-005f24cef1 | +---------------------------------------+-----------+------------------------------------+ $ echo Hello \u0026gt; test.txt $ swift upload test test.txt $ swift list test $ swift list test test.txt #\r#\r10. Heat ( Orchestration ) 설치\r#\r#\r클라우딩 컴퓨팅이 꽃인 Orchestaration 기능을 수행하는 Heat 서비스를 설치해보도록 하겠습니다. Heat 설치는 controller, network 노드 순으로 우리어집니다. Heat*에 대한 설명은 Heat을 참조해주세요. #\rHeat 서비스 생성 $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-heat-common python-heatclient # heat 서비스 관련 패키지를 다운로드 합니다. $ openstack user create --domain default --project service --password qwer1234 heat $ openstack role add --project service --user heat admin $ openstack role create heat_stack_owner $ openstack role create heat_stack_user $ openstack role add --project admin --user admin heat_stack_owner $ openstack service create --name heat --description \u0026#34;Openstack Orchestration\u0026#34; orchestration $ openstack service create --name heat-cfn --description \u0026#34;Openstack Orchestration\u0026#34; cloudformation # heat 유저를 생성하고 관리자의 권한을 부여합니다. $ export heat_api=10.10.10.20 $ openstack endpoint create --region RegionOne orchestration public http://$heat_api:8004/v1/AUTH_%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne orchestration internal http://$heat_api:8004/v1/AUTH_%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne orchestration admin http://$heat_api:8004/v1/AUTH_%\\(tenant_id\\)s $ openstack endpoint create --region RegionOne cloudformation public http://$heat_api:8000/v1 $ openstack endpoint create --region RegionOne cloudformation internal http://$heat_api:8000/v1 $ openstack endpoint create --region RegionOne cloudformation admin http://$heat_api:8000/v1 # heat 서비스의 endpoint를 등록합니다. 여기서 proxy 서버는 네트워크 노드를 등록합니다. $ openstack domain create --description \u0026#34;Stack projects and users\u0026#34; heat $ openstack user create --domain heat --password qwer1234 heat_domain_admin $ openstack role add --domain heat --user heat_domain_admin admin # heat domain을 생성하고 heat 유저에게 권한을 부여합니다. #\rheat의 DB를 생성합니다. $ mysql -u root -p MariaDB [(none)]\u0026gt; create database heat; MariaDB [(none)]\u0026gt; grant all privileges on heat.* to heat@\u0026#39;localhost\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; grant all privileges on heat.* to keystone@\u0026#39;%\u0026#39; identified by \u0026#39;pw\u0026#39;; MariaDB [(none)]\u0026gt; flush privileges; # heat DB를 생성합니다. 여기서 pw는 qwer1234으로 모두 통일하였습니다. #\r이어서 network 노드에서 heat 서비스를 설치해보겠습니다. $ yum --enablerepo=centos-openstack-stein,epel -y install openstack-heat-api openstack-heat-api-cfn openstack-heat-engine python-heatclient # heat 서비스를 위한 패키지를 설치합니다. $ vi /etc/heat/heat.conf [DEFAULT] deferred_auth_method = trusts trusts_delegated_roles = heat_stack_owner # Heat installed server heat_metadata_server_url = http://network:8000 heat_waitcondition_server_url = http://network:8000/v1/waitcondition heat_watch_server_url = http://network:8003 heat_stack_user_role = heat_stack_user # Heat domain name stack_user_domain_name = heat # Heat domain admin name stack_domain_admin = heat_domain_admin # Heat domain admin\u0026#39;s password stack_domain_admin_password = qwer1234 # RabbitMQ connection info transport_url = rabbit://openstack:qwer1234@controller # MariaDB connection info [database] connection = mysql+pymysql://heat:qwer1234@controller/heat # Keystone auth info [clients_keystone] auth_uri = http://controller:5000 # Keystone auth info [ec2authtoken] auth_uri = http://controller:5000 [heat_api] bind_host = 0.0.0.0 bind_port = 8004 [heat_api_cfn] bind_host = 0.0.0.0 bind_port = 8000 # Keystone auth info [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = heat password = qwer1234 [trustee] auth_plugin = password auth_url = http://controller:5000 username = heat password = qwer1234 user_domain_name = default # heat.conf 파일을 수정합니다. $ su -s /bin/bash heat -c \u0026#34;heat-manage db_sync\u0026#34; $ systemctl start openstack-heat-api openstack-heat-api-cfn openstack-heat-engine $ systemctl enable openstack-heat-api openstack-heat-api-cfn openstack-heat-engine # DB의 데이터를 삽입하고, 서비스슬 등록합니다. #\r방화벽을 사용중이면 방화벽을 설정합니다. $ firewall-cmd --add-port={8000/tcp,8004/tcp} --permanent $ firewall-cmd --reload #\r#\r$ yum --enablerepo=centos-openstack-stein,epel -y install openstack-designate-api openstack-designate-central openstack-designate-worker openstack-designate-producer openstack-designate-mdns python-designateclient bind bind-utils # 서비스 관련 패키지를 설치합니다. $ rndc-confgen -a -k designate -c /etc/designate.key -r /dev/urandom $ chown named:designate /etc/designate.key $ chmod 640 /etc/designate.key # key를 생성합니다. $ vi /etc/named.conf # create new options { listen-on port 53 { any; }; listen-on-v6 port 53 { none; }; directory \u0026#34;/var/named\u0026#34;; dump-file \u0026#34;/var/named/data/cache_dump.db\u0026#34;; statistics-file \u0026#34;/var/named/data/named_stats.txt\u0026#34;; memstatistics-file \u0026#34;/var/named/data/named_mem_stats.txt\u0026#34;; # replace query range to your own environment allow-query { localhost; 10.10.10.0/24; }; allow-new-zones yes; request-ixfr no; recursion no; bindkeys-file \u0026#34;/etc/named.iscdlv.key\u0026#34;; managed-keys-directory \u0026#34;/var/named/dynamic\u0026#34;; pid-file \u0026#34;/run/named/named.pid\u0026#34;; session-keyfile \u0026#34;/run/named/session.key\u0026#34;; }; include \u0026#34;/etc/designate.key\u0026#34;; controls { inet 0.0.0.0 port 953 allow { localhost; } keys { \u0026#34;designate\u0026#34;; }; }; logging { channel default_debug { file \u0026#34;data/named.run\u0026#34;; severity dynamic; }; }; zone \u0026#34;.\u0026#34; IN { type hint; file \u0026#34;named.ca\u0026#34;; }; $ chown -R named. /var/named $ systemctl start named $ systemctl enable naemd $ vi /etc/designate/designate.conf [DEFAULT] log_dir = /var/log/designate transport_url = rabbit://openstack:qwer1234@controller root_helper = sudo designate-rootwrap /etc/designate/rootwrap.conf [database] connection = mysql+pymysql://heat:qwer1234@controller/heat [service:api] listen = 0.0.0.0:9001 auth_strategy = keystone api_base_uri = http://controller:9001 enable_api_v2 = True enabled_extensions_v2 = quotas, reports [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = heat password = qwer1234 [service:worker] enabled = True notify = True [storage:sqlalchemy] connection = mysql+pymysql://heat:qwer1234@controller/heat $ su -s /bin/sh -c \u0026#34;designate-manage database sync\u0026#34; designate $ systemctl start designate-central designate-api $ systemctl enable designate-central designate-api $ vi /etc/designate/pools.yaml # create new (replace hostname and IP address to your own environment) - name: default description: Default Pool attributes: {} ns_records: - hostname: network.srv.world. priority: 1 nameservers: - host: 10.10.10.20 port: 53 targets: - type: bind9 description: BIND9 Server masters: - host: 10.10.10.20 port: 5354 options: host: 10.10.10.20 port: 53 rndc_host: 10.10.10.20 rndc_port: 953 rndc_key_file: /etc/designate.key $ su -s /bin/sh -c \u0026#34;designate-manage pool update\u0026#34; designate Updating Pools Configuration $ systemctl start designate-worker designate-producer designate-mdns $ systemctl enable designate-worker designate-producer designate-mdns #\r이어서 selinux와 방화벽을 설정합니다. $ setsebool -P named_write_master_zones on $ firewall-cmd --add-service=dns --permanent $ firewall-cmd --add-port={5354/tcp,9001/tcp} --permanent $ firewall-cmd --reload controller\u0026gt; $openstack dns service list # 확인 #\r#\r#\r11. Openstack 대시보드 메인 로고 및 링크 변경\r#\r#\r#\r12. Neutron 기반 Service Functon Chaining ( SFC ) 기능 구성\r#\r#\r#\r"},{"id":81,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-11/","title":"OpenStack Ussuri : Gnocch","section":"OpenStack Training","content":"\rOpenStack Ussuri : Gnocch\r#\r#\r----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | | Heat API | | metadata agent | ----------------------- | API-CFN | | Neutron Server | | Heat Engine | | Gnocchi | ----------------------- ----------------------- --------------------------------- | [ Storage Node 1, 2, 3 ] | | | | Swift-account-auditor | | Swift-account-replicator | | Swift-account | | Swift-container-auditor | | Swift-container-replicator | | Swift-container-updater | | Swift-container | | Swift-object-auditor | | Swift-object-replicator | | Swift-object-updater | | Swift-swift-object | --------------------------------- #\rOpenStack Ussuri : Gnnoch\r#\r#\rGnnoch #\r#\rGnocchi service 및 User 생성\r#\r$ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 gnocchi +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | b470c69e28db47cdbfc81e06cc67f627 | | domain_id | default | | enabled | True | | id | 3217be4917454641994660bd1f3ea007 | | name | gnocchi | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user gnocchi admin $ controller ~(keystone)\u0026gt; openstack service create --name gnocchi --description \u0026#34;Metric Service\u0026#34; metric -------------------------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Metric Service | | enabled | True | | id | 6ac9ec31386f4291b582bd5b504ac485 | | name | gnocchi | | type | metric | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne metric public http://controller:8041 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 12f4410ed82240b0b1340d48b0627612 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 6ac9ec31386f4291b582bd5b504ac485 | | service_name | gnocchi | | service_type | metric | | url | http://controller:8041 | +-------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne metric internal http://controller:8041 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 70f43453f93b407e94d2dd11ddce7260 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 6ac9ec31386f4291b582bd5b504ac485 | | service_name | gnocchi | | service_type | metric | | url | http://controller:8041 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne metric admin http://controller:8041 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | bb9a955359fd4af18599913465f46958 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 6ac9ec31386f4291b582bd5b504ac485 | | service_name | gnocchi | | service_type | metric | | url | http://controller:8041 | +--------------+----------------------------------+ #\rGnocchi 유저의 DB를 생성합니다.\r#\r#\r$ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database gnocchi; $ MariaDB\u0026gt; grant all privileges on gnocchi.* to gnocchi@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on gnocchi.* to gnocchi@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit; #\r#\rcontroller node Gnoochi 설치\r#\r#\r$ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-gnocchi-api openstack-gnocchi-metricd python3-gnocchiclient # gnoochi 및 관련 모듈을 설치합니다. $ controller\u0026gt; vi /etc/gnocchi/gnocchi.conf [DEFAULT] log_dir = /var/log/gnocchi [api] auth_mode = keystone [database] backend = sqlalchemy [indexer] url = mysql+pymysql://gnocchi:qwer1234@controller/gnocchi [storage] driver = file file_basepath = /var/lib/gnocchi [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = gnocchi password = qwer1234 service_token_roles_required = true $ controller\u0026gt; vi /etc/httpd/conf.d/10-gnocchi_wsgi.conf Listen 8041 \u0026lt;VirtualHost *:8041\u0026gt; \u0026lt;Directory /usr/bin\u0026gt; AllowOverride None Require all granted \u0026lt;/Directory\u0026gt; CustomLog /var/log/httpd/gnocchi_wsgi_access.log combined ErrorLog /var/log/httpd/gnocchi_wsgi_error.log SetEnvIf X-Forwarded-Proto https HTTPS=1 WSGIApplicationGroup %{GLOBAL} WSGIDaemonProcess gnocchi display-name=gnocchi_wsgi user=gnocchi group=gnocchi processes=6 threads=6 WSGIProcessGroup gnocchi WSGIScriptAlias / /usr/bin/gnocchi-api \u0026lt;/VirtualHost\u0026gt; # 새로 생성합니다. $ controller\u0026gt; su -s /bin/bash gnocchi -c \u0026#34;gnocchi-upgrade\u0026#34; $ controller\u0026gt; systemctl enable --now openstack-gnocchi-metricd $ controller\u0026gt; systemctl restart httpd # gnocchi DB를 import 시킨 후 서비스를 등록합니다. $ controller\u0026gt; semanage port -a -t http_port_t -p tcp 8041 $ controller\u0026gt; firewall-cmd --add-port=8041/tcp --permanent $ controller\u0026gt; firewall-cmd --reload # SELinux 및 방화벽을 설정합니다. "},{"id":82,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-12/","title":"OpenStack Ussuri : Trove","section":"OpenStack Training","content":"\r! 아직 수정 중 문제있음\r#\rOpenStack Ussuri : Trove\r#\r#\r----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | | Heat API | | metadata agent | ----------------------- | API-CFN | | Neutron Server | | Heat Engine | | Gnocchi Trove API | ----------------------- ----------------------- --------------------------------- | [ Storage Node 1, 2, 3 ] | | | | Swift-account-auditor | | Swift-account-replicator | | Swift-account | | Swift-container-auditor | | Swift-container-replicator | | Swift-container-updater | | Swift-container | | Swift-object-auditor | | Swift-object-replicator | | Swift-object-updater | | Swift-swift-object | --------------------------------- #\rOpenStack Ussuri : Trove\r#\r#\rTrove는 관리형 데이터베이스 서비스 입니다. Trove*에 대한 설명은 Heat을 참조해주세요. #\r#\rTrove service 및 User 생성\r#\r$ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 trove +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | b470c69e28db47cdbfc81e06cc67f627 | | domain_id | default | | enabled | True | | id | 3cdb0abe0a3a429ba08f98d8db786b6d | | name | trove | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user trove admin $ controller ~(keystone)\u0026gt; openstack service create --name trove --description \u0026#34;Database\u0026#34; database +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | Database | | enabled | True | | id | 701b7dca93e74509aaf811eafc29cc03 | | name | trove | | type | database | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne database public http://controller:8779/v1.0/%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | 58fa28821c444c869be463b550f48651 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 701b7dca93e74509aaf811eafc29cc03 | | service_name | trove | | service_type | database | | url | http://controller:8779/v1.0/%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne database internal http://controller:8779/v1.0/%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | 2809c9cb57884ceabf2902c6b6e62ced | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 701b7dca93e74509aaf811eafc29cc03 | | service_name | trove | | service_type | database | | url | http://controller:8779/v1.0/%(tenant_id)s | +--------------+-------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne database admin http://controller:8779/v1.0/%\\(tenant_id\\)s +--------------+-------------------------------------------+ | Field | Value | +--------------+-------------------------------------------+ | enabled | True | | id | d86280b59bf04be28e71a57ff8b36a0b | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 701b7dca93e74509aaf811eafc29cc03 | | service_name | trove | | service_type | database | | url | http://controller:8779/v1.0/%(tenant_id)s | +--------------+-------------------------------------------+ #\rTrove 유저의 DB를 생성합니다.\r#\r#\r$ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database trove; $ MariaDB\u0026gt; grant all privileges on trove.* to trove@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on trove.* to trove@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit; #\r#\rTrove 설치\r#\r#\r$ controller ~(keystone)\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-trove python-troveclient # Trove 서비스 및 관련 모듈을 설치합니다. $ controller ~(keystone)\u0026gt; vi /etc/trove/trove.conf [DEFAULT] network_driver = trove.network.neutron.NeutronDriver management_networks = ef7541ad-9599-4285-878a-e0ab62032b03 management_security_groups = d0d797f7-11d4-436e-89a3-ac8bca829f81 cinder_volume_type = lvmdriver-1 nova_keypair = trove-mgmt default_datastore = mysql taskmanager_manager = trove.taskmanager.manager.Manager trove_api_workers = 5 transport_url = rabbit://openstack:qwer1234@controller control_exchange = trove rpc_backend = rabbit reboot_time_out = 300 usage_timeout = 900 agent_call_high_timeout = 1200 use_syslog = False debug = True [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = trove password = qwer1234 service_token_roles_required = true [service_credentials] auth_url = http://controller/identity/v3 region_name = RegionOne project_name = service password = qwer1234 project_domain_name = Default user_domain_name = Default username = trove [database] connection = mysql+pymysql://trove:qwer1234@controller/trove [mariadb] tcp_ports = 3306,4444,4567,4568 [mysql] tcp_ports = 3306 [postgresql] tcp_ports = 5432 $ controller ~(keystone)\u0026gt; vi /etc/trove/trove-guestagent.conf [DEFAULT] log_file = trove-guestagent.log log_dir = /var/log/trove/ ignore_users = os_admin control_exchange = trove transport_url = rabbit://openstack:qwer1234@controller rpc_backend = rabbit command_process_timeout = 60 use_syslog = False debug = True [service_credentials] auth_url = http://controller/identity/v3 region_name = RegionOne project_name = service password = qwer1234 project_domain_name = Default user_domain_name = Default username = trove $ controller ~(keystone)\u0026gt; su -s /bin/sh -c \u0026#34;trove-manage db_sync\u0026#34; trove $ controller ~(keystone)\u0026gt; systemctl enable --now openstack-trove-api.service openstack-trove-taskmanager.service openstack-trove-conductor.service $ controller ~(keystone)\u0026gt; #\r"},{"id":83,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-13/","title":"OpenStack Ussuri : Designate","section":"OpenStack Training","content":"\rOpenStack Ussuri : Designate\r#\r#\r----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | | Heat API | | metadata agent | ----------------------- | API-CFN | | Neutron Server | | Heat Engine | | Gnocchi Trove API | | Designate Services | ----------------------- ----------------------- #\rOpenStack Ussuri : Designate\r#\r#\rDesignate는 OpenStack 서비스에서 DNS 서비스를 배포, 관리를 담당합니다. Desigante는 Network node의 설치를 진행하고, controller node의 API를 이용하겠습니다. Designate의 보다 자세한 설명은 Designate를 참조해주세요. #\r#\rDesignate service 및 User 생성\r#\r$ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 designate +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | b470c69e28db47cdbfc81e06cc67f627 | | domain_id | default | | enabled | True | | id | 7563701765d24b4884c0b324b7997530 | | name | designate | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user designate admin $ controller ~(keystone)\u0026gt; openstack service create --name designate --description \u0026#34;OpenStack DNS Service\u0026#34; dns +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack DNS Service | | enabled | True | | id | 0e7dacc11b5b48c099d3fe110f8b8197 | | name | designate | | type | dns | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne dns public http://network:9001/ +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 20b26900a14d44209ade2fab0a0f3bbc | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 0e7dacc11b5b48c099d3fe110f8b8197 | | service_name | designate | | service_type | dns | | url | http://network:9001/ | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne dns internal http://network:9001/ +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 856883757b604b93a1273ecc4775f549 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 0e7dacc11b5b48c099d3fe110f8b8197 | | service_name | designate | | service_type | dns | | url | http://network:9001/ | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne dns admin http://network:9001/ +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | c6fef7cbb6a848228fa8ef4067ebcc49 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 0e7dacc11b5b48c099d3fe110f8b8197 | | service_name | designate | | service_type | dns | | url | http://network:9001/ | +--------------+----------------------------------+ #\rDesignate 유저의 DB를 생성합니다.\r#\r#\r$ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database designate; $ MariaDB\u0026gt; grant all privileges on designate.* to designate@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on designate.* to designate@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit; #\r#\rNetwork Node Desigante 설치\r#\r#\r$ network\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-designate-api openstack-designate-central openstack-designate-worker openstack-designate-producer openstack-designate-mdns python3-designateclient bind bind-utils # designate 및 관련 모듈을 설치합니다. $ network\u0026gt; rndc-confgen -a -k designate -c /etc/designate.key -r /dev/urandom $ network\u0026gt; chown named:designate /etc/designate.key $ network\u0026gt; chmod 640 /etc/designate.key # 역할기반 키를 생성하고 권한을 설정합니다. $ network\u0026gt; cp /etc/named.conf /etc/named.conf.backup $ network\u0026gt; vi /etc/named.conf options { listen-on port 53 { any; }; listen-on-v6 port 53 { none; }; directory \u0026#34;/var/named\u0026#34;; dump-file \u0026#34;/var/named/data/cache_dump.db\u0026#34;; statistics-file \u0026#34;/var/named/data/named_stats.txt\u0026#34;; memstatistics-file \u0026#34;/var/named/data/named_mem_stats.txt\u0026#34;; # replace query range to your environment allow-query { localhost; 10.10.10.0/24; }; allow-new-zones yes; request-ixfr no; recursion no; bindkeys-file \u0026#34;/etc/named.iscdlv.key\u0026#34;; managed-keys-directory \u0026#34;/var/named/dynamic\u0026#34;; pid-file \u0026#34;/run/named/named.pid\u0026#34;; session-keyfile \u0026#34;/run/named/session.key\u0026#34;; }; include \u0026#34;/etc/designate.key\u0026#34;; controls { inet 0.0.0.0 port 953 allow { localhost; } keys { \u0026#34;designate\u0026#34;; }; }; logging { channel default_debug { file \u0026#34;data/named.run\u0026#34;; severity dynamic; }; }; zone \u0026#34;.\u0026#34; IN { type hint; file \u0026#34;named.ca\u0026#34;; }; $ network\u0026gt; chmod 640 /etc/named.conf $ network\u0026gt; chgrp named /etc/named.conf $ network\u0026gt; chown -R named. /var/named $ network\u0026gt; systemctl enable --now named # named dns 서비스를 시작합니다. $ network\u0026gt; vi /etc/designate/designate.conf [DEFAULT] log_dir = /var/log/designate transport_url = rabbit://openstack:qwer1234@controller root_helper = sudo designate-rootwrap /etc/designate/rootwrap.conf [database] connection = mysql+pymysql://designate:qwer1234@controller/designate [service:api] listen = 0.0.0.0:9001 auth_strategy = keystone api_base_uri = http://network:9001 enable_api_v2 = True enabled_extensions_v2 = quotas, reports [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = designate password = qwer1234 [service:worker] enabled = True notify = True [storage:sqlalchemy] connection = mysql+pymysql://designate:qwer1234@controller/designate $ network\u0026gt; su -s /bin/bash -c \u0026#34;designate-manage database sync\u0026#34; designate $ network\u0026gt; systemctl enable --now designate-central designate-api # designate api db를 임포트 시키고 서비스를 시작 및 등록합니다. $ network\u0026gt; vi /etc/designate/pools.yaml - name: default description: Default Pool attributes: {} ns_records: - hostname: network priority: 1 nameservers: - host: network port: 53 targets: - type: bind9 description: BIND9 Server masters: - host: network port: 5354 options: host: network port: 53 rndc_host: network rndc_port: 953 rndc_key_file: /etc/designate.key $ network\u0026gt; chmod 640 /etc/designate/pools.yaml $ network\u0026gt; chgrp designate /etc/designate/pools.yaml $ network\u0026gt; su -s /bin/bash -c \u0026#34;designate-manage pool update\u0026#34; designate $ network\u0026gt; systemctl enable --now designate-worker designate-producer designate-mdns # designate pool db를 임포트 시키고 서비스를 시작 및 등록합니다. $ network\u0026gt; setsebool -P named_write_master_zones on $ network\u0026gt; firewall-cmd --add-service=dns --permanent $ network\u0026gt; firewall-cmd --add-port={5354/tcp,9001/tcp} --permanent $ network\u0026gt; firewall-cmd --reload # SELinux 및 방화벽을 설정합니다. #\r#\r확인\r#\r#\r$ controller ~(keystone)\u0026gt; openstack dns service list +--------------------------------------+----------+--------------+--------+-------+--------------+ | id | hostname | service_name | status | stats | capabilities | +--------------------------------------+----------+--------------+--------+-------+--------------+ | 43f62f8d-20bc-43b9-8c64-758ac0a2a074 | network | central | UP | - | - | | ab90b2dc-381d-4ca8-ae66-fad57a9f9c11 | network | api | UP | - | - | | 2dbc8027-0c6a-4c4a-b7a0-92a2b19517a7 | network | worker | UP | - | - | | 502ce893-3256-432f-9c6f-2353078ee585 | network | producer | UP | - | - | | 078b306a-e3bb-461d-9c97-71679c9f8830 | network | mdns | UP | - | - | +--------------------------------------+----------+--------------+--------+-------+--------------+ $ controller ~(keystone)\u0026gt; openstack zone create --email dnsmaster@server.education server.education. $ controller ~(keystone)\u0026gt; openstack zone list $ controller ~(keystone)\u0026gt; openstack recordset create --record \u0026#39;192.168.100.10\u0026#39; --type A server.education. node01 $ controller ~(keystone)\u0026gt; openstack recordset list server.education. $ controller ~(keystone)\u0026gt; dig -p 5354 @network.srv.world node01.server.education. $ controller ~(keystone)\u0026gt; openstack zone create --email dnsmaster@server.education 100.168.192.in-addr.arpa. $ controller ~(keystone)\u0026gt; openstack zone list $ controller ~(keystone)\u0026gt; openstack recordset create --record \u0026#39;node01.server.education.\u0026#39; --type PTR 100.168.192.in-addr.arpa. 10 $ controller ~(keystone)\u0026gt; openstack recordset list 100.168.192.in-addr.arpa. $ controller ~(keystone)\u0026gt; dig -p 5354 @network.srv.world -x 192.168.100.10 $ controller ~(keystone)\u0026gt; openstack recordset list server.education. $ controller ~(keystone)\u0026gt; openstack recordset delete server.education. node01.server.education. $ controller ~(keystone)\u0026gt; openstack recordset list server.education. $ controller ~(keystone)\u0026gt; openstack zone list $ controller ~(keystone)\u0026gt; openstack zone delete server.education. $ controller ~(keystone)\u0026gt; openstack zone list #\r"},{"id":84,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-14/","title":"OpenStack Ussuri : Barbican","section":"OpenStack Training","content":"\rOpenStack Ussuri : Barbican\r#\r#\r----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | | Heat API | | metadata agent | ----------------------- | API-CFN | | Neutron Server | | Heat Engine | | Gnocchi Trove API | | Designate Services | | Barbican API | ----------------------- ----------------------- #\rOpenStack Ussuri : Barbican\r#\r#\rBarbican은 키 관리 서비스 입니다. 비밀 데이터의 안전한 저장, 프로비저닝 및 관리를 제공합니다. 여기에는 대칭 키, 비대칭 키, 인증서 및 원시 바이너리 데이터와 같은 키 자료가 포함됩니다. 자세한 설명은 Barbican을 참조해주세요. #\r#\rBarbican service 및 User 생성\r#\r$ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 barbican +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | b470c69e28db47cdbfc81e06cc67f627 | | domain_id | default | | enabled | True | | id | bc85b317bd7c4cc1a4d5aee81c383421 | | name | barbican | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user barbican admin $ controller ~(keystone)\u0026gt; openstack service create --name barbican --description \u0026#34;OpenStack Key Manager\u0026#34; key-manager -------------------------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Key Manager | | enabled | True | | id | ec2cbdda740a4887b5737fe885b4b86e | | name | barbican | | type | key-manager | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne key-manager public http://controller:9311 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 3254f8ccb5894560ab3dea0268dddd03 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | ec2cbdda740a4887b5737fe885b4b86e | | service_name | barbican | | service_type | key-manager | | url | http://controller:9311 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne key-manager internal http://controller:9311 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 37a440f72212422ca7c590e322afe56c | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | ec2cbdda740a4887b5737fe885b4b86e | | service_name | barbican | | service_type | key-manager | | url | http://controller:9311 | +--------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne key-manager admin http://controller:9311 +--------------+----------------------------------+ | Field | Value | +--------------+----------------------------------+ | enabled | True | | id | 2ad3a9aabcb840cc832470039ee37b00 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | ec2cbdda740a4887b5737fe885b4b86e | | service_name | barbican | | service_type | key-manager | | url | http://controller:9311 | +--------------+----------------------------------+ #\r#\rBarbican 유저의 DB를 생성합니다.\r#\r#\r$ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database barbican; $ MariaDB\u0026gt; grant all privileges on barbican.* to barbican@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on barbican.* to barbican@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit; #\r#\rcontoller node Barbican 설치\r#\r$ controller ~(keystone)\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-barbican # Barbucan 서비스 및 관련 모듈을 설치합니다. $ controller ~(keystone)\u0026gt; vi /etc/barbican/barbican.conf [DEFAULT] bind_host = 0.0.0.0 bind_port = 9311 host_href = http://controller:9311 log_file = /var/log/barbican/api.log sql_connection = mysql+pymysql://barbican:qwer1234@controller/barbican transport_url = rabbit://openstack:qwer1234@controller [oslo_policy] policy_file = /etc/barbican/policy.json policy_default_rule = default [secretstore] namespace = barbican.secretstore.plugin enabled_secretstore_plugins = store_crypto [crypto] namespace = barbican.crypto.plugin enabled_crypto_plugins = simple_crypto [simple_crypto_plugin] kek = \u0026#39;YWJjZGVmZ2hpamtsbW5vcHFyc3R1dnd4eXoxMjM0NTY=\u0026#39; [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = barbican password = qwer1234 $ controller ~(keystone)\u0026gt; su -s /bin/bash barbican -c \u0026#34;barbican-manage db upgrade\u0026#34; $ controller ~(keystone)\u0026gt; systemctl enable --now openstack-barbican-api # Barbican 서비스를 DB에 임포트 시킨 후, 서비스를 등록합니다. $ controller ~(keystone)\u0026gt; firewall-cmd --add-port=9311/tcp --permanent $ controller ~(keystone)\u0026gt; firewall-cmd --reload # 방화벽을 설정합니다. #\r#\r확인\r#\r#\r$ controller ~(keystone)\u0026gt; openstack secret store --name secret01 --payload secretkey +---------------+------------------------------------------------------------------------+ | Field | Value | +---------------+------------------------------------------------------------------------+ | Secret href | http://controller:9311/v1/secrets/86cbaa20-0cb9-479f-82ed-80a02f34b83d | | Name | secret01 | | Created | None | | Status | None | | Content types | None | | Algorithm | aes | | Bit length | 256 | | Secret type | opaque | | Mode | cbc | | Expiration | None | +---------------+------------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack secret list +------------------------------------------------------------------------+----------+---------------------------+--------+---------------------------+-----------+------------+-------------+------+------------+ | Secret href | Name | Created | Status | Content types | Algorithm | Bit length | Secret type | Mode | Expiration | +------------------------------------------------------------------------+----------+---------------------------+--------+---------------------------+-----------+------------+-------------+------+------------+ | http://controller:9311/v1/secrets/86cbaa20-0cb9-479f-82ed-80a02f34b83d | secret01 | 2020-08-16T09:00:00+00:00 | ACTIVE | {\u0026#39;default\u0026#39;: \u0026#39;text/plain\u0026#39;} | aes | 256 | opaque | cbc | None | +------------------------------------------------------------------------+----------+---------------------------+--------+---------------------------+-----------+------------+-------------+------+------------+ $ controller ~(keystone)\u0026gt; openstack secret get http://controller:9311/v1/secrets/86cbaa20-0cb9-479f-82ed-80a02f34b83d +---------------+------------------------------------------------------------------------+ | Field | Value | +---------------+------------------------------------------------------------------------+ | Secret href | http://controller:9311/v1/secrets/86cbaa20-0cb9-479f-82ed-80a02f34b83d | | Name | secret01 | | Created | 2020-08-16T09:00:00+00:00 | | Status | ACTIVE | | Content types | {\u0026#39;default\u0026#39;: \u0026#39;text/plain\u0026#39;} | | Algorithm | aes | | Bit length | 256 | | Secret type | opaque | | Mode | cbc | | Expiration | None | +---------------+------------------------------------------------------------------------+ # get 뒤에는 키 생성시 생성되는 값을 입력해주셔야 됩니다 ! $ controller ~(keystone)\u0026gt; openstack secret get http://controller:9311/v1/secrets/86cbaa20-0cb9-479f-82ed-80a02f34b83d --payload +---------+-----------+ | Field | Value | +---------+-----------+ | Payload | secretkey | +---------+-----------+ $ controller ~(keystone)\u0026gt; openstack secret order create --name secret02 --algorithm aes --bit-length 256 --mode cbc --payload-content-type application/octet-stream key +----------------+-----------------------------------------------------------------------+ | Field | Value | +----------------+-----------------------------------------------------------------------+ | Order href | http://controller:9311/v1/orders/ffe9a05e-db5e-4b7d-8b5a-86f1349863c3 | | Type | Key | | Container href | N/A | | Secret href | None | | Created | None | | Status | None | | Error code | None | | Error message | None | +----------------+-----------------------------------------------------------------------+ $ controller ~(keystone)\u0026gt; openstack secret order list +-----------------------------------------------------------------------+------+----------------+------------------------------------------------------------------------+---------------------------+--------+------------+---------------+ | Order href | Type | Container href | Secret href | Created | Status | Error code | Error message | +-----------------------------------------------------------------------+------+----------------+------------------------------------------------------------------------+---------------------------+--------+------------+---------------+ | http://controller:9311/v1/orders/ffe9a05e-db5e-4b7d-8b5a-86f1349863c3 | Key | N/A | http://controller:9311/v1/secrets/4c3e2e5b-3585-44ae-901a-25dee6ede5a7 | 2020-08-16T09:08:06+00:00 | ACTIVE | None | None | +-----------------------------------------------------------------------+------+----------------+------------------------------------------------------------------------+---------------------------+--------+------------+---------------+ $ controller ~(keystone)\u0026gt; openstack secret order get http://controller:9311/v1/orders/ffe9a05e-db5e-4B7D-8B5A-86f1349863c3 +----------------+------------------------------------------------------------------------+ | Field | Value | +----------------+------------------------------------------------------------------------+ | Order href | http://controller:9311/v1/orders/ffe9a05e-db5e-4b7d-8b5a-86f1349863c3 | | Type | Key | | Container href | N/A | | Secret href | http://controller:9311/v1/secrets/4c3e2e5b-3585-44ae-901a-25dee6ede5a7 | | Created | 2020-08-16T09:08:06+00:00 | | Status | ACTIVE | | Error code | None | | Error message | None | +----------------+------------------------------------------------------------------------+ # get 뒤에는 키 생성시 생성되는 값을 입력해주셔야 됩니다 ! $ controller ~(keystone)\u0026gt; openstack secret get http://controller:9311/v1/secrets/4c3e2e5b-3585-44ae-901a-25dee6ede5a7 +---------------+------------------------------------------------------------------------+ | Field | Value | +---------------+------------------------------------------------------------------------+ | Secret href | http://controller:9311/v1/secrets/4c3e2e5b-3585-44ae-901a-25dee6ede5a7 | | Name | secret02 | | Created | 2020-08-16T09:08:06+00:00 | | Status | ACTIVE | | Content types | {\u0026#39;default\u0026#39;: \u0026#39;application/octet-stream\u0026#39;} | | Algorithm | aes | | Bit length | 256 | | Secret type | symmetric | | Mode | cbc | | Expiration | None | +---------------+------------------------------------------------------------------------+ # get 뒤에는 키 생성시 생성되는 값을 입력해주셔야 됩니다 ! #\r"},{"id":85,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-15/","title":"OpenStack Ussuri : Rally","section":"OpenStack Training","content":"\rOpenStack Ussuri : Rally\r#\r#\r----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | | Heat API | | metadata agent | ----------------------- | API-CFN | | Neutron Server | | Heat Engine | | Gnocchi Trove API | | Designate Services | | Barbican API | ----------------------- | Rally | ----------------------- #\rOpenStack Ussuri : Rally\r#\r#\rRally는 오픈스택 소스를 GUI 환경으로 보여주는 서비스입니다. Rally의 자세한 설명은 Rally를 참조해주세요. #\r#\rRally 유저의 DB를 생성합니다.\r#\r#\r$ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database rally; $ MariaDB\u0026gt; grant all privileges on Rally.* to rally@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on Rally.* to rally@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit; #\r#\rRally 설치\r#\r$ controller ~(keystone)\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-rally openstack-rally-plugins python3-fixtures # Rally 서비스 및 관련 모듈을 설치합니다. $ controller ~(keystone)\u0026gt; vi /etc/rally/rally.conf [DEFAULT] log_file = rally.log log_dir = /var/log/rally connection = mysql+pymysql://rally:qwer1234@controller/rally $ controller ~(keystone)\u0026gt; mkdir /var/log/rally $ controller ~(keystone)\u0026gt; rally db create # log 파일을 저장할 폴더를 만들고 db를 임포트 시킵니다. $ controller ~(keystone)\u0026gt; rally deployment create --fromenv --name=my_cloud +--------------------------------------+----------------------------+----------+------------------+--------+ | uuid | created_at | name | status | active | +--------------------------------------+----------------------------+----------+------------------+--------+ | 35f9c79c-a47e-49d3-af88-b06b6020b92a | 2020-08-16T09:16:23.793238 | my_cloud | deploy-\u0026gt;finished | | +--------------------------------------+----------------------------+----------+------------------+--------+ $ controller ~(keystone)\u0026gt; source ~/.rally/openrc $ controller ~(keystone)\u0026gt; rally deployment show my_cloud +---------------------------+----------+----------+-------------+-------------+---------------+ | auth_url | username | password | tenant_name | region_name | endpoint_type | +---------------------------+----------+----------+-------------+-------------+---------------+ | http://controller:5000/v3 | admin | *** | admin | | None | +---------------------------+----------+----------+-------------+-------------+---------------+ $ controller ~(keystone)\u0026gt; rally deployment check -------------------------------------------------------------------------------- Platform openstack: -------------------------------------------------------------------------------- Available services: +-------------+----------------+-----------+ | Service | Service Type | Status | +-------------+----------------+-----------+ | __unknown__ | placement | Available | | barbican | key-manager | Available | | cinder | volumev3 | Available | | cloud | cloudformation | Available | | glance | image | Available | | gnocchi | metric | Available | | heat | orchestration | Available | | keystone | identity | Available | | neutron | network | Available | | nova | compute | Available | | swift | object-store | Available | | trove | database | Available | +-------------+----------------+-----------+ $ controller ~(keystone)\u0026gt; vi ~/boot-and-delete.json { \u0026#34;NovaServers.boot_and_delete_server\u0026#34;: [ { \u0026#34;args\u0026#34;: { \u0026#34;flavor\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;m1.small\u0026#34; }, \u0026#34;image\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Ubuntu1804\u0026#34; }, \u0026#34;force_delete\u0026#34;: false }, \u0026#34;runner\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;constant\u0026#34;, \u0026#34;times\u0026#34;: 10, \u0026#34;concurrency\u0026#34;: 2 }, \u0026#34;context\u0026#34;: {} } ] } $ controller ~(keystone)\u0026gt; rally task start ~/boot-and-delete.json -------------------------------------------------------------------------------- Preparing input task -------------------------------------------------------------------------------- Task is: { \u0026#34;NovaServers.boot_and_delete_server\u0026#34;: [ { \u0026#34;args\u0026#34;: { \u0026#34;flavor\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;m1.small\u0026#34; }, \u0026#34;image\u0026#34;: { \u0026#34;name\u0026#34;: \u0026#34;Ubuntu1804\u0026#34; }, \u0026#34;force_delete\u0026#34;: false }, \u0026#34;runner\u0026#34;: { \u0026#34;type\u0026#34;: \u0026#34;constant\u0026#34;, \u0026#34;times\u0026#34;: 10, \u0026#34;concurrency\u0026#34;: 2 }, \u0026#34;context\u0026#34;: {} } ] } Task syntax is correct :) Running Rally version 3.0.0 -------------------------------------------------------------------------------- Task 887a0d20-37ad-4351-aeca-00f646634552: started -------------------------------------------------------------------------------- .... .... -------------------------------------------------------------------------------- Task 887a0d20-37ad-4351-aeca-00f646634552 has 0 error(s) -------------------------------------------------------------------------------- +-----------------------------------------------------------------------------------------------------------------------+ | Response Times (sec) | +--------------------+-----------+--------------+--------------+--------------+-----------+-----------+---------+-------+ | Action | Min (sec) | Median (sec) | 90%ile (sec) | 95%ile (sec) | Max (sec) | Avg (sec) | Success | Count | +--------------------+-----------+--------------+--------------+--------------+-----------+-----------+---------+-------+ | nova.boot_server | 4.466 | 5.409 | 34.472 | 40.002 | 45.533 | 14.471 | 100.0% | 10 | | nova.delete_server | 2.412 | 2.736 | 13.708 | 15.417 | 17.127 | 6.352 | 100.0% | 10 | | total | 6.922 | 12.091 | 40.809 | 44.416 | 48.023 | 20.823 | 100.0% | 10 | | -\u0026gt; duration | 5.922 | 11.091 | 39.809 | 43.416 | 47.023 | 19.823 | 100.0% | 10 | | -\u0026gt; idle_duration | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 1.0 | 100.0% | 10 | +--------------------+-----------+--------------+--------------+--------------+-----------+-----------+---------+-------+ Load duration: 108.251619 Full duration: 134.177109 HINTS: * To plot HTML graphics with this data, run: rally task report 887a0d20-37ad-4351-aeca-00f646634552 --out output.html * To generate a JUnit report, run: rally task export 887a0d20-37ad-4351-aeca-00f646634552 --type junit-xml --to output.xml * To get raw JSON output of task results, run: rally task report 887a0d20-37ad-4351-aeca-00f646634552 --json --out output.json #\r"},{"id":86,"href":"/cloud/docs/OpenStack/OpenStackTraining/OpenStack-Ussuri-16/","title":"OpenStack Ussuri : Manila","section":"OpenStack Training","content":"\rOpenStack Ussuri : Manila\r#\r#\r----------------------- ----------------------- ----------------------- | [ Controller Node ] | | [ Compute Node ] | | [ Network Node ] | | | | Libvirt | | Open vSwitch | | MariaDB RabbitMQ | | Nova compute | | L2 Agent | | Memcached Keystone | | Open vSwitch | | L3 Agent | | httpd Cinder API | | L2 Agent | | metadata agent | | Nova-API Compute | | Cinder-LVM | | Swift-proxy | | L2 agent L3 agent | | NFS | | Heat API | | metadata agent | | Manila Share | | API-CFN | | Neutron Server | ----------------------- | Heat Engine | | Gnocchi Trove API | | Designate Services | | Barbican API | ----------------------- | Rally Manila API | ----------------------- #\rOpenStack Ussuri : Manila\r#\r#\rManila는 OpenStack에서 맡는 서비스입니다. Manila의 대한 보다 자세한 설명은 Manila를 참조해주세요. #\r#\rManila service 및 User 생성\r#\r$ controller ~(keystone)\u0026gt; openstack user create --domain default --project service --password qwer1234 manila +---------------------+----------------------------------+ | Field | Value | +---------------------+----------------------------------+ | default_project_id | b470c69e28db47cdbfc81e06cc67f627 | | domain_id | default | | enabled | True | | id | 4ea7c62d89194d9883e6773a977133b6 | | name | manila | | options | {} | | password_expires_at | None | +---------------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack role add --project service --user manila admin $ controller ~(keystone)\u0026gt; openstack service create --name manila --description \u0026#34;OpenStack Shared Filesystem\u0026#34; share +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Shared Filesystem | | enabled | True | | id | 1129696ac3f5449293b638e0daec3bde | | name | manila | | type | share | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack service create --name manilav2 --description \u0026#34;OpenStack Shared Filesystem V2\u0026#34; sharev2 +-------------+----------------------------------+ | Field | Value | +-------------+----------------------------------+ | description | OpenStack Shared Filesystem V2 | | enabled | True | | id | 1d94787a2d34489dbe880faa5e165e5e | | name | manilav2 | | type | sharev2 | +-------------+----------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne share public http://controller:8786/v1/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | d3d6590a342047eab8abca304701d90d | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 1129696ac3f5449293b638e0daec3bde | | service_name | manila | | service_type | share | | url | http://controller:8786/v1/%(tenant_id)s | +--------------+-----------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne share internal http://controller:8786/v1/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | 0a6516d199d346febe62800b87a10eb9 | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 1129696ac3f5449293b638e0daec3bde | | service_name | manila | | service_type | share | | url | http://controller:8786/v1/%(tenant_id)s | +--------------+-----------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne share admin http://controller:8786/v1/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | 6153d88f7eab40caa669c3130f03226a | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 1129696ac3f5449293b638e0daec3bde | | service_name | manila | | service_type | share | | url | http://controller:8786/v1/%(tenant_id)s | +--------------+-----------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne sharev2 public http://controller:8786/v2/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | 22e9d4e2b62a4203ae182041c9c10049 | | interface | public | | region | RegionOne | | region_id | RegionOne | | service_id | 1d94787a2d34489dbe880faa5e165e5e | | service_name | manilav2 | | service_type | sharev2 | | url | http://controller:8786/v2/%(tenant_id)s | +--------------+-----------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne sharev2 internal http://controller:8786/v2/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | eb4e0b33fae7432d87078a0ba2c2e8de | | interface | internal | | region | RegionOne | | region_id | RegionOne | | service_id | 1d94787a2d34489dbe880faa5e165e5e | | service_name | manilav2 | | service_type | sharev2 | | url | http://controller:8786/v2/%(tenant_id)s | +--------------+-----------------------------------------+ $ controller ~(keystone)\u0026gt; openstack endpoint create --region RegionOne sharev2 admin http://controller:8786/v2/%\\(tenant_id\\)s +--------------+-----------------------------------------+ | Field | Value | +--------------+-----------------------------------------+ | enabled | True | | id | 212c9ddfbc554dfb83f80e3a252db235 | | interface | admin | | region | RegionOne | | region_id | RegionOne | | service_id | 1d94787a2d34489dbe880faa5e165e5e | | service_name | manilav2 | | service_type | sharev2 | | url | http://controller:8786/v2/%(tenant_id)s | +--------------+-----------------------------------------+ #\rManila 유저의 DB를 생성합니다.\r#\r#\r$ controller\u0026gt; mysql -u root -p $ MariaDB\u0026gt; create database manila; $ MariaDB\u0026gt; grant all privileges on manila.* to manila@\u0026#39;localhost\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; grant all privileges on manila.* to manila@\u0026#39;%\u0026#39; identified by \u0026#39;qwer1234\u0026#39;; $ MariaDB\u0026gt; flush privileges; $ MariaDB\u0026gt; exit; #\r#\rcontroller node manila api 설치\r#\r#\r$ controller\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-manila python3-manilaclient # manila 및 관련 모듈을 설치합니다. $ controller\u0026gt; vi /etc/manila/manila.conf [DEFAULT] my_ip = controller api_paste_config = /etc/manila/api-paste.ini rootwrap_config = /etc/manila/rootwrap.conf state_path = /var/lib/manila auth_strategy = keystone default_share_type = default_share_type share_name_template = share-%s transport_url = rabbit://openstack:qwer1234@controller [database] connection = mysql+pymysql://manila:qwer1234@controller/manila [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = manila password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ controller\u0026gt; su -s /bin/bash manila -c \u0026#34;manila-manage db sync\u0026#34; $ controller\u0026gt; systemctl enable --now openstack-manila-api openstack-manila-scheduler $ controller\u0026gt; firewall-cmd --add-port=8786/tcp --permanent $ controller\u0026gt; firewall-cmd --reload # 방화벽을 설정합니다. $ controller ~(keystone)\u0026gt; manila service-list +----+------------------+------------+------+---------+-------+----------------------------+ | Id | Binary | Host | Zone | Status | State | Updated_at | +----+------------------+------------+------+---------+-------+----------------------------+ | 1 | manila-scheduler | controller | nova | enabled | up | 2020-08-21T01:27:53.000000 | +----+------------------+------------+------+---------+-------+----------------------------+ # 확인 #\r#\rcompute node manila share 설차\r#\r#\r$ compute\u0026gt; dnf --enablerepo=centos-openstack-ussuri,powertools,epel -y install openstack-manila-share python3-manilaclient mariadb-devel python3-devel gcc make $ compute\u0026gt; pip3 install mysqlclient $ compute\u0026gt; vi /etc/manila/manila.conf [DEFAULT] my_ip = compute api_paste_config = /etc/manila/api-paste.ini rootwrap_config = /etc/manila/rootwrap.conf state_path = /var/lib/manila auth_strategy = keystone default_share_type = default_share_type share_name_template = share-%s transport_url = rabbit://openstack:qwer1234@controller [database] connection = mysql+pymysql://manila:qwer1234@controller/manila [keystone_authtoken] www_authenticate_uri = http://controller:5000 auth_url = http://controller:5000 memcached_servers = controller:11211 auth_type = password project_domain_name = default user_domain_name = default project_name = service username = manila password = qwer1234 [oslo_concurrency] lock_path = $state_path/tmp $ compute\u0026gt; mkdir /var/lib/manila $ compute\u0026gt; chown manila. /var/lib/manila $ compute\u0026gt; firewall-cmd --add-service=nfs --permanent $ compute\u0026gt; firewall-cmd --reload # 새로운 Disk install $ compute\u0026gt; dnf -y install nfs-utils nfs4-acl-tools $ compute\u0026gt; fdisk /dev/sdc ... ... $ compute\u0026gt; pvcreate /dev/sdc1 $ compute\u0026gt; vgcreate manila-volumes /dev/sdc1 $ compute\u0026gt; vi /etc/manila/manila.conf [DEFAULT] enabled_share_backends = lvm [lvm] share_backend_name = LVM share_driver = manila.share.drivers.lvm.LVMShareDriver driver_handles_share_servers = False lvm_share_volume_group = manila-volumes lvm_share_export_ips = compute $ compute\u0026gt; systemctl enable --now openstack-manila-share nfs-server #\r#\r확인\r#\r#\r$ controller ~(keystone)\u0026gt; manila type-create default_share_type False +----------------------+--------------------------------------+ | Property | Value | +----------------------+--------------------------------------+ | ID | 9f6323f6-7443-4a83-ba70-7c10f78366c9 | | Name | default_share_type | | Visibility | public | | is_default | YES | | required_extra_specs | driver_handles_share_servers : False | | optional_extra_specs | | | Description | None | +----------------------+--------------------------------------+ $ controller ~(keystone)\u0026gt; manila type-list +--------------------------------------+--------------------+------------+------------+--------------------------------------+----------------------+-------------+ | ID | Name | visibility | is_default | required_extra_specs | optional_extra_specs | Description | +--------------------------------------+--------------------+------------+------------+--------------------------------------+----------------------+-------------+ | 9f6323f6-7443-4a83-ba70-7c10f78366c9 | default_share_type | public | YES | driver_handles_share_servers : False | | None | +--------------------------------------+--------------------+------------+------------+--------------------------------------+----------------------+-------------+ $ controller ~(keystone)\u0026gt; manila create NFS 10 --name share01 +---------------------------------------+--------------------------------------+ | Property | Value | +---------------------------------------+--------------------------------------+ | id | 72ab96c5-80f5-401a-b414-ab76a240acf1 | | size | 10 | | availability_zone | None | | created_at | 2020-08-21T01:52:16.000000 | | status | creating | | name | share01 | | description | None | | project_id | edd7025c02574d3aa2d3ab6e56208320 | | snapshot_id | None | | share_network_id | None | | share_proto | NFS | | metadata | {} | | share_type | 9f6323f6-7443-4a83-ba70-7c10f78366c9 | | is_public | False | | snapshot_support | False | | task_state | None | | share_type_name | default_share_type | | access_rules_status | active | | replication_type | None | | has_replicas | False | | user_id | 4ebf85318da84b5cb1257152f9fc35ba | | create_share_from_snapshot_support | False | | revert_to_snapshot_support | False | | share_group_id | None | | source_share_group_snapshot_member_id | None | | mount_snapshot_support | False | | progress | None | | share_server_id | None | | host | | +---------------------------------------+--------------------------------------+ $ controller ~(keystone)\u0026gt; manila list $ controller ~(keystone)\u0026gt; manila access-allow share01 ip 1.1.1.0/24 --access-level rw $ controller ~(keystone)\u0026gt; manila access-list share01 $ controller ~(keystone)\u0026gt; openstack server start CentOS_8 $ controller ~(keystone)\u0026gt; manila show share01 | grep path | cut -d\u0026#39;|\u0026#39; -f3 $ controller ~(keystone)\u0026gt; ssh centos@10.0.0.247 $ controller ~(keystone)\u0026gt; sudo mount -t nfs \\ 10.0.0.50:/var/lib/manila/mnt/share-3544d5a3-7157-4c10-aaa3-edd4b6fd2512 /mnt $ controller ~(keystone)\u0026gt; df -hT $ controller ~(keystone)\u0026gt; #\r"},{"id":87,"href":"/cloud/docs/OpenStack/OpenStackTraining/Devstack/","title":"DevStack","section":"OpenStack Training","content":"\r#\rDevStack Stein 설치\r#\r#\rDevStack\r#\r#\rDevbian 계열 ( ex : Ubuntu )의 OpenStack 자동화 설치 툴 #\rDevStack 설치\r#\r#\rUpdate Ubuntu System $ sudo apt -y update $ sudo apt -y upgrade $ sudo apt -y dist-upgrade # Ubuntu의 시스템 및 패키지를 업데이트 합니다. $ sudo init 6 # 시스템을 재시작합니다. #\r#\rAdd Stack User $ sudo useradd -s /bin/bash -d /opt/stack -m stack # devstack 설치를 위해 stack 유저를 생성합니다. $ echo \u0026#34;stack ALL=(ALL) NOPASSWD: ALL\u0026#34; | sudo tee /etc/sudoers.d/stack # 암호 없이 접근할 권한을 부여합니다. #\r#\rDownload DevStack loacl.conf 파일의 추가적인 설정은 DevStack을 참조해주세요. $ su - stack $ sudo apt -y install git $ git clone https://git.openstack.org/openstack-dev/devstack # stack user로 진입하여, devstack을 다운받습니다. $ vi local.conf [[local|localrc]] ADMIN_PASSWORD=[ PW ] DATABASE_PASSWORD=$ADMIN_PASSWORD RABBIT_PASSWORD=$ADMIN_PASSWORD SERVICE_PASSWORD=$ADMIN_PASSWORD HOST_IP=[ 현재 호스트의 IP ] # 설치를 위한 설정 파일을 생성합니다. # PW, IP에는 사용자가 원하는 PW, 설치 호스트 네트워크의 IP를 기입합니다. #\r#\rStart OpenStack Deployment On Ubuntu 18.04 with DevStack $ cd devstack ./stack.sh #\r#\rAccess OpenStack Dashboard http://[ HOST IP ]/dashboard로 접속합니다. User Name = admin Password = local.conf의 PW #\r"},{"id":88,"href":"/cloud/docs/AWS/AWSTraining/OwnCloud/","title":"AWS OwnCloud","section":"AWS Training","content":"\rNas-Owncloud 실습\r#\r#\rOwncloud를 활용하여 Ec2 Nas 만들기\r#\r#\r#\r#\r#\rEC2 생성\n\u0026gt; OS : Ubuntu 18.04\r\u0026gt; Flavor : t2.micro\r\u0026gt; Storage : 100G ( 원하는 만큼, 차후에 EFS 등으로도 가능합니다. )\r\u0026gt; VPC : Custop\r\u0026gt; 보안그룹 : Custop 인스턴스를 생성합니다. #\r#\r먼저, Owncloud를 사용하기 위해서는 LAMP를 설치해야합니다. $ sudo apt install -y tasksel $ sudo tasksel install -y lamp-server # LAMP 간편 설치 $ sudo apt install -y apache2 # apache2 설치 $ sudo apt install -y mysql-server # mysql 설치 $ sudo apt install -y php7.2 $ sudo apt install -y libapache2-mod-php7.2 $ sudo apt install -y php-mysql # php 및 연동모듈 설치 $ apache2 -v $ mysql --version $ php -v # 확인 LAMP란? #\r#\r$ wget -nv https://download.owncloud.org/download/repositories/10.0/Ubuntu_18.04/Release.key -O Release.key $ apt-key add - \u0026lt; Release.key $ echo \u0026#39;deb http://download.owncloud.org/download/repositories/10.0/Ubuntu_18.04/ /\u0026#39; | sudo tee /etc/apt/sources.list.d/owncloud.list # Ubuntu의 기본패키지에는 Owncloud가 지정되어 있지 않음 Owncloud 저장소 지정 #\r#\r$ sudo apt -y update $ sudo apt -y upgrade $ sudo apt -y install php-bz2 php-curl php-gd php-imagick php-intl php-mbstring php-xml php-zip owncloud-files $ ls -l /var/www/owncloud/ # 확인 Owncloud 설치 #\r#\r$ mysql -u root -p $ mysql\u0026gt; CREATE DATABASE [ DB 이름 ]; $ mysql\u0026gt; GRANT ALL ON [ DB이름 ].* to \u0026#39;[ 계정 ]\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;[ PW ]\u0026#39;; $ mysql\u0026gt; FLUSH PRIVILEGES; $ mysql\u0026gt; exit owncloud DB 및 원격접속 계정생성 #\r#\r$ sudo vi /etc/apache2/apache2.conf \u0026lt;Directory /var/www/owncloud\u0026gt; Options FollowSymlinks AllowOverride All Require all granted \u0026lt;/Directory\u0026gt; apache2.conf에서 owncloud에 대한 접근 권한을 설정합니다. #\r#\r$ sudo vi /etc/apache2/sites-available/000-default.conf DocumentRoot /var/www/html \u0026gt; DocumentRoot /var/www/owncloud apache2의 기본 경로를 수정합니다. #\r#\r$ sudo mkdir /data $ sudo chmod 0770 /data $ sudo chown www-data:www-data /data # owncloud 사용을 위한 권한 및 소유자 변경 저장의 사용할 폴더를 미리 만들어 둡니다. #\r#\r$ sudo systemctl restart apache2 $ sudo service apache2 restart apache2를 재시작합니다. #\r#\rhttp://IP를 통해 접속합니다. 알맞은 값을 기입 후 설치를 완료합니다. #\r#\r설치가 완료되면, 루트계정을 통해 접속합니다. #\r#\r설치가 완료되었습니다. #\r#\rElastci IP 를 주어 고정시킬 수 있고, 방화벽, 보안그룹의 설정을 통해 특정 IP만을 접속하게 할 수 있습니다. 다음은 owncloud를 커스터마이징 해보도록 하겠습니다. #\r#\rOwncloud 설정\r#\r#\r도메인 등록\n$ vi /var/www/owncloud/config/config.php array ( 0 =\u0026gt; \u0026#39;IP\u0026#39; 1 =\u0026gt; \u0026#39;Domain\u0026#39; ) 도메인 접근 허용 설정 "},{"id":89,"href":"/cloud/docs/OpenStack/OpenStackTraining/Packstack/","title":"Packstack","section":"OpenStack Training","content":"\rPackstack Stein 설치\r#\r#\rPackstack\r#\r#\rRedhat 계열 ( ex : CentOS )의 OpenStack 자동화 설치 툴 #\r#\rPackstack stain 설치\r#\r#\r기본적으로 PackStack은 올인원 or 다중노드로 구성할 수 있으며, 여기서는 올인원으로 설치를 진행하며, 다중노드에 대한 설정은 추가하도록 하겠습니다. #\r설치사양\r#\r#\rOS CPU RAM DISK CenOS7 4/ 2 10240 100G #\r만약 다중 노드에 경우 소스를 분산시키고 각 노드에 설정을 추가합니다. hosts, hostname 등록 및 설정 다중 노드의 경우 controller node에서 다른 노드의 ssh 접속을 위한 키를 등록시킵니다. $ controller\u0026gt; $ ssh-keygen $ controller\u0026gt; $ ssh-copy-id network $ controller\u0026gt; $ ssh-copy-id compute $ controller\u0026gt; $ ssh-copy-id ... 다른 노드 #\r#\r설치 순서\r#\r#\rfirewalld 설정 setenforce을 진행합니다. $ systemctl stop firewalld $ systemctl disable firewalld $ systemctl stop NetworkManagaer $ systemctl disable NetworkManagaer # 방화벽 및 네트워크 매니저 설정을 진행합니다. $ setenforce 0 $ sed -i \u0026#39;s/=enforcing/=disabled/g\u0026#39; /etc/sysconfig/selinux # setenforce 설정을 진행합니다. #\r#\rOpenStack stain release를 등록합니다. $ yum -y update # 기본 패키지를 업데이트 합니다. $ yum install -y centos-release-openstack-stein $ yum -y update # stein 레포지터리를 등록 후, 다시 업데이트를 진행합니다. #\r#\r올인원의 경우 $ yum install -y openstack-packstack $ packstack --allinone # packstack을 통해 OpenStack 설치를 진행합니다. #\r#\r다중노드의 경우 $ packstack --gen-answer-file=/root/stein-answer.txt # Packstack 설정 파일을 설치합니다. $ vi /root/stein.answer.txt CONFIG_CONTROLLER_HOST=contoller CONFIG_COMPUTE_HOSTS=compute1,compute2,compute3.... CONFIG_NETWORK_HOSTS=network1,network2.... CONFIG_PROVISION_DEMO=n CONFIG_NTP_SERVERS=0.centos.pool.ntp.org iburst, 1.centos.pool.ntp.org iburst, 2.centos.pool.ntp.org iburst, 3.centos.pool.ntp.org iburst CONFIG_CINDER_VOLUMES_SIZE=100G # 기본적인 설정을 진행합니다. # 설치 시 각 OpenStack의 서비스들을 원하는 Node의 설치할 수 있습니다. $ packstack --answer-file=/root/stein-answer.txt # packstack 설치를 진행합니다. #\r#\r접속 IP, PW 확인 $ /var/tmp/packstack/....../openstack-setup.log | cat USERNAME= $ /var/tmp/packstack/....../openstack-setup.log | cat ADMIN_PW= # 사용자 이름 및 암호 출력 #\r"},{"id":90,"href":"/cloud/docs/AWS/AWSTraining/CloudFormation/","title":"AWS CloudFormation","section":"AWS Training","content":"\rAWS CloudFormation\r#\r#\r이번 장에서는 CloudFormation의 탬플릿을 사용하여 서버를 자동 구축되도록 생성해보도록 하겠습니다. CloudFormation의 대한 개념은 CloudFormation을 참고하세요. #\rCloudFormation을 활용한 자동구축\r#\r#\r#\rCloudFormation 아키텍처 예시\r#\r#\r#\r먼저, AWS에서 CloudFormation 검색 후 클릭합니다. #\r#\r스택 생성을 클릭합니다. #\r#\r#\r스택 생성을 위해 아래의 값을 cloudformation_instance.template 을 생성하여 업로드 합니다. 보통 Templates 파일은 S3에 저장된 것을 사용하지만, 여기서는 로컬환경에서 가져와 사용해보도록 하겠습니다. CloudFormation Templates 참조 #\r{ \u0026#34;AWSTemplateFormatVersion\u0026#34; : \u0026#34;2010-09-09\u0026#34;, \u0026#34;Resources\u0026#34;: { \u0026#34;Instance\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;AWS::EC2::Instance\u0026#34;, \u0026#34;Properties\u0026#34;:{ \u0026#34;Monitoring\u0026#34;: \u0026#34;false\u0026#34;, \u0026#34;ImageId\u0026#34;: \u0026#34;[ AMI ID ]\u0026#34;, \u0026#34;KeyName\u0026#34;: \u0026#34;[ Key ]\u0026#34;, \u0026#34;InstanceType\u0026#34;: \u0026#34;t2.micro\u0026#34;, \u0026#34;NetworkInterfaces\u0026#34;: [ { \u0026#34;DeviceIndex\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;AssociatePublicIpAddress\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;DeleteOnTermination\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;[ 서브넷 ID ]\u0026#34;, \u0026#34;GroupSet\u0026#34;: [\u0026#34;[ 보안 그룹 ]\u0026#34;] } ] } } }, \u0026#34;Description\u0026#34;: \u0026#34;SampleInstance\u0026#34; } #\rCloudFormation 기본형식 { \u0026#34;AWSTemplateFormatVersion\u0026#34; : \u0026#34;version date\u0026#34;, \u0026#34;Description\u0026#34; : \u0026#34;JSON string\u0026#34;, \u0026#34;Parameters\u0026#34;: { set of parameters }, \u0026#34;Mappings\u0026#34;: { set of mappings }, \u0026#34;Conditions\u0026#34;: { set of conditions }, \u0026#34;Resources\u0026#34;: { set of resources }, \u0026#34;Outputs\u0026#34;: { set of outpus } } 옵션 설명 AWSTemplateFormatVersion 템플릿의 버전 Description 템플릿의 대한 설명 ( 시스템이 읽지 않음 ) Parameters 스택 생성 때에 전달할 값, 탬플릿 내부에서 Ref 함수로 참조 Mappings 해시 테이블처럼 키에 따라 값을 지정할 수 있으며, 리전마다 사용할 AMI를 다르게 하는 경우 등의 사용 Conditions 조건을 판단, 조건에 일치하는 경우 실행할 리소스를 지정할 수 있음 Resources 생성할 자원을 정의, EC2 인스턴스, 보안 그룹 등의 생성할 자원 유형을 지정하고 설정 ( 아직 모든 서비스를 이용할 수는 없음 ) Outputs 탬플릿으로 생성한 결과를 출력 #\r#\r업로드가 완료되면, 스택의 이름을 지정합니다. #\r#\r스택 옵션 구성에서는 IAM 역할, 그 외에도 스택의 정책과 옵션들을 구성할 수 있습니다. 여기에서는 기본 값으로 진행하겠습니다. #\r#\r스택의 생성이 완료되면, 그림과 같이 상태에서 로그를 확인하실 수 있습니다. 생성이 완료되면 인스턴스가 생성된 것을 확인 할 수 있습니다. #\r#\rCloudFormation 업데이트\r#\r#\r이번에는 생성된 Stack을 업데이트 하는 방법에 대해 알아보도록 하겠습니다. #\r먼저, 위에서 생성한 Stack \u0026gt; 업데이트를 클릭합니다. #\r#\r스택 업데이트를 클릭하면 현재 템플릿을 사용하면서 스택의 옵션만 바꿀건지, 혹은 탬플릿 자체를 변경할 것인지에 대한 옵션이 나옵니다. 저희는 탬플릿 자체에 대한 옵션을 바꾸기 위해 기존 templates 파일을 아래와 같이 수정하여 업데이트 하도록 하겠습니다. Designer 편집기에서 추가하셔도 상관은 없습니다. { \u0026#34;AWSTemplateFormatVersion\u0026#34; : \u0026#34;2010-09-09\u0026#34;, \u0026#34;Resources\u0026#34;: { \u0026#34;Instance\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;AWS::EC2::Instance\u0026#34;, \u0026#34;Properties\u0026#34;:{ \u0026#34;Monitoring\u0026#34;: \u0026#34;false\u0026#34;, \u0026#34;ImageId\u0026#34;: \u0026#34;ami-01af223aa7f274198\u0026#34;, \u0026#34;KeyName\u0026#34;: \u0026#34;Study\u0026#34;, \u0026#34;InstanceType\u0026#34;: \u0026#34;t2.micro\u0026#34;, \u0026#34;NetworkInterfaces\u0026#34;: [ { \u0026#34;DeviceIndex\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;AssociatePublicIpAddress\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;DeleteOnTermination\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;SubnetId\u0026#34;: \u0026#34;subnet-463b3d0a\u0026#34;, \u0026#34;GroupSet\u0026#34;: [\u0026#34;sg-f553af91\u0026#34;] } ], \u0026#34;UserData\u0026#34;: { \u0026#34;Fn::Base64\u0026#34; : { \u0026#34;Fn::Join\u0026#34; : [\u0026#34;\u0026#34;, [ \u0026#34;#!/bin/bash\\n\u0026#34;, \u0026#34;yum update -y\\n\u0026#34;, \u0026#34;yum install -y httpd\\n\u0026#34;, \u0026#34;service httpd start\\n\u0026#34;, \u0026#34;chkconfig httpd on\\n\u0026#34; ]] } } } } }, \u0026#34;Description\u0026#34;: \u0026#34;SampleInstance\u0026#34; } #\r#\r탬플릿 업로드 후, 위와 동일하게 생성하면 보기와 같이 업데이트를 확인하실 수 있습니다. #\r#\r생성된 인스턴스로 접속하면, Apache가 설치되어 있는 것을 확인하실 수 있습니다. #\r#\rCloudForamtion 파라미터 설정\r#\r#\r위에서는 고정 값으로 스택을 생성했지만, 만약 고정 값으로 생성을 진행할 경우, 에러가 발생할 수 있으며, 여러 탬플릿을 생성해야하는 번거로움이 존재합니다. 이번에는 파라미터 값을 설정하여 CloudFormation을 사용하는 방법에 대해 알아보도록 하겠습니다. #\r먼저 위에서 생성한 템플릿을 Parameter 값을 사용하도록 수정하여 보겠습니다. { \u0026#34;AWSTemplateFormatVersion\u0026#34; : \u0026#34;2010-09-09\u0026#34;, \u0026#34;Parameters\u0026#34;: { \u0026#34;ImageId\u0026#34; : { \u0026#34;Type\u0026#34;: \u0026#34;String\u0026#34;, \u0026#34;Default\u0026#34;: \u0026#34;ami-01af223aa7f274198\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;IamgeId\u0026#34; }, \u0026#34;KeyName\u0026#34; : { \u0026#34;Type\u0026#34;: \u0026#34;String\u0026#34;, \u0026#34;Default\u0026#34;: \u0026#34;Study\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;Keypair name\u0026#34; }, \u0026#34;InstanceType\u0026#34; : { \u0026#34;Type\u0026#34;: \u0026#34;String\u0026#34;, \u0026#34;Default\u0026#34;: \u0026#34;t2.micro\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;InstanceType\u0026#34; }, \u0026#34;AssociatePublicIpAddress\u0026#34; : { \u0026#34;Type\u0026#34;: \u0026#34;String\u0026#34;, \u0026#34;Default\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;PublicIP\u0026#34;, \u0026#34;AllowedValues\u0026#34;: [\u0026#34;true\u0026#34;, \u0026#34;false\u0026#34;] }, \u0026#34;DeleteOnTermination\u0026#34; : { \u0026#34;Type\u0026#34;: \u0026#34;String\u0026#34;, \u0026#34;Default\u0026#34;: \u0026#34;true\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;DeleteOnTermination\u0026#34;, \u0026#34;AllowedValues\u0026#34;: [\u0026#34;true\u0026#34;, \u0026#34;false\u0026#34;] }, \u0026#34;SubnetId\u0026#34; : { \u0026#34;Type\u0026#34;: \u0026#34;String\u0026#34;, \u0026#34;Default\u0026#34;: \u0026#34;subnet-463b3d0a\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;SubnetId\u0026#34; }, \u0026#34;GroupSet\u0026#34; : { \u0026#34;Type\u0026#34;: \u0026#34;String\u0026#34;, \u0026#34;Default\u0026#34;: \u0026#34;sg-f553af91\u0026#34;, \u0026#34;Description\u0026#34;: \u0026#34;GroupSet\u0026#34; } }, \u0026#34;Resources\u0026#34;: { \u0026#34;Instance\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;AWS::EC2::Instance\u0026#34;, \u0026#34;Properties\u0026#34;:{ \u0026#34;Monitoring\u0026#34;: \u0026#34;false\u0026#34;, \u0026#34;ImageId\u0026#34;: { \u0026#34;Ref\u0026#34; : \u0026#34;ImageId\u0026#34; }, \u0026#34;KeyName\u0026#34;: { \u0026#34;Ref\u0026#34; : \u0026#34;KeyName\u0026#34; }, \u0026#34;InstanceType\u0026#34;: { \u0026#34;Ref\u0026#34; : \u0026#34;InstanceType\u0026#34; }, \u0026#34;NetworkInterfaces\u0026#34;: [ { \u0026#34;DeviceIndex\u0026#34;: \u0026#34;0\u0026#34;, \u0026#34;AssociatePublicIpAddress\u0026#34;: { \u0026#34;Ref\u0026#34; : \u0026#34;AssociatePublicIpAddress\u0026#34; }, \u0026#34;DeleteOnTermination\u0026#34;: { \u0026#34;Ref\u0026#34; : \u0026#34;DeleteOnTermination\u0026#34; }, \u0026#34;SubnetId\u0026#34;: { \u0026#34;Ref\u0026#34; : \u0026#34;SubnetId\u0026#34; }, \u0026#34;GroupSet\u0026#34;: [{ \u0026#34;Ref\u0026#34; : \u0026#34;GroupSet\u0026#34; }], } ], \u0026#34;UserData\u0026#34;: { \u0026#34;Fn::Base64\u0026#34; : { \u0026#34;Fn::Join\u0026#34; : [\u0026#34;\u0026#34;, [ \u0026#34;#!/bin/bash\\n\u0026#34;, \u0026#34;yum update -y\\n\u0026#34;, \u0026#34;yum install -y httpd\\n\u0026#34;, \u0026#34;service httpd start\\n\u0026#34;, \u0026#34;chkconfig httpd on\\n\u0026#34; ]] } } } } }, \u0026#34;Description\u0026#34;: \u0026#34;SampleInstance\u0026#34; } 특정 리소스 값들은 파라미터 값에서 가져오는 방식으로 수정하였습니다. 위와 같이 설정을 마친 후, 동일하게 스택의 생성을 진행해봅니다. #\r#\r템플릿을 업로드 후 동일하게 진행합니다. #\r#\r하지만 전과는 다르게 수정한 파라미터 값들을 선택하거나 기입하는 선택란이 추가되었습니다. 기본적으로 Default 값들을 출력하며, AllowedValues 값이 존재할 시 그 값들만을 선택가능합니다. #\r#\r생성이 완료되었습니다. 이와 같이 파라미터 값을 사용하면 보다 편리하게 서비스들의 구현이 가능합니다. #\r#\r예제 1.\r#\r다음의 탬플릿을 생성해보세요.\r#\rVPC를 생성하고, 3개의 서브넷이 모두 인터넷 게이트웨이로 연결되게 생성하는 템플릿을 생성하세요. #\r예제 2.\r#\r다음의 탬플릿을 생성해보세요.\r#\r웨어 생성한 VPC의 서브넷을 선택해 생성이 가능하도록 인스턴스를 만들고, userdata를 통해 인스턴스의 8080으로 바로 접속이 가능하게 tomcat을 설치해주세요. "},{"id":91,"href":"/cloud/docs/AWS/AWSTraining/NoServer/","title":"AWS 서버리스 사이트 구축","section":"AWS Training","content":"\rAWS 서버리스 사이트 구축\r#\r#\r이번 장에서는 S3를 통해 서버가 없는 정적인 사이트를 구현해보도록 하겠습니다. 이와 같이 서버리스의 가장 큰 특징은 EC2처럼 상시 실행 상태 중이 아니여도, 사용자가 요청시에만 실행이 가능하기 때문에 비용면과 운영면에서 효율적이라 할 수 있습니다. AWS에서는 S3에서 웹 호스팅 기능을 제공하고 있어, 이를 통해 구현해보도록 하겠습니다. #\rAWS 서버리스 사이트 구축\r#\r#\r#\r먼저, AWS에 접속하여 S3 서비스를 검색 후, 클릭합니다. #\r#\rS3를 시작하기 위해 버킷을 생성합니다. #\r#\r버킷의 이름을 지정하고, 리전을 선택합니다. #\r#\r기본 값으로 설정을 진행합니다. #\r#\r단, 그림과 같이 퍼블릭 엑세스의 대한 차단을 해제합니다. #\r#\r버킷의 생성이 완료되었습니다. #\r#\r다음으로는 생성된 버킷을 호스팅 등록하기 전에, 버킷의 정책을 먼저 생성하겠습니다. 버킷의 생성이 완료되면, 생성된 버킷을 클릭합니다. 생성된 버킷에서 권한 -\u0026gt; 버킷 정책을 클릭 후, 하단의 정책 생성기를 클릭합니다. #\r#\r그림은 정책생성기로, 원하는 정책옵션을 선택하면 그 옵션을 Json파일로 변환시켜주는 역할을 수행합니다. 여기서는 아래의 값으로 설정을 진행합니다. Select Type : S3 Bucket Policy\nPrincipal : \u0026quot; * \u0026ldquo; ( Principal는 리소스로의 접근을 허가 또는 거부할 사용자, 계정, 서비스, 엔티티를 나타냅니다.) Actions : GetObject ( Actions는 허가할 조작을 나타냅니다.)\nARN : arn:aws:s3::: [ 버킷 이름 ]/[ Key_name ] ( 허용할 파일 혹은 디렉토리를 나타냅니다. 여기서 /Key_name은 /*을 사용합니다. )\n#\r#\r생성 후, Add Statement를 클릭하면 현재 선택한 옵션들은 Json 형식으로 바꾸어 줍니다. { \u0026#34;Id\u0026#34;: \u0026#34;Policy1593408879908\u0026#34;, \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Sid\u0026#34;: \u0026#34;Stmt1593408870453\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetBucketObjectLockConfiguration\u0026#34; ], \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Resource\u0026#34;: \u0026#34;arn:aws:s3:::s3-serverless-web/*\u0026#34;, \u0026#34;Principal\u0026#34;: \u0026#34;*\u0026#34; } ] } #\r#\r다음은 미리 index.html과 error.html 파일을 업로드 하겠습니다. #\r#\r위의 그림과 같이 파일을 업로드 합니다. 모든 설정은 기본 값으로 설정합니다. #\r#\r이제, 호스팅을 위해 S3에서 정적 웹 사이트 호스팅을 설정하겠습니다. S3의 속성 -\u0026gt; 정적 웹 사이트 호스팅을 선택합니다. #\r#\r정적 웹 사이트 호스팅 창이 나오면 인덱스 문서 및 오류 문서의 업로드한 파일을 기입 후 저장합니다. #\r#\r이제 S3 EndPoint로 접속하면 index.html을 확인할 수 있습니다. 또한 에러 발생시에는 error.html이 보여지는 것을 확인할 수 있습니다. #\r이제 이것으로 기본적인 S3를 사용한 정적사이트 구축이 완료되었습니다. 이어서 서비스와 기능을 추가시켜보도록 하겠습니다. #\r#\rAWS 서버리스 사이트 세부설정\r#\r#\rRedirection Rules\r#\r#\rRedirection Rules란 특정 경로 또는 HTTP 오류 코드 등의 조건에 따라 라우팅을 지정해주는 기능입니다. #\r#\r\u0026lt;RoutingRules\u0026gt; \u0026lt;RoutingRule\u0026gt; \u0026lt;Condition\u0026gt; \u0026lt;KeyPrefixEquals\u0026gt;hello/\u0026lt;/KeyPrefixEquals\u0026gt; \u0026lt;/Condition\u0026gt; \u0026lt;Redirect\u0026gt; \u0026lt;ReplaceKeyPrefixWith\u0026gt;bye/\u0026lt;/ReplaceKeyPrefixWith\u0026gt; \u0026lt;/Redirect\u0026gt; \u0026lt;/RoutingRule\u0026gt; \u0026lt;/RoutingRules\u0026gt; # KeyPrefixEquals로 진입한 트래픽을 ReplaceKeyPrefixWith로 진입시킵니다. Redirection Rules의 설정을 위해 다시 정적 웹 사이트 호스팅 설정을 클릭합니다. 후 위의 값을 리디렉션 규칙에 작성합니다. 위 설정을 마치면 Endpoint에 hello로 진입시 bye로 진입되는 것을 확인 할 수 있습니다. #\r#\r\u0026lt;RoutingRules\u0026gt; \u0026lt;RoutingRule\u0026gt; \u0026lt;Condition\u0026gt; \u0026lt;HttpErrorCodeReturnedEquals\u0026gt;404\u0026lt;/HttpErrorCodeReturnedEquals\u0026gt; \u0026lt;/Condition\u0026gt; \u0026lt;Redirect\u0026gt; \u0026lt;ReplaceKeyWith\u0026gt;index.html\u0026lt;/ReplaceKeyWith\u0026gt; \u0026lt;/Redirect\u0026gt; \u0026lt;/RoutingRule\u0026gt; \u0026lt;/RoutingRules\u0026gt; # HttpErrorCodeReturnedEquals는 특정 에러가 발생하면 에러를 보여주는 대신 ReplaceKeyWith 값을 보여줍니다. 이와 동일하게 위의 값을 다시 리디렉션 규칙에 작성합니다. 설정을 마치면, Endpoint/의 모든 Null 값이 index.html로 옮겨지는 것을 확인할 수 있습니다. #\r#\r차후 Lmabda, DNS, CDN 서비스를 추가하여 업데이트 하겠습니다. DNS 설정\r#\r#\r#\r#\r#\r#\r#\r#\r#\r#\r#\r"},{"id":92,"href":"/cloud/docs/AWS/AWSTraining/EBS/","title":"정리 중","section":"AWS Training","content":"\rAWS Elastic Fire System\r#\r#\rEFS\r#\r#\r#\rAWS 서비스에서 EFS를 클릭합니다. #\r#\r스토리지 생성을 위해 파일 시스템 생성을 클릭합니다. #\r#\r네트워크 엑세스를 구성합니다. 여기서는 기본 VPC에서 가용영역 a, c를 사용하겠습니다. #\r#\r파일 시스템 설정 구성을 설정합니다. 여기서는 후에 설정을 전부 기본 값을 사용하여 생성합니다. #\r#\r생성된 내용을 확인합니다. #\r#\rEFS 사용하기 위해 가용영역 a, c에 인스턴스를 생성합니다. #\r#\r$ yum install make git binutils\r$ git clone https://github.com/aws/efs-utils\r$ cd efs-utils\r$ ./build-deb.sh\r$ cd build\r$ yum install -y ./amazon-efs-utils-1.5-1.deb\r$ yum install -y install nfs-common 패키지들을 설치합니다. #\r#\r#\r#\r#\r#\r"},{"id":93,"href":"/cloud/docs/AWS/AWSTraining/Cognito/","title":"AWS Cognito","section":"AWS Training","content":"\rAWS Cognito\r#\r#\rAWS Cognito\r#\r#\r#\rCognito는 기본적으로 모바일에서 인증을 진행 후, 인증 혹은 비인증에 해당하는 리소스에 대한 사용 권한을 부여 받는 형식으로 진행됩니다. #\r#\rCognito 서비스 사용을 위해서 먼저, AWS에 접속하여 Cognito를 검색합니다. Cognito에 대한 개념은 Cognito를 참고하세요. #\r#\rCognito의 메인 페이지에서 \u0026gt; 자격 증명 풀 관리를 클릭합니다. #\r#\r새 자격 증명 풀을 생성합니다. 인증되지 않은 자격 증명은 비인증 사용자에 대한 엑세스 권한을 설정하는 옵션입니다. 인증 공급자는 사용자의 인증을 확인해 OpenID Connect 기반의 프로바이저입니다. #\r#\r생성이 완료되면 새로운 IAM 권한을 생성하고 허용합니다. #\r#\r이제 다시 풀 관리로 진입하면, 생성된 풀의 확인이 가능합니다. 생성한 풀을 선택하여 해당 풀에 진입합니다. #\r#\r풀에 대한 자격증명을 편집합니다. #\r#\rAWS Mobile SDK\r#\r#\r이제 다음으로 AWS Mobile SDK에 대한 사용방법을 알아보도록 하겠습니다. AWS Moblie SDK 참조 핸드폰의 기종에 맞춰 안드로이드 스튜디오 혹은 Xcode를을 준비해주세요. 여기서는 Vmware의 Mac환경을 설치하여 진행하도록 하겠습니다. VMware Mac 환경설치 #\r$ sudo gem install bundler $ sudo gem install cocoapods $ pod setup # CocoaPods 라이브러리를 설치합니다. $ git clone https://github.com/awslabs/aws-sdk-ios-samples.git $ Samples 코드를 다운 받습니다. $ cd [ 다운로드 경로 ]/S3TransferManager-Sample/Objective-C $ cat Podfile # 해당 디렉토리로 이동하여 Podfile을 확인합니다. Podfile은 프로젝트에 필요한 라이브러리를 작성하는 파일입니다. $ pod install # Podfile의 작성되어 있는 라이브러리들을 설치합니다. AWS Mobile SDK을 사용하기 위한 환경을 구현합니다. #\r#\r설치가 완료되면 Xcode를 실행합니다. 단, .xcodeproj가 아닌 .xcworkspace파일을 실행해야 합니다. #\r#\r#import \u0026lt;Foundation/Foundation.h\u0026gt; NSString *const AWSAccountID = @\u0026#34;Your-AccountID\u0026#34;; NSString *const CognitoPoolID = @\u0026#34;Your-PoolID\u0026#34;; NSString *const CognitoRoleUnauthID = @\u0026#34;Your-RoleUnauthID\u0026#34;; NSString *const CognitoRoleAuth = @\u0026#34;Your-RoleID\u0026#34;; NSString *const S3BucketName = @\u0026#34;Your-S3-Bucket-Name\u0026#34;; Constant.m 파일을 편집합니다. #\r#\r#\r#\r예제 1.\r#\r다음의 인스턴스를 생성해보세요.\r#\r예제 1. 답안\r↕\r사용자 계정을 생성할 시, 엑세스 유형에서 프로그래밍 방식 엑세스만을 선택합니다. 정책에서 admin의 권한을 선택 후 생성합니다. "},{"id":94,"href":"/cloud/docs/AWS/AWSTraining/EC2Site/","title":"EC2 동적 사이트 구축","section":"AWS Training","content":"\rEC2 동적 사이트 구축\r#\r#\r이번 장에서는 EC2와 WordPress, RDS를 활용해 동적 사이트를 구축해보겠습니다. 이 장에서는 RDS 복제본 사용시 과금이 청구될 수 있습니다. 이를 원치 않는 분들은, RDS 설정 시, Multi-AZ 설정을 하지 않고, 1개의 Master RDS만 생성 후 진행하세요.\r#\rEC2 동적 사이트 구축\r#\r#\r#\rVPC VPC 이름 IPv4 CIDR VPC-WordPress 10.0.0.0/16 #\rSubnet Subnet 이름 VPC AZ IPv4 CIDR WordPress-Public-Subnet VPC-WordPress ap-northeast-a 10.0.1.0/24 WordPress-Public-Subnet2 VPC-WordPress ap-northeast-c 10.0.2.0/24 RDS-Private-Subnet VPC-WordPress ap-northeast-a 10.0.11.0/24 RDS-Private-Subnet2 VPC-WordPress ap-northeast-c 10.0.12.0/24 #\rRouting Table Routing Table 이름 VPC Subnet Public-rt VPC-WordPress WordPress-Public-Subnet, WordPress-Public-Subnet2 Private-rt VPC-WordPress RDS-Private-Subnet, RDS-Private-Subnet2 #\r보안 그룹 보안 그룹 이름 VPC 인 바운드 규칙 아웃 바운드 규칙 WordPress-sg VPC-WordPress SSH : 22/TCP : 0.0.0.0/24, HTTP : 80/TCP : 0.0.0.0/24 모든 트래픽 : 0.0.0.0/0 RDS-sg VPC-WordPress WordPress-sg, 3306/TCP : WordPress-sg 모든 트래픽 : 0.0.0.0/0 먼저 위의 아키텍처와 표와 같이 VPC와 서브넷을 생성해주세요. 인터넷 게이트 생성 후, VPC에 연결하세요. 모든 라우팅 테이블의 게이트웨이는 인터넷 게이트웨이로 지정해주세요. VPC 사용자 정의 VPC 생성 #\r#\rEC2를 활용한 동적 사이트 구축\r#\r#\r기본적인 설정을 끝마치셨다면, 이제 동적 사이트 아래의 순서에 맞춰 구현해보겠습니다. 1. RDS 생성\n2. 인스턴스 생성\n3. ELB 생성\n#\r#\r1. RDS 생성\r#\r#\r먼저 RDS 서브넷의 생성을 위해, RDS \u0026gt; 서브넷 그룹 \u0026gt; DB 서브넷 그룹을 위와 동일하게 생성합니다. #\r#\r아래의 형식에 맞춰 RDS를 생성합니다. RDS 설치 참고 기본설정 설정 항목 값 License Model genral-publicl-license DB Engine Version 5.7.28 DB Instance Class db.t2.micro Multi-AZ Deployment General Purpose ( SSD ) Allocated Storage 20 GB DB 인스턴스 식별자 WordPressDB 마스터 사용자 ID, PW root/qwer1234 #\r네트워크 설정 설정항목 값 VPC VPC-WordPress Subnet Group rds-private Publicly Accessible no AZ ap-northeast-2a VPC Security Groups RDS-sg #\r백업 설정 설정항목 값 백업 보존 기간 1일 백업 기간 기본 설정 없음 #\r유지 관리설정 설정항목 값 마이너 버전 자동 업그레이드 사용 유지 관리 기간 기본 설정 없음 삭제 방지 삭제 방지 활성화 X 개인 설정 및 이 이외 값을 기본 값을 유지합니다. #\r2. 인스턴스 생성\r#\r#\r다음의 값으로 인스턴스를 생성합니다. 설정 항목 값 AMI Amazon Linux AMI Instance Type t2.micro Network VPC-WordPress Subnet WordPress-Public Auto-asstign Public Enable Name WordPress-a Security Group Wordpress-sg #\r#\r생성이 완료되면 아래의 미들웨어들을 설치합니다. 유저 이름은 ec2-user입니다. $ sudo yum install -y php php-mysql php-gd php-mbstring # 관련 미들웨어를 설치합니다. $ sudo yum install -y mysql # mysql을 설치합니다. $ wget -O /tmp/wordpress-4.1-ja.tar.gz https://ko.wordpress.org/wordpress-4.6.1-ko_KR.tar.gz # wordpress-4.6.1...의 파일을 wordpress-4.1-ja.tar.gz의 이름으로 다운받습니다. $ sudo tar zxf /tmp/wordpress-4.1-ja.tar.gz -C /opt # wordpress 압축파일을 /opt에 압축을 해제합니다. $ sudo ln -s /opt/wordpress /var/www/html # 심볼릭 링크를 생성합니다. $ sudo chown -R apache:apache /opt/wordpress # wordpress의 소유 권한을 apache로 수정합니다. $ sudo chkconfig httpd on # httpd가 정상적으로 작동하는 지 체크합니다. $ sudo service httpd start $ httpd 서비스를 시작합니다. #\r#\r설치가 완료되면 DB 접속을 위한 계정을 생성합니다. $ mysql -u root -p -h [ RDS Endpoint ] $ password : qwer1234 mysql\u0026gt; create user \u0026#39;wordpress-user\u0026#39;@\u0026#39;%\u0026#39; identified by \u0026#39;wordpress\u0026#39;; mysql\u0026gt; create database wordpress; mysql\u0026gt; grant all privileges on wordpress.* to \u0026#34;wordpress-user\u0026#34;@\u0026#34;%\u0026#34;; mysql\u0026gt; flush privileges; #\r#\r계정 생성이 완료되었으면, http://인스턴스의 Public IP/wordpress/wp-admin/install.php로 접속합니다. #\r#\r데이터베이스, 사용자명, 비밀번호에 위에서 생성한 값들을 입력 후, 데이터베이스의 호스트에는 RDS의 엔드포인트 값을 입력합니다. #\r#\r설치를 실행합니다. #\r#\r사이트의 제목과 관리자명 등을 설정합니다. #\r#\r설정이 완료되면, 설정한 계정을 통해 로그인합니다. #\r#\rWored Press의 설치가 완료되었습니다. #\r#\r생성이 완료되면 AMI 이미지를 생성합니다. AMI 이미지를 통해 동일한 인스턴스를 다른 가용영역에 생성합니다. #\r#\r3. ELB 생성\r#\r#\r80/tcp 외부로 ALB를 생성해주세요. ELB 생성 참고 #\r#\rELB의 DNS로의 접속이 확인되면, 대상그룹 또한 확인합니다. #\r#\r다음으로는 WordPress의 접속 IP를 변경해보겠습니다. WordPress의 관리자로 접속하여 설정 -\u0026gt; 워드프레스 주소, 사이트 주소를 변경합니다. 워드프레스 주소 : http://[ ALB DNS ]/wordpress 사이트 주소 : http://[ ALB DNS ] ALB에서 Desciption -\u0026gt; Edit stickiness에서 로드밸런서의 쿠키 값을 사용하도록 설정 후, 시간은 1800초로 설정합니다. #\r#\r이제 마지막으로 WordPress-sg의 80/tcp 포트의 대상을 0.0.0.0/0이 아닌, ALB를 대상으로 설정 및, SSH 접속을 해제하면 모든 설정이 완료됩니다. #\r#\rMarketplace를 사용\r#\r#\r위 처럼 직접 구현하는 방법 외에도 이미 구현되어 있는 AMI를 구입하여 사용하는 방법도있습니다. #\r위 그림과 같이 Markplace에서 구입이 가능합니다. Marketplace로 구현을 할 경우, 이미 구축되어진 인프라를 사용하는 만큼, 간편하고 빠르게 사용할 수 있지만, 세부적인 사항에 대해서는 설정이 어렵다는 단점이 있습니다. "},{"id":95,"href":"/cloud/docs/AWS/AWSTraining/ElasticBeanstalk/","title":"Elastic Beanstalk 사이트 구축","section":"AWS Training","content":"\rElastic Beanstalk 사이트 구축\r#\r#\r이번 장에서는 Elastic Beanstalk를 활용해서 WordPress 사이트를 구축해보겠습니다. Elastic Beanstalk가 무엇인지는 Elastic Beanstalk를 참조해주세요. #\rElastic Beanstalk 사이트 구축\r#\r#\r#\rElastic Beanstalk는 zip 형식으로 애플리케이션을 압축해서 AWS 상에 업로드 할 수 있습니다. WordPress를 사용하기 위해 WordPress에서 zip 형식으로 다운로드 합니다. #\r#\r다운로드가 완료되면 AWS에서 Elastic Beanstalk를 검색합니다. #\r#\rElastic Beanstalk의 생성을 위해 Create Application을 클릭합니다. #\r#\r애플리케이션의 이름과 태그를 설정합니다. #\r#\r플랫폼에서는 사용할 플랫폼을 설정할 수 있습니다. 여기서는 PHP를 선택합니다. #\r#\r애플리케이션 코드에서는 코드 업로드를 클릭합니다. 소스 코드는 위에어 다운로드 한 WordPress.zip 파일을 업로드 합니다. 업로드가 완료되면 추가 옵션 구성을 클릭하여 세부설정으로 진입합니다. #\r#\rElasticBeanstalk의 구성을 위해 사용자 지정을 클릭 후 아래항목으로 이동합니다. #\r#\r먼저 최하단으로 진입하여 데이터베이스 설정을 진행으르 진행 후, 네트워크 설정을 진행합니다. 네트워크 및 데이터베이스에 대한 설정은 [EC2 동적 사이트 구축) (https://mung0001.github.io/docs/cloudcomputing/awstraining/ec2site/)의 VPC 및 보안그룹을 사용하였습니다. #\r#\r설정이 완료되면 다시 위로 올라와 인스턴스의 보안그룹과 키 페어를 등록합니다. 설정이 완료되면 앱 생성을 클릭하여 ElasticBeanstalk를 생성합니다. #\r#\r위의 그림과 설치가 완료되면 EC2, RDS등이 설치된 것을 확인 할 수 있습니다. 다음으로는 Elastic Beanstalk의 URL를 통해 http://[ 생성한 애플리케이션 URL ]/wordpress로 진입합다. #\r#\rWordPress가 설치된 것을 확인할 수 있습니다. #\r#\r위의 그림과 같이 설정을 진행합니다. ElasticBeanstalk에 의해 생성된 db의 이름은 기본적으로 ebdb로 생성되어 있습니다. 데이터베이스의 호스트는 생성된 RDS의 EndPorint를 설정합니다. #\r#\r다음의 웹 사이트 이름, 관리자의 대한 추가 설정을 마치면 WordPress의 생성이 완료되었습니다. #\r이와 같이 ElasticBeanstalk를 사용하면 AWS의 다양한 서비스와 PIP 뿐만이 아닌, 다양한 패키지들을 간단하게 생성이 가능합니다. #\r#\rElastic Beanstalk의 eb ( awsebcli ) 활용\r#\r#\reb 명령어는 Elastic Beanstalk 전용 CLI로, AWS CLI와 별도로 설치가 필요합니다. #\r#\r$ pip install awsebcli # awsebcli 설치 $ eb --version $ awsebcli 설치확인 awsebcli를 설치합니다. #\r#\r$ cd /[ WordPress 압축 푼 파일 경로 ] $ eb init -p php # php 플랫폼 지정 다운 받은 WordPress의 압축을 해제하고, 해당 디렉토리를 플랫폼으로 지정합니다. #\r#\r$ eb create [ RDS 이름 ] --database --timoute 30 # eb 애플리케이션에 사용할 RDS 생성 RDS를 생성합니다. #\r#\rdefine(\u0026#39;DB_NAME\u0026#39;, $_SERVER[\u0026#39;RDS_DB_NAME\u0026#39;]); define(\u0026#39;DB_USER\u0026#39;, $_SERVER[\u0026#39;RDS_USERNAME\u0026#39;]); define(\u0026#39;DB_PASSWORD\u0026#39;, $_SERVER[\u0026#39;RDS_PASSWORD\u0026#39;]); define(\u0026#39;DB_HOST\u0026#39;, $_SERVER[\u0026#39;RDS_HOSTNAME\u0026#39;]); define(\u0026#39;FORCE_SSL_LOGIN\u0026#39;, true); define(\u0026#39;FORCE_SSL_ADMIN\u0026#39;, true); 압축을 해제한 WordPress 디렉토리 내의 wp-config-ample.php를 복사해서 wp-config.php를 생성 후, wp-config파일을 수정합니다. 위와 동일하게 wp-includes/functions.php 또한 수정합니다. #\r#\r"},{"id":96,"href":"/cloud/docs/AWS/AWSTraining/SES/","title":"AWS SES 메일 시스템 구축","section":"AWS Training","content":"\rAWS SES 메일 시스템 구축\r#\r#\r이번 장에서는 SES로 메일을 전송하는 시스템을 구축하여 보겠습니다. 단, SES 사용을 위해서는 버지나이 북부, 오레곤, 아일랜드만이 사용이 가능합니다. #\r메일 시스템 구축 순서\n1. Simple Email Service ( SES ) 사용\n2. EC2 인스턴스로 메일 서버를 구축\n3. 서드 파티 도구를 사용\n#\rAWS SES 메일 시스템 구축\r#\r#\r#\r먼저, SES 서비스를 이용하기 위해 AWS에서 SES를 검색합니다. #\r#\rEmail Addresses \u0026gt; Verify a New Email Address를 클릭하여 인증을 진행합니다. 사용하실 메일주소를 입력 후, 인증을 진행합니다. #\r#\r사용하실 메일로 접속하여 인증을 진행하면, 다음과 같이 verified 항목이 체크됩니다. #\r#\r확인을 위해 등록하신 메일주소를 체크하고 상단의 Send a Test Email을 클릭합니다. #\r#\r값을 입력하고 이메일을 발송합니다. #\r#\r메일주소로 접속하면, 메일이 도착한 것을 확인할 수 있습니다. #\r#\r좌측 메뉴의 Sending Statistics를 클릭하면 현재 메일 사용량과 제한을 알 수 있습니다. 또한 현재 그림에는 보이지 않지만 상단의 Request a Sending Limit Increase를 클릭하면 허용량을 증가시키는 것이 가능합니다. 단, 신청 시, 완료까지 평균적으로 1일의 시간이 소요됩니다. #\r#\r메일함 완성 후에 업데이트 예정 #\r#\r#\r#\r#\r#\r예제 1.\r#\r다음의 인스턴스를 생성해보세요.\r#\r예제 1. 답안\r↕\r사용자 계정을 생성할 시, 엑세스 유형에서 프로그래밍 방식 엑세스만을 선택합니다. 정책에서 admin의 권한을 선택 후 생성합니다. "},{"id":97,"href":"/cloud/docs/AWS/AWSTraining/AWS-Lambda-Crawling/","title":"AWS Lambda Crawling","section":"AWS Training","content":"\rAWS Lambda Crawling\r#\r#\rAWS Lambda Crawling\r#\r#\r#\r#\r#\r#\r#\r$ pip3 install [ Package ] -t . $ pip3 install bs4 -t . $ \u0026#39;[ 7z 경로, 다른 zip도 가능 ]\u0026#39; a \u0026#39;[ 압축할 패키지 이름 ]\u0026#39; \u0026#39;[ 압축할 패키지 경로 ]\u0026#39; $ \u0026#39;C:\\Program Files\\7-Zip\\7z.exe\u0026#39; a \u0026#39;C:\\AWSLambda\\bs4.zip\u0026#39; \u0026#39;.\u0026#39; #\r#\r#\r#\r#\r#\r#\r#\r#\r#\r#\r#\r#\r#\r#\r#\r#\r#\r#\r#\r예제 1.\r#\r다음의 인스턴스를 생성해보세요.\r#\r예제 1. 답안\r↕\r사용자 계정을 생성할 시, 엑세스 유형에서 프로그래밍 방식 엑세스만을 선택합니다. 정책에서 admin의 권한을 선택 후 생성합니다. import json import urllib.request from bs4 import BeautifulSoup def lambda_handler(event, context): url = \u0026ldquo;\rhttps://www.google.com\u0026rdquo; soup = BeautifulSoup(urllib.request.urlopen(url).read(), \u0026ldquo;html.parser\u0026rdquo;) a_tags = soup.find_all(\u0026ldquo;a\u0026rdquo;) result_list = [] for i in a_tags: result_list.append(i.get_text()) return { \u0026lsquo;statusCode\u0026rsquo;: 200, \u0026lsquo;body\u0026rsquo;: json.dumps(result_list) }\n"},{"id":98,"href":"/cloud/docs/Azure/AzureTraining/Base-copy-3/","title":"Azure 학생 계정생성","section":"Azure Training","content":"\rAzure 학생 계정생성\r#\r#\rAzure 학생 계정생성\r#\r#\r이번 장에서는 Azure 서비스의 사용을 위한 계정생성에 대해 알아보도록 하겠습니다.\n기본적으로 Azure의 서비스를 사용할 때에는 계정이 필요하며, 여기서 학생의 신분으로 가입을 진행할 경우 여러 혜택을 받을 수 있습니다.\n윈도우 10 edu\n윈도우 Server 2019\nVisual Studio 2017 Enterprise\nSQL Server 2017 Enterprise\nAzure 100$ 크레딧\n이와 같은 혜택을 받기 위해서는 학교 메일 (ac.kr or .edu)의 메일이 필요합니다.\n그럼 학생계정으로 Azure 계정을 생성해보도록 하겠습니다.\n#\r#\rAzure for Students\r#\r#\rAzure for Students에 접속합니다. 지금 구독하기를 클릭합니다. #\r#\r이메일 학번과 패스워들를 입력하면 해당 이메일의 학교로 링크가 변경됩니다. ex) 학번@dankook.ac.kr 로그인을 진행합니다. 만약 학교계정이 없으면 일반 계정으로 진행하셔도 상관없읍니다. (학생 해택은 없음) #\r#\r핸드폰 번호를 기입 후, 문자 혹은 전화를 통해 본인인증을 진행합니다. #\r#\r회원가입을 진행합니다. #\r#\r약관의 동의합니다. #\r#\r하단과 같이 게정이 모두 설정되었다는 화면이 나오면, 생성이 완료된 것입니다. #\r#\r하단과 같이 VM을 포함한 다수의 서비스를 이용할 수 있습니다. #\r"},{"id":99,"href":"/cloud/docs/AWS/AWSTraining/Game/","title":"EC2 끄투온라인 서버 구축","section":"AWS Training","content":"\rAWS 끄투온라인 서버 구축\r#\r#\rAWS 끄투온라인 서버 구축\r#\r#\r#\r끄투 온라인은 오픈소스의 끝말잇기 게임입니다. #\r#\rEC2를 생성합니다. EC2 생성은 EC2 생성을 참조해주세요. OS 유형 disk security group Ubuntu18.04 t2.mini 8 all-open #\r인스턴스를 생성 후, 아래와 같이 진행합니다. $ sudo apt -y update $ sudo apt -y upgrade $ sudo apt -y install node.js $ sudo apt -y install npm $ npm install -g grunt grunt-cli $ sudo apt -y install postgresql $ sudo apt -y install git $ sudo git clone https://github.com/JJoriping/KKuTu.git # 서버 구축에 필요한 패키지들을 설치합니다. $ sudo su - postgres $ psql postgres=# ALTER USER postgres with encrypted password \u0026#39;qwer1234\u0026#39;; postgres=# CREATE DATABASE main; postgres-# \\l List of databases Name | Owner | Encoding | Collate | Ctype | Access privileges -----------+----------+----------+---------+---------+----------------------- main | postgres | UTF8 | C.UTF-8 | C.UTF-8 | postgres | postgres | UTF8 | C.UTF-8 | C.UTF-8 | template0 | postgres | UTF8 | C.UTF-8 | C.UTF-8 | =c/postgres + | | | | | postgres=CTc/postgres template1 | postgres | UTF8 | C.UTF-8 | C.UTF-8 | =c/postgres + | | | | | postgres=CTc/postgres # 게임 데이터의 삽입을 위한 DB를 생성합니다. # 새로운 커널 하나를 다시 킨 후 $ cd KKuTu/Server/lib/sub/ $ mv global.inc.json global.json $ mv auth.inc.json auth.json $ vi global.json \u0026#34;PASS\u0026#34;:\u0026#34;...\u0026#34;, \u0026gt;\u0026#34;PASS\u0026#34;:\u0026#34;qwer1234\u0026#34;, \u0026#34;PG_PASSWORD\u0026#34;: \u0026#34;...\u0026#34;,\u0026gt; \u0026#34;PG_PASSWORD\u0026#34;: \u0026#34;qwer1234\u0026#34;, # DB에 접속하기 위한 패스워드를 수정합니다. $ cd ~/KKuTu $ sudo -u postgres psql --quiet main \u0026lt; ./db.sql # DB를 삽입합니다. $ chmod +x server-setup.bat $ ./server-setup.bat $ node ./Server/lib/Game/cluster.js 0 1 $ ctrl + z $ bg $ disown -h $ node Server/lib/Web/cluster.js 1 $ ctrl + z $ bg $ disown -h $ netstat -anlp | grep :8496 $ netstat -anlp | grep :80 # 확인 IP ] 접속 #\r#\r"}]