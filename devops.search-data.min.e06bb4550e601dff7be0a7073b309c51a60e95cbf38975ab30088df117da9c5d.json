[{"id":0,"href":"/devops/docs/Kubernetes/Kubernetes/1.-Runtime/ContainerD/file0/","title":" Concept","section":"ContainerD","content":" ContainerD # Containerd는 Docker 사에서 moby project 와 함께 발표하여 CNCF 에 기증한 오픈소스입니다.\nContainerD 2022년 4월 Docker engine이 쿠버네티스에서 사용중단을 발표한 후, 높은 점유율을 이루고 있습니다.\n간단하게 기존에 사용하던 Docker engine을 사용하지 않고 ContainerD를 사용 하게된 이유를 정리하자면 쿠버네티스는 여러 컨테이너 런타임과 통신할 수 있도록 하는 CRI라는 표준 인터페이스를 설계함.\nDocker engine은 CRI 인터페이스가 생기기전 존재한 기술로 CRI 인터페이스와 맞지 않았음.\n이를 해결하기 위해 dockershim이라는 어댑터 컴포넌트를 개발하였음.\n이 쉼의 존재는 kubelet 자체에 많은 불필요한 복잡성을 도입했고, 일부 통합은 이 쉼 때문에 Docker에 대해 일관성 없게 구현되었으며, 이로 인해 유지 관리 부담이 증가하게 됨.\n이처럼 벤더 특정 코드(특정 제품인 Docker에 종속적인 코드)를 유지 관리하는 것은 쿠버네티스의 오픈 소스 철학에 부합하지 않았고, 2022년 4월 v1.24에서 완전한 제거를 발표하였음. 그렇다고, ContainerD가 Docker와 완전히 다른 것이 아닌 게, containerD는 도커를 컨테이너 런타임으로 사용할 때 내부적으로 사용되는 컨테이너 런타임 기술로, 이젠 이러한 기술을 도커에서 빼서 containerd만 따로 사용하는 것입니다.\n즉, 현재는 Docker에서 컨테이너 런타임을 분리하여 ContainerD를 사용하고, 여전히 관련 이미지 개발 등은 Docker을 사용하는 것입니다.\nDocker Engine, ContainerD에 간단 비교는 아래를 참고해주세요.\nDocker Engine vs ContainerD # 특성 Docker Engine ContainerD 설명 Docker의 전체 컨테이너 관리 플랫폼 경량화된 컨테이너 런타임 주요 기능 이미지 빌드, 배포, 컨테이너 실행 컨테이너 실행, 이미지 관리 API Docker API 제공 CRI (Container Runtime Interface) 지원 설치 및 설정 복잡한 설치 및 설정 비교적 간단한 설치 및 설정 부하 상대적으로 높은 리소스 소모 더 경량화되어 리소스 효율성 높음 의존성 여러 추가 도구 (예: Docker Compose) 필요 Kubernetes에서 직접 사용 가능 주요 사용 사례 개발 및 테스트 환경 프로덕션 환경, 특히 Kubernetes에서 사용 References # [kubernetes] ☸️쿠버네티스의 도커 지원 중단에 대한 모든 것 "},{"id":1,"href":"/devops/docs/Kubernetes/cert/cka/","title":"0. CKA","section":"Cert","content":" CKA # CKA # # # CKA 자격증은 Certified Kubernetes Administrator를 의미하며, Kubernetes 플랫폼에 대한 숙련도를 Linux Foundation에서 검증해주는 자격증을 의미\nCKA 자격시험은 실기형 시험으로 Kubernetes 환경에서 명령어를 활용해 리소스를 다루는 형태로 문제가 출제되며. 2시간의 시험 시간 동안 66/100점 이상이면 시험에 통과\n# Section Table 분야 비중 Cluster Architecture, Installation \u0026amp; Configuration 25% Workloads \u0026amp; Scheduling 15% Service \u0026amp; Networking 20% Storage 10% TroubleShooting 30% CKA 관련 사이트 # CKA 시험등록 Killer Answer "},{"id":2,"href":"/devops/docs/Docker/Docker/Docker00/","title":"0. Docker\u0026 Container","section":"Docker","content":" Docker 와 Container # Docker의 등장배경 # Docker는 2013년에 dotCloud의 의해 2013년 PyCon에서 (The future of Linux Containers) 처음 데모 되었다.\n이는 오클랜드 항구에 들어오는 모든 컨테이너 선박을 보며, 한 서버에서다른 서버로 앱을 옮기는 것 보다, 지구 반대편으로 컨테이너를 옮기는 것이 더 쉽다라는 취지에서 개발됨.\n위 문제는 기존 가상화기술을 사용하면 가능했으나, 리소스의 수가 커지고 대규모의 관리가 증대됨에 따라 필요성이 대두되어짐.\ndotCloud 팀은 가상화 자체가 문제가 아니라 가상화 사용 방식이 문제라는 것을 인식했으며, 전체 운영 체제를 가상화하는 대신 애플리케이션과 해당 종속성만 가상화하는 것이 더 효율적이라 생각해었고, 이 것이 Container 의 개념으로 개발됨.\nContainer란? # 기본 운영 체제(OS) 커널을 동일한 시스템의 다른 컨테이너와 공유하는 격리된 환경에서 애플리케이션을 실행하는 방법\nContainer의 격리된 환경의 특징\nVM이 완전한 운영체제와 에뮬리이션을 갖는 반면, 컨테이너는 호스트 시스템과 커널을 공유 위와 같은 특성으로 VM의 비해 사용되는 리소스가 적어, 가볍고 빠르게 실행이 가능 컨테이너는 완전 격리된 상태이기에, 실행 환경이 동일하면 어떠한 방식으로도 실행이 가능 즉, 컨테이너 기반 가상화는 기존 가상화와 달리 하이퍼바이저 위에서 여러 개의 Guest OS를 실행하는 대신 호스트 OS 커널을 사용하여 격리된 여러 개의 컨테이너를 실행\nContainer 기반 기술 # Chroot and Chroot Jail # Chroot(Change Root)는 프로세스의 Root 디렉토리를 변경하여 파일 시스템에서 특정 파일 및 디렉터리 인덱스를 좁힐 수 있는 기능\nJail은 chroot에서 더 진보된 단계로, 기존 Chroot 설정이여도 프로세스가 네트워크 통신 등의 역할을 수행할 수 있었지만, Jail은 이를 제한 할 수 있었음.\n이어 서로 다른 프로세스 그룹 간의 경계 관리 솔루션인 Solaris Zones이 출시되며, Container 라는 용어가 활용되기 시작하였음.\nLXC (LinuX Container) # LXC란 리눅스 컨테이너로 해당 커널의 주 구성요소는 namespace, cgroups, chroot 이다. cgroup (control group) # cgroup을 사용하여 각 컨테이너에 대한 시스템 리소스(CPU, 메모리, 디스크 I/O)를 제한하고 우선순위를 지정하며, 각 컨테이너에 리소스를 제어되고 효율적인 방식으로 할당하여 컨테이너의 성능에 영향을 미치는 것을 방지하는 역할을 수행한다. namespace # LXC는 Linux 커널 namespace를 사용하여 각 컨테이너에 대해 별도의 네임스페이스를 생성 namespace는 프로세스 ID, 네트워크 인터페이스, 파일 시스템 등 각 컨테이너에 대한 다양한 시스템 리소스를 격리하여, 다른 컨테이너 리소스의 간섭을 막는 역할을 수행한다. chroot # 위에서 나타냈듯이, 각 컨테이너는 고유한 파일 시스템 계층 구조를 가질 수 있으며, 한 컨테이너 내의 프로세스가 다른 컨테이너의 파일에 액세스 하거나 수정 불가능하게 함 위 LXC 커널들을 사용하여 컨테이너 서비스가 개발되었기 때문에, 다른 운영체제서는 사용이 불가능 Namespaces: 네임스페이스는 리눅스에서 프로세스를 격리하고 독립적인 환경을 제공하는 기술로, 여러 가지 네임스페이스를 활용하여 프로세스, 마운트 포인트, 네트워크, 호스트 이름 등을 격리\nCgroups (컨트롤 그룹): 리눅스에서 프로세스 그룹을 생성하고 리소스를 할당하거나 제한하는 기술 Cgroups를 사용하여 CPU, 메모리, 디스크 I/O 등의 자원을 제어하고 할당\nAppArmor 및 SELinux Profiles: AppArmor와 SELinux는 각각 리눅스 시스템에서 프로세스의 접근 권한을 제한하는 보안 모듈로 프로파일을 사용하여 각 컨테이너의 권한을 제어하고 보안을 강화\nNetwork Devices (네트워크 디바이스): 네트워크를 격리하고 각 컨테이너에 독립적인 네트워크 환경을 제공 및 네트워크 디바이스를 사용하여 컨테이너 간 통신이나 호스트와의 통신을 관리\nChroot (체인지 루트): 파일 시스템에서 특정 디렉토리를 컨테이너의 루트로 변경, 이를 통해 컨테이너는 호스트 시스템과 독립된 파일 시스템 환경을 구축이 가능\nSeccomp Policies: Seccomp은 리눅스에서 프로세스가 사용할 수 있는 시스템 콜을 제한하는 커널 보안 모듈로 Seccomp를 사용하여 컨테이너에서 특정 시스템 콜을 차단하여 보안을 강화\nDocker의 등장 # LXC는 사용자 공간 수준에서 깔끔하고 강력한 인터페이스를 제공하지만 여전히 사용하기 쉽지 않고 대중적 매력을 불러일으키지도 못했고, Docker 커널 기능을 다루는 복잡성의 대부분을 추상화하면서 애플리케이션과 그 종속성을 컨테이너에 묶는 간단한 형식을 제공하여 이를 해결하였다.\n단, Docker는 초기 LXC에서 실행환경을 구성하였으나, 이후 Go Lang을 활용한 libcontainer로 내부 환경을 변경하여 LXC와 같은 외부 패키지에 의존적이지 않도록 개발을 진행하였다.\nDocker의 이해 # 도커는 위 그림과 같이 모듈식 아키텍처를 가지고 있으며, 서비스를 제공하기 위해 몇 가지 주요 구성 요소를 사용 Dockerd: docker engine으로 불리며 API 요청을 수신하고 개체를 관리하는 데몬 프로세스\nContainerd: Docker 객체를 관리하기 위해 이미지 다운로드 및 컨테이너 실행과 같은 작업을 수행\nrunc: 커널 기능과 상호작용하며 네임스페이스 및 제어 그룹을 생성하는 표준 메커니즘을 제공\nDocker Image의 이해 # 도커의 이미지는 컨테이너를 인스턴스화 하는 데 사용하는 읽기 전용 레이어 파일이다.\n이미지는 Dockerfile를 통해 생성하며, Dockerfile의 각 명령은 상위 이미지 위에 레이어를 생성하여 적용시키는 개념이다.\nDocker Storage # Docker Image로 생성된 컨테이너는 위와 같이 Layer 형식으로 구성 되며, 이는 위 그림과 같이 스토리지 드라이버에 저장된다.\n스토리지 드라이버는 이미지 레이어와 컨테이너 레이어의 콘텐츠를 관리하며, aufs, overlay, overlay2, btrfs, ztf 등의 여러 스토리지 드라이버를 사용 할 수 있다.\n각 스토리지 드라이버는 구현 방식이 다르지만 모두 스택 가능한 이미지 레이어와 CoW(Copy On Write 기록 중 복사) 전략을 사용 (CoW는 기본적으로 효율성을 극대화하기 위해 파일을 공유하고 복사하는 전략)\n종류 특징 Volume 볼륨은 호스트 파일 시스템의 특별한 디렉토리나 Docker가 관리하는 볼륨 드라이버에 의해 생성되며, 컨테이너에 마운트되며, 볼륨은 컨테이너의 생명주기 동안 데이터를 유지하고, 여러 컨테이너 간에 데이터를 쉽게 공유하는 역할을 수행 Bind Mount 바인드 마운트는 호스트 머신의 파일 시스템 경로를 직접 컨테이너 경로에 마운트하는 방식 Tmpfs 컨테이너 내의 임시 파일 시스템으로, RAM을 기반으로 컨테이너의 실행 중에만 유지되며, 컨테이너가 종료되면 데이터가 손실 Docker Networking # Docker 컨테이너는 다른 워크로드 유형에 대한 명시적인 지식 없이도 서로 연결될 수 있으며, Docker가 아닌 워크로드와도 연결이 가능한데, 이는 완전히 연결 가능한 Docker의 네트워킹 하위 시스템 덕분에 가능 이는 아래의 네트워크 드라이버를 통해 지원 종류 특징 bridge 브리지 드라이버를 사용하여 독립형 컨테이너에서 실행되는 애플리케이션 간에 통신 (기본 드라이버) host 호스트 드라이버는 컨테이너와 호스트 사이의 네트워크 격리를 제거하고 호스트 네트워크를 직접 사용 overlay 오버레이 드라이버를 사용하여 여러 Docker 데몬을 함께 연결 (Docker Swarm) macvlan macvlan 드라이버를 사용하면 Docker 데몬이 MAC 주소를 통해 컨테이너로 트래픽을 라우팅할 수 있도록 MAC 주소를 컨테이너에 할당이 가능 none 네트워크 비활성화 Docker bridge network # Docker는 기본적으로 브리지 네트워크 \u0026ldquo;docker0\u0026quot;을 생성하고 \u0026ldquo;vethxx\u0026quot;를 통해 모든 컨테이너 네트워크를 여기에 연결\n기본 브리지 네트워크에 연결된 컨테이너는 IP 주소를 통해 서로 통신할 수 있습니다 . 또한 브리지 네트워크 “docker0”은 호스트 네트워크 “eth0”에 연결되어 외부 네트워크에 대한 연결을 제공\n참조 # "},{"id":3,"href":"/devops/docs/fastapi/fastapi/fastapi00/","title":"0. FastAPI이란?","section":"FastAPI","content":" FastAPI # FastAPI 공식문서 FAST API란? # FastAPI는 Python으로 작성된 현대적인 웹 프레임워크로, asyncio를 기반으로 한 ASGI(Asynchronous Server Gateway Interface)를 사용하여 비동기 작업을 통해 고성능과 간단한 코드 작성 방식을 제공합니다. 비동기 작업은 요청이 들어올 때 블로킹되지 않고 여러 작업을 병렬로 처리하므로, I/O 바운드 작업(예: 데이터베이스 쿼리, 외부 API 호출)에 대해 매우 높은 성능을 발휘합니다. # 예시 from fastapi import FastAPI app = FastAPI() @app.get(\u0026#34;/async-example\u0026#34;) async def async_example(): data = await fetch_data_from_api() db_result = await fetch_data_from_db() return {\u0026#34;api_data\u0026#34;: data, \u0026#34;db_result\u0026#34;: db_result} FastAPI는 비동기 처리와 함께 Pydantic의 데이터 검증을 활용하여 JSON 데이터의 직렬화 및 역직렬화를 최적화 Starlette와 Uvicorn 사용 FastAPI는 Starlette을 기반으로 하여 HTTP 및 WebSocket 처리 성능이 뛰어나며, Uvicorn이라는 ASGI 서버로 실행됩니다. Uvicorn은 단일 스레드로도 높은 요청 처리량을 제공하며, 멀티프로세스 옵션을 통해 대규모 서비스에서도 확장 가능합니다 Swagger UI 및 ReDoc 같은 UI로 API 문서를 확인하고 테스트가 가능합니다. FAST API의 역사 # FastAPI는 2018년에 Sebastián Ramírez에 의해 처음 발표되었습니다. Flask와 Django와 같은 기존 프레임워크의 제한점을 보완하고, 비동기 프로그래밍의 필요성을 반영하여 설계되었습니다.\nFAST API의 특징 # FAST API의 장점 # 빠른 개발 속도\n자동완성 및 OpenAPI 지원으로 빠르고 효율적인 API 개발이 가능합니다.\nfrom typing import Union from fastapi import FastAPI app = FastAPI() @app.get(\u0026#34;/\u0026#34;) def read_root(): return {\u0026#34;Hello\u0026#34;: \u0026#34;World\u0026#34;} @app.get(\u0026#34;/items/{item_id}\u0026#34;) def read_item(item_id: int, q: Union[str, None] = None): return {\u0026#34;item_id\u0026#34;: item_id, \u0026#34;q\u0026#34;: q} 고성능\nFastAPI는 ASGI를 기반으로 하여 비동기 I/O 작업을 효율적으로 처리하며, Flask와 같은 기존 프레임워크보다 더 높은 성능을 자랑합니다.\n자동 문서 생성\nSwagger UI와 ReDoc을 통해 API 문서를 자동으로 생성합니다.\n데이터 검증 및 직렬화\nPydantic을 활용한 강력한 데이터 검증 기능을 제공합니다. 이를 통해 JSON 데이터를 Python 객체로 안전하게 변환하고, 잘못된 데이터 처리를 방지합니다.\nOAuth2 및 보안\nFastAPI는 OAuth2 및 다양한 인증 방식을 기본 지원하여 보안이 중요한 API 개발에 적합합니다.\nFAST API의 단점 # 학습 자료 부족\nFastAPI는 비교적 새로운 프레임워크로, Django와 Flask에 비해 학습 자료가 제한적입니다.\n코드 복잡성 증가\nFastAPI는 다양한 기능을 제공하지만, 프로젝트 규모가 커질수록 코드 구조가 복잡해질 수 있습니다. 이를 해결하려면 모듈화를 적절히 활용해야 합니다.\nPython Framework 비교 # 기능 FastAPI Flask Django 속도 매우 빠름 보통 보통 비동기 지원 지원 기본 미지원 Django 3.0+부터 제한적으로 지원 문서화 자동 생성 수동 작성 필요 수동 작성 필요 데이터 검증 기본 제공 (Pydantic) 수동 작성 필요 수동 작성 필요 커뮤니티 성장 중 매우 크고 활성화 매우 크고 활성화 출처 : Chat GPT\nFastAPI 활용 사례 # 머신러닝 모델 배포\nFastAPI는 비동기 기능 덕분에 고성능 머신러닝 API를 쉽게 구현할 수 있습니다. 모델 예측 결과를 빠르게 제공하거나 데이터를 실시간으로 처리하는 데 유리합니다.\nIoT 애플리케이션\n대규모 IoT 기기와의 데이터 통신 및 제어를 위한 API를 개발할 때 이상적입니다.\n"},{"id":4,"href":"/devops/docs/CICD/CICD/git00/","title":"0. Git이란?","section":"CI/CD 배포 입문","content":" GIT # Git이란? # 깃(Git)은 2005년에 리누스 토르발스에 의해 개발된 분산 버전관리 시스템(Distributed Version Control Systems - DVCS)\n컴퓨터 파일의 변경사항을 추적하고 여러명의 사용자들 간에 파일에 대한 작업을 조율하는데 사용하는 형상관리 도구 이다.\nDVCS에서의 클라이언트는 단순히 파일의 마지막 스냅샷을 Checkout 하지 않고, 저장소를 히스토리와 더불어 전부 복제하여, 서버에 문제가 생기더라도 바로 복구가 가능하다.\nGIT과 SVN의 차이 # 단, Git은 기존 SVN(Subversion SVN)와 기능면에서는 유사해 보일 수는 있으나, 아래와 같은 차이를 가지고 있다.\n기능 SVN GIT 파일관리 중앙서버 업로드 로컬저장소 저장 후, 중앙서버 업로드 형상관리 동시 업로드 시 충돌가능 Branch, Merge로 충돌가능성이 낮음 작업관리 모든 작업이 서버에서 진행 작업은 로컬에서 진행 후, 업로드만 서버에 진행 형상관리 히스토리 관리 기능이 부족 히스토리 관리가 용이하게 구현되어있음 즉, Git과 SVN의 가장 큰 차이는 SVN은 서버단에서 작업을 수행하지만, GIT 로컬에서 자기만의 레포지터리를 생성 및, 분기를 이용한 효율적인 형상관리가 가능하다.\n대부분의 버전관리는 시간순으로 진행되나, GIT은 Branch를 통해 관리한다.\nGit은 대부분의 명령을 local에서 진행하기 때문에, 네트워크 등의 영향을 받지 않고, 무결성을 유지함에 보다 용이하다.\n# GIT Status # Git의 상태에는 크게 3가지가 있다. Committed란 데이터가 로컬 데이터베이스에 안전하게 저장됐다는 것을 의미 Modified는 수정한 파일을 아직 로컬 데이터베이스에 커밋하지 않은 상태 Staged란 현재 수정한 파일을 곧 커밋할 것이라고 표시한 상태 위는 Git의 워킹 트리를 나타내며, Git 디렉토리는 Git이 프로젝트의 메타데이터와 객체 데이터베이스를 저장하는 곳을 의미한다.\n워킹트리는 프로젝트의 특정 버전을 Checkout한 것이며, Git 디렉토리는 현재 작업하는 디스크에 존재하고, 디렉토리 안에 압축된 데이터베이스에서 파일을 가져와 워킹 트리를 생성한다.\nGit에서 Staging Area는 Index라고도 하며, Staging Area는 단순한 파일로, commit할 파일들에 대한 정보를 저장한다.\n즉, Git의 기본적으로 Git의 구동동작은 아래와 같다.\n워킹트리에서 파일을 수정 Staging Area에 파일을 Stage 해서 commit할 스냅샷을 만든다. 여기서 추가, 수정, 삭제 등의 작업이 가능하다. Staging Area에 있는 파일들을 commit해서 Git 디렉토리에 영구적인 스냅샷을 저장한다. 결과적으로 Git 디렉토리에 있는 파일들은 Committed 된 상태이며, 파일을 수정하고 Staging Area에 추가했다면 Staged 된 상태라고 할 수 있다.\n여기서 Checkout 후, 수정했지만 Staging Area에 추가되지 않았다면 Modified된 상태이다.\nGit 설정 # Git 최초 설정 # Git을 설치하고 나면 Git의 사용 환경을 적합하게 설정해주어야 한다.\n이는 git config 라는 도구와 설정으로 내용을 확인하고 변경할 수 있다.\n/etc/gitconfig : 시스템의 모든 사용자와 모든 저장소에 적용되는 설정 ( git config \u0026ndash;system ) ~/.gitconfig, ~/.config/git/config : 특정 사용자에게만 적용되는 설정 ( git config \u0026ndash;global ) .git/config : 현재 디렉토리에만 적용되어 있는 설정 ( git config \u0026ndash;local ) 위 설정들은 역순으로 우선시 되어 1 \u0026lt; 2 \u0026lt; 3 과 같은 우선순위를 가지고 있다.\n$ git config --global user.name \u0026#34;John Doe\u0026#34; $ git config --global user.email johndoe@example.com \u0026ndash;global 옵션으로 설정하는 것은 한번이며 (전역), 만약 프로젝트마다 다른 이름과 메일주소를 사용하고 싶다면 \u0026ndash;global 옵션을 빼고 사용한다. # $ git config --list user.name=John Doe user.email=johndoe@example.com color.status=auto color.branch=auto color.interactive=auto color.diff=auto $ git config user.name john Doe 설정했던 옵션들은 git config \u0026ndash;list 명령어로 확인할 수 있다. # Git의 기초 # $ cd $ git init 위 명령어를 통해 .git이라는 하위 디렉터리를 만들며, 이 안에는 저장소에 필요한 뼈대 파일(Skeleton)이 들어 있다. # $ git add *.c $ git add LICENSE $ git commit -m \u0026#39;initial project version\u0026#39; 위 명령어를 통해 GIt 저장소가 생성되었고 파일 버전 관리가 시작되었다. (commit) # $ git clone https://github.com/libgit2/libgit2 $ git clone https://github.com/libgit2/libgit2 \u0026lt;other name\u0026gt; 다른 프로젝트의 참여하고 싶거나, git 저장소를 복사하고 싶을 때, git clone 명령어를 사용한다. Subversion과 같은 VCS에 익숙한 사용자에게는 \u0026ldquo;Checkout\u0026rdquo; 이 아닌, \u0026ldquo;clone\u0026rdquo; 이라는 점이 다르며, git은 서버에 있는 거의 모든 데이터를 복사한다. 즉, git은 서버의 모든 데이터 및 프로젝트의 히스토리를 전부 받아와, 실제 서버의 디스크가 망가져도, 로컬에서 복구가 가능한 특징을 가진다. (단, 서버설정파일은 제외) # 이제 git 저장소를 만들고(init) 워킹 디렉토리에 Checkout(commit)도 헀다면, 이제는 파일의 스냅샷을 커밋한다. 워킹 디렉토리의 파일은 크게 Tracked(관리대상)과 Untracked(비관리대상)으로 나뉘며, Tracked 파일은 이미 스냅샷에 포함돼 있던 파일(레포지터리에 있던)이다. Tracked 파일은 다시 Unmodified(비수정)와 Modified(수정된), 그리고 Staged(commit으로 저장소에 기록될) 상태로 나뉘어진다. 이 외의 나머지는 untracked파일이며, 이는 워킹 디렉토리에 있는 파일 중 StagingArea에 포함되지 않는 파일이다. 처음 clone을 진행하면, 모든 파일은 Tracked(스냅샷에 포함)파일이지만, Unmodified(수정되지 않았기에)상태이다. 만약 clone 진행 후, 어떤 파일을 수정하게 되면 unmodified -\u0026gt; modified 상태로 상태가 변경되며 실제로 commit을 진행하기 위한 staged 상태를 만들고, staged 상태의 파일을 commit하게 되며, git은 이러한 lifecycle을 반복하게 된다. # $ git status On branch master Your branch is up-to-date with \u0026#39;origin/master\u0026#39;. nothing to commit, working directory clean 위 명령어를 실행하면 현재 하나도 수정되지 않았음을 알려준다. $ echo \u0026#39;My Project\u0026#39; \u0026gt; README $ git status On branch master Your branch is up-to-date with \u0026#39;origin/master\u0026#39;. Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) README nothing added to commit but untracked files present (use \u0026#34;git add\u0026#34; to track) README 파일은 “Untracked”에 속해 있는데 이것은 README 파일이 Untracked 상태라는 것을 의미한다. Git은 Untracked 파일을 아직 스냅샷(커밋)에 넣어지지 않은 파일이라고 본다. git init 명령을 실행한 후, git add (files) 명령을 실행했던 걸 기억할 것이다. 이 명령을 통해 디렉토리에 있는 파일을 추적하고 관리하도록 한다. git add 명령은 파일 또는 디렉토리의 경로를 아규먼트로 받는다. # $ git add README $ git status On branch master Your branch is up-to-date with \u0026#39;origin/master\u0026#39;. Changes to be committed: (use \u0026#34;git reset HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: README Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git checkout -- \u0026lt;file\u0026gt;...\u0026#34; to discard changes in workingdirectory) modified: CONTRIBUTING.md git status 명령을 실행하면 README 파일이 Tracked 상태이면서 commit에 추가될 Staged 상태라는 것이 확인이 가능하다. \u0026ldquo;Changes to be commiteed\u0026rdquo; 에 들어 있는 파일은 Staged 상태라는 것을 의미한다. 즉, commit을 실행하면 add를 실행한 시점의 파일이 commit되어 stage -\u0026gt; git history에 남게된다. CONTRIBUTING.md은 \u0026ldquo;Changes not staged for commit\u0026quot;에 있으며, 이는 수정한 파일이 Tracked 상태이지만 아직 Staged 상태는 아니라는 것이며 이는 add 명령어를 통해 staged에 올릴 수 있음을 의미한다. # $ git add CONTRIBUTING.md $ git status On branch master Your branch is up-to-date with \u0026#39;origin/master\u0026#39;. Changes to be committed: (use \u0026#34;git reset HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: README modified: CONTRIBUTING.md add 후 다시 staus를 입력하면 staged 상태로 올라간 것을 확인할 수 있다. # $ git status -s M README MM Rakefile A lib/git.rb M lib/simplegit.rb ?? LICENSE.txt # 이는 위처럼 status -s 옵션을 통해 간단하게 확인할 수 있으며 앞에 문자는 아래와 같은 의미를 가진다. A : New file M : Modified file MM : 작업 디렉터리 및 스테이지 변경 ?? : Untracked Unmodified 파일을 출력되지 않음 # 파일무시하기 # $ cat .gitignore *.[oa] *~ .gitignore 파일을 만들고 그 안에 무시할 패턴을 적으면, 해당 패턴과 일치하는 파일들은 commit 되지 않는다. .gitignore은 아래와 같은 특징을 가진다. 아무것도 없는 라인이나, #로 시작하는 라인은 무시한다. 표준 Glob 패턴을 사용한다. 이는 프로젝트 전체에 적용된다. 슬래시(/)로 시작하면 하위 디렉토리에 적용되지(Recursivity) 않는다. 디렉토리는 슬래시(/)를 끝에 사용하는 것으로 표현한다. 느낌표(!)로 시작하는 패턴의 파일은 무시하지 않는다 기타 예제는 (gitignore_repo)[https://github.com/github/gitignore]를 참조하자. # 변경사항 확인하기 # $ git diff $ git diff --staged git status 명령은 특정파일의 Staged 상태인지는 확인할 수 있으나, 변경사항은 확인할 수 없다. git diff 명령을 사용하는데 Patch처럼 어떤 라인을 추가했고 삭제했는지가 궁금할 때 사용한다. # $ git log commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test commit a11bef06a3f659402fe7563abf99ad00de2209e6 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Sat Mar 15 10:31:28 2008 -0700 first commit $ git log -p -2 commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number diff --git a/Rakefile b/Rakefile ... $ git log --stat commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number Rakefile | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 ... git log 명령을 실행하면 저장소의 커밋 히스토리를 시간순으로 보여준다. 즉, 가장 최근의 커밋이 가장 먼저 나온다. 그리고 이어서 각 커밋의 SHA-1 체크섬, 저자 이름, 저자 이메일, 커밋한 날짜, 커밋 메시지를 보여준다. -p, \u0026ndash;patch 는 굉장히 유용한 옵션이다. -p 는 각 커밋의 diff 결과를 보여준다. \u0026ndash;stat 옵션으로 각 커밋의 통계 정보를 출력할 수 있다. \u0026ndash;pretty 옵션이다. 이 옵션을 통해 히스토리 내용을 보여줄 때 기본 형식 이외에 여러 가지 중에 하나를 선택할 수 있다. # 회귀 # # $ git commit -m \u0026#39;initial commit\u0026#39; $ git add forgotten_file $ git commit --amend 위는 실수로 파일을 Stage 하는 것을 깜빡하고 빠트린 파일이 있으면 위와 같이 고칠 수 있다. 하지만, 이는 두 번째 commit이 첫 번째 commit이 완전히 뒤집어 쓰는 것(첫 번째 commit은 히스토리가 없어진다)으로 주의가 필요하다. # $ git reset HEAD CONTRIBUTING.md Unstaged changes after reset: M CONTRIBUTING.md $ git status On branch master Changes to be committed: (use \u0026#34;git reset HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) renamed: README.md -\u0026gt; README Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git checkout -- \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: CONTRIBUTING.md $ git status Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git checkout -- \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: CONTRIBUTING.md $ git checkout -- CONTRIBUTING.md $ git status On branch master Changes to be committed: (use \u0026#34;git reset HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) renamed: README.md -\u0026gt; README reset과 staged는 비슷하게 보일 수 있으나, 서로 사용되는 영역이 다른다. reset은 staged영역을 조절하는 데 사용되며, checkout은 주로 브런치 간 이동이나 특정 파일의 변경 내용을 취소하는 데 사용된다. # 리모트 저장소 # # $ git remote -v origin https://github.com/schacon/ticgit (fetch) origin https://github.com/schacon/ticgit (push) remote는 연결되어 있는 저장소를 의미하며, 이는 단지 네트워크 뿐이 아닌 다른 저장소도 의미함을 인지한다. 위 명령어를 통해 현재 연결되어 있는 저장소를 출력할 수 있다. # $ git remote origin $ git remote add pb https://github.com/paulboone/ticgit $ git remote -v origin https://github.com/schacon/ticgit (fetch) origin https://github.com/schacon/ticgit (push) pb https://github.com/paulboone/ticgit (fetch) pb https://github.com/paulboone/ticgit (push) git remote add \u0026lt;단축이름\u0026gt; 으로 원격 저장소를 연격할 수 있다. "},{"id":5,"href":"/devops/docs/Git/Git/git00/","title":"0. Git이란?","section":"Git","content":" GIT # Git이란? # 깃(Git)은 2005년에 리누스 토르발스에 의해 개발된 분산 버전관리 시스템(Distributed Version Control Systems - DVCS)\n컴퓨터 파일의 변경사항을 추적하고 여러명의 사용자들 간에 파일에 대한 작업을 조율하는데 사용하는 형상관리 도구 이다.\nDVCS에서의 클라이언트는 단순히 파일의 마지막 스냅샷을 Checkout 하지 않고, 저장소를 히스토리와 더불어 전부 복제하여, 서버에 문제가 생기더라도 바로 복구가 가능하다.\nGIT과 SVN의 차이 # 단, Git은 기존 SVN(Subversion SVN)와 기능면에서는 유사해 보일 수는 있으나, 아래와 같은 차이를 가지고 있다.\n기능 SVN GIT 파일관리 중앙서버 업로드 로컬저장소 저장 후, 중앙서버 업로드 형상관리 동시 업로드 시 충돌가능 Branch, Merge로 충돌가능성이 낮음 작업관리 모든 작업이 서버에서 진행 작업은 로컬에서 진행 후, 업로드만 서버에 진행 형상관리 히스토리 관리 기능이 부족 히스토리 관리가 용이하게 구현되어있음 즉, Git과 SVN의 가장 큰 차이는 SVN은 서버단에서 작업을 수행하지만, GIT 로컬에서 자기만의 레포지터리를 생성 및, 분기를 이용한 효율적인 형상관리가 가능하다.\n대부분의 버전관리는 시간순으로 진행되나, GIT은 Branch를 통해 관리한다.\nGit은 대부분의 명령을 local에서 진행하기 때문에, 네트워크 등의 영향을 받지 않고, 무결성을 유지함에 보다 용이하다.\n# GIT Status # Git의 상태에는 크게 3가지가 있다. Committed란 데이터가 로컬 데이터베이스에 안전하게 저장됐다는 것을 의미 Modified는 수정한 파일을 아직 로컬 데이터베이스에 커밋하지 않은 상태 Staged란 현재 수정한 파일을 곧 커밋할 것이라고 표시한 상태 위는 Git의 워킹 트리를 나타내며, Git 디렉토리는 Git이 프로젝트의 메타데이터와 객체 데이터베이스를 저장하는 곳을 의미한다.\n워킹트리는 프로젝트의 특정 버전을 Checkout한 것이며, Git 디렉토리는 현재 작업하는 디스크에 존재하고, 디렉토리 안에 압축된 데이터베이스에서 파일을 가져와 워킹 트리를 생성한다.\nGit에서 Staging Area는 Index라고도 하며, Staging Area는 단순한 파일로, commit할 파일들에 대한 정보를 저장한다.\n즉, Git의 기본적으로 Git의 구동동작은 아래와 같다.\n워킹트리에서 파일을 수정 Staging Area에 파일을 Stage 해서 commit할 스냅샷을 만든다. 여기서 추가, 수정, 삭제 등의 작업이 가능하다. Staging Area에 있는 파일들을 commit해서 Git 디렉토리에 영구적인 스냅샷을 저장한다. 결과적으로 Git 디렉토리에 있는 파일들은 Committed 된 상태이며, 파일을 수정하고 Staging Area에 추가했다면 Staged 된 상태라고 할 수 있다.\n여기서 Checkout 후, 수정했지만 Staging Area에 추가되지 않았다면 Modified된 상태이다.\nGit lifecycle # 워킹 디렉토리의 파일은 크게 Tracked(관리대상)과 Untracked(비관리대상)으로 나뉘며, Tracked 파일은 이미 스냅샷에 포함돼 있던 파일(레포지터리에 있던)이다. Tracked 파일은 다시 Unmodified(비수정)와 Modified(수정된), 그리고 Staged(commit으로 저장소에 기록될) 상태로 나뉘어진다. 이 외의 나머지는 untracked파일이며, 이는 워킹 디렉토리에 있는 파일 중 StagingArea에 포함되지 않는 파일이다. 처음 clone을 진행하면, 모든 파일은 Tracked(스냅샷에 포함)파일이지만, Unmodified(수정되지 않았기에)상태이다. 만약 clone 진행 후, 어떤 파일을 수정하게 되면 unmodified -\u0026gt; modified 상태로 상태가 변경되며 실제로 commit을 진행하기 위한 staged 상태를 만들고, staged 상태의 파일을 commit하게 되며, git은 이러한 lifecycle을 반복하게 된다. Git 명령어 정리 표 # 명령어 설명 주요 옵션 및 설명 git add 변경 사항을 스테이징 영역에 추가 .: 모든 변경 사항 추가 git commit 스테이징된 변경 사항을 커밋 -m \u0026quot;message\u0026quot;: 커밋 메시지 추가 git status 현재 작업 상태 확인 - git log 커밋 로그 확인 --oneline: 한 줄 요약 git show 특정 커밋의 변경 사항 및 메타데이터 표시 - git diff 변경 사항 비교 --staged: 스테이징된 변경 사항 비교 git push 로컬 커밋을 원격 저장소에 푸시 origin branch: 특정 브랜치로 푸시 git pull 원격 저장소의 변경 사항을 가져와 병합 --rebase: rebase 방식으로 병합 git clone 원격 저장소를 복제 --depth 1: 얕은 복제 (최신 히스토리만 복제) git branch 브랜치를 관리 (생성, 삭제, 목록 등) -d: 브랜치 삭제, -m: 브랜치 이름 변경 git reflog 모든 참조 로그 확인 - git reset 커밋 취소 또는 되돌리기 --hard: 변경 사항 삭제, --soft: 스테이징 유지 git stash 작업 중인 변경 사항 임시 저장 pop: 저장된 변경 사항 적용, list: 스태시 목록 git checkout 다른 브랜치 또는 커밋으로 전환 -b: 새 브랜치 생성 및 전환 git rebase 브랜치의 기반을 다른 브랜치로 변경 --interactive: 대화형 rebase git cherry-pick 특정 커밋을 현재 브랜치에 적용 - git revert 이전 커밋을 되돌리는 새로운 커밋 생성 - git tag 특정 커밋에 태그 추가 -a: 주석이 있는 태그 생성, -d: 태그 삭제 git blame 각 라인의 마지막 변경 내용 표시 - git fetch 원격 저장소의 변경 사항을 가져오기 --all: 모든 브랜치의 변경 사항 가져오기 git merge 다른 브랜치를 현재 브랜치로 병합 --no-ff: fast-forward 병합 방지, --squash: squash 병합 Git 설정 # Git 최초 설정 # Git을 설치하고 나면 Git의 사용 환경을 적합하게 설정해주어야 한다.\n이는 git config 라는 도구와 설정으로 내용을 확인하고 변경할 수 있다.\n/etc/gitconfig : 시스템의 모든 사용자와 모든 저장소에 적용되는 설정 ( git config \u0026ndash;system ) ~/.gitconfig, ~/.config/git/config : 특정 사용자에게만 적용되는 설정 ( git config \u0026ndash;global ) .git/config : 현재 디렉토리에만 적용되어 있는 설정 ( git config \u0026ndash;local ) 위 설정들은 역순으로 우선시 되어 1 \u0026lt; 2 \u0026lt; 3 과 같은 우선순위를 가지고 있다.\n$ git config --global user.name \u0026#34;John Doe\u0026#34; $ git config --global user.email johndoe@example.com \u0026ndash;global 옵션으로 설정하는 것은 한번이며 (전역), 만약 프로젝트마다 다른 이름과 메일주소를 사용하고 싶다면 \u0026ndash;global 옵션을 빼고 사용한다. # $ git config --list user.name=John Doe user.email=johndoe@example.com color.status=auto color.branch=auto color.interactive=auto color.diff=auto $ git config user.name john Doe 설정했던 옵션들은 git config \u0026ndash;list 명령어로 확인할 수 있다. # Git의 기초 # $ cd $ git init 위 명령어를 통해 .git이라는 하위 디렉터리를 만들며, 이 안에는 저장소에 필요한 뼈대 파일(Skeleton)이 들어 있다. # $ git add *.c $ git add LICENSE $ git commit -m \u0026#39;initial project version\u0026#39; 위 명령어를 통해 GIt 저장소가 생성되었고 파일 버전 관리가 시작되었다. (commit) # $ git clone https://github.com/libgit2/libgit2 $ git clone https://github.com/libgit2/libgit2 \u0026lt;other name\u0026gt; 다른 프로젝트의 참여하고 싶거나, git 저장소를 복사하고 싶을 때, git clone 명령어를 사용한다. Subversion과 같은 VCS에 익숙한 사용자에게는 \u0026ldquo;Checkout\u0026rdquo; 이 아닌, \u0026ldquo;clone\u0026rdquo; 이라는 점이 다르며, git은 서버에 있는 거의 모든 데이터를 복사한다. 즉, git은 서버의 모든 데이터 및 프로젝트의 히스토리를 전부 받아와, 실제 서버의 디스크가 망가져도, 로컬에서 복구가 가능한 특징을 가진다. (단, 서버설정파일은 제외) # # $ git status On branch master Your branch is up-to-date with \u0026#39;origin/master\u0026#39;. nothing to commit, working directory clean 위 명령어를 실행하면 현재 하나도 수정되지 않았음을 알려준다. $ echo \u0026#39;My Project\u0026#39; \u0026gt; README $ git status On branch master Your branch is up-to-date with \u0026#39;origin/master\u0026#39;. Untracked files: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed) README nothing added to commit but untracked files present (use \u0026#34;git add\u0026#34; to track) README 파일은 “Untracked”에 속해 있는데 이것은 README 파일이 Untracked 상태라는 것을 의미한다. Git은 Untracked 파일을 아직 스냅샷(커밋)에 넣어지지 않은 파일이라고 본다. git init 명령을 실행한 후, git add (files) 명령을 실행했던 걸 기억할 것이다. 이 명령을 통해 디렉토리에 있는 파일을 추적하고 관리하도록 한다. git add 명령은 파일 또는 디렉토리의 경로를 아규먼트로 받는다. # $ git add README $ git status On branch master Your branch is up-to-date with \u0026#39;origin/master\u0026#39;. Changes to be committed: (use \u0026#34;git reset HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: README Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git checkout -- \u0026lt;file\u0026gt;...\u0026#34; to discard changes in workingdirectory) modified: CONTRIBUTING.md git status 명령을 실행하면 README 파일이 Tracked 상태이면서 commit에 추가될 Staged 상태라는 것이 확인이 가능하다. \u0026ldquo;Changes to be commiteed\u0026rdquo; 에 들어 있는 파일은 Staged 상태라는 것을 의미한다. 즉, commit을 실행하면 add를 실행한 시점의 파일이 commit되어 stage -\u0026gt; git history에 남게된다. CONTRIBUTING.md은 \u0026ldquo;Changes not staged for commit\u0026quot;에 있으며, 이는 수정한 파일이 Tracked 상태이지만 아직 Staged 상태는 아니라는 것이며 이는 add 명령어를 통해 staged에 올릴 수 있음을 의미한다. # $ git add CONTRIBUTING.md $ git status On branch master Your branch is up-to-date with \u0026#39;origin/master\u0026#39;. Changes to be committed: (use \u0026#34;git reset HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: README modified: CONTRIBUTING.md add 후 다시 staus를 입력하면 staged 상태로 올라간 것을 확인할 수 있다. # $ git status -s M README MM Rakefile A lib/git.rb M lib/simplegit.rb ?? LICENSE.txt # 이는 위처럼 status -s 옵션을 통해 간단하게 확인할 수 있으며 앞에 문자는 아래와 같은 의미를 가진다. A : New file M : Modified file MM : 작업 디렉터리 및 스테이지 변경 ?? : Untracked Unmodified 파일을 출력되지 않음 # 파일무시하기 # $ cat .gitignore *.[oa] *~ .gitignore 파일을 만들고 그 안에 무시할 패턴을 적으면, 해당 패턴과 일치하는 파일들은 commit 되지 않는다. .gitignore은 아래와 같은 특징을 가진다. 아무것도 없는 라인이나, #로 시작하는 라인은 무시한다. 표준 Glob 패턴을 사용한다. 이는 프로젝트 전체에 적용된다. 슬래시(/)로 시작하면 하위 디렉토리에 적용되지(Recursivity) 않는다. 디렉토리는 슬래시(/)를 끝에 사용하는 것으로 표현한다. 느낌표(!)로 시작하는 패턴의 파일은 무시하지 않는다 기타 예제는 (gitignore_repo)[https://github.com/github/gitignore]를 참조하자. # 변경사항 확인하기 # $ git diff $ git diff --staged git status 명령은 특정파일의 Staged 상태인지는 확인할 수 있으나, 변경사항은 확인할 수 없다. git diff 명령을 사용하는데 Patch처럼 어떤 라인을 추가했고 삭제했는지가 궁금할 때 사용한다. # $ git log commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Sat Mar 15 16:40:33 2008 -0700 removed unnecessary test commit a11bef06a3f659402fe7563abf99ad00de2209e6 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Sat Mar 15 10:31:28 2008 -0700 first commit $ git log -p -2 commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number diff --git a/Rakefile b/Rakefile ... $ git log --stat commit ca82a6dff817ec66f44342007202690a93763949 Author: Scott Chacon \u0026lt;schacon@gee-mail.com\u0026gt; Date: Mon Mar 17 21:52:11 2008 -0700 changed the version number Rakefile | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) commit 085bb3bcb608e1e8451d4b2432f8ecbe6306e7e7 ... git log 명령을 실행하면 저장소의 커밋 히스토리를 시간순으로 보여준다. 즉, 가장 최근의 커밋이 가장 먼저 나온다. 그리고 이어서 각 커밋의 SHA-1 체크섬, 저자 이름, 저자 이메일, 커밋한 날짜, 커밋 메시지를 보여준다. -p, \u0026ndash;patch 는 굉장히 유용한 옵션이다. -p 는 각 커밋의 diff 결과를 보여준다. \u0026ndash;stat 옵션으로 각 커밋의 통계 정보를 출력할 수 있다. \u0026ndash;pretty 옵션이다. 이 옵션을 통해 히스토리 내용을 보여줄 때 기본 형식 이외에 여러 가지 중에 하나를 선택할 수 있다. # 회귀 # # $ git commit -m \u0026#39;initial commit\u0026#39; $ git add forgotten_file $ git commit --amend 위는 실수로 파일을 Stage 하는 것을 깜빡하고 빠트린 파일이 있으면 위와 같이 고칠 수 있다. 하지만, 이는 두 번째 commit이 첫 번째 commit이 완전히 뒤집어 쓰는 것(첫 번째 commit은 히스토리가 없어진다)으로 주의가 필요하다. # $ git reset HEAD CONTRIBUTING.md Unstaged changes after reset: M CONTRIBUTING.md $ git status On branch master Changes to be committed: (use \u0026#34;git reset HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) renamed: README.md -\u0026gt; README Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git checkout -- \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: CONTRIBUTING.md $ git status Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git checkout -- \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: CONTRIBUTING.md $ git checkout -- CONTRIBUTING.md $ git status On branch master Changes to be committed: (use \u0026#34;git reset HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage) renamed: README.md -\u0026gt; README reset과 staged는 비슷하게 보일 수 있으나, 서로 사용되는 영역이 다른다. reset은 staged영역을 조절하는 데 사용되며, checkout은 주로 브런치 간 이동이나 특정 파일의 변경 내용을 취소하는 데 사용된다. # 리모트 저장소 # # $ git remote -v origin https://github.com/schacon/ticgit (fetch) origin https://github.com/schacon/ticgit (push) remote는 연결되어 있는 저장소를 의미하며, 이는 단지 네트워크 뿐이 아닌 다른 저장소도 의미함을 인지한다. 위 명령어를 통해 현재 연결되어 있는 저장소를 출력할 수 있다. # $ git remote origin $ git remote add pb https://github.com/paulboone/ticgit $ git remote -v origin https://github.com/schacon/ticgit (fetch) origin https://github.com/schacon/ticgit (push) pb https://github.com/paulboone/ticgit (fetch) pb https://github.com/paulboone/ticgit (push) git remote add \u0026lt;단축이름\u0026gt; 으로 원격 저장소를 연격할 수 있다. "},{"id":6,"href":"/devops/docs/Kubernetes/k8s/k8s/","title":"0. Kubernetes","section":"Kubernetes","content":" Kubernetes # Kubernetes # # "},{"id":7,"href":"/devops/docs/Kubernetes/k8s/k8s00/","title":"0. Kubernetes","section":"Kubernetes","content":" Kubernetes # Kubernetes # # kubernetes란 컨테이너화된 워크로드와 서비스를 관리하기 위한 확장가능한 오픈소스 플랫폼이라 할 수 있다. IaC기반으로 선언적 구성과 자동화의 용이하며, 빠르게 성장하는 생태계를 가지고 있다. # # Kubernets가 대두되는 이유 # # 위 그림은 Traditional Deployment (전통적인 배포), Virtualized Deployment (가상화 배포), Container Deployment(컨테이너 배포)로 나뉘어지고 있으며 각 배포들은 하기와 같은 특징들을 가지고 있다.\n전통적인 배포: 물리 서버에서 배포가 진행되며, 리소스의 한계를 전의할 방법이 없어 성능저하와 여러 장애를 유발 가능성이 존재 가상화 배포: 전통적인 배포에 해결책으로 물리서버 위에 가상화서버(별도의 격리)를 올려 리소스의 한계를 타파하고, 효율을 극대화시킨다. 컨테이너 배포: 컨테이너와 VM은 유사하지만 격리 속성을 완화하여 애플리케이션 간에 운영체제(OS)를 공유하는 특징이 있으며, 프로세스단에서 작동하여 비교적 가볍다고 여겨지며, 기본 인프라와의 종속성을 끊어, 클라우드나 OS 배포본에 상관없이 이식이 가능한 장점을 가지고 있다. 즉, Kubernetes는 컨테이너 배포를 보다 용이하게 관리할 수 있게 해주는 워크로드 관리 플랫폼으로, 현재 관련 기술의 표준으로 자리잡고 있다.\n이러한 kubernetes는 다음과 같은 기능을 제공한다.\n서비스 디스커버리와 로드 밸런싱: 쿠버네티스는 자체 DNS 이름을 사용하거나 자체 IP주소를 사용하여 컨테이너를 노출할 수 있으며, 로드 밸런싱을 배포하여 안정적인 배포가 가능 스토리지 오케스트레이션: 로컬 저장소, 공용 클라우드 공급자와 같이 저장소 시스템의 자동 탑재가 가능 자동화된 롤아웃과 롤백: 사용자의 요구사항에 맞춰 오케스트레이션 서비스의 사용이 가능 자동화된 빈 패킹: 컨테이너화된 작업을 실행하는 데, 클러스터 노드를 사용하여 효율적인 사용이 가능토록 함ㅁ 자동화된 복구: 실패한 컨테이너는 다시시작 및 교체하여 자동으로 형상관리를 진행 시크릿과 구성 관리: OAuth, SSH와 같은 중요한 정보를 저장하고 관리가 가능 # # kubernetes의 요소 # 쿠버네티스의 컴포넌트(요소)는 위 그림의 컴포넌트들을 가진다. 쿠버네티스 클러스터는 컨테이너화된 어플리케이션을 실행하는 노드라고 칭하는 워커머신의 집합을 최소한 한 개를 가지게 된다. # Control Plane # 컨트롤 플레인 클러스터에관한 결정적인 결정( 스케쥴링 )을 수행하고 이벤트( 배포 )에 대한 트리거를 감지하고 반응하는 역할을 수행한다. 컨트롤 플레인 클러스터는 어느 노드에게서나 사용이 가능하지만, 보통 컨트롤 프레인 클러스터가 올려진 노드에는 다른 파드를 생성하지 않는다. 컨트롤 플레인은 아래의 컴포넌트들을 포함하고 있다. # Kube-apiserver # API 서버는 쿠버네티스의 API를 노출하는 쿠버네티스의 컨트롤 컴포넌트이다. 즉, API 서버는 쿠버네티스 컴포넌트의 프론트 엔드라 할 수 있다. kube-apiserver은 수평적으로 확장되도록 디자인이 되어 있어, 더 많은 인스턴스를 배포할 수 있다. 이는 여러 kube-apiserver 인스턴스를 실행하고, 인스턴스간의 트래픽을 균형있게 조절할 수 있게한다. # etcd # 모든 클러스터 데이터를 담는 쿠버네티스 뒷단의 저장소로 사용되는 일관성, 고가용성 키-값 저장소이다. 즉 쿠버네티스의 모든 정보들은 etcd에 키-값 값으로 저장된다. # kube-scheduler # 쿠버 스케쥴러는 노드가 배정되지 않은 새로운 파드를 제공하고, 실행할 노드를 선택하는 컴포넌트이다. 스케쥴링 결정을 위해서 고려되는 여러 요소 ( 리소스, HW, SW, Roul etc )를 모두 포함한다. # kube-controller-manager # 컨트롤러의 프로세스를 실행하는 컴포넌트로, 논리적으로 각 컨트롤러는 분리된 프로세스이지만, 복잡성을 낮추기 위해 단일 바이너리 파일로 컴파일되어진다. 해당 컨트롤러는 아래와 같은 종류를 가지고 있다. 노드 컨트롤러: 노드가 다운되었을 때 통지와 대응에 관한 대응 잡 컨트롤러: 일회성 작업을 나타내는 잡 오브젝트를 감시한 다음, 해당 작업을 완료할 때까지 동작하는 파드를 생성 엔드포인트슬라이스 컨트롤러: 서비스와 파드 사이의 연결고리를 제공하기 위한 엔드포인트슬라이스 오브젝트를 생성 서비스어카운트 컨트롤러: 새로운 네임스페이스에 대한 기본 서비스어카운트를 생성 # cloud-controller-manager # 클라우드별 컨트롤 로직을 포함하는 쿠버네티스의 컴포넌트로, CSP의 API를 연결하고 해당 플랫폼과 상호작용하는 역할을 수행한다. 이는 로컬에서 실행 중인 경우 해당 컴포넌트는 존재되지 않으며, 존재할 경우 하기의 의존성을 가질 수 있다. 노드 컨트롤러: 노드의 응답이 멈춘 후 클라우드 상에서 삭제되었는 지 판별하기 위해 사업자에게 제공되는 정보 라우트 컨트롤러: 기본 클라우드 인프라에 경로를 구성하는 것 서비스 컨트롤러: 클라우드 제공 사업자 로드밸런서를 생성, 업데이트, 삭제하는 것 # node component # 노트 컴포넌트는 동작 중인 파드를 유지시키고 쿠버네티스 런타임 환경을 제공하며, 모든 노드 상에서 동작한다. # kubelet # 각 노드에서 실행되는 에이전트로, 각 파드에서 컨테이너가 확실하게 동작하도록 관리하는 역할을 수행한다. 단, 쿠버네티스를 통해서 생성된 컨테이너만을 관리하며, 그 외 컨테이너는 관리하지 않는다. # kube-proxy # 쿠버 프록시는 각 노드에서 실행되는 네트워크 프록시로, 쿠버네티스 서비스 개념의 구현부분이다. 즉, 쿠버 프록시는 각 노드의 네트워크 규칙을 유지 및 관리하며, 해당 규칙으로 내부 네트워크 세션이나 클러스터 바깥 파드로 네트워크 통신을 가능토록 한다. 운영 체제에 가용한 패킷 필터링이 있는 경우에는 이를 사용하고, 그렇지 않으면 자체 포워드를 사용한다. # 애드온 # 애드온은 쿠버네티스 리소스(데몬셋, 디폴로이먼트 등)을 이용하여 클러스터 기능을 구현하며, 클러스터 단위의 기능을 제공한다. 애드온에 대한 네임스페이스 리소스는 kube-system 네임스페이스에 속한다. # DNS # 모든 쿠버네티스 요소들을 클러스터의 DNS를 갖추어야만 한다. 클러스터 DNS는 구성환경 내 다른 DNS 서버와 더불어, 쿠버네티스 서비스를 위해 DNS 레코드를 제공해 주는 DNS 서버를 의미한다. # 웹 UI ( 대시보드 ) # 대시보드는 쿠버네티스 클러스터를 위한 웹 기반 UI이며, 웹을 통해 관리 및 문제 해결을 도와준다. # 컨테이너 리소스 모니터링 # 중앙 데이터베이스 내의 컨테이너들에 대한 포괄적인 시게열 매트릭스를 기록하고 그 데이터를 열함하기 위한 UI를 제공해 준다. # 클러스터-레벨 로깅 # 검색/ 열람 인터페이스와 함께 중앙 로그 저장소에 컨테이너 로그를 저장하는 역할을 수행한다. "},{"id":8,"href":"/devops/docs/Kubernetes/k8s/k8s01/","title":"1. Kubernetes Object","section":"Kubernetes","content":" Kubernetes Object # Kubernetes Object # 쿠버네티스의 오브젝트란 시스템에서 영속성을 가지는 명세서를 의미하며, 이는 아래와 같이 기술할 수 있다.\n어떤 노드에서 어떤 파드 및 어플리케이션의 동작 유무 해당 어플리케이션의 사용가능 리소스 해당 어플레케이션의 재구동 정책, 업그레이드, 가용성 등의 대한 동작 정책 즉, 쿠버네티스 오브젝트란 하나의 의도를 담은 명세서를 의미하며, 이를 생성하게되면 쿠버네티스 상에서는 해당 오브젝트의 영속성을 보장하기 위해 지속적으로 동작할 것이고, 이를 통해 하나 혹은 몇몇의 오브젝트로 사용자의 워크로드의 관리가 보다 쉽게 가능해진다.\n# 오브젝트의 Spec, Status # 대부분의 쿠버네티스 오브젝트는 구성을 결정해주는 오브젝트 필드를 포함하게 되는 데, 이는 spec과 status다. spec은 해당 오브젝트를 생성할 때 리소스에 필요한 요청사항을 제공하여 설정한다. status는 쿠버네티스와 요소간 제공되고 업데이트된 오브젝트의 현재 상태를 의미한다. # 오브젝트 기술하기 # apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: selector: matchLabels: app: nginx replicas: 2 # tells deployment to run 2 pods matching the template template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 위는 .yaml 파일을 이용하여 디플로이먼트를 생ㅅ어하기 위한 방식으로 kubectl을 사용하여 쿠버네티스 API를 호출하여 반영시키는 방식이다. $ kubectl apply -f deployment.yaml deployment.apps/nginx-deployment created 위와 같이 생성하고자 하는 오브젝트에 대한 .yaml 파일 내에 해당 값을을 설정해줘야 한다.\napiVersion: 해당 파일의 오브젝트를 사용하기 위한 쿠버네티스의 API 버전이 어떤 것인지 kind: 어떤 종류의 오브젝트를 생성하려는 지 metadata: 이름, 문자열, UID, namespace 등을 포함하여 오브젝트를 구분하게 해 줄 데이터 spec: 오브젝트의 상태를 기술 spec은 각 오브젝트마다 (kind)마다 다르기에 각자 다른 템플릿이 존재하고, 이는 요청에 따라 값이 달라지기 때문에 많은 경험을 필요로 한다.\n# # Object Management # # 오브젝트를 관리하는 방법으로는 아래와 같이 명령형 커맨드, 명령형 오브젝트 구성, 선언형 오브젝트 구성으로 나뉘어져 있다. 관리기법 대상 권장 환경 지원하는 작업자 수 학습 난이도 명령형 커맨드 활성 오브젝트 개발 환경 1+ 낮음 명령형 오브젝트 구성 개별 파일 프로덕션 환경 1 보통 선언형 오브젝트 구성 파일이 있는 디렉터리 프로덕션 환경 1+ 높음 # 명령형 커맨드 # $ kubetl create deployment nginx --image nginx 명령형 커맨드의 경우 클러스터 내 활성 오브젝트를 대상으로 직접 동작시키며, 사용자는 실행할 작업을 인수 또는 플래그로 kubectl 커맨드를 호출한다. 이는 일회성 작업의 개념으로 추천하지 않는 방법이며, 직접적인 영향을 끼치고, 이전 구성에 대한 이력을 제공해주지 않아 문제가 발생시 대응이 어렵다. # 명령형 오브젝트 구성 # 명령형 오브젝트 구성은 kubectl, 선택적 플래그, 파일이름을 사용하여 이미 정의된 파일을 통해 생성한다. $ cat nginx.yaml apiVersion: apps/v1 kind: Deployment metadata: name: nginx-deployment spec: selector: matchLabels: app: nginx replicas: 2 # tells deployment to run 2 pods matching the template template: metadata: labels: app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 $ kubectl create -f nginx.yaml $ kubectl delete -f nginx.yaml -f redis.yaml 오브젝트를 파일로 관리함으로써, Git 과 같은 소스 컨트롤 시스템에 보관이 가능하다. 관련 히스토리 및 감사의 추적이 보다 쉽고, 프로세스들과의 통합에 유용하다. # 선언형 오브젝트 구성 # 선언형 오브젝트는 명령형 오브젝트와 동일하게 오브젝트 구성 파일을 대상으로 작동시키지만, 선연형 오브젝트는 한 파일의 관련 오브젝트들이 명시되어 있는 반면, 선언형 오브젝트는 각 오브젝트 구성파일이 나뉘어져 있다는 점에 차이가 있다. $ kubectl diff -f configs/ $ kubectl apply -f configs/ $ kubectl diff -R -f configs/ $ kubectl apply -R -f configs/ # 레이블과 셀렉터 # # 레이블 # 레이블은 파드와 같은 오브젝트에 첨부된 키와 값의 쌍이며, 이는 오브젝트의 특성을 식별하는 데 사용되어 사용자에게는 중요하지만 코어 시스템에 직접적인 의미는 없다. \u0026#34;metadata\u0026#34;: { \u0026#34;labels\u0026#34;: { \u0026#34;key1\u0026#34; : \u0026#34;value1\u0026#34;, \u0026#34;key2\u0026#34; : \u0026#34;value2\u0026#34; } } 레이블은 UI와 CLI에서 효율적인 쿼리를 사용하고 검색에 사용하기 적합하며, 식별되지 않는 정보는 어노테이션으로 기록해야 한다. 레이블은 키와 값 쌍으로 이루어져 있으며, 유효한 레이블 키에는 슬래시(/)로 구분된다. 접두사를 생략한 레이블은 개인용으로 간주하며, 시스템 컴포넌트(kube-scheduler, kube-controller-manager, kube-apiserver, kubectl) 또는 다른 타사의 자동화 구성요서의 접두사를 지정해야한다. kubernetes.io/ 와 k8s.io/ 접두사는 쿠버네티스의 핵심 컴포넌트로 에약되어 있다.\napiVersion: v1 kind: Pod metadata: name: label-demo labels: environment: production app: nginx spec: containers: - name: nginx image: nginx:1.14.2 ports: - containerPort: 80 위는 environment: production, app: nginx 2개의 레이블이 있는 구성 파일이다. 위처럼 이름과 UID와 다르게 레이블은 고유하지 않으며, 일반적으로 라벨과 비슷한 역할을 한다. 사용자는 레이블 셀렉터를 통해 해당 오브젝트들을 식별할 수 있다. # 집합성 기준 요건 # environment in (production, qa) # (enviromen:prodction), (environment:qa) 리소스를 선택한다. / = tier notin (frontend, backend) # (tier:frontend), (tier:backend) 리소스를 제외하고 선택한다. / != partition # partition을 포함한 모든 리소스를 선택한다. !partition # partition을 포함하지 않는 모든 리소스를 선택한다. 집합성 기준은 위와 같이 in, notion, exists 의 3개 연산자를 지원한다. # 셀렉터 # selector: matchLabels: component: redis matchExpressions: - {Key: tier, operator: In, Values: [cache]} - {key: environment, operator: NotIn, values: [dev]} services에서 지정하는 파드 집합은 레이블 셀럭터로 정의한다. 위와 동일하게 replicationcontrollers가 관리하는 파드의 오브젝트 구릅도 레이블 셀렉터로 정의한다. stateDiagram-v2 POD ReplicaSet --\u003e POD Deployment --\u003e ReplicaSet DaemonSet --\u003e POD StatefulSet --\u003e POD Job --\u003e POD Cronjob --\u003e POD "},{"id":9,"href":"/devops/docs/Kubernetes/kube/book/k8s/","title":"1. Kubernetes_환경구성","section":"Book Study","content":" Kubernetes # Kubernetes # ctrl # timedatectl set-timezone Asia/Seoul apt -y install nginx libnginx-mod-stream echo \u0026#39; stream { upstream k8s-api { server 1.0.0.200:6443; } server { listen 6443; proxy_pass k8s-api; } } \u0026#39; \u0026gt;\u0026gt; /etc/nginx/nginx.conf unlink /etc/nginx/sites-enabled/default systemctl enable --now nginx curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /\u0026#34; | tee /etc/apt/sources.list.d/kubernetes.list apt update apt -y install kubectl mkdir -p $HOME/.kube wget https://raw.githubusercontent.com/projectcalico/calico/master/manifests/calico.yaml # install kubectl bash apt -y install bash-completion source /usr/share/bash-completion/bash_completion kubectl completion bash | tee /etc/bash_completion.d/kubectl \u0026gt; /dev/null echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.bashrc echo \u0026#39;complete -o default -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.bashrc exec bash controlplan # timedatectl set-timezone Asia/Seoul apt -y install haproxy keepalived containerd echo \u0026#39; # Frontend for Kubernetes API frontend kubernetes-api bind 1.0.0.200:6443 # CP VIP와 포트를 바인딩 default_backend kube_apiserver # Backend for Kubernetes API backend kube_apiserver balance roundrobin # 또는 preferred server 방식 server cp0 1.0.0.201:6443 check \u0026#39; \u0026gt;\u0026gt; /etc/haproxy/haproxy.cfg echo \u0026#39; global_defs { router_id LVS_MASTER / LVS_SLAVE } vrrp_instance VI_1 { state MASTER interface ens19 # Network interface to bind the VIP virtual_router_id 51 priority 101 # Higher priority for Master advert_int 1 authentication { auth_type PASS auth_pass 1234 } virtual_ipaddress { 1.0.0.200 # Virtual IP to be shared } } \u0026#39; \u0026gt;\u0026gt; /etc/keepalived/keepalived.conf systemctl enable --now haproxy keepalived timedatectl set-timezone Asia/Seoul apt -y install containerd mkdir /etc/containerd containerd config default | tee /etc/containerd/config.toml sed -i \u0026#34;s|^\\( *sandbox_image *= *\\).*|\\1\\\u0026#34;registry.k8s.io/pause:3.9\\\u0026#34;|\u0026#34; /etc/containerd/config.toml sed -i \u0026#34;s|^\\( *SystemdCgroup *= *\\).*|\\1true|\u0026#34; /etc/containerd/config.toml systemctl enable --now containerd.service cat \u0026gt; /etc/sysctl.d/99-k8s-cri.conf \u0026lt;\u0026lt;EOF net.bridge.bridge-nf-call-iptables=1 net.bridge.bridge-nf-call-ip6tables=1 net.ipv4.ip_forward=1 EOF modprobe overlay; modprobe br_netfilter echo -e overlay\\\\nbr_netfilter \u0026gt; /etc/modules-load.d/k8s.conf echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward sysctl -p swapoff -a sed -i \u0026#39;/\\/swap.img/s/^/#/\u0026#39; /etc/fstab # disable apparmor profiles below apparmor_parser -R /etc/apparmor.d/runc apparmor_parser -R /etc/apparmor.d/crun ln -s /etc/apparmor.d/runc /etc/apparmor.d/disable/ ln -s /etc/apparmor.d/crun /etc/apparmor.d/disable curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /\u0026#34; | tee /etc/apt/sources.list.d/kubernetes.list apt update apt -y install kubeadm kubelet kubectl kubeadm init --control-plane-endpoint=ctrl-main --apiserver-advertise-address=9.9.9.201 --pod-network-cidr=192.168.0.0/16 --cri-socket=unix:///run/containerd/containerd.sock scp /etc/kubernetes/admin.conf ohc@ctrl:/tmp kubeadm init --control-plane-endpoint=ctrl --apiserver-advertise-address=10.1.61.170 --pod-network-cidr=192.168.0.0/16 --cri-socket=unix:///run/containerd/containerd.sock dataplan # timedatectl set-timezone Asia/Seoul apt -y install containerd mkdir /etc/containerd containerd config default | tee /etc/containerd/config.toml sed -i \u0026#34;s|^\\( *sandbox_image *= *\\).*|\\1\\\u0026#34;registry.k8s.io/pause:3.9\\\u0026#34;|\u0026#34; /etc/containerd/config.toml sed -i \u0026#34;s|^\\( *SystemdCgroup *= *\\).*|\\1true|\u0026#34; /etc/containerd/config.toml systemctl enable --now containerd.service cat \u0026gt; /etc/sysctl.d/99-k8s-cri.conf \u0026lt;\u0026lt;EOF net.bridge.bridge-nf-call-iptables=1 net.bridge.bridge-nf-call-ip6tables=1 net.ipv4.ip_forward=1 EOF echo 1 \u0026gt; /proc/sys/net/ipv4/ip_forward sysctl -p modprobe overlay; modprobe br_netfilter echo -e overlay\\\\nbr_netfilter \u0026gt; /etc/modules-load.d/k8s.conf swapoff -a sed -i \u0026#39;/\\/swap.img/s/^/#/\u0026#39; /etc/fstab # disable apparmor profiles below apparmor_parser -R /etc/apparmor.d/runc apparmor_parser -R /etc/apparmor.d/crun ln -s /etc/apparmor.d/runc /etc/apparmor.d/disable/ ln -s /etc/apparmor.d/crun /etc/apparmor.d/disable curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /\u0026#34; | tee /etc/apt/sources.list.d/kubernetes.list apt update apt -y install kubeadm kubelet kubectl "},{"id":10,"href":"/devops/docs/Kubernetes/kube/patten/k8s/","title":"1. 분산 기본 요소","section":"쿠버네티스 패턴","content":"\n책의 주요구성 # 패턴명\n각 패턴에는 이름이 붙어 있는데, 이 패턴명은 각 장의 제목이기도 하다. 패턴명은 패턴 언어의 핵심이다. 문제\n더 넓은 맥락을 제공하고 패턴 영역을 자세하게 설명한다. 해결책\n패턴이 쿠버네티스 고유의 방식으로 어떻게 문제를 해결하는지에 관한 내용을 다룬다. 또한, 주어진 패턴의 일부분이거나 관련성 있는 다른 패턴들에 대한 상호 참조도 포함한다. 정리\n주어진 맥락에 대한 해결책의 장단점에 대해 정리한다. 참고자료\n마지막 절로서, 패턴과 관련된 부가 정보 출처를 제공한다. 클라우드 네이티브 # 쿠버네티스 같은 클라우드 네이티브 플랫폼에서 가장 인기 있는 애플리케이션 아키텍처는 마이크로서비스 microservice 방식으로, 해당 방식은 소프트웨어 개발 기술은 운영 복잡성을 보다 효율적으로 관리할 수 있게 해줌 바운디드 컨텍스트 개념은 대형 모델들을 각 컴포넌트로 분리해 다루고, 애그리깃 개념은 바운디드 컨텍스트를 트랜잭션 경계를 갖는 모듈로 그룹화는 개념에 근거 개념 Bounded Context (바운디드 컨텍스트) Aggregate (애그리깃) 정의 시스템 내에서 모델이 의미 있게 구분되는 영역을 나타냄. 각 바운디드 컨텍스트는 독립적으로 설계되고 이해될 수 있는 도메인 모델을 갖음. 도메인 모델의 집합으로, 특정 엔티티와 그와 관련된 엔티티들을 함께 묶어서 일관성을 유지하는 단위. 목표 도메인 모델을 명확하게 분리하여, 각 모델이 서로 다른 컨텍스트에서 다르게 해석되지 않도록 함. 도메인 내에서 불변성을 보장하고, 하나의 트랜잭션 내에서 일관성을 유지하기 위한 집합체. 구성 요소 여러 개의 유비쿼터스 언어를 사용할 수 있으며, 각각 독립적인 도메인 모델을 가질 수 있음. 엔티티, 값 객체, 루트 엔티티가 포함되어, 일관성 있게 트랜잭션을 처리하는 집합체. 책임 특정 도메인의 경계를 정의하고, 해당 경계 내에서만 특정 모델과 언어를 사용함. 비즈니스 규칙을 캡슐화하고, 애그리깃 루트(AGGREGATE ROOT) 엔티티를 통해 다른 엔티티에 대한 접근을 제어. 설계 및 구현 시스템 내에서 분리된 여러 컴포넌트를 만들고, 각 컴포넌트 내에서 독립적인 도메인 모델을 정의하고 관리. 트랜잭션 일관성 유지, 객체 간 관계를 캡슐화하고, 애그리깃 루트를 통해 도메인 객체를 조작. 통합 다른 바운디드 컨텍스트와의 통합은 명확한 인터페이스와 계약을 통해 이루어짐. 애그리깃 내부에서의 상태 변경은 루트를 통해서만 이루어지며, 다른 애그리깃과의 상호작용은 제한됨. 일관성 관리 각 바운디드 컨텍스트 내에서 일관성 있게 도메인 모델을 관리하며, 바운디드 컨텍스트 간의 일관성은 느슨하게 유지될 수 있음. 애그리깃 내부의 엔티티들 간의 일관성은 반드시 애그리깃 루트를 통해 보장되며, 외부 시스템과의 일관성은 다른 방식으로 처리. 예시 전자상거래 시스템의 주문과 결제는 각각 다른 바운디드 컨텍스트일 수 있음. 주문 애그리깃: 주문 엔티티, 주문 항목 엔티티, 결제 엔티티 등이 애그리깃의 일관성을 유지하면서 묶여 있음. ()[]\n가장 낮은 코드 레벨 code level 에서는, 정의된 모든 변수, 생성한 모든 메소드, 인스턴스화하기로 결정한 모든 클래스가 장기간의 애플리케이션 유지 관리에 중요한 역할을 수행\n도메인 주도 설계 domain-driven design 란 아키텍처를 가능한 한 현실세계에 가깝게 맞추려는 의도로 비즈니스 관점에서 소프트웨어를 설계하는 방법\n마이크로서비스 아키텍처 방식 microservices architectural style 은 매우 빠르게 발전해 표준이 되었으며, 변화하는 분산 애플리케이션 설계에 대한 소중한 원칙과 실용적인 방법을 제공\n컨테이너 contalner 는 분산 애플리케이션을 패키징하고 실행하는 표준 방법으로 빠르게 적용되었다. 훌륭한 클라우드 네이티브 요소인 모듈식의 재사용 가능한 컨테이너를 만드는 것이 또 하나의 기본 전제조건\n에서는 클린 코드나 도메인 주도 설계 , 마이크로서비스에 관해서는 다루지 않으며, 그보다는 컨테이너 오케스트레이션 문제를 해결할 패턴과 실용적인 방법만을 집중해서 다룬다.\n분산 기본 요소 # 기존 객체 지향 프로그래밍 세계에는 클래스와 객체, 패키지, 상속, 캡슐화, 다형성 Poymorphism 같은 개념이 있다. 자바 런타임은 객체와 애플리케이션의 수명주기 관리 방법에 대해 특정 기능을 제공하고 보장한다.\n자바 언어와 자바 가상 머신 (VM) 은 애플리케이션을 생성하기 위한 로컬 인프로세스 in-process 빌딩 블록을 제공\n쿠버네티스는 멀티 노드와 멀티 프로세스로 퍼져 있는 분산 시스템을 구축하기 위한 새로운 분산 기본 요소와 런타임을 제공함으로써 이 빌딩 블록이라는 널리 알려진 사고방식에 완전히 새로운 관점을 추가\n개념 로컬 기본 요소 분산 기본 요소 캡슐화 동작 클래스 컨테이너 이미지 인스턴스화 동작 객체 컨테이너 재사용 단위 jar 파일 컨테이너 이미지 컴포지션 (Composition) 클래스 A 가 클래스 B 를 포함 사이드카 패턴 상속 클래스 A 가 클래스 B 를 확장 \u0026lsquo;FROM 부모 이미지\u0026rsquo; 로 만든 컨테이너 이미지 배포 단위 jar/.war/.ear 파드 빌드타임 / 런타임 격리 모듈 , 패키지 , 클래스 네임스페이스 , 파드 , 컨테이너 초기화 필요 조건 생성자 초기화 컨테이너 초기화 직후 트리거 Init 메소드 postStart 삭제 직전 트리거 Destroy 메소드 preStop 정리 (Cleanup) 절차 finalize(), 셧다운 훅 Defer 컨테이너 비동기 \u0026amp; 병렬 실행 ThreadPoolExecutor, ForkJoinPool 잡 주기적 작업 Timer, ScheduledExecutorSerivice 크론잡 백그라운드 작업 데몬 스레드 데몬세트 설정 관리 System.getenv(), Properties 컨피그맵 , 시크릿 Container # 컨테이너 Container 는 쿠버네티스 기반 클라우드 네이티브 애플리케이션의 빌딩 블록\n객체 지향 프로그래밍 (OOP) 과 자바를 비교해 본다면 , 컨테이너 이미지는 클래스와 비슷하며 컨테이너는 객체와 유사\n컨테이너를 사용한다고 병렬화가 더 좋아지는 것은 아니지만 , 요점은 컨테이너가 쿠버네티스에서 기본적인 역할 을 하며, 모듈화된 재사용 가능한 단일 목적의 컨테이너 이미지를 만드는 것은 모든 프로젝트는 물론이고 심지어는 컨테이너 에코시스템을 통틀어 장기적인 성공을 거두는 데 기본이 된다는 점\n패키징과 격리를 제공하는 컨테이너 이미지의 기술적 특성 외 에 컨테이너는 과연 무엇인지 정리해보면\n컨테이너 이미지는 하나의 문제를 해결하는 기능 단위다.\n컨테이너 이미지는 하나의 팀에 의해 소유되며, 릴리스 주기가 있다.\n컨테이너 이미지는 자기 완비적이며, 런타임 의존성을 정의하고 수행한다.\n컨테이너 이미지는 불변적이며, 한번 만들어지면 변경되지 않는다. 즉 이미 설정 값이 정해져 있다.\n컨테이너 이미지는 런타임 의존성과 자원 요구사항이 정의되어 있다.\n컨테이너 이미지에는 기능을 노출시키기 위해 잘 정의된 API 가 있다.\n컨테이너는 일반적으로 하나의 유닉스 프로세스로 실행된다.\n컨테이너는 일회용이며 언제든지 스케일 업 scale up 과 스케일 다운 scale down 을 안전하게 수행할 수 있다.\nPod # 대부분의 클라우드 네이티브 플랫폼은 컨테이너 그룹의 수명주기를 관리하기 위해 또 다른 기본 요소를 제공하는데, 쿠버네티스에서는 이를 파드 Pod라 부른다. 파드란 컨테이너 그룹의 스케줄링과 배포 , 격리된 런타임에 대한 최소 단위 개발이나 빌드 때의 마이크로서비스는 한 팀에서 개발하고 릴리스 하는 컨테이너 이미지에 해당된다. 그러나 런타임 시의 마이크로서비스는 배포와 배치 Placement, 스케일의 단위인 파드로 표현된다\n규모나 마이그레이션에 관계없이 컨테이너를 실행하는 유일한 방법은 파드 추상화를 통하는 것\n파드의 특성\n파드는 스케줄링의 최소 단위다. 이 말은 스케줄러가 파드에 속한 모든 컨테이너의 요구사항을 만족하는 호스트를 찾으려 시도한다는 뜻\n파드는 파드에 속한 컨테이너들의 동일 장소 배치 colocation 를 보장\n파드는 파드 안의 모든 컨테이너가 공유하는 하나의 IP 주소와 이름, 포트 범위를 갖는다.\nService # 쿠버네티스의 서비스는 추상화로, 서비스 이름을 IP 주소와 포트 번호로 영구히 연결시켜 준다.\n파드가 스케일 업이나 다운, 컨테이너 정상상태 health 확인 실패나 노드 이전 같은 여러 가지 이유로 언제든지 생성되고 사라질 수 있는 일시적인 자원으로 파드는 다른 노드에 다시 스케줄링될 수 있다.\n이 말은 파드의 네트워크 주소는 애플리케이션이 실행되는 동안 바뀔 수 있으며, 파드를 찾고 로드 밸런싱하기 위한 또 다른 기본 요소가 필요하다는 사실을 의미\n그래서 서비스는 애플리케이션에 접근하기 위한, 이름으로 된 진입점이라 할 수 있다.\n대부분 사례에서 서비스는 파드 세트에 대한 진입점으로 사용되지만, 모든 경우가 그렇지는 않다. 서비스는 일반적인 기본 요소며 , 쿠버네티스 클러스터 외부에서 제공되는 기능들을 가리킬 수도 있다. 따라서 서비스는 서비스 디스커버리 discovery 와 로드 밸런싱으로 사용될 수 있으며, 서비스컨슈머 consumer 에게 영향을 주지 않으면서 구현 변경과 스케일을 가능하게 해준다.\nLabel # 마이크로서비스는 빌드 시에는 컨테이너지만 실행 시에는 파드로 나타난다는 것을 앞서 살펴봤다.\n그러면 여러 개의 마이크로서비스로 구성된 애플리케이션은 어떻게 되는가 ? 이에, 쿠버네티스에서 제공하는 레이블 label 과 네임스페이스 namespace 라는 2 가지 기본 요소는 애플리케이션 개념을 정의한다.\n마이크로서비스를 도입하면 통일된 하나의 애플리케이션 개념은 사라지고, 하나의 애플리케이션 레벨로 수행하는 핵심 아티팩트나 동작 또한 더 이상 존재하지 않는다. 그러나 일부 독립 서비스가 애플리케이션에 속함을 나타내야 한다면 레이블을 쓰면 된다.\n레이블 사용예시\n레이블은 실행 중인 특정 파드의 인스턴스들을 가리키기 위해 레플리카세트 ReplicaSet 에서 사용된다. 즉 모든 파드 정의에는 스케줄링에서 사용될 고유한 레이블 조합 레이블은 스케줄러에서 많이 사용된다. 스케줄러는 파드의 요구사항에 맞는 노드에 파드를 배치하기 위해 사용 레이블은 파드를 논리적 그룹으로 묶어 가리킬 수 있고 그 파드 그룹에 애플리케이션 식별자를 지정이 가능하다. 이와 같은 일반적인 사용 예 외에 레이블은 메타데이터를 저장하는 데도 쓰인다. 어떤 레이블이 사용될지 미리 예측하기는 어렵지만 파드의 모든 중요한 면을 설명할 수 있도록 레이블을 사전에 정의 ( 비즈니스 특성과 중요도 , 하드웨어 아키텍처나 위치 설정 같은 특정 런타임 플랫폼 의존성을 가리키는 레 이블 ) Annotation # 레이블과 유사한 또 다른 기본 요소로는 애노테이션 anotation 이 있다.\n레이블처럼 애노테이션도 맵 map 형태로 구성되지만 사람보다는 기계를 위한 용도로 사용되며, 검색 불가능한 메타데이터 metadata 를 지정하는 데 사용\n다양한 도구나 라이브러리에 인식시키기 위해 객체에 추가적인 메타데이터를 넣는 용도로 사용된다. 애노테이션은 주로 빌드 ID, 릴리스 ID, 이미지 정보 , 타임스탬프 , 것에 브랜치명 , Pull request 번호 , 이미지 해시 , 레지스트리 주소 , 작성자 이름 , 도구 정보 등에\nNamespace # 쿠버네티스 네임스페이스를 활용하면, 멀티 호스트로 구성된 쿠버네티스 클러스터를 논리적 자원 풀 Pool 로 나눌 수 있다.\n네임스페이스는 쿠버네티스 자원에 대한 영역 scope 을 제공하고, 또한 권한과 정책을 클러스터의 하위 섹션에 적용하는 메커니즘을 제공\n네임스페이스의 가장 일반적인 사용 예는 개발 환경, 테스트 환경, 통합 테스트 환경, 운영 환경 같은 다양한 소프트웨어 환경으로 구분하는 것\n네임스페이스는 멀티테넌시 multitenancy 를 구현하는 데 쓰이고, 팀의 작업공간이나 각 프로젝트, 심지어는 특정 애플리케이션을 격리하는 데도 사용\n통상적으로는, 개발, 테스트, 통합테스트 환경 등의 비운영 쿠버네티스 클러스터를 하나 만들고, 성능 테스트와 운영 환경을 위한 또 다른 운영 쿠버네티스 클러스터를 만든다\n네임스페이스 사용예시\n네임스페이스는 쿠버네티스 자원으로서 관리\n네임스페이스는 컨테이너, 파드, 서비스, 레플리카세트 등의 자원에 대한 영역을 제공\n리소스쿼터 ResourceQuota 는 네임스페이스당 자원 소모랑을 제한할 수 있는 제약조건을 제공한다. 리소스쿼터를 사용하면 클러스터 관리자는 타입별 객체의 수량을 제어할 수 있다.\n"},{"id":11,"href":"/devops/docs/CICD/CICD/with-toc/","title":"1. 학습목표","section":"CI/CD 배포 입문","content":" 학습목표 # 클라우드 서비스를 활용하기 위한 기본 지식 학습\n클라우드 서비스에 내 프로젝트를 단순 배포하기 위한 환경을 구축\n클라우드 서비스 내 프로젝트 배포를 간편화\n클라우드 서비스에 환경 구축 없이 프로젝트 배포 ( Elastic Beanstalk )\n클라우드 서비스에 배포 자동화\n클라우드 서비스 무중단 배포\n정적 IP 할당을 위한 NLB 활용\n최종목표\n스프링 부트를 사용한 간단한 프로젝트를 생성 후, 배포 "},{"id":12,"href":"/devops/docs/Git/Git/git03/","title":"3. Git Branch","section":"Git","content":" GIT # Git Branch 이란? # Branch란 독립적인 이력 관리 영역을 의미\nBranch이란 특정지점의 커밋에서 분기 해서 커밋을 이어 나가는 모습이 마치 나무의 가지가 뻗어 나가는것과 비슷하다고하여 붙여진 이름 브랜치를 사용하면 저장소를 따로 만들 필요 없이 한 저장소 안에서 기능추가,디버그, 테스트등의 작업을 동시에 할 수 있으며, 저장소 를 안정적이면서도 유연하게 운영이 가능\nGit Merge 이란? # 다른 브랜치의 작업내용을 현재 작업 중인브 랜치에 병합할때 git merge를 사용 단, git merge를 사용하면 자동으로 병합되지만, 충돌이 발생시에는 사용자가 직접 충돌을 해결해야 됨 Fast-forward Merge # 특징\n두 개의 브랜치가 존재\n하나의 브랜치에서 새로운 커밋을 생성\n다른 브랜치에서는 아무런 변경 사항이 없음\n브랜치는 분리되어 있지 않고 직선으로 연결된 것처럼 보이는 특징을 가지며, 단순히 두 브랜치의 포인터를 이동시켜 새로운 커밋을 가리키게 만드는 것만으로 병합이 이루어지는 병합을 Fast-forward 병합이라고 함, 이 때, 기존 브랜치가 새로운 커밋으로 이동\n3-way Merge # 특징\n두 개의 브랜치가 존재\n각 브랜치에서는 서로 다른 변경 사항 존재\n이 두 브랜치를 병합\n병합진행 과정\n병합할 브랜치의 마지막 커밋 (merge 대상 브랜치)\n현재 브랜치의 마지막 커밋 (merge를 실행하는 브랜치)\n두 브랜치의 공통 조상 (공통 부모 커밋)\n이런 방식으로 병합을 수행하여 각 브랜치에서의 변경 사항을 적절히 통합\nFast-forward 병합: 두 브랜치의 이력이 간단하고 직선적인 경우에 발생합니다. 이전 커밋이 공통 부모가 되지 않으며, 단순히 브랜치의 포인터를 이동시켜 새로운 커밋\n3-way 병합: 두 브랜치가 서로 다른 변경 사항을 가지고 있을 때 발생하며, 이전 커밋이 공통 조상이 됩니다. 이전 커밋을 기반으로 변경 사항을 적절히 통합하여 새로운 병합 커밋\n학습을 위한 Git을 통한 형상 관리 및 협업 시나리오 # Git 초기 설정 및 레포지터리 생성 mkdir my-project cd my-project git init # 원격 레포지터리 추가 git remote add origin https://github.com/username/my-project.git 첫 파일 추가 및 커밋 # 파일 생성 echo \u0026#34;# My Project\u0026#34; \u0026gt; README.md # 파일을 스테이징하고 커밋 git add README.md git commit -m \u0026#34;Initial commit\u0026#34; # 원격 저장소로 푸시 git push origin master 브런치 생성 및 전환 # 새로운 브랜치 생성 및 전환 git checkout -b feature-branch 코드 수정 및 푸쉬 echo \u0026#34;New feature code\u0026#34; \u0026gt; feature.txt # 변경 사항 스테이징 및 커밋 git add feature.txt git commit -m \u0026#34;Add new feature\u0026#34; 브랜치 병합 수행 (Fast-forward) # master 브랜치로 전환 git checkout master # 병합 수행 (Fast-forward) git merge --ff feature-branch # 병합 결과 확인 git log 브랜치 병합 수행 (No-fast-forward) # 새로운 기능 브랜치 생성 및 전환 git checkout -b feature-branch-2 # 파일 수정 및 커밋 echo \u0026#34;Another new feature\u0026#34; \u0026gt; feature2.txt git add feature2.txt git commit -m \u0026#34;Add another new feature\u0026#34; # master 브랜치로 전환 및 병합 (No-fast-forward) git checkout master git merge --no-ff feature-branch-2 Git 협업 # 원격 저장소에서 변경 사항 가져오기 git fetch origin git pull origin master git push origin feature-branch Git 협업 # feature-branch 브랜치를 master 브랜치로 리베이스 git checkout feature-branch git rebase master Git 복구하기 # 마지막 커밋 되돌리기 (작업 내용 유지) git reset --soft HEAD~1 마지막 수정 인물 추정 # 파일의 각 라인의 변경 내용 표시 git blame \u0026lt;file\u0026gt; "},{"id":13,"href":"/devops/docs/Kubernetes/Kubernetes/2.-Provisioning/Kubeadm/file0/","title":"Kubeadm Concept","section":"Kubeadm","content":" Kubeadm # Kubeadm은 쿠버네티스 클러스터 생성을 위한 \u0026ldquo;빠른 경로\u0026quot;의 모범 사례로 kubeadm init 및 kubeadm join 을 제공하도록 만들어진 도구\n쿠버네티스는 분산 시스템 관리 도구로, 컨테이너화된 애플리케이션을 효율적으로 배포, 관리, 확장할 수 있게 해주지만, 초기 설정 및 유지 관리 작업은 복잡할 수 있으며, 이를 간편하게 해주기 위한 프로비저닝 툴 중 하나가 kubeadm\nkubeadm은 실행 가능한 최소 클러스터를 시작하고 실행하는 데 필요한 작업을 수행\n설계 상, 시스템 프로비저닝이 아닌 부트스트랩(bootstrapping)만 다룬다.\n즉, 대시보드, 모니터링 솔루션 및 클라우드별 애드온과 같은 다양한 있으면 좋은(nice-to-have) 애드온을 설치하는 것은 범위에 포함되지 않는다.\nKubeadm 명령어 # 명령어 설명 예시 kubeadm init 쿠버네티스 컨트롤 플레인 노드를 부트스트랩합니다. kubeadm init --pod-network-cidr=10.244.0.0/16 kubeadm join 워커 노드를 부트스트랩하고 클러스터에 조인시킵니다. kubeadm join \u0026lt;master-ip\u0026gt;:\u0026lt;port\u0026gt; --token \u0026lt;token\u0026gt; --discovery-token-ca-cert-hash \u0026lt;hash\u0026gt; kubeadm upgrade 현재 클러스터를 새로운 버전으로 업그레이드합니다. kubeadm upgrade apply v1.20.0 kubeadm config 클러스터 초기화 및 업그레이드 시 설정 구성을 관리합니다. kubeadm config print init-defaults kubeadm token kubeadm join 명령어에 필요한 토큰을 생성하거나 관리합니다. kubeadm token create --print-join-command kubeadm reset kubeadm init 또는 kubeadm join으로 인한 변경 사항을 모두 되돌립니다. kubeadm reset kubeadm certs 쿠버네티스 인증서를 관리합니다. kubeadm certs renew all kubeadm kubeconfig 쿠버네티스 클러스터의 kubeconfig 파일을 관리합니다. kubeadm kubeconfig user kubeadm version kubeadm의 현재 버전을 출력합니다. kubeadm version kubeadm alpha 미리 보기 기능으로 커뮤니티 피드백을 위해 제공되는 실험적 기능을 실행합니다. kubeadm alpha certs renew References # Kubeadm "},{"id":14,"href":"/devops/docs/Kubernetes/Kubernetes/","title":"Kubernetes Training","section":"Kubernetes","content":" Kubernetes Standard Architecture # 해당 섹션에는 2023 표준 아키텍처를 기준으로 필자의 주관을 참조여 구성됩니다. 설치순서 ( 순서는 필자의 주관으로 강제가 아님. ) # 각 컴포넌트 중, 색상으로 표시한 컴포넌트를 기준으로 설치됩니다. 1. Container Runtime # 툴: containerd, Docker 설명: 쿠버네티스가 컨테이너를 실행하는 런타임을 설치합니다. 가이드: 각 노드에 containerd 또는 Docker를 설치합니다. kubelet이 사용할 컨테이너 런타임을 설정합니다. 2. Cluster Provisioning # 툴: kubeadm, KubeSpray, Terraform 설명: 쿠버네티스 클러스터를 생성하고, 노드들을 구성합니다. 이 단계에서는 쿠버네티스 클러스터의 기본 인프라를 배포합니다. 가이드: Kubeadm: kubeadm init 명령어를 사용하여 클러스터를 초기화합니다. 각 노드를 클러스터에 추가합니다. KubeSpray: Ansible을 사용하여 다중 노드 클러스터를 자동으로 배포합니다. Terraform: 인프라를 코드로 정의하여 클라우드 환경에서 쿠버네티스 클러스터를 프로비저닝합니다. 3. Container Network Interface # 툴: Calico, MetalLB, NGINX, K8GB 설명: 클러스터 내의 네트워킹을 설정합니다. Calico를 통해 네트워크 정책과 CNI를 설정합니다. 가이드: Calico를 설치하여 네트워크 정책과 Pod 간의 통신을 설정합니다. MetalLB를 사용하여 로드밸런서를 구성합니다. NGINX 또는 K8GB로 인그레스 컨트롤러를 설정합니다. 4. Usability Tools # 툴: Helm, OpenLens 설명: 클러스터에서 쉽게 애플리케이션을 배포하고 관리할 수 있도록 도와주는 도구들을 설정합니다. 가이드: Helm을 사용하여 패키지 매니저로서 애플리케이션을 설치합니다. OpenLens를 통해 클러스터를 관리하고 모니터링합니다. 5. Container Natvie Storage # 툴: Rook Ceph, Ceph 설명: 클러스터 내에서 스토리지를 설정하여 애플리케이션이 사용할 수 있게 합니다. 가이드: Rook/Ceph를 사용하여 퍼시스턴트 볼륨을 제공합니다. Velero를 설치하여 클러스터 백업 및 복원을 설정합니다. 6. Backup and Restore Service # 툴: Velero 설명: Kubernetes 클러스터의 백업 및 복원을 관리합니다. Velero를 사용하여 클러스터의 상태와 데이터를 안전하게 저장하고, 필요시 복구할 수 있습니다. 가이드: Velero를 설치하여 클러스터의 백업 및 복구 작업을 자동화합니다. 클러스터 내의 퍼시스턴트 볼륨 및 네임스페이스 데이터를 백업하고 복구할 수 있는 설정을 구성합니다 7. Mesh Service # 툴: Istio 설명: 서비스 간의 통신을 관리하고, 서비스 메시 패턴을 설정합니다. 가이드: Istio를 설치하여 마이크로서비스 간의 트래픽 관리, 모니터링, 보안을 설정합니다. 8. Access Management Service # 툴: Keycloak 설명: SSO(Single Sign-On) 및 ID 관리 시스템을 설정합니다. 가이드: Keycloak을 설치하고, 클러스터의 RBAC 및 OIDC 인증을 통합합니다. SSO를 통해 애플리케이션 액세스를 제어합니다. 9. Key Management Service # 툴: HashiCorp Vault 설명: 클러스터에서 사용하는 키와 인증서 관리 서비스를 설정합니다. 가이드: Vault를 설정하여 비밀 정보 및 인증서를 관리합니다. Kubernetes와 통합하여 비밀 데이터를 관리합니다. 10. Container Images Managemet Service # 툴: Harbor 설명: 쿠버네티스 클러스터에서 사용하는 이미지를 저장하고 관리할 컨테이너 이미지 레지스트리를 설정합니다. 가이드: Harbor를 설치하여 내부 레지스트리를 설정하고, 이미지를 푸시하고 풀할 수 있게 합니다. 11. Monitoring and Logging # 툴: Prometheus, Grafana, Fluentd, Elasticsearch, Kibana 설명: 클러스터의 모니터링 및 로깅을 설정합니다. 가이드: Prometheus를 설치하여 메트릭을 수집하고 Grafana를 통해 시각화합니다. Fluentd, Elasticsearch, Kibana를 설정하여 로그를 수집하고 분석합니다. 12. CI/CD Pipeline # 툴: Jenkins, GitLab, Argo 설명: 애플리케이션의 지속적 통합과 지속적 배포를 설정합니다. 가이드: Jenkins/GitLab을 설정하여 빌드 파이프라인을 설정합니다. Argo를 사용하여 지속적 배포(CD)를 자동화합니다. 13. Multi Cluster Management # 툴: Karmada 설명: 여러 클러스터를 관리하고 페더레이션 설정을 합니다. 가이드: Karmada를 설정하여 멀티 클러스터 관리 및 페더레이션을 지원합니다. "},{"id":15,"href":"/devops/docs/Kubernetes/Kubernetes/0.-Resource/file0/","title":"Manger Node","section":"Requirements source","content":" Kubernets Manager Node # Kubernets Manager Node # Manager Node는 노드는 클러스터에 대한 요청을 수신하고 분배하는 역할을 하는 로드 밸런서 역할을 하는 서버를 의미합니다.\n일반적으로 NGINX, HAProxy와 같은 프록시 서버를 사용하며, 여기서는 Nginx로 구성합니다.\n해당 노드의 주 역할은 아래와 같습니다.\n역할 설명 예시 요청 라우팅 클라이언트의 API 요청을 적절한 서비스나 백엔드 노드로 전달합니다. NGINX가 클라이언트 요청을 받아 특정 서비스로 라우팅합니다. 예를 들어, /api/users 요청은 사용자 서비스로 전달됩니다. 로드 밸런싱 요청을 여러 백엔드 노드에 균등하게 분배하여 성능을 최적화합니다. HAProxy가 두 개의 인스턴스(예: app-1, app-2)로 요청을 분배합니다. 각 인스턴스가 50%의 트래픽을 처리합니다. SSL 종료 HTTPS 요청을 처리하고 SSL 인증서를 관리하여 보안을 강화합니다. NGINX가 SSL 인증서를 사용하여 클라이언트와의 연결을 암호화합니다. 내부 통신은 HTTP로 유지합니다. 캐싱 정적 콘텐츠를 캐싱하여 반복적인 요청에 대한 응답 속도를 향상시킵니다. NGINX가 자주 요청되는 이미지 파일을 캐싱하여, 사용자가 이미지를 요청할 때마다 백엔드 서버에 요청하지 않습니다. 트래픽 관리 요청의 수를 제한하거나 특정 요청을 차단하여 트래픽을 관리합니다. HAProxy가 특정 IP에서의 요청 수를 제한하여 DDoS 공격을 방어합니다. 예를 들어, 100초당 10회 요청으로 제한할 수 있습니다. 상태 검사 백엔드 서비스의 상태를 주기적으로 확인하여, 실패한 서비스에 요청을 보내지 않도록 합니다. HAProxy가 app-1 인스턴스의 상태를 확인하고, 문제가 발생한 경우 해당 인스턴스에 요청을 보내지 않도록 합니다. 간단하게 기존에 사용하던 Docker engine을 사용하지 않고 ContainerD를 사용 하게된 이유를 정리하자면 쿠버네티스는 여러 컨테이너 런타임과 통신할 수 있도록 하는 CRI라는 표준 인터페이스를 설계함.\nDocker engine은 CRI 인터페이스가 생기기전 존재한 기술로 CRI 인터페이스와 맞지 않았음.\n이를 해결하기 위해 dockershim이라는 어댑터 컴포넌트를 개발하였음.\n이 쉼의 존재는 kubelet 자체에 많은 불필요한 복잡성을 도입했고, 일부 통합은 이 쉼 때문에 Docker에 대해 일관성 없게 구현되었으며, 이로 인해 유지 관리 부담이 증가하게 됨.\n이처럼 벤더 특정 코드(특정 제품인 Docker에 종속적인 코드)를 유지 관리하는 것은 쿠버네티스의 오픈 소스 철학에 부합하지 않았고, 2022년 4월 v1.24에서 완전한 제거를 발표하였음. Kubernets Manager Node Install # # nginx를 설치합니다. $ apt -y install nginx libnginx-mod-stream # nginx에 프록시를 세팅합니다. $ vi /etc/nginx/nginx.conf stream { upstream k8s-api { server 7.7.7.100:6443; # contolplan IP } server { listen 6443; proxy_pass k8s-api; } } # Nginx의 default 웹을 비활성화합니다. $ unlink /etc/nginx/sites-enabled/default $ systemctl restart nginx # kubectl 레포지터리를 등록하고 설치합니다. $ curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg $ echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /\u0026#34; | tee /etc/apt/sources.list.d/kubernetes.list $ apt update $ apt -y install kubectl # (option) kubectl alias k $ apt -y install bash-completion $ source /usr/share/bash-completion/bash_completion $ kubectl completion bash | tee /etc/bash_completion.d/kubectl \u0026gt; /dev/null $ echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ echo \u0026#39;complete -o default -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt;~/.bashrc $ exec bash "},{"id":16,"href":"/devops/docs/Kubernetes/Kubernetes/0.-Resource/","title":"Requirements source","section":"Kubernetes Training","content":" Requirements source # 기초 환경구성 # Role Hostname OS 커널 CPU Mem IP Manager ctrl Ubuntu 24.04.1 LTS Linux 6.8.0-45-generic 1 2048M nat 10.1.61.179 / Nat 7.7.7.254 ControlPlan cp0 Ubuntu 24.04.1 LTS Linux 6.8.0-45-generic 1 2048M Nat 7.7.7.100 DataPlan node0 Ubuntu 24.04.1 LTS Linux 6.8.0-45-generic 1 2048M Nat 7.7.7.110 매우 대충 그렸지만, 넓은 아량으로 이해 부탁드립니다. 😄 진도를 나아가며 점차 추가해나아갈 예정입니다. 기본설정 # NTP 설정 # # NTP를 설정합니다. # NTP 서버가 있으면, 해당 서버로 시간대를 잡아두어도 좋습니다. $ timedatectl set-timezone Asia/Seoul "},{"id":17,"href":"/devops/docs/CICD/CICD/table-of-contents/with-toc/","title":"With ToC","section":"Table of Contents","content":" Caput vino delphine in tamen vias # Cognita laeva illo fracta # Lorem markdownum pavent auras, surgit nunc cingentibus libet Laomedonque que est. Pastor An arbor filia foedat, ne fugit aliter, per. Helicona illas et callida neptem est Oresitrophos caput, dentibus est venit. Tenet reddite famuli praesentem fortibus, quaeque vis foret si frondes gelidos gravidae circumtulit inpulit armenta nativum.\nTe at cruciabere vides rubentis manebo Maturuit in praetemptat ruborem ignara postquam habitasse Subitarum supplevit quoque fontesque venabula spretis modo Montis tot est mali quasque gravis Quinquennem domus arsit ipse Pellem turis pugnabant locavit Natus quaerere # Pectora et sine mulcere, coniuge dum tincta incurvae. Quis iam; est dextra Peneosque, metuis a verba, primo. Illa sed colloque suis: magno: gramen, aera excutiunt concipit.\nPhrygiae petendo suisque extimuit, super, pars quod audet! Turba negarem. Fuerat attonitus; et dextra retinet sidera ulnas undas instimulat vacuae generis? Agnus dabat et ignotis dextera, sic tibi pacis feriente at mora euhoeque comites hostem vestras Phineus. Vultuque sanguine dominoque metuit risi fama vergit summaque meus clarissimus artesque tinguebat successor nominis cervice caelicolae.\nLimitibus misere sit # Aurea non fata repertis praerupit feruntur simul, meae hosti lentaque citius levibus, cum sede dixit, Phaethon texta. Albentibus summos multifidasque iungitur loquendi an pectore, mihi ursaque omnia adfata, aeno parvumque in animi perlucentes. Epytus agis ait vixque clamat ornum adversam spondet, quid sceptra ipsum est. Reseret nec; saeva suo passu debentia linguam terga et aures et cervix de ubera. Coercet gelidumque manus, doluit volvitur induta?\nEnim sua # Iuvenilior filia inlustre templa quidem herbis permittat trahens huic. In cruribus proceres sole crescitque fata, quos quos; merui maris se non tamen in, mea.\nGermana aves pignus tecta # Mortalia rudibusque caelum cognosceret tantum aquis redito felicior texit, nec, aris parvo acre. Me parum contulerant multi tenentem, gratissime suis; vultum tu occupat deficeret corpora, sonum. E Actaea inplevit Phinea concepit nomenque potest sanguine captam nulla et, in duxisses campis non; mercede. Dicere cur Leucothoen obitum?\nPostibus mittam est nubibus principium pluma, exsecratur facta et. Iunge Mnemonidas pallamque pars; vere restitit alis flumina quae quoque, est ignara infestus Pyrrha. Di ducis terris maculatum At sede praemia manes nullaque!\n"},{"id":18,"href":"/devops/docs/CICD/CICD/key/","title":"암호화","section":"CI/CD 배포 입문","content":" 암호화의 기술과 역사 # 암호화의 역사 # 시대 기간 특징 종류 고대 고대 - 19세기 말 수동 암호 사용 (단순, 문자 대입하여 암호화) Scytale, Caesar, Vigenere, Beaufort 등 근대 1900 - 1940년대 기계 암호 사용 (복잡한 기계를 이용하여 암호화) Enigma, M-209 등 현대 1950년대 - 현재 샤뇬의 \u0026ldquo;암호학의 수학적 배경\u0026rdquo; 발표 이후 시작, 컴퓨터 암호 사용 (컴퓨터 연산을 이용하여 암호화) DES, SEED, Rijindael, RSA, ECC, KCDSA 등 고대에는 외교, 군사 등의 한정적인 분야의 사용되었으나, 현대에는 인터넷, 전자상거래 등이 발달하면서 전반적인 분야의 대한 보안(암호화)의 기능이 중요시 되기 시작했다. 현대 암호화 기술 # 1. 대칭키 암호화 기술 (비밀키) # 송신자와 수신자간의 데이터가 오갈 때, 암호화 및 복호화를 동일한 Key로 진행하는 방식 즉, 송신자 A가 수신자 B에게 특정 파일을 Q라는 Key를 사용하여 암호화해서 보내면, B는 A가 사용했던 Q라는 key를 사용하여 복호화해야만 받은 파일의 확인이 가능하다. 대칭키 암호화는 블록, 스트링 암호를 사용하며, 특징은 아래와 같다. 블록암호(DES): Data Encryption Standard의 약자로 1976년 미국가표준국(NIST) 주도하에 설계된 암호화 방식이다. 63비트 단위의 블록 길이로 암호화한다. 블록 중 키의 길이는 58비트 나머지 8비트는 패리티 체크에 사용 블록암호(AES): DES의 해독 방법이 나오면서 DES를 대체하기 위하여 채택된 방식이다. Advanced Encryption Standard의 약자로 1997년부터 진행하여, 2001년 존 대먼과 빈센트 라이언이 개발한 Rijndael의 알고리즘을 기반하여 만들어졌다. 128비트로 DES보다 더 큰 단위의 블록 길이로 암호화한다. 128비트뿐만 아니라 192비트, 256비트 길이로 암호화 가능 스트링암호: 데이터 스트림(흐름)을 순차적으로 처리해가는 암호 알고리즘으로 데이터가 발생하는 즉시 암호화하여 보내는 방식, 1비트, 8비트, 또는 32 비트 등의 단위로 암호화와 복호화를 진행 구분 블록암호 스트링암호 장점 암호 복잡성이 높고, 기밀성이 높고, 해시 함수를 사용하여 암호화한다. 암호화 속도가 빠르며, 비트 단위로 암호화하기 때문에 다음 한 비트의 에러 발생이 다음 비트에 영향을 주지 않는다. 단점 암호화 속도가 느리며, 블록 내부의 한 비트의 에러 발생이 다른 비트에 쉽게 에러 전달된다. 암호화의 확산이 낮기 때문에 암호의 복잡성이 떨어지며, 비트 단위로 암호화가 진행되기 때문에 비트 사이에 삽입 변경 쉬워, 삽입공격에 취약하다 종류 DES, IDES, SEED, RC5, AES LFSR(Shift Register), MUX generator 암호화 단위 블록 비트 주요대상 일반 데이터 전송, 저장 음성, 오디오/비디오 스트리밍 실시간 부적합 적합 2. 비대칭 암호화 기술 (공개키) # 암호화를 위한 키와, 복호화를 위한 키가 다른 암호화 방식을 말한다. RSA(Rivest, Shamir, Adleman), ECC(Elliptic Curve Cryptosystem), NTRU, XTR 등이 존재한다. 비대칭 암호화 기술은 Public, Private Key 기술을 활용하며, 송신자 A가 수신자 B에게 파일을 보낸다면, 먼저 수신자 B의 Public Key를 사용하여 암호화 시킨 후 발송하면, 이 파일은 Private Key가 있는 B만이 복호화하여 파일을 열 수 있는 구조이다. 3. PKI (Public Key Infrastructure, 공개키기반구조) # PKI는 위에서 언급한 공개키 암호화와 전자서명을 사용할 수 있게 구조를 제시해 둔 것이다. 기존 공개키 방식은 해커 C가 A가 B에게 암호화 통신 중간에 끼어들어, B가 A에게 다시 파일을 보낼 때, 자신의 공공키를 제시하는 식의 문제가 생기기 시작했고, 이를 예방하기 위해 PKI라는 개념을 등장시켰다. PKI는 공개키 기반 구조를 가지기 위해 비대칭키 암호화 방식에서 CA라는 개념을 등장 시킨다. PKI 구성요소는 아래와 같다. 인증기관(CA, Certificate Authority): 사용자의 인증서 발급 및 관리 Ex) 한국정보인증(KICA), 금융결제원(yesSign), 한국진흥정보원(Sigate) 등 등록기관(RA, Registration Authority): 신원확인, 고객 데이터 유지 등 인증기관의 입증을 대행하는 등록기관. Ex) 은행, 증권사 디렉토리(Directory): 인증서 및 인증서 취소목록 등 PKI와 관련된 정보를 저장 및 검색하는 장소 인증서(Certificate): 공개키나 공개키의 정보를 포함하는 인증서 Ex) X.509 인증서 4. SSL/TLS # SSL/TLS는 프로토콜로 PKI가 제공하는 공개 키 인프라와 디지털 인증서를 사용해서 Browser와 server 간 통신. 즉 Website 트랜잭션에 보안 및 무결성을 제공하는 기술이다. SSL (Secure Socket Layer): Browser와 Server가 서로 통신할 때 보안 및 무결성을 제공하는 프로토콜 TLS (Transport Layer Security): SSL과 마찬가지로 Browser와 Server가 서로 통신할 때 보안 및 무결성을 제공하는 프로토콜 즉 SSL과 TLS는 동일한 목적을 수행하는 프로토콜이지만 차이점이라면 TLS 프로토콜은 SSL 프로토콜의 업데이트된 상위 버전이라는 것으로, SSL이 표준화 되면서 이름이 TLS로 변경되었다. 4-1. TLS 통신과정 (Handshake과정) # 클라이언트에서 서버로 접속한다. (https://URL) 클라이언트는 랜덤데이터를 만들어 서버에 보낸다. 클라이언트에서 사용 가능한 암호화방식들을 서버에 보낸다. 서버 -\u0026gt; 클라이언트 서버 또한 랜덤데이터를 만들어 클라이언트에 보낸다. 클라이언트가 보낸 암호화방식들 중에 사용할 방식을 선정하여 클라이언트에 보낸다. SSL 인증서도 같이 보낸다. (SSL 인증서에는 사이트의 Public Key, CA, 도메인 정보등이 존재) 5. 실습 # $ brew install mkcert # 인증을 위한 패키지 설치 $ mkcert -install # localhost 인증된 발급기관 추가(localhost용 ca) $ mkcert -key-file key.pem -cert-file cert.pem localhost 127.0.0.1 ::1 # localhost, 127.0.0.1(IPv4), ::1(IPv6)에서 사용할 수 있는 인증서 생성 cert.pem, key.pem이라는 파일이 생성 cert.pem 파일의 경우 공개키와 인증기관의 서명을 포함하고 있는 인증서이며, key.pem의 경우 개인 키 # https.js 파일 생성 후 확인 const https = require(\u0026#39;https\u0026#39;); const fs = require(\u0026#39;fs\u0026#39;); https .createServer( { key: fs.readFileSync(\u0026#39;./key.pem\u0026#39;, \u0026#39;utf-8\u0026#39;), cert: fs.readFileSync(\u0026#39;./cert.pem\u0026#39;, \u0026#39;utf-8\u0026#39;), }, function (req, res) { res.write(\u0026#39;Congrats! You made https server now :)\u0026#39;); res.end(); } ) .listen(443); $ sudo node https.js $ curl localhost:443 Congrats! You made https server now :) https:localhost:443 으로 접속하여도 자물쇠 아이콘을 확인할 수 있음 Reference https://m.blog.naver.com/taeheon714/222278059898 https://byoungsoo.github.io/etc/2022/06/08/pki.html https://swingswing.tistory.com/155 "},{"id":19,"href":"/devops/docs/Kubernetes/Kubernetes/1.-Runtime/ContainerD/file1/","title":" install","section":"ContainerD","content":" ContainerD Install # ContainerD 환경구성 # # CRI를 사용하기 위한 네트워크 설정 # net.bridge.bridge-nf-call-iptables: 브리징된 네트워크 인터페이스에서 트래픽을 iptables를 통해 필터링 할 수 있도록 허용 # net.bridge.bridge-nf-call-ip6tables: IPv6 네트워크에서도 브리지된 트래픽을 ip6tables를 통해 필터링할 수 있도록 허용 # net.ipv4.ip_forward: IP 포워딩을 활성화 $ cat \u0026gt; /etc/sysctl.d/99-k8s-cri.conf \u0026lt;\u0026lt;EOF net.bridge.bridge-nf-call-iptables=1 net.bridge.bridge-nf-call-ip6tables=1 net.ipv4.ip_forward=1 EOF # 변경사항 적용 $ sysctl --system # OverlayFS: 파일 시스템을 로드하여 컨테이너의 파일 시스템을 효율적으로 관리 # br_netfilter: 브리지 네트워크 트래픽을 iptables로 전달할 수 있도록 하는 모듈 $ modprobe overlay; modprobe br_netfilter $ echo -e overlay\\\\nbr_netfilter \u0026gt; /etc/modules-load.d/k8s.conf # iptables 백엔드를 iptables-legacy로 전환 # 쿠버네티스는 일부 환경에서 iptables-legacy 백엔드와 더 잘 호환되기 때문에 이를 설정 # iptables-legacy: 전통적인 iptables # iptables-nft: nftables 기반의 iptables 구현 $ update-alternatives --config iptables There are 2 choices for the alternative iptables (providing /usr/sbin/iptables). Selection Path Priority Status ------------------------------------------------------------ * 0 /usr/sbin/iptables-nft 20 auto mode 1 /usr/sbin/iptables-legacy 10 manual mode 2 /usr/sbin/iptables-nft 20 manual mode Press \u0026lt;enter\u0026gt; to keep the current choice[*], or type selection number: 1 update-alternatives: using /usr/sbin/iptables-legacy to provide /usr/sbin/iptables (iptables) in manual mode # swap off $ swapoff -a $ sed -i \u0026#39;/\\/swap.img/s/^/#/\u0026#39; /etc/fstab # apparmor 프로파일 비활성화 $ apparmor_parser -R /etc/apparmor.d/runc $ apparmor_parser -R /etc/apparmor.d/crun $ ln -s /etc/apparmor.d/runc /etc/apparmor.d/disable/ $ ln -s /etc/apparmor.d/crun /etc/apparmor.d/disable/ ContainerD 설치 # # ContainerD를 설치합니다. $ apt -y install containerd # ContainerD의 디렉터리를 생성합니다. $ mkdir /etc/containerd # ContinerD의 기본 설정파일을 생성합니다. $ containerd config default | tee /etc/containerd/config.toml # sandbox_image 버전을 설정합니다. sed -i \u0026#34;s|^\\( *sandbox_image *= *\\).*|\\1\\\u0026#34;registry.k8s.io/pause:3.9\\\u0026#34;|\u0026#34; /etc/containerd/config.toml # Cgroup의 사용여부를 수정합니다. sed -i \u0026#34;s|^\\( *SystemdCgroup *= *\\).*|\\1true|\u0026#34; /etc/containerd/config.toml # 설정적용 $ systemctl restart containerd # 설치확인 $ containerd -version containerd github.com/containerd/containerd 1.7.12 $ systemctl status containerd ● containerd.service - containerd container runtime Loaded: loaded (/usr/lib/systemd/system/containerd.service; enabled; preset:\u0026gt; Active: active (running) since Mon 2024-09-23 09:31:59 UTC; 8min ago Docs: https://containerd.io Process: 1416 ExecStartPre=/sbin/modprobe overlay (code=exited, status=0/SUCC\u0026gt; Main PID: 1418 (containerd) Tasks: 7 Memory: 13.3M (peak: 14.9M) CPU: 1.004s CGroup: /system.slice/containerd.service container.d config 정리 # 섹션 설명 disabled_plugins 비활성화된 플러그인 목록을 정의합니다. imports 가져올 플러그인 목록을 정의합니다. oom_score OOM(Out-Of-Memory) 점수를 설정하여 우선 순위를 결정합니다. root Containerd의 루트 디렉토리를 설정합니다. state 상태 정보를 저장할 디렉토리 위치를 설정합니다. cgroup cgroup 설정 경로를 지정합니다. debug 디버깅 설정 (주소, 포맷, 레벨 등)과 관련된 옵션입니다. grpc GRPC 서버 설정 (소켓 주소, 메시지 크기 제한 등)을 지정합니다. metrics 메트릭 수집을 위한 설정입니다. plugins 다양한 Containerd 플러그인의 설정을 정의합니다. plugins.\u0026quot;io.containerd.gc.v1.scheduler\u0026quot; 가비지 컬렉션 스케줄러의 설정입니다. plugins.\u0026quot;io.containerd.grpc.v1.cri\u0026quot; CRI(Container Runtime Interface) 관련 설정입니다. plugins.\u0026quot;io.containerd.grpc.v1.cri\u0026quot;.cni CNI(Container Network Interface) 설정입니다. plugins.\u0026quot;io.containerd.grpc.v1.cri\u0026quot;.containerd Containerd 자체 설정을 정의합니다. plugins.\u0026quot;io.containerd.grpc.v1.cri\u0026quot;.registry 이미지 레지스트리와 관련된 설정입니다. plugins.\u0026quot;io.containerd.runtime.v1.linux\u0026quot; Linux 런타임 설정입니다. plugins.\u0026quot;io.containerd.snapshotter.v1.overlayfs\u0026quot; OverlayFS 스냅샷터 설정입니다. stream_processors 스트림 프로세서 관련 설정을 정의합니다. timeouts Containerd 내부에서 다양한 작업의 타임아웃을 정의합니다. ttrpc TTRPC 관련 설정입니다. "},{"id":20,"href":"/devops/docs/Kubernetes/Kubernetes/10.-CIMS/Harbor/file1/","title":" install","section":"Harbor","content":"aaa\n"},{"id":21,"href":"/devops/docs/Kubernetes/Kubernetes/11.-ML/Elasticsearch/file1/","title":" install","section":"Elasticsearch","content":"aaa\n"},{"id":22,"href":"/devops/docs/Kubernetes/Kubernetes/11.-ML/Fluentd/file1/","title":" install","section":"Fluentd","content":"aaa\n"},{"id":23,"href":"/devops/docs/Kubernetes/Kubernetes/11.-ML/Kibana/file1/","title":" install","section":"Kibana","content":"aaa\n"},{"id":24,"href":"/devops/docs/Kubernetes/Kubernetes/12.CI/CD/ArgoCD/file1/","title":" install","section":"ArgoCD","content":"aaa\n"},{"id":25,"href":"/devops/docs/Kubernetes/Kubernetes/13.-MCM/Karmada/file1/","title":" install","section":"Karmada","content":"aaa\n"},{"id":26,"href":"/devops/docs/Kubernetes/Kubernetes/3.-CNI/Calico/file1/","title":" install","section":"Calico","content":"aaa\n"},{"id":27,"href":"/devops/docs/Kubernetes/Kubernetes/3.-CNI/MetalLB/file1/","title":" install","section":"MetaLB","content":"aaa\n"},{"id":28,"href":"/devops/docs/Kubernetes/Kubernetes/3.-CNI/Nginx/file1/","title":" install","section":"Nginx","content":"aaa\n"},{"id":29,"href":"/devops/docs/Kubernetes/Kubernetes/4.-Tools/Helm/file1/","title":" install","section":"Helm","content":"aaa\n"},{"id":30,"href":"/devops/docs/Kubernetes/Kubernetes/4.-Tools/OpenLens/file1/","title":" install","section":"OpenLens","content":"aaa\n"},{"id":31,"href":"/devops/docs/Kubernetes/Kubernetes/5.-CNS/Rook/file1/","title":" install","section":"Rook Ceph","content":"aaa\n"},{"id":32,"href":"/devops/docs/Kubernetes/Kubernetes/6.-BR/Velero/file1/","title":" install","section":"Velero","content":"aaa\n"},{"id":33,"href":"/devops/docs/Kubernetes/Kubernetes/7.-Mesh/Istio/file1/","title":" install","section":"Istio","content":"aaa\n"},{"id":34,"href":"/devops/docs/Kubernetes/Kubernetes/8.-AMS/Keycloak/file1/","title":" install","section":"Keycloak","content":"aaa\n"},{"id":35,"href":"/devops/docs/Kubernetes/Kubernetes/9.-KMS/Vault/file1/","title":" install","section":"Vault","content":"aaa\n"},{"id":36,"href":"/devops/docs/Kubernetes/Kubernetes/99.-ETC/0/file1/","title":" install","section":"임시폴더","content":"aaa\n"},{"id":37,"href":"/devops/docs/Kubernetes/cert/ckad/","title":"1. CKAD","section":"Cert","content":" CKAD # CKAD # # "},{"id":38,"href":"/devops/docs/Docker/Docker/Docker01/","title":"1. Docker 기본 명령어","section":"Docker","content":" Docker # Docker 기본 명령어 # 컨테이너 생성 # $ docker run [OPTION] NAME[:TAG|@DIGEST] OPTION 특징 -d, \u0026ndash;detach 백그라운드에서 실행합니다. -i, \u0026ndash;interactive 상호적으로 실행하며, 표준 입력을 유지합니다. -t, \u0026ndash;tty 할당된 tty를 사용하여 실행합니다. \u0026ndash;name 컨테이너에 이름을 할당합니다. -e, \u0026ndash;env 컨테이너 내에서 사용할 환경 변수를 설정합니다. \u0026ndash;rm 컨테이너가 종료되면 자동으로 삭제합니다. \u0026ndash;network 컨테이너가 사용할 네트워크를 지정합니다. \u0026ndash;publish, -p 호스트와 컨테이너 간의 포트 매핑을 설정합니다. \u0026ndash;volume, -v 호스트와 컨테이너 간의 볼륨 매핑을 설정합니다. \u0026ndash;help 도움말을 표시합니다. Network 생성 # $ docker network create [OPTIONS] NETWORK 옵션 설명 -d 네트워크 드라이버 지정 (기본값: bridge) \u0026ndash;subnet 네트워크의 서브넷 설정 \u0026ndash;gateway 네트워크의 게이트웨이 IP 설정 \u0026ndash;ip-range 네트워크의 IP 범위 설정 \u0026ndash;attachable 기존 네트워크에 컨테이너 연결 허용 \u0026ndash;internal 외부에서의 네트워크 접근 제한 \u0026ndash;label 네트워크에 메타데이터 설정 \u0026ndash;opt 드라이버별 옵션 설정 \u0026ndash;ipv6 IPv6 지원 활성화 \u0026ndash;ipam-driver IP 주소 관리 드라이버 지정 \u0026ndash;ipam-opt IP 주소 관리 옵션 설정 \u0026ndash;attachable 기존 네트워크에 컨테이너 연결 허용 \u0026ndash;internal 외부에서의 네트워크 접근 제한 \u0026ndash;ingress 인그레스 네트워크 생성 \u0026ndash;ingress-opt 인그레스 옵션 설정 volume 생성 # $ docker volume create [OPTIONS] STORAGE 옵션 설명 \u0026ndash;storage-driver 사용할 스토리지 드라이버 설정 \u0026ndash;volume-driver 사용할 볼륨 드라이버 설정 \u0026ndash;add-registry 이미지를 가져올 도커 레지스트리 추가 \u0026ndash;disable-content-trust 이미지에 대한 콘텐츠 신뢰 기능 비활성화 \u0026ndash;icc 컨테이너 간 통신 허용 여부 설정 \u0026ndash;live-restore 도커 데몬 재시작 시 컨테이너 자동 복구 설정 \u0026ndash;log-driver 로깅 드라이버 설정 \u0026ndash;log-level 로깅 레벨 설정 \u0026ndash;storage-opt 스토리지 드라이버 옵션 설정 \u0026ndash;selinux-enabled SELinux 지원 여부 설정 \u0026ndash;storage-opt 스토리지 드라이버 옵션 설정 \u0026ndash;tls TLS 보안 연결 설정 \u0026ndash;tlscacert TLS CA 인증서 파일 경로 설정 \u0026ndash;tlscert TLS 인증서 파일 경로 설정 \u0026ndash;tlskey TLS 키 파일 경로 설정 \u0026ndash;tlsverify TLS 연결 검증 설정 컨테니어 시작 # $ docker start [OPTION] OPTION 특징 -d, \u0026ndash;detach 백그라운드에서 실행합니다. -i, \u0026ndash;interactive 상호적으로 실행하며, 표준 입력을 유지합니다. -t, \u0026ndash;tty 할당된 tty를 사용하여 실행합니다. \u0026ndash;name 컨테이너에 이름을 할당합니다. -e, \u0026ndash;env 컨테이너 내에서 사용할 환경 변수를 설정합니다. \u0026ndash;rm 컨테이너가 종료되면 자동으로 삭제합니다. \u0026ndash;network 컨테이너가 사용할 네트워크를 지정합니다. \u0026ndash;publish, -p 호스트와 컨테이너 간의 포트 매핑을 설정합니다. \u0026ndash;volume, -v 호스트와 컨테이너 간의 볼륨 매핑을 설정합니다. \u0026ndash;help 도움말을 표시합니다. 컨테이너 목록 확인 # $ docker ps [OPTION] OPTION 특징 -a, \u0026ndash;all 모든 컨테이너를 출력합니다. (종료된 컨테이너 포함) -q, \u0026ndash;quiet 컨테이너 ID만 출력합니다. \u0026ndash;no-trunc 출력을 자르지 않고 전체 정보를 표시합니다. -n, \u0026ndash;last n 최근 n개의 컨테이너만 표시합니다. -s, \u0026ndash;size 각 컨테이너의 크기 정보를 표시합니다. \u0026ndash;format 사용자 지정 포맷으로 출력합니다. \u0026ndash;filter 필터를 적용하여 특정 조건을 만족하는 컨테이너만 표시합니다. \u0026ndash;help 도움말을 표시합니다. 컨테이너 중지 # $ docker stop [OPTIONS] CONTAINER [CONTAINER...] OPTION 특징 -t, \u0026ndash;time 정지 프로세스에 대한 타임아웃(초)을 설정합니다. 기본값은 10초입니다. \u0026ndash;help 도움말을 표시합니다. 컨테이너 제거 # $ docker rm [OPTIONS] CONTAINER [CONTAINER...] OPTION 특징 -f, \u0026ndash;force 실행 중인 컨테이너를 강제로 중지하고 제거합니다. -v, \u0026ndash;volumes 컨테이너와 관련된 볼륨을 함께 제거합니다. \u0026ndash;link 컨테이너를 다른 컨테이너에 연결한 경우 해당 연결을 제거합니다. \u0026ndash;help 도움말을 표시합니다. 이미지 확인 # $ docker images [OPTIONS] [REPOSITORY[:TAG]] OPTION 특징 -a, \u0026ndash;all 모든 이미지를 표시합니다. \u0026ndash;digests 각 이미지의 다이제스트 정보를 표시합니다. \u0026ndash;format 사용자 지정 포맷으로 출력합니다. \u0026ndash;no-trunc 출력을 자르지 않고 전체 정보를 표시합니다. -q, \u0026ndash;quiet 이미지 ID만 출력합니다. \u0026ndash;help 도움말을 표시합니다. 이미지 다운로드 # $ docker pull [OPTIONS] NAME[:TAG|@DIGEST] OPTION 특징 -a, \u0026ndash;all-tags 이미지의 모든 태그를 가져옵니다. \u0026ndash;disable-content-trust 이미지의 내용 신뢰 기능을 비활성화합니다. \u0026ndash;help 도움말을 표시합니다. 이미지 삭제 # $ docker rmi [OPTIONS] IMAGE [IMAGE...] 컨테이너 접속 # $ docker exec [OPTIONS] CONTAINER COMMAND [ARG...] OPTION 특징 -d, \u0026ndash;detach 백그라운드에서 실행합니다. -i, \u0026ndash;interactive 상호적으로 실행하며, 표준 입력을 유지합니다. \u0026ndash;env 컨테이너 내에서 사용할 환경 변수를 설정합니다. \u0026ndash;user 명령을 실행할 사용자 또는 UID를 지정합니다. \u0026ndash;workdir 명령을 실행할 작업 디렉토리를 지정합니다. \u0026ndash;tty 할당된 tty를 사용하여 실행합니다. \u0026ndash;help 도움말을 표시합니다. 컨테이너 로그 확인 # $ docker logs [OPTIONS] CONTAINER OPTION 특징 \u0026ndash;details 로그 항목의 추가 세부 정보를 표시합니다. -f, \u0026ndash;follow 실시간으로 로그를 출력하며, 계속해서 갱신됩니다. \u0026ndash;since 특정 시간 이후의 로그만 표시합니다. \u0026ndash;tail 지정된 개수의 최근 로그 항목만 표시합니다. -t, \u0026ndash;timestamps 로그 항목에 타임스탬프를 표시합니다. \u0026ndash;until 특정 시간 이전의 로그만 표시합니다. \u0026ndash;help 도움말을 표시합니다. 이미지 생성 # $ docker commit [OPTION] [CONTAINER] [NAME] OPTION 특징 -a, \u0026ndash;author 커미트한 사용자를 지정합니다. -c, \u0026ndash;change 이미지 생성 시 Dockerfile 형식으로 변경을 추가합니다. -m, \u0026ndash;message 커밋에 대한 설명 또는 메시지를 추가합니다. -p, \u0026ndash;pause 커밋 시 컨테이너를 일시 중지합니다. "},{"id":39,"href":"/devops/docs/fastapi/fastapi/fastapi01/","title":"1. FastAPI 기초 다지기","section":"FastAPI","content":" FastAPI 기초다지기 # 개발환경은 여기를 참조해주세요. FastAPI 프로젝트 구조 # FastAPI 프로젝트를 만들고자 한다면 프로젝트 구조를 잘 만들어야 한다. 그런데 FastAPI에는 프로젝트의 구조를 정의하는 규칙이 없다. (?) 기본적으로는 아래의 구조를 가진다. ├── main.py ├── database.py ├── models.py ├── domain │ ├── answer │ ├── question │ └── user └── frontend 프로젝트를 설정하는 main # main.py는 FastAPI 애플리케이션의 진입점 역할을 합니다. 여기서 라우터를 등록, 미들웨어 설정, 데이터베이스 연결 등을 수행합니다. from fastapi import FastAPI from domain.question import question_router from domain.answer import answer_router from domain.user import user_router app = FastAPI() # 라우터 등록 app.include_router(question_router.router, prefix=\u0026#34;/questions\u0026#34;, tags=[\u0026#34;questions\u0026#34;]) app.include_router(answer_router.router, prefix=\u0026#34;/answers\u0026#34;, tags=[\u0026#34;answers\u0026#34;]) app.include_router(user_router.router, prefix=\u0026#34;/users\u0026#34;, tags=[\u0026#34;users\u0026#34;]) 주요 역할: FastAPI 객체 생성 라우터를 include_router로 등록 (선택) 데이터베이스 연결, 미들웨어 추가 데이터베이스를 설정하는 database # database.py는 데이터베이스와의 연결 및 ORM 설정을 담당합니다. FastAPI에서는 일반적으로 SQLAlchemy 또는 Tortoise ORM을 사용합니다. from sqlalchemy import create_engine from sqlalchemy.ext.declarative import declarative_base from sqlalchemy.orm import sessionmaker DATABASE_URL = \u0026#34;sqlite:///./test.db\u0026#34; engine = create_engine(DATABASE_URL, connect_args={\u0026#34;check_same_thread\u0026#34;: False}) SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine) Base = declarative_base() 주요 역할: 데이터베이스 URL 정의 엔진과 세션 구성 Base 객체 생성 (모델 클래스의 기반) 모델을 관리하는 models # models.py는 데이터베이스 테이블을 정의하는 파일입니다. SQLAlchemy를 사용하여 각 테이블의 스키마를 선언합니다. from sqlalchemy import Column, Integer, String, Text, ForeignKey from database import Base class Question(Base): __tablename__ = \u0026#34;questions\u0026#34; id = Column(Integer, primary_key=True, index=True) title = Column(String, index=True) content = Column(Text) user_id = Column(Integer, ForeignKey(\u0026#34;users.id\u0026#34;)) API 프로젝트 구조 비교 # 1. Domain-Driven Design (DDD) 기반 구조 # 구조 설명 # 도메인별로 비즈니스 로직, 데이터 처리, 라우팅, 스키마를 모듈화하여 관리합니다. 도메인이 복잡하거나 확장 가능한 시스템에서 적합합니다. 구조 예시 # project/ ├── domain/ │ ├── question/ │ │ ├── question_router.py │ │ ├── question_crud.py │ │ └── question_schema.py │ ├── answer/ │ └── user/ ├── main.py ├── database.py └── models.py 2. Service-Oriented Architecture (SOA) # 구조 설명 # 기능별로 서비스를 분리하여 관리합니다. 각 서비스는 독립적이며, 서로 최소한의 의존성을 가집니다. 대규모 서비스에서 적합하며, 마이크로서비스로 전환하기 쉽게 확장 가능합니다. 구조 예시 # project/ ├── services/ │ ├── user_service/ │ │ ├── router.py │ │ ├── service.py │ │ └── models.py │ ├── product_service/ │ │ ├── router.py │ │ ├── service.py │ │ └── models.py │ └── order_service/ │ ├── router.py │ ├── service.py │ └── models.py ├── main.py └── shared/ ├── database.py └── utils 3. Monolithic 구조 # 구조 설명 # 단일 코드베이스에서 모든 기능을 관리합니다. 소규모 프로젝트 또는 빠른 개발 주기를 요구하는 프로젝트에 적합합니다. 구조 예시 # project/ ├── app/ │ ├── routers/ │ │ ├── user_router.py │ │ ├── product_router.py │ │ └── order_router.py │ ├── models/ │ │ ├── user_model.py │ │ ├── product_model.py │ │ └── order_model.py │ └── services/ │ ├── user_service.py │ ├── product_service.py │ └── order_service.py ├── main.py └── database.py 구조 비교 # 구조 장점 단점 적합한 프로젝트 Domain-Driven Design (DDD) 모듈화로 유지보수 및 확장성 용이 초기 설계 및 도메인 정의에 시간 소요 복잡하고 도메인이 명확한 프로젝트 Service-Oriented Architecture (SOA) 독립성 높은 서비스로 마이크로서비스 전환 용이, 대규모 시스템 관리 적합 서비스 간 통신 설계 및 관리의 복잡성 대규모 및 확장 가능한 프로젝트 Monolithic 구조 간단한 구조로 빠른 개발 가능 규모가 커지면 유지보수 어려움 소규모 프로젝트, 프로토타이핑 등 "},{"id":40,"href":"/devops/docs/Kubernetes/Kubernetes/2.-Provisioning/Kubeadm/file1/","title":"Kubeadm install","section":"Kubeadm","content":" Kubeadm Install # kubeadm을 설치하기 위한 환경은 전 인덱스를 참고 부탁드립니다. # 쿠버네티스 패키지 저장소에서 GPG 키를 다운로드 $ curl -fsSL https://pkgs.k8s.io/core:/stable:/v1.30/deb/Release.key | gpg --dearmor -o /etc/apt/keyrings/kubernetes-apt-keyring.gpg # 쿠버네티스 저장소를 추가 $ echo \u0026#34;deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/v1.30/deb/ /\u0026#34; | tee /etc/apt/sources.list.d/kubernetes.list # 패키지 목록 업데이트 $ apt update # kubeadm kubelet kubectl Install $ apt -y install kubeadm kubelet kubectl 명령어 설명 주요 기능 및 역할 예시 kubeadm 쿠버네티스 클러스터를 초기화하고 관리하는 도구입니다. 클러스터 초기화, 클러스터 업그레이드, 인증서 관리, 토큰 관리 kubeadm initkubeadm join kubelet 각 노드에서 실행되는 주요 에이전트로, 컨테이너의 상태를 관리하는 역할을 수행합니다. 컨테이너 생성 및 관리, Pod 상태 확인 및 보고- 노드 상태 확인 /etc/systemd/system/kubelet.service로 실행 kubectl 쿠버네티스 클러스터를 관리하고 조작하기 위한 CLI(Command Line Interface) 도구입니다. 리소스 조회 및 관리, 애플리케이션 배포 및 업데이트, 로그 확인 kubectl get podskubectl apply -f deployment.yaml "},{"id":41,"href":"/devops/docs/Kubernetes/Kubernetes/2.-Provisioning/Kubeadm/file2/","title":"Kubeadm update","section":"Kubeadm","content":" Kubeadm update # 차후 작성예정 # "},{"id":42,"href":"/devops/docs/Docker/Docker/Docker02/","title":"2. Docker Registry","section":"Docker","content":" Docker # Docker Registry # Registry # Docker의 Registry는 이미지를 저장하는 장소이며 크게 Docker Hub, Private Registry로 나뉘어진다. Private Registry는 내부망, 로컬으로 나뉘어진다. Docker Hub 사용 # $ docker login ... $ docker tag Push_image [ID]/[Image_name] $ docker pull [ID]/[REPO] "},{"id":43,"href":"/devops/docs/Kubernetes/k8s/k8s03/","title":"3. Workload\u0026 Scheduling","section":"Kubernetes","content":" Kubernetes # Workload\u0026amp; Scheduling # # Pod # Pod란 컨테이너를 표현하는 kubernetstis의 최소 단위 파드는 특유한 \u0026ldquo;로컬호스트\u0026rdquo; 애플리케이션 모형 을 만들어. 상대적으로 밀접하게 결합되어진 상이한 애플리케이션 컨테이너들을 수용하는 역할을 수행\n파드 내 컨테이너는 IP 주소, 그리고 포트 스페이스를 공유 및 스케쥴링 되며 동일 노드 상의 컨텍스트를 공유하면서 동작\n즉, POD는 다양한 목적에 맞게 App을 배포하고 관리 하는 역할을 수행\nPOD의 지속적인 배포, 오케스트레이션 역할 수행이 필요할 시 Replicaset, Deployment 사용\n노드 단위 시스템으로 모든 노드에서 동일한 파드를 유지하도록 보장 통합 DaemonSet\n특정 DB와 같이 POD 생성 시에, 노드 및 특정 Volume이 필요 시 StatefulSet\n1회성 작업 Job, 주기적인 배치 작업 Cronjob\n쿠버네티스 리소스 # 각 리소스는 파드를 관리 최소 단위로 하여 상위 리소스가 자식 리소스를 관리한다. 예를 들어, Deployment는 ReplicaSet을 관리한고, 다시 ReplicaSet은 Pod를 관리하는 역할을 수행 ReplicaSet # Replicaset은 지정한 숫자만큼파드가 실행하도록 관리하는 가장 기본적인 컨트롤러\nReplicaSets는 Replication Controller의 발전된 형태이며 집합기반의 셀렉터를 지원\n집합기반(in, notin, exists) 같은 집합연산자를 지원하여 명시된 셀렉터 조건에 맞는 새로운 파드도 직접적으로 관리\nDeployment # 디플로이먼트(Deployment)는 파드와 레플리카셋(ReplicaSet)에 대한 선언적 업데이트를 제공\n쿠버네티스에서 상태가 없는(stateless) 앱을 배포할 때 사용하는 가장 기본적인 컨트롤러\nDeployment는 유지해야할 Pod 개수만이 아니라 배포 방법에 대한 세부적인 기능을 수행할 수 있다. 앱을 배포할 때에 롤링 업데이트를 하거나, 배포 도중 Delay를 주어 배포의 안정성을 확보할 수 있다. 그리고 앱 배포 이후에 오류 발견 시 이전 버전으로 롤백이 가능\nDaemonSet # DaemonSet은 특정 노드의 작업이 필요할 때 실행하는 Pod를 컨트롤\n클러스터 안에 새롭게 노드가 추가되면 DaemonSet은 자동으로 해당 노드에 파드를 실행\nDaemonSet의 대표적인 용도\n모든 노드에서 클러스터 스토리지 데몬 실행\n모든 노드에서 로그 수집 데몬 실행\n모든 노드에서 노드 모니터링 데몬 실행\nStatefulSet # 이전의 리소스들은 모두 상태가 없는(stateless) Pod를 관리하는 용도 였다. StatefulSet은 특정 볼륨을 사용해서 특정 데이터를 저장하는 경우에 필요\nElasticsearch는 마스터 노드와 데이터 노드로 나뉘어 지고, 데이터 노드는 실제로 색인된 데이터를 저장하는 노드이다. 데이터의 안전성을 위해 Primary Shard와 Replica Shard로 나위어 데이터 손실 방지를 위해 서로 다른 노드에 하나씩 분포되어 있다. 그렇기 때문에 elasticsearch의 데이터 노드는 순서와 갯수 상태가 보존되어야 한다. 이럴 경우 statefulSet으로 배포\nJob # CronJob은 Job을 반복 일정에 따라 만든다. 백업, 리포트 생성 등의 정기적 작업을 수행하기 위해 사용된다. 리눅스 cron 명령어에서 사용하는 형식을 사용하여 지정한 시간(자정 한번)에 한번만 잡을 실행하거나 지정한 시간동안(10분주기) 주기적으로 반복 CronJob # CronJob은 Job을 반복 일정에 따라 만든다. 백업, 리포트 생성 등의 정기적 작업을 수행하기 위해 사용된다. 리눅스 cron 명령어에서 사용하는 형식을 사용하여 지정한 시간(자정 한번)에 한번만 잡을 실행하거나 지정한 시간동안(10분주기) 주기적으로 반복 쿠버네티스 접근법 # 쿠버네티스는 명령형 (Imperative), 선언형 (Declarative) 접근 법이 사용되며, 명령형 접근법의 경우 CLI기반의 객체관리, 선언형의 경우 (Kubectl apply)를 통한 YAML 파일 기반 객체 관리하는 방법이라 할 수 있다. 명령형 (Imperative) 접근 # $ kubectl run nginx --image=nginx $ kubectl create deployment nginx --image=nginx $ kubectl expose deployment nginx --port=80 $ kubectl edit deployment nginx $ kubectl scale deployment nginx --replicas=5 $ kubectl set image deployment nginx nginx=nginx:1.18 $ kubectl \u0026lt;create|replace|delete\u0026gt; -f nginx.yaml 명령형 접근법은 원하는 상태를 만들기 위해 필요한 동작을 지시하는 방식\n즉 kubectl을 통해 구성 요소를 생성, 수정, 삭제 하는 명령어를 칭하며, 이는 요구되는 환경을 어떻게 만들 것인가에 초점을 두고 있다.\n이는 YAML 파일을 통해 구성 요소의 상태를 정의해 놓은 경우에도, create, replace에 해당하는 작업을 실행하면 이는 명령형 접근법에 속한다.\n이러한 명령형 접근법은 아래의 한게점을 가진다.\n명령어 만으로 수행 가능한 작업이 제한적 작업 내역의 추적이 어려움 현재 작업 환경의 설정사항을 직접 파악 단, 필요한 요소를 명령어 한 줄로 즉시 생성하는 것이 명확한 장점이며, 이를 통해 빠르고 간결한 작업 수행이 요구되는 환경에서 명령형 접근법은 유용할 수 있다.\n선언형 (Declarative) 접근 # apiVersion: v1 kind: Pod metadata: name: nginx labels: app: nginx spec: containers: - name: nginx-container image: nginx:1.20.2 $ kubectl apply -f nginx.yaml 선언형 접근법은 원하는 상태(오브젝트)를 YAML을 통해 선언하는 방식\n선언형 접근법은 요구되는 환경이 무엇인가에 초점을 둔다.\nkubectl apply 명령이 선언적 접근법에 해당하며, 이 명령은 적용하고자 하는 YAML 파일이 요구되는 문법에 맞게 작성되었느지를 검토 후, 해당되는 요소가 기준의 클러스터에 이미 배포되어 있는지를 체크하고, 신규생성이나 업데이트를 진행한다.\n즉, 관리자가 선언한 특정한 상태를 시스템이 스스로 파악하여 반영하는 접근법\n활성 객체 설정 (Live Object Configuration) # # 활성 객체 설정이란 쿠버네티스에서 클러스터 안에서 구동 중인 객체에 대한 정보를 담고 있는 일종의 데이터로 대게 etcd에 저장이 되어있다. 만약 선언형(YAML) 형식의 구성파일로 만든 객체라면, 해당 파일이 JSON 포맷으로 변환되어 어노테이션(metadata.annotation) 안에 kubectl.kubernetes.io/last-applied-configuration 항목으로 함께 삽입되며, References # https://peterica.tistory.com/480 "},{"id":44,"href":"/devops/docs/fastapi/fastapi/fastapi02/","title":"FastAPI Model","section":"FastAPI","content":" FastAPI Model # "},{"id":45,"href":"/devops/docs/Docker/Docker/Docker03/","title":"3. Dockerfile\u0026 Compose","section":"Docker","content":" Docker # Dockerfile # Dockerfile # Instruction 설명 ADD 로컬 또는 원격 파일 및 디렉토리 추가 ARG 빌드 시간 변수 사용 CMD 기본 명령어 지정 COPY 파일 및 디렉토리 복사 ENTRYPOINT 기본 실행 파일 지정 ENV 환경 변수 설정 EXPOSE 응용 프로그램이 수신 대기 중인 포트 설명 FROM 기본 이미지에서 새 빌드 단계 생성 HEALTHCHECK 컨테이너의 시작 시간에 대한 건강 상태 확인 LABEL 이미지에 메타데이터 추가 MAINTAINER 이미지 작성자 지정 ONBUILD 이미지가 빌드에 사용될 때 지시 RUN 빌드 명령어 실행 SHELL 이미지의 기본 셸 설정 STOPSIGNAL 컨테이너 종료에 대한 시스템 콜 신호 지정 USER 사용자 및 그룹 ID 설정 VOLUME 볼륨 마운트 생성 WORKDIR 작업 디렉토리 변경 Dockerfile 예시 # # 기본 이미지로부터 빌드 스테이지 생성 FROM ubuntu:latest # 로컬 또는 원격 파일 및 디렉토리 추가 ADD ./app /app # 빌드 시간 변수 사용 ARG version=1.0 # 기본 명령어 지정 CMD [\u0026#34;./app/start.sh\u0026#34;] # 파일 및 디렉토리 복사 COPY ./config /config # 기본 실행 파일 지정 ENTRYPOINT [\u0026#34;/app/entrypoint.sh\u0026#34;] # 환경 변수 설정 ENV APP_HOME=/app # 응용 프로그램이 수신 대기 중인 포트 설명 EXPOSE 8080 # 건강 상태 확인 HEALTHCHECK CMD curl --fail http://localhost:8080/ || exit 1 # 이미지에 메타데이터 추가 LABEL version=$version LABEL maintainer=\u0026#34;Your Name \u0026lt;your.email@example.com\u0026gt;\u0026#34; # 이미지 작성자 지정 MAINTAINER Your Name \u0026lt;your.email@example.com\u0026gt; # 이미지가 빌드에 사용될 때 지시 ONBUILD ADD . /app/src ONBUILD RUN /app/build.sh # 빌드 명령어 실행 RUN apt-get update \u0026amp;\u0026amp; apt-get install -y \\ package1 \\ package2 \\ \u0026amp;\u0026amp; rm -rf /var/lib/apt/lists/* # 이미지의 기본 셸 설정 SHELL [\u0026#34;/bin/bash\u0026#34;, \u0026#34;-c\u0026#34;] # 컨테이너 종료에 대한 시스템 콜 신호 지정 STOPSIGNAL SIGTERM # 사용자 및 그룹 ID 설정 USER 1000:1000 # 볼륨 마운트 생성 VOLUME /app/data # 작업 디렉토리 변경 WORKDIR /app Docker compose # version: \u0026#39;3\u0026#39; # 도커 컴포즈 버전 지정 services: # 서비스 정의 시작 web: # 서비스 이름 image: nginx:latest # 도커 이미지 지정 ports: - \u0026#34;8080:80\u0026#34; # 호스트와 컨테이너 포트 매핑 volumes: - ./web-content:/usr/share/nginx/html # 볼륨 매핑 networks: - frontend # 네트워크 지정 db: image: mysql:latest environment: MYSQL_ROOT_PASSWORD: example # 환경 변수 설정 volumes: - db-data:/var/lib/mysql networks: - backend networks: frontend: # 사용자 정의 네트워크 정의 backend: volumes: db-data: # 사용자 정의 볼륨 정의 옵션 설명 -f, \u0026ndash;file 컴포즈 설정 파일 지정 (기본값: docker-compose.yml) -p, \u0026ndash;project-name 프로젝트 이름 설정 (기본값: 디렉터리 이름) -v, \u0026ndash;verbose 자세한 출력 활성화 -q, \u0026ndash;quiet 출력을 최소화 \u0026ndash;log-level 로그 레벨 설정 (기본값: INFO) \u0026ndash;no-ansi ANSI 제어 코드를 사용하지 않음 \u0026ndash;version 버전 정보 출력 \u0026ndash;help 도움말 출력 -H, \u0026ndash;host 컴포즈 엔진에 연결할 Docker 호스트 설정 \u0026ndash;compatibility 호환성 모드 활성화 (v3 이하의 구성 파일 사용) \u0026ndash;env-file 환경 파일에서 변수 지정 \u0026ndash;project-directory 프로젝트 디렉터리 설정 (기본값: 현재 디렉터리) \u0026ndash;compatibility 호환성 모드 활성화 (v3 이하의 구성 파일 사용) \u0026ndash;project-directory 프로젝트 디렉터리 설정 (기본값: 현재 디렉터리) \u0026ndash;compatibility 호환성 모드 활성화 (v3 이하의 구성 파일 사용) \u0026ndash;project-directory 프로젝트 디렉터리 설정 (기본값: 현재 디렉터리) \u0026ndash;compatibility 호환성 모드 활성화 (v3 이하의 구성 파일 사용) \u0026ndash;project-directory 프로젝트 디렉터리 설정 (기본값: 현재 디렉터리) \u0026ndash;compatibility 호환성 모드 활성화 (v3 이하의 구성 파일 사용) \u0026ndash;project-directory 프로젝트 디렉터리 설정 (기본값: 현재 디렉터리) "},{"id":46,"href":"/devops/docs/Kubernetes/k8s/k8s04/","title":"4. Node Mangament","section":"Kubernetes","content":" Kubernetes # Node Mangament # # Taints # taint는 특정 POD들을 노드로부터 배제하는 역할을 수행 노드에 특정한 key-Vaule 값을 통해 테인즈를 걸고, 허용 조건에 맞춘 POD만을 해당 노드에 스케줄링 $ kubectl taint node \u0026lt;노드이름\u0026gt; \u0026lt;키\u0026gt;=\u0026lt;값\u0026gt;:\u0026lt;효과\u0026gt; NoSchedule: 해당 노드에는 일반적으로 스케줄링 진행 X / 이미 실행중인 노드 영향 X PreferNoSchedule: 일반적인 상황에서 스케줄링이 되지 않으나, 다른 노드가 없을 때는 스케줄링 진행 NoExecute: 노드에 있는 모든(실행중인 노드 포함)에 대해 영향을 미치며, 만약 해당 테인트에 맞지 않는 모든 노드를 삭제 Node Affinity # Node Affinity란 특정 노드에만 스케줄링 되도록 노드 레이블을 기반으로 제어하는 방법 POD 스펙에서 노드 어피니티 규칙의 지정이 가능 Concept Command Option Example Taints kubectl taint node --key, --value kubectl taint node node-1 key1=value1:NoSchedule --effect kubectl taint node node-1 key1=value1:NoSchedule --effect=NoExecute Node Affinity Node Affinity in Pod Spec nodeAffinity See Pod YAML example below kubectl label nodes kubectl label nodes node-1 key1=value1 kubectl get nodes --show-labels "},{"id":47,"href":"/devops/docs/Docker/Docker/Docker04/","title":"4. Docker 실습","section":"Docker","content":" Docker # # "},{"id":48,"href":"/devops/docs/Kubernetes/k8s/k8s05/","title":"5. ConfigMap\u0026 Secret","section":"Kubernetes","content":" Kubernetes # Configmap\u0026amp; Secret # # ConfigMap # 컨테이너 구성 정보를 한 대 모아 관리할 수 있도록 만들어진 객체 ConfigMap 일부 적용 apiVersion: v1 kind: Pod metadata: name: genid-stone spec: containers: - image: smlinux/genid:env env: - name: INTERVAL valueFrom: configMapKeyRef: name: ttabae-config key: INTERVAL name: fakeid volumeMounts: - name: html mountPath: /webdata - image: nginx:1.14 name: web-server volumeMounts: - name: html mountPath: /usr/share/nginx/html readOnly: true ports: - containerPort: 80 volumes: - name: html emptyDir: {} ConfigMap 전체적용 apiVersion: v1 kind: Pod metadata: name: genid-boy spec: containers: - image: smlinux/genid:env envFrom: - configMapRef: name: ttabae-config name: fakeid volumeMounts: - name: html mountPath: /webdata - image: nginx:1.14 name: web-server volumeMounts: - name: html mountPath: /usr/share/nginx/html readOnly: true ports: - containerPort: 80 volumes: - name: html emptyDir: {} ConfigMap Volume(Mount) 적용 apiVersion: v1 kind: Pod metadata: name: genid-volume spec: containers: - image: smlinux/genid:env env: - name: INTERVAL valueFrom: configMapKeyRef: name: ttabae-config key: INTERVAL name: fakeid-generator volumeMounts: - name: html mountPath: /webdata - image: nginx:1.14 name: web-server ports: - containerPort: 80 volumeMounts: - name: html mountPath: /usr/share/nginx/html readOnly: true - name: config mountPath: /etc/nginx/conf.d readOnly: true volumes: - name: html emptyDir: {} - name: config configMap: name: ttabae-config items: - key: nginx-config.conf path: nginx-config.conf Secret # ConfigMap이 컨테이너 구성 정보를 모아서 관리 한다면, Secet은 컨테이너가 사용하는 pw, auth token, ssh public, private key 등의 중요 및 민감한 정보를 base64 인코딩하여 관리하는 것이다.\nSecret 데이터 전달방법\nCommand-lint Argument(명령어): 명령어를 통해 직접 인수를 전달 Environment Variable(환경 변수): Secret 데이터를 환경 변수로 전달 Volumn Mount(볼륨 마운트): Secret 데이터를 파일 시스템에 볼륨 마운트 하여 컨테이너에 전달 Referance # https://nangman14.tistory.com/76 https://velog.io/@seungyeon/%EB%94%B0%EB%B0%B0%EC%BF%A0-%EC%A0%95%EB%A6%AC "},{"id":49,"href":"/devops/docs/Kubernetes/k8s/k8s06/","title":"6. Service","section":"Kubernetes","content":" Kubernetes Service # CNI (Container Network Interface) # Service Network # Service는 파드들을 통해 실행되고 있는 애플리케이션을 네트워크에 노출(expose)시키는 가상의 컴포넌트 쿠버네티스 내부의 다양한 객체들이 애플리케이션 및 다른 외부의 애플리케이션이나 사용자와 연결될 수 있도록 도와주는 브릿지 역할을 수행 이와 같은 Service가 별도로 필요한 이유는 파드들의 반영속적인(ephemeral) 특성을 가지고 있기 때문이며, 파드들은 일회성 자원으로 언제든 다른 노드로 옮겨지거나 삭제될 수 있으며, 이로인해 새로이 생성될 때마다 새로운 내부 IP를 받게 되므로, 이것만으로 클러스터 내/외부와 통신을 계속 유지하기는 어렵다. 즉, 위와 같은 이유로 파드가 외부와 통신할 수 있도록 클러스터 내부에서 고정적인 IP를 갖는 서비스(Service)를 이용하도록 하고 있다. 서비스는 또한 디플로이먼트나 스테이트풀셋처럼 같은 애플리케이션을 구동하도록 구성된 여러 파드들에게 단일한 네트워크 진입점을 부여하는 역할을 수행한다. 서비스를 정의하고 생성할 때에는 spec.ports 아래에 연결하고자 하는 항목 별로 각각 2개씩의 포트가 지정되어 있어야 하며, 추가로 서비스의 타입 또한 지정이 가능하다. Service.yaml # apiVersion: v1 kind: Service metadata: name: my-service spec: selector: app: my-app # Selector 값과 spec.selector.matchLabels.app이 일치해야 함 ports: - name: http protocol: TCP port: 80 # 서비스 쪽에서 열려있는 포트 targetPort: 8080 # 파드의 애플리케이션 포트 Service_Kind.yaml # apiVersion: v1 kind: Service metadata: name: my-service spec: selector: app: my-app # Selector 값과 spec.selector.matchLabels.app이 일치해야 함 type: { ClusterIP | NodePort | LoadBalancer ExternalName } # type 지정 ports: - name: http protocol: TCP port: 80 # 서비스 쪽에서 열려있는 포트 targetPort: 8080 # 파드의 애플리케이션 포트 위와 같은 서비스의 유형은 아래와 같이 5가지가 있다. ClusterIP NodePort LoadBalancer ExternalName Headless ClusterIP # 쿠버네티스가 지원하는 기본적인 형태의 서비스로 가상의 클러스터 전용 IP 로 들어온 클러스터 내부 트래픽을 해당 파드의 \u0026lt;파드IP:port\u0026gt;:로 넘겨주도록 동작하므로, 오직 클러스터 내부에서만 접근 가능하다. spec.selector에서 지정된 레이블로 여러 파드들이 존재할 경우, 서비스는 그 파드들을 외부 요청(request)을 전달할 엔드포인트(endpoints)로 선택하여 트래픽을 분배 ClusterIP 이용하여 한 노드 안에 여러 파드, 또는 여러 노드에 걸쳐 있는 여러 파드에 동일한 서비스를 적용 $ kubectl create service clusterip nginx --http=80:8080 # kubectl create service clusterip \u0026lt;spec.selector vaule\u0026gt; \u0026lt;protocol=port:targetport\u0026gt; $ kubectl expose pod nginx --port=8080 --name nginx-service --type=ClusterIP # kubectl expose \u0026lt;component type\u0026gt; \u0026lt;component name\u0026gt; \u0026lt;port=targetport\u0026gt; \u0026lt;service name\u0026gt; \u0026lt;--type=service type\u0026gt; apiVersion: v1 kind: Service metadata: name: my-service spec: selector: app: my-app # Selector 값과 spec.selector.matchLabels.app이 일치해야 함 type: ClusterIP # type 지정 ports: - name: http protocol: TCP port: 80 # 서비스 쪽에서 열려있는 포트 targetPort: 8080 # 파드의 애플리케이션 포트 NodePort # NodePort는 외부에서 노드 IP의 특정 포트(:)로 들어오는 요청을 감지하여, 해당 포트와 연결된 파드로 트래픽을 전달하는 유형의 서비스 클러스터 내부로 들어온 트래픽을 특정 파드로 연결하기 위한 ClusterIP가 자동으로 생성 NodePort의 경우에도 spec.selector에 해당하는 모든 파드들에 동일한 로드 밸런싱이 적용 $ kubectl create service nordport nginx --http=80:8080 # kubectl create service nordport \u0026lt;spec.selector vaule\u0026gt; \u0026lt;protocol=port:targetport\u0026gt; $ kubectl expose pod nginx --port=8080 --name nginx-service --type=nordport # kubectl expose \u0026lt;component type\u0026gt; \u0026lt;component name\u0026gt; \u0026lt;port=targetport\u0026gt; \u0026lt;service name\u0026gt; \u0026lt;--type=service type\u0026gt; apiVersion: v1 kind: Service metadata: name: my-service spec: selector: app: my-app # Selector 값과 spec.selector.matchLabels.app이 일치해야 함 type: NodePort # type 지정 ports: - name: http protocol: TCP port: 80 # 서비스 쪽에서 열려있는 포트 targetPort: 8080 # 파드의 애플리케이션 포트 nodePort: 30008 # 외부 사용자가 애플리케이션에 접근하기 위한 포트번호(선택) / 없을 시 30000에서 32767 사이 자동생성 LoadBalancer # 별도의 외부 로드 밸런서를 제공하는 클라우드(CSP / AWS, Azure, GCP 등) 환경을 고려하여, 로드 밸런서를 클러스터의 서비스로 프로비저닝할 수 있는 LoadBalancer 유형도 제공 서비스를 클라우드 제공자 측의 자체 로드 밸런서로 노출시키며, 이에 필요한 NodePort와 ClusterIP 역시 자동 생성 외부의 로드 밸런서를 통해 들어온 트래픽이 서비스의 설정값을 따라 해당되는 파드들로 연결되며, 트래픽이 어떻게 로드 밸런싱이 될지는 클라우드 제공자의 설정에 따름 $ kubectl create service loadbalancer nginx --http=80:8080 # kubectl create service loadbalancer \u0026lt;spec.selector vaule\u0026gt; \u0026lt;protocol=port:targetport\u0026gt; $ kubectl expose pod nginx --port=8080 --name nginx-service --type=loadbalancer # kubectl expose \u0026lt;component type\u0026gt; \u0026lt;component name\u0026gt; \u0026lt;port=targetport\u0026gt; \u0026lt;service name\u0026gt; \u0026lt;--type=service type\u0026gt; apiVersion: v1 kind: Service metadata: name: my-service spec: selector: app: my-app # Selector 값과 spec.selector.matchLabels.app이 일치해야 함 type: NodePort # type 지정 ports: - name: http protocol: TCP port: 80 # 서비스 쪽에서 열려있는 포트 targetPort: 8080 # 파드의 애플리케이션 포트 status: loadBalancer: ingress: - ip: 192.0.2.127 # CSP LoadBalenser의 IP ㅁ ExternalName # Service에 selector 대신 DNS name을 직접 명시하고자 할 때 사용 spec.externalName 항목에 필요한 DNS 주소를 기입하면, 클러스터의 DNS 서비스가 해당 주소에 대한 CNAME 레코드를 반환하게 된다. $ kubectl create service externalname --external-name=example.com # kubectl create service clusterip \u0026lt;--external-name=spec.externalName vaule\u0026gt; apiVersion: v1 kind: my-service metadata: name: my-app spec: type: ExternalName externalName: my.database.example.com Headless # .spec.clusterIP필드 값을 None으로 설정하여 클러스터 IP가 없는 서비스의 생성이 가능 로드밸런싱이 필요 없거나 단일 서비스 IP가 필요 없을 때 사용 apiVersion: v1 kind: Service metadata: name: my-service spec: selector: app: my-app # Selector 값과 spec.selector.matchLabels.app이 일치해야 함 clusterIP: None # clusterIP를 None으로 설정 ports: # 헤드리스 서비스의 경우 클러스터 내에서 DNS 조회를 통해 특정 파드의 IP를 얻을 때 해당 파드에 접근할 포트를 지정하기 위해 ports 필드를 사용 - name: http protocol: TCP port: 80 targetPort: 8080 References # https://prod.velog.io/@pinion7/Kubernetes-%EB%A6%AC%EC%86%8C%EC%8A%A4-Service%EC%97%90-%EB%8C%80%ED%95%B4-%EC%9D%B4%ED%95%B4%ED%95%98%EA%B3%A0-%EC%8B%A4%EC%8A%B5%ED%95%B4%EB%B3%B4%EA%B8%B0 "},{"id":50,"href":"/devops/docs/CICD/CICD/table-of-contents/","title":"Table of Contents","section":"CI/CD 배포 입문","content":" Ubi loqui # Mentem genus facietque salire tempus bracchia # Lorem markdownum partu paterno Achillem. Habent amne generosi aderant ad pellem nec erat sustinet merces columque haec et, dixit minus nutrit accipiam subibis subdidit. Temeraria servatum agros qui sed fulva facta. Primum ultima, dedit, suo quisque linguae medentes fixo: tum petis.\nRapit vocant si hunc siste adspice # Ora precari Patraeque Neptunia, dixit Danae Cithaeron armaque maxima in nati Coniugis templis fluidove. Effugit usus nec ingreditur agmen ac manus conlato. Nullis vagis nequiquam vultibus aliquos altera suum venis teneas fretum. Armos remotis hoc sine ferrea iuncta quam!\nLocus fuit caecis # Nefas discordemque domino montes numen tum humili nexilibusque exit, Iove. Quae miror esse, scelerisque Melaneus viribus. Miseri laurus. Hoc est proposita me ante aliquid, aura inponere candidioribus quidque accendit bella, sumpta. Intravit quam erat figentem hunc, motus de fontes parvo tempestate.\niscsi_virus = pitch(json_in_on(eupViral), northbridge_services_troubleshooting, personal( firmware_rw.trash_rw_crm.device(interactive_gopher_personal, software, -1), megabit, ergonomicsSoftware(cmyk_usb_panel, mips_whitelist_duplex, cpa))); if (5) { managementNetwork += dma - boolean; kilohertz_token = 2; honeypot_affiliate_ergonomics = fiber; } mouseNorthbridge = byte(nybble_xmp_modem.horse_subnet( analogThroughputService * graphicPoint, drop(daw_bit, dnsIntranet), gateway_ospf), repository.domain_key.mouse(serverData(fileNetwork, trim_duplex_file), cellTapeDirect, token_tooltip_mashup( ripcordingMashup))); module_it = honeypot_driver(client_cold_dvr(593902, ripping_frequency) + coreLog.joystick(componentUdpLink), windows_expansion_touchscreen); bashGigabit.external.reality(2, server_hardware_codec.flops.ebookSampling( ciscNavigationBacklink, table + cleanDriver), indexProtocolIsp); Placabilis coactis nega ingemuit ignoscat nimia non # Frontis turba. Oculi gravis est Delphice; inque praedaque sanguine manu non.\nif (ad_api) { zif += usb.tiffAvatarRate(subnet, digital_rt) + exploitDrive; gigaflops(2 - bluetooth, edi_asp_memory.gopher(queryCursor, laptop), panel_point_firmware); spyware_bash.statePopApplet = express_netbios_digital( insertion_troubleshooting.brouter(recordFolderUs), 65); } recursionCoreRay = -5; if (hub == non) { portBoxVirus = soundWeb(recursive_card(rwTechnologyLeopard), font_radcab, guidCmsScalable + reciprocalMatrixPim); left.bug = screenshot; } else { tooltipOpacity = raw_process_permalink(webcamFontUser, -1); executable_router += tape; } if (tft) { bandwidthWeb *= social_page; } else { regular += 611883; thumbnail /= system_lag_keyboard; } Caesorum illa tu sentit micat vestes papyriferi # Inde aderam facti; Theseus vis de tauri illa peream. Oculos uberaque non regisque vobis cursuque, opus venit quam vulnera. Et maiora necemque, lege modo; gestanda nitidi, vero? Dum ne pectoraque testantur.\nVenasque repulsa Samos qui, exspectatum eram animosque hinc, aut manes, Assyrii. Cupiens auctoribus pariter rubet, profana magni super nocens. Vos ius sibilat inpar turba visae iusto! Sedes ante dum superest extrema.\n"},{"id":51,"href":"/devops/docs/Git/Git/git99/","title":"99. Git 명령어 요약정리","section":"Git","content":" GIT 명령어 요약정리 # Git 명령어는 git +명령어 이름 형태로 구성하며, 필요에 따라 -키 또는 \u0026ndash;옵션을 추가가 가능\nGit 작업영역: Working Directory, Staging Area, Repository\nGit 파일의상태: Modified,Staged,Commited\n브런치(branch): 독립적인 이력 관리 영역 / git init시 master 브런치가 생성됨\nmaster: 해당브랜치의 끝(최신커밋)을 참조하는 개체 (Refs)\nHEAD: 포인터 역할을 수행하며, 커밋을 직접 참조 할 수 있을 뿐만 아니라 Refs(다른참조 개체)도 참조가능\ngit init # 저장소(repository) 생성 git config user.name \u0026#34;［작성자 이름］\u0026#34; # 사용자 이름 설정 --global 추가시 전역설정 git config user.email \u0026#34;［이메일 계정]\u0026#34; # 사용자 이메일 설정 --global 추가시 전역설정 git config --list # 저장소 설정 전체 출력 git config ［설정 항목] # 해당 항목 설정 값 출력(예 : git config user.name) git help # 도움말 git status # 저장소의 상태 정보 출력 git add ［파일 이름 \u0026amp; 디렉터리] # 해당 파일을 Staging Area에 update git add . # Working Directory 안에 추가，수정된 모든 파일을 Staging Area에 을리기 git commit # 이력 저장，커밋 git commit -m \u0026#34;［메시지］\u0026#34; # vim을 사용하지 않고 인라인으로 메시지를 추가하여 커밋 git commit -am \u0026#34;［메시지］\u0026#34; # git add와 git commit을 한꺼번에 명령 (Untracked 파일은 제외) git status # 저장소 파일의 상태 출력 git status -s # 저장소 파일 상태를 간략하게 표시 git log # 저장소의 커밋 히스토리（로그，이력）를 출력 git log --pretty=oneline # 로그 출력 시 커밋을 한 줄로 간략하게 표시 （--pretty 옵션 사용） git log --oneline # 로그 출력 시 커밋을 한 줄로 표시 （해시도 앞자리 7글자만 출력） git log --graph # 로그를 그래프 형태로 출력 git show # 가장 최근 커밋의 상세 정보 출력 git show ［커밋 해시］ # 해당 커밋의 상세 정보 출력 git show HEAD # HEAD가 참조하는 커밋의 상세 정보 출력 git show HEAD〜n # HEAD를 기준으로 n단계 이전의 커밋 정보 출력 - git diff는 각 파일의 변경사항을 비교하는 명령어 git diff # 최근 커밋과 변경 사항이 발생한(Unstaged) 파일들의 내용 비교 git diff --staged # 현재 스테이지된 변경사항을 출력 git diff [commit hash1] [commit hash2] # commit1과 commit2를 비교 git reset # Staging Area 의파일전체 를언스테이징 상태로 되돌리기 git reset [파일이름(또는경로)] # 해당파일(또는경로)을 언스테이징 상태로 되돌리기 git checkout은 HEAD의 참조를 변경하는 명령 최신 커밋을 참조할 때 HEAD는 master를 간, 직접적으로 참조하고 있으며, HEAD는 master에서 떨어진 Detacghed 상태 또는 DetachedHEAD가 됨 gitcheckout [커밋해시] # 해당커밋으로파일상태변경 git checkout-: # HEAD가이전에참조했던커밋으로상태변경 git checkout master # HEAD가master를참조 git checkout HEAD~n # HEAD를기준으로 n단계이전커밋으로상태변경 git reset은 커밋을 취소하는 명령어이지만, 해당 커밋이 삭제되는 것이 아닌 브런치의 포인터를 바꾸는 개념 Working Dirtory Stating Area Repository \u0026ndash;hard 변경 변경 변경 \u0026ndash;mixed (default) 유지 변경 변경 \u0026ndash;soft 유지 유지 변경 git reset [커밋주소] git remote # 현재 브랜치에 추가 된 원격 저장소 리스트 출력 git remote -v (--verbose) # 현재 브랜치에 추가 된 원격 저장소 리스트 출력(주소포함) git remote add [원격저장소이름] [원격저장소주소] # 해당이름으로 원격저장소의 주소등록 git remote rm [원격저장소이름] # 해당 원격 저장소를 삭제 git push -u (--set-upstream-to) [원격 저장소 이름] [로컬 저장소의 브런치] # 로컬저장소의 브랜치가 원격저장소를 추적하도록 설정하고, 파일들을 원격저장소로 저장 git push [원격 저장소 이름] [로컬 저장소 브런치] # 로컬 브런치의 변경사항을 원격 저장소 (레포지터리)에 Push (업로드) # upstream (-u) 설정 후, 원격 저장소, 로컬 저장소 브런치 생략이 가능 git pull [원격 저장소 이름] [로컬 저장소 브런치] # 원격저장소의 정보를 현재 로컬브랜치에 병합 (fetch + merge) # upstream (-u) 설정 후, 원격 저장소, 로컬 저장소 브런치 생략이 가능 git tag # 로컬저장소의 모든 태그를 조회 git tag [태그이름] # 현재 커밋에 태그를 생성(Lightweight 태그) git tag [태그이름] [커밋해시] # 해당 커밋에 태그를 생성 (Lightweight 태그) git tag -a [태그이름] -m \u0026#34;[메시지]\u0026#34; [커밋해시] # 메시지를 추가하여 태그 생성 (Annotated tag) git tag -am [태그이름] \u0026#34;[메시지]\u0026#34; # 현재 커밋에 메시지를 추가하여 태그 생성 (Annotated tag) git show [태그이름] # 해당 태그가 부착된 커밋의 상세정보 확인 git push --tags # 생성된 전체태그를 원격 저장소에 푸시(=git push origin -tags) git push [태그이름] # 해당태그를 원격저장소에 푸시 (= git push origin \u0026#34;[태그이름]\u0026#34;) git tag -d [태그이름] # 해당 태그 삭제 git push -d [태그이름] # 원격저장소에서 해당 태그 삭제 git reset은 master의 참조를 특정 커밋으로 되돌리는 명령 git revert는 특정 커밋을 취소하는 내용의 새로운 커밋을 만드는 명령 git revert [커밋 해시] # 해당 커밋으로 되돌리기 git revert -n (--no-edit) [커밋 해시] # 커밋 메시지 수정 없이 기본메시지로 되돌리기 git revert n [커밋 해시] # 커밋 하지 않고 스테이징 상태로 되돌리기 git revert [커밋 해시1]..[커밋 해시2] # 해당 구간 만큼 커밋 되돌리기, 커밋 해시1은 되돌려지지 않음 git branch # 현재 브랜치 표시 git branch --list # 브랜치 목록 표시 git branch [브랜치이름] # 해당 브랜치이름으로 브랜치 생성 git checkout [브랜치이름] git switch [브랜치이름] # 해당브랜치로전환 git checkout -b [브랜치이름] git switch -c [브랜치이름] # 브랜치 생성과 동시에 전환 git branch -m [브랜치이름] [새로운 브랜치이름] # 브랜치 이름변경 git branch -d [브랜치이름] # 해당 로컬 브랜치 삭제 git push -d [repo] [브랜치이름] # 레포지터리 브런치 삭제 git merge [브랜치이름] # 해당 이름의 브랜치를 병합 git merge --ff [브랜치이름] # fast-for ward 관계에 있으면 커밋을 생성하지않고 현재 브랜치의 참조만 변경(default) git merge --no-ff [브랜치이름] # fast-forward 관계에 있어도 머지 커밋 생성 git merge --squash [브랜치이름] # 병합할 브랜치의 내용을 하나의 커밋에 합침 병합할 브랜치 정보는 생략 git rebase [브랜치이름] # 현재 브랜치가 해당 브랜치(브랜치이름)부터 분기하도록 재배치 git rebase --continue # 충돌 수정 후 재배치 진행 git rebase --abort # rebase 취소 "},{"id":52,"href":"/devops/docs/Kubernetes/k8s/k8s99/","title":"Kubernetes_Object_Table","section":"Kubernetes","content":" Kubernetes Object # 애플리케이션의 실행 # Pod # apiVersion: v1 kind: Pod metadata: name: \u0026lt;pod-name\u0026gt; labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; spec: containers: - name: \u0026lt;container-name\u0026gt; image: \u0026lt;container-image\u0026gt; ports: - containerPort: \u0026lt;port\u0026gt; 필드 설명 apiVersion 쿠버네티스 API의 버전을 지정 kind 리소스의 유형을 지정 (Pod) metadata 리소스의 메타데이터를 포함하는 블록 - name Pod의 이름을 지정 - labels Pod에 부여되는 레이블을 정의 spec Pod의 구성을 정의하는 블록 - containers Pod에서 실행될 컨테이너 목록 - - name 컨테이너의 이름을 지정 - - image 사용할 컨테이너 이미지를 지정 - - ports 컨테이너가 오픈할 포트를 정의 ReplicaSet # apiVersion: apps/v1 kind: ReplicaSet metadata: name: \u0026lt;replicaset-name\u0026gt; labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; spec: replicas: \u0026lt;number-of-replicas\u0026gt; selector: matchLabels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; template: metadata: labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; spec: containers: - name: \u0026lt;container-name\u0026gt; image: \u0026lt;container-image\u0026gt; ports: - containerPort: \u0026lt;port\u0026gt; 필드 설명 apiVersion 쿠버네티스 API의 버전을 지정 kind 리소스의 유형을 지정 (ReplicaSet) metadata 리소스의 메타데이터를 포함하는 블록 - name ReplicaSet의 이름을 지정 - labels ReplicaSet에 부여되는 레이블을 정의 spec ReplicaSet의 구성을 정의하는 블록 - replicas 복제할 Pod의 수를 지정 - selector Pod를 선택하기 위한 레이블 선택기를 지정 - - matchLabels Pod를 선택할 때 사용할 레이블을 지정 - - matchExpressions 레이블 선택을 위한 표현식을 지정 Deployment # apiVersion: apps/v1 kind: Deployment metadata: name: \u0026lt;deployment-name\u0026gt; labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; spec: replicas: \u0026lt;number-of-replicas\u0026gt; selector: matchLabels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; template: metadata: labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; spec: containers: - name: \u0026lt;container-name\u0026gt; image: \u0026lt;container-image\u0026gt; ports: - containerPort: \u0026lt;port\u0026gt; 필드 설명 apiVersion 쿠버네티스 API의 버전을 지정 kind 리소스의 유형을 지정 (Deployment) metadata 리소스의 메타데이터를 포함하는 블록 - name Deployment의 이름을 지정 - labels Deployment에 부여되는 레이블을 정의 spec Deployment의 구성을 정의하는 블록 - replicas 복제할 Pod의 수를 지정 - selector Pod를 선택하기 위한 레이블 선택기를 지정 - - matchLabels Pod를 선택할 때 사용할 레이블을 지정 - - matchExpressions 레이블 선택을 위한 표현식을 지정 - template 새로운 Pod를 생성하기 위한 템플릿을 지정 - - metadata 템플릿 Pod의 메타데이터를 정의 - - spec 템플릿 Pod의 구성을 정의 네트워크의 관리 # Service # apiVersion: v1 kind: Service metadata: name: \u0026lt;service-name\u0026gt; labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; spec: selector: \u0026lt;selector-key\u0026gt;: \u0026lt;selector-value\u0026gt; ports: - protocol: TCP port: \u0026lt;service-port\u0026gt; targetPort: \u0026lt;target-port\u0026gt; 필드 설명 apiVersion 쿠버네티스 API의 버전을 지정 kind 리소스의 유형을 지정 (Service) metadata 리소스의 메타데이터를 포함하는 블록 - name Service의 이름을 지정 - labels Service에 부여되는 레이블을 정의 spec Service의 구성을 정의하는 블록 - selector 해당 서비스에 연결될 Pod를 선택하기 위한 레이블 선택기를 지정 - ports 서비스가 오픈할 포트를 정의 Ingress # apiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: \u0026lt;ingress-name\u0026gt; labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; spec: rules: - host: \u0026lt;host-name\u0026gt; http: paths: - path: / pathType: Prefix backend: service: name: \u0026lt;backend-service-name\u0026gt; port: number: \u0026lt;backend-service-port\u0026gt; 필드 설명 apiVersion 쿠버네티스 API의 버전을 지정 kind 리소스의 유형을 지정 (Ingress) metadata 리소스의 메타데이터를 포함하는 블록 - name Ingress의 이름을 지정 - labels Ingress에 부여되는 레이블을 정의 spec Ingress의 구성을 정의하는 블록 - rules Ingress 규칙을 정의 - - host 호스트 이름을 지정 - - http HTTP 경로 및 백엔드 서비스를 지정 애플리케이션 설정 정보의 관리 # nampspace # apiVersion: v1 kind: Namespace metadata: name: \u0026lt;namespace-name\u0026gt; 필드 설명 apiVersion 쿠버네티스 API의 버전을 지정 kind 리소스의 유형을 지정 (Namespace) metadata 리소스의 메타데이터를 포함하는 블록 - name Namespace의 이름을 지정 - labels Namespace에 부여되는 레이블을 정의 ConfigMap # apiVersion: v1 kind: ConfigMap metadata: name: \u0026lt;configmap-name\u0026gt; labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; data: key1: value1 key2: value2 필드 설명 apiVersion 쿠버네티스 API의 버전을 지정 kind 리소스의 유형을 지정 (ConfigMap) metadata 리소스의 메타데이터를 포함하는 블록 - name ConfigMap의 이름을 지정 - labels ConfigMap에 부여되는 레이블을 정의 data 설정 데이터를 키-값 쌍으로 정의 Secrets # apiVersion: v1 kind: Secret metadata: name: \u0026lt;secret-name\u0026gt; labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; data: \u0026lt;key\u0026gt;: \u0026lt;base64-encoded-value\u0026gt; type: Opaque 필드 설명 apiVersion 쿠버네티스 API의 버전을 지정 kind 리소스의 유형을 지정 (Secret) metadata 리소스의 메타데이터를 포함하는 블록 - name Secret의 이름을 지정 - labels Secret에 부여되는 레이블을 정의 data 암호화된 데이터를 키-값 쌍으로 정의 type Secret 유형을 나타내며, 주로 Opaque 등이 사용됨 배치 잡의 관리 # Job # apiVersion: batch/v1 kind: Job metadata: name: \u0026lt;job-name\u0026gt; labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; spec: template: metadata: labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; spec: containers: - name: \u0026lt;container-name\u0026gt; image: \u0026lt;container-image\u0026gt; ports: - containerPort: \u0026lt;port\u0026gt; 필드 설명 apiVersion 쿠버네티스 API의 버전을 지정 kind 리소스의 유형을 지정 (Job) metadata 리소스의 메타데이터를 포함하는 블록 - name Job의 이름을 지정 - labels Job에 부여되는 레이블을 정의 spec Job의 구성을 정의하는 블록 - template 작업을 수행할 Pod의 템플릿을 지정 - - metadata 템플릿 Pod의 메타데이터를 정의 - - spec 템플릿 Pod의 구성을 정의 CronJob # apiVersion: batch/v1beta1 kind: CronJob metadata: name: \u0026lt;cronjob-name\u0026gt; labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; spec: schedule: \u0026lt;cron-schedule\u0026gt; jobTemplate: metadata: labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; spec: template: metadata: labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; spec: containers: - name: \u0026lt;container-name\u0026gt; image: \u0026lt;container-image\u0026gt; ports: - containerPort: \u0026lt;port\u0026gt; 필드 설명 apiVersion 쿠버네티스 API의 버전을 지정 kind 리소스의 유형을 지정 (CronJob) metadata 리소스의 메타데이터를 포함하는 블록 - name CronJob의 이름을 지정 - labels CronJob에 부여되는 레이블을 정의 spec CronJob의 구성을 정의하는 블록 - schedule 크론잡의 실행 스케줄을 지정 - jobTemplate 크론잡이 생성하는 Job의 템플릿을 지정 - - metadata 템플릿 Job의 메타데이터를 정의 - - spec 템플릿 Job의 구성을 정의 볼륨 # StorageClass # apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: \u0026lt;storageclass-name\u0026gt; labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; spec: provisioner: kubernetes.io/aws-ebs parameters: type: gp2 reclaimPolicy: Retain 필드 설명 apiVersion 쿠버네티스 API의 버전을 지정 kind 리소스의 유형을 지정 (StorageClass) metadata 리소스의 메타데이터를 포함하는 블록 - name StorageClass의 이름을 지정 - labels StorageClass에 부여되는 레이블을 정의 spec StorageClass의 구성을 정의하는 블록 - provisioner 스토리지 프로비저너를 지정 - parameters 스토리지 클래스의 매개변수를 지정 - - type 스토리지의 유형을 지정 - reclaimPolicy PV 재사용 정책을 지정 (Retain, Delete 중 선택) PersistentVolume # apiVersion: v1 kind: PersistentVolume metadata: name: \u0026lt;pv-name\u0026gt; labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; spec: capacity: storage: \u0026lt;storage-capacity\u0026gt; accessModes: - \u0026lt;access-mode\u0026gt; storageClassName: \u0026lt;storage-class-name\u0026gt; hostPath: path: \u0026lt;host-path\u0026gt; 필드 설명 apiVersion 쿠버네티스 API의 버전을 지정 kind 리소스의 유형을 지정 (PersistentVolume) metadata 리소스의 메타데이터를 포함하는 블록 - name PV의 이름을 지정 - labels PV에 부여되는 레이블을 정의 spec PV의 구성을 정의하는 블록 - capacity PV의 용량을 지정 - accessModes PV에 접근할 수 있는 모드를 지정 - storageClassName PV에 할당된 스토리지 클래스의 이름을 지정 - hostPath 호스트 머신의 파일 시스템 경로를 지정 (hostPath 볼륨 유형의 경우) PersistentVolumeClaim # apiVersion: v1 kind: PersistentVolumeClaim metadata: name: \u0026lt;pvc-name\u0026gt; labels: \u0026lt;key\u0026gt;: \u0026lt;value\u0026gt; spec: accessModes: - \u0026lt;access-mode\u0026gt; resources: requests: storage: \u0026lt;storage-capacity\u0026gt; 필드 설명 apiVersion 쿠버네티스 API의 버전을 지정 kind 리소스의 유형을 지정 (PersistentVolumeClaim) metadata 리소스의 메타데이터를 포함하는 블록 - name PVC의 이름을 지정 - labels PVC에 부여되는 레이블을 정의 spec PVC의 구성을 정의하는 블록 - accessModes PVC에 요청되는 접근 모드를 지정 - resources PVC에 요청되는 용량을 지정 "},{"id":53,"href":"/devops/docs/fastapi/fastapi/fastapi99/","title":"Fastapi99","section":"FastAPI","content":" # "},{"id":54,"href":"/devops/docs/Kubernetes/Kubernetes/10.-CIMS/Harbor/file0/","title":" Concept","section":"Harbor","content":"aaa\n"},{"id":55,"href":"/devops/docs/Kubernetes/Kubernetes/11.-ML/Elasticsearch/file0/","title":" Concept","section":"Elasticsearch","content":"aaa\n"},{"id":56,"href":"/devops/docs/Kubernetes/Kubernetes/11.-ML/Fluentd/file0/","title":" Concept","section":"Fluentd","content":"aaa\n"},{"id":57,"href":"/devops/docs/Kubernetes/Kubernetes/11.-ML/Kibana/file0/","title":" Concept","section":"Kibana","content":"aaa\n"},{"id":58,"href":"/devops/docs/Kubernetes/Kubernetes/12.CI/CD/ArgoCD/file0/","title":" Concept","section":"ArgoCD","content":"aaa\n"},{"id":59,"href":"/devops/docs/Kubernetes/Kubernetes/13.-MCM/Karmada/file0/","title":" Concept","section":"Karmada","content":"aaa\n"},{"id":60,"href":"/devops/docs/Kubernetes/Kubernetes/3.-CNI/Calico/file0/","title":" Concept","section":"Calico","content":"aaa\n"},{"id":61,"href":"/devops/docs/Kubernetes/Kubernetes/3.-CNI/MetalLB/file0/","title":" Concept","section":"MetaLB","content":"aaa\n"},{"id":62,"href":"/devops/docs/Kubernetes/Kubernetes/3.-CNI/Nginx/file0/","title":" Concept","section":"Nginx","content":"aaa\n"},{"id":63,"href":"/devops/docs/Kubernetes/Kubernetes/4.-Tools/Helm/file0/","title":" Concept","section":"Helm","content":"aaa\n"},{"id":64,"href":"/devops/docs/Kubernetes/Kubernetes/4.-Tools/OpenLens/file0/","title":" Concept","section":"OpenLens","content":"aaa\n"},{"id":65,"href":"/devops/docs/Kubernetes/Kubernetes/5.-CNS/Rook/file0/","title":" Concept","section":"Rook Ceph","content":"aaa\n"},{"id":66,"href":"/devops/docs/Kubernetes/Kubernetes/6.-BR/Velero/file0/","title":" Concept","section":"Velero","content":"aaa\n"},{"id":67,"href":"/devops/docs/Kubernetes/Kubernetes/7.-Mesh/Istio/file0/","title":" Concept","section":"Istio","content":"aaa\n"},{"id":68,"href":"/devops/docs/Kubernetes/Kubernetes/8.-AMS/Keycloak/file0/","title":" Concept","section":"Keycloak","content":"aaa\n"},{"id":69,"href":"/devops/docs/Kubernetes/Kubernetes/9.-KMS/Vault/file0/","title":" Concept","section":"Vault","content":"aaa\n"},{"id":70,"href":"/devops/docs/Kubernetes/Kubernetes/99.-ETC/0/file0/","title":" Concept","section":"임시폴더","content":"aaa\n"}]